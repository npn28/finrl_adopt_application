{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f0f424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/usr/local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution - (/usr/local/lib/python3.9/site-packages)\u001b[0m\n",
      "Collecting alpaca_trade_api\n",
      "  Downloading alpaca_trade_api-1.2.2-py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api) (1.26.5)\n",
      "Requirement already satisfied: websocket-client<2,>=0.56.0 in /Users/evienguyen/venv/lib/python3.9/site-packages (from alpaca_trade_api) (1.1.0)\n",
      "Collecting msgpack==1.0.2\n",
      "  Downloading msgpack-1.0.2-cp39-cp39-macosx_10_14_x86_64.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api) (1.2.4)\n",
      "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api) (2.25.1)\n",
      "Collecting websockets<10,>=8.0\n",
      "  Downloading websockets-9.1-cp39-cp39-macosx_10_9_x86_64.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 6.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api) (1.20.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from requests<3,>2->alpaca_trade_api) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>2->alpaca_trade_api) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3,>2->alpaca_trade_api) (2021.5.30)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/site-packages (from pandas->alpaca_trade_api) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/site-packages (from pandas->alpaca_trade_api) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->alpaca_trade_api) (1.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/usr/local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution - (/usr/local/lib/python3.9/site-packages)\u001b[0m\n",
      "Installing collected packages: websockets, msgpack, alpaca-trade-api\n",
      "Successfully installed alpaca-trade-api-1.2.2 msgpack-1.0.2 websockets-9.1\n"
     ]
    }
   ],
   "source": [
    "            # !pip install alpaca_trade_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb039e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpaca_trade_api as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tradeapi.REST()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4497978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_441.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_504.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_567.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_630.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_693.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_756.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_819.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_882.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_945.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_1008.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_1071.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_1134.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_1197.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_1260.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_126.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_189.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_252.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_315.csv\n",
      "/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble_378.csv\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# files = glob.glob('/Users/evienguyen/Documents/FinRL/FinRL/finrl/results/actions_trade_ensemble*')\n",
    "# files.sort(key=os.path.getmtime)\n",
    "\n",
    "# action_trade =  sorted(files,key=os.path.getmtime)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2293badc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-06-19'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "validation_window = 63\n",
    "rebalance_window = 63\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "start = datetime.today() - timedelta(days=validation_window + rebalance_window)\n",
    "start = start.strftime('%Y-%m-%d')\n",
    "\n",
    "df = YahooDownloader(start_date = start,\n",
    "                     end_date = today,\n",
    "                     ticker_list = config.SP_500_TICKER).fetch_data()\n",
    "\n",
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)\n",
    "\n",
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eee93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_agent = DRLEnsembleAgent(df=processed_full,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)\n",
    "\n",
    "last_state_ensemble = []\n",
    "\n",
    "ppo_sharpe_list = []\n",
    "ddpg_sharpe_list = []\n",
    "a2c_sharpe_list = []\n",
    "\n",
    "model_use = []\n",
    "validation_start_date_list = []\n",
    "validation_end_date_list = []\n",
    "iteration_list = []\n",
    "\n",
    "insample_turbulence = ensemble_agent.df[(ensemble_agent.df.date<ensemble_agent.train_period[1]) & (ensemble_agent.df.date>=ensemble_agent.train_period[0])]\n",
    "insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 0.85)\n",
    "\n",
    "start = time.time()\n",
    "# for i in range(self.rebalance_window + self.validation_window, len(self.unique_trade_date), self.rebalance_window):\n",
    "validation_start_date = self.unique_trade_date[i - self.rebalance_window - self.validation_window]\n",
    "validation_end_date = self.unique_trade_date[i - self.rebalance_window]\n",
    "\n",
    "validation_start_date_list.append(validation_start_date)\n",
    "validation_end_date_list.append(validation_end_date)\n",
    "iteration_list.append(i)\n",
    "\n",
    "print(\"============================================\")\n",
    "## initial state is empty\n",
    "if i - self.rebalance_window - self.validation_window == 0:\n",
    "    # inital state\n",
    "    initial = True\n",
    "else:\n",
    "    # previous state\n",
    "    initial = False\n",
    "\n",
    "# Tuning trubulence index based on historical data\n",
    "# Turbulence lookback window is one quarter (63 days)\n",
    "end_date_index = self.df.index[self.df[\"date\"] == self.unique_trade_date[i - self.rebalance_window - self.validation_window]].to_list()[-1]\n",
    "start_date_index = end_date_index - 63 + 1\n",
    "\n",
    "historical_turbulence = self.df.iloc[start_date_index:(end_date_index + 1), :]\n",
    "\n",
    "historical_turbulence = historical_turbulence.drop_duplicates(subset=['date'])\n",
    "\n",
    "historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\n",
    "\n",
    "print(historical_turbulence_mean)\n",
    "\n",
    "if historical_turbulence_mean > insample_turbulence_threshold:\n",
    "    # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
    "    # then we assume that the current market is volatile,\n",
    "    # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
    "    # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
    "    turbulence_threshold = insample_turbulence_threshold\n",
    "else:\n",
    "    # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
    "    # then we tune up the turbulence_threshold, meaning we lower the risk\n",
    "    turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n",
    "print(\"turbulence_threshold: \", turbulence_threshold)\n",
    "\n",
    "############## Environment Setup starts ##############\n",
    "## training env\n",
    "train = data_split(self.df, start=self.train_period[0], end=self.unique_trade_date[i - self.rebalance_window - self.validation_window])\n",
    "self.train_env = DummyVecEnv([lambda: StockTradingEnv(train,\n",
    "                                                    self.stock_dim,\n",
    "                                                    self.hmax,\n",
    "                                                    self.initial_amount,\n",
    "                                                    self.buy_cost_pct,\n",
    "                                                    self.sell_cost_pct,\n",
    "                                                    self.reward_scaling,\n",
    "                                                    self.state_space,\n",
    "                                                    self.action_space,\n",
    "                                                    self.tech_indicator_list,\n",
    "                                                    print_verbosity=self.print_verbosity)])\n",
    "\n",
    "validation = data_split(self.df, start=self.unique_trade_date[i - self.rebalance_window - self.validation_window],\n",
    "                        end=self.unique_trade_date[i - self.rebalance_window])\n",
    "############## Environment Setup ends ##############\n",
    "\n",
    "############## Training and Validation starts ##############\n",
    "print(\"======Model training from: \", self.train_period[0], \"to \",\n",
    "      self.unique_trade_date[i - self.rebalance_window - self.validation_window])\n",
    "# print(\"training: \",len(data_split(df, start=20090000, end=test.datadate.unique()[i-rebalance_window]) ))\n",
    "# print(\"==============Model Training===========\")\n",
    "print(\"======A2C Training========\")\n",
    "model_a2c = self.get_model(\"a2c\",self.train_env,policy=\"MlpPolicy\",model_kwargs=A2C_model_kwargs)\n",
    "model_a2c = self.train_model(model_a2c, \"a2c\", tb_log_name=\"a2c_{}\".format(i), iter_num = i, total_timesteps=timesteps_dict['a2c']) #100_000\n",
    "\n",
    "print(\"======A2C Validation from: \", validation_start_date, \"to \",validation_end_date)\n",
    "val_env_a2c = DummyVecEnv([lambda: StockTradingEnv(validation,\n",
    "                                                    self.stock_dim,\n",
    "                                                    self.hmax,\n",
    "                                                    self.initial_amount,\n",
    "                                                    self.buy_cost_pct,\n",
    "                                                    self.sell_cost_pct,\n",
    "                                                    self.reward_scaling,\n",
    "                                                    self.state_space,\n",
    "                                                    self.action_space,\n",
    "                                                    self.tech_indicator_list,\n",
    "                                                    turbulence_threshold=turbulence_threshold,\n",
    "                                                    iteration=i,\n",
    "                                                    model_name='A2C',\n",
    "                                                    mode='validation',\n",
    "                                                    print_verbosity=self.print_verbosity)])\n",
    "val_obs_a2c = val_env_a2c.reset()\n",
    "self.DRL_validation(model=model_a2c,test_data=validation,test_env=val_env_a2c,test_obs=val_obs_a2c)\n",
    "sharpe_a2c = self.get_validation_sharpe(i,model_name=\"A2C\")\n",
    "print(\"A2C Sharpe Ratio: \", sharpe_a2c)\n",
    "\n",
    "print(\"======PPO Training========\")\n",
    "model_ppo = self.get_model(\"ppo\",self.train_env,policy=\"MlpPolicy\",model_kwargs=PPO_model_kwargs)\n",
    "model_ppo = self.train_model(model_ppo, \"ppo\", tb_log_name=\"ppo_{}\".format(i), iter_num = i, total_timesteps=timesteps_dict['ppo']) #100_000\n",
    "print(\"======PPO Validation from: \", validation_start_date, \"to \",validation_end_date)\n",
    "val_env_ppo = DummyVecEnv([lambda: StockTradingEnv(validation,\n",
    "                                                    self.stock_dim,\n",
    "                                                    self.hmax,\n",
    "                                                    self.initial_amount,\n",
    "                                                    self.buy_cost_pct,\n",
    "                                                    self.sell_cost_pct,\n",
    "                                                    self.reward_scaling,\n",
    "                                                    self.state_space,\n",
    "                                                    self.action_space,\n",
    "                                                    self.tech_indicator_list,\n",
    "                                                    turbulence_threshold=turbulence_threshold,\n",
    "                                                    iteration=i,\n",
    "                                                    model_name='PPO',\n",
    "                                                    mode='validation',\n",
    "                                                    print_verbosity=self.print_verbosity)])\n",
    "val_obs_ppo = val_env_ppo.reset()\n",
    "self.DRL_validation(model=model_ppo,test_data=validation,test_env=val_env_ppo,test_obs=val_obs_ppo)\n",
    "sharpe_ppo = self.get_validation_sharpe(i,model_name=\"PPO\")\n",
    "print(\"PPO Sharpe Ratio: \", sharpe_ppo)\n",
    "\n",
    "print(\"======DDPG Training========\")\n",
    "model_ddpg = self.get_model(\"ddpg\",self.train_env,policy=\"MlpPolicy\",model_kwargs=DDPG_model_kwargs)\n",
    "model_ddpg = self.train_model(model_ddpg, \"ddpg\", tb_log_name=\"ddpg_{}\".format(i), iter_num = i, total_timesteps=timesteps_dict['ddpg'])  #50_000\n",
    "print(\"======DDPG Validation from: \", validation_start_date, \"to \",validation_end_date)\n",
    "val_env_ddpg = DummyVecEnv([lambda: StockTradingEnv(validation,\n",
    "                                                    self.stock_dim,\n",
    "                                                    self.hmax,\n",
    "                                                    self.initial_amount,\n",
    "                                                    self.buy_cost_pct,\n",
    "                                                    self.sell_cost_pct,\n",
    "                                                    self.reward_scaling,\n",
    "                                                    self.state_space,\n",
    "                                                    self.action_space,\n",
    "                                                    self.tech_indicator_list,\n",
    "                                                    turbulence_threshold=turbulence_threshold,\n",
    "                                                    iteration=i,\n",
    "                                                    model_name='DDPG',\n",
    "                                                    mode='validation',\n",
    "                                                    print_verbosity=self.print_verbosity)])\n",
    "val_obs_ddpg = val_env_ddpg.reset()\n",
    "self.DRL_validation(model=model_ddpg,test_data=validation,test_env=val_env_ddpg,test_obs=val_obs_ddpg)\n",
    "sharpe_ddpg = self.get_validation_sharpe(i,model_name=\"DDPG\")\n",
    "\n",
    "ppo_sharpe_list.append(sharpe_ppo)\n",
    "a2c_sharpe_list.append(sharpe_a2c)\n",
    "ddpg_sharpe_list.append(sharpe_ddpg)\n",
    "\n",
    "print(\"======Best Model Retraining from: \", self.train_period[0], \"to \",\n",
    "      self.unique_trade_date[i - self.rebalance_window])\n",
    "# Environment setup for model retraining up to first trade date\n",
    "train_full = data_split(self.df, start=self.train_period[0], end=self.unique_trade_date[i - self.rebalance_window])\n",
    "self.train_full_env = DummyVecEnv([lambda: StockTradingEnv(train_full,\n",
    "                                                    self.stock_dim,\n",
    "                                                    self.hmax,\n",
    "                                                    self.initial_amount,\n",
    "                                                    self.buy_cost_pct,\n",
    "                                                    self.sell_cost_pct,\n",
    "                                                    self.reward_scaling,\n",
    "                                                    self.state_space,\n",
    "                                                    self.action_space,\n",
    "                                                    self.tech_indicator_list,\n",
    "                                                    print_verbosity=self.print_verbosity)])\n",
    "# Model Selection based on sharpe ratio\n",
    "if (sharpe_ppo >= sharpe_a2c) & (sharpe_ppo >= sharpe_ddpg):\n",
    "    model_use.append('PPO')\n",
    "\n",
    "    model_ensemble = self.get_model(\"ppo\",self.train_full_env,policy=\"MlpPolicy\",model_kwargs=PPO_model_kwargs)\n",
    "    model_ensemble = self.train_model(model_ensemble, \"ensemble\", tb_log_name=\"ensemble_{}\".format(i), iter_num = i, total_timesteps=timesteps_dict['ppo']) #100_000\n",
    "elif (sharpe_a2c > sharpe_ppo) & (sharpe_a2c > sharpe_ddpg):\n",
    "    model_use.append('A2C')\n",
    "\n",
    "    model_ensemble = self.get_model(\"a2c\",self.train_full_env,policy=\"MlpPolicy\",model_kwargs=A2C_model_kwargs)\n",
    "    model_ensemble = self.train_model(model_ensemble, \"ensemble\", tb_log_name=\"ensemble_{}\".format(i), iter_num = i, total_timesteps=timesteps_dict['a2c']) #100_000\n",
    "else:\n",
    "    model_use.append('DDPG')\n",
    "\n",
    "    model_ensemble = self.get_model(\"ddpg\",self.train_full_env,policy=\"MlpPolicy\",model_kwargs=DDPG_model_kwargs)\n",
    "    model_ensemble = self.train_model(model_ensemble, \"ensemble\", tb_log_name=\"ensemble_{}\".format(i), iter_num = i, total_timesteps=timesteps_dict['ddpg']) #50_000\n",
    "\n",
    "############## Training and Validation ends ##############\n",
    "\n",
    "############## Trading starts ##############\n",
    "print(\"======Trading from: \", self.unique_trade_date[i - self.rebalance_window], \"to \", self.unique_trade_date[i])\n",
    "#print(\"Used Model: \", model_ensemble)\n",
    "last_state_ensemble = self.DRL_prediction(model=model_ensemble, name=\"ensemble\",\n",
    "                                         last_state=last_state_ensemble, iter_num=i,\n",
    "                                         turbulence_threshold = turbulence_threshold,\n",
    "                                         initial=initial)\n",
    "############## Trading ends ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "346ce47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ticker in actions_trade.columns:\n",
    "    if actions_trade.iloc[-1][ticker] > 0:\n",
    "        api.submit_order(\n",
    "            symbol=ticker,\n",
    "            qty=actions_trade.iloc[-1][ticker],\n",
    "            side='buy',\n",
    "            type='market',\n",
    "            time_in_force='gtc'\n",
    "        )\n",
    "    elif actions_trade.iloc[-1][ticker] < 0:\n",
    "        api.submit_order(\n",
    "            symbol=ticker,\n",
    "            qty= actions_trade.iloc[-1][ticker],\n",
    "            side='sell',\n",
    "            type='market',\n",
    "            time_in_force='gtc'\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
