{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d2f0f424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: alpaca_trade_api in /usr/local/lib/python3.9/site-packages (1.2.2)\n",
      "Requirement already satisfied: schedule in /usr/local/lib/python3.9/site-packages (1.1.0)\n",
      "Requirement already satisfied: holidays in /usr/local/lib/python3.9/site-packages (0.11.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api) (1.2.4)\n",
      "Requirement already satisfied: websockets<10,>=8.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api) (9.1)\n",
      "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api) (1.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api) (1.19.5)\n",
      "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api) (1.26.5)\n",
      "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api) (2.25.1)\n",
      "Requirement already satisfied: msgpack==1.0.2 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api) (1.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3,>2->alpaca_trade_api) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from requests<3,>2->alpaca_trade_api) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>2->alpaca_trade_api) (2.10)\n",
      "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.9/site-packages (from holidays) (0.2.1)\n",
      "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.9/site-packages (from holidays) (2.1.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from holidays) (1.15.0)\n",
      "Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.9/site-packages (from holidays) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/site-packages (from holidays) (2.8.1)\n",
      "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.9/site-packages (from convertdate>=2.3.0->holidays) (0.5.11)\n",
      "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.9/site-packages (from convertdate>=2.3.0->holidays) (2021.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install alpaca_trade_api schedule holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bb039e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import alpaca_trade_api as api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.trade.backtest import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import (\n",
    "    NormalActionNoise,\n",
    "    OrnsteinUhlenbeckActionNoise,)\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.td3.policies import MlpPolicy\n",
    "from stable_baselines3.common.noise import (\n",
    "    NormalActionNoise,\n",
    "    OrnsteinUhlenbeckActionNoise,\n",
    ")\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "\n",
    "import itertools\n",
    "from datetime import datetime, time\n",
    "import schedule\n",
    "import holidays\n",
    "\n",
    "holiday_check = holidays.US()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f03842e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload # python 2.7 does not require this\n",
    "import finrl.model.models\n",
    "reload(finrl.model.models)\n",
    "from finrl.model.models import DRLEnsembleAgent\n",
    "\n",
    "import finrl.env.env_stocktrading \n",
    "reload(finrl.env.env_stocktrading)\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "\n",
    "import finrl.preprocessing.data\n",
    "reload(finrl.preprocessing.data)\n",
    "from finrl.preprocessing.data import data_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "972b853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = api.REST('PK16U0CS4BSI2T7LLNJ7',\n",
    "        'Yh0OAxgUzUUhhiSzxQBgvpEUa7nc8lVhhzFVKK0B',\n",
    "        'https://paper-api.alpaca.markets', api_version='v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "29073a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/quanphan/Documents/Project Development/finrl_adopt_application'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b0454f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(agent, model_name, env):\n",
    "    \n",
    "    MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\n",
    "    \n",
    "#     model = get_latest_file(config.TRAINED_MODEL_DIR, model_name)\n",
    "    model = get_latest_file('./old_trained_models/', model_name)\n",
    "    model = MODELS[agent].load(model, env=env)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0550f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_daily(model, model_name, tb_log_name, total_timesteps=5000):\n",
    "    \n",
    "    model = model.learn(total_timesteps=total_timesteps, tb_log_name=tb_log_name)\n",
    "    model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name.upper()}_{total_timesteps//1000}k\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1de286f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_trade(actions_trade):\n",
    "    \n",
    "    for ticker in actions_trade.columns[1:]:\n",
    "        if actions_trade.iloc[-1][ticker] > 0:\n",
    "            api.submit_order(\n",
    "                symbol=ticker,\n",
    "                qty=int(actions_trade.iloc[-1][ticker]),\n",
    "                side='buy',\n",
    "                type='market',\n",
    "                time_in_force='gtc'\n",
    "            )\n",
    "        elif actions_trade.iloc[-1][ticker] < 0:\n",
    "            api.submit_order(\n",
    "                symbol=ticker,\n",
    "                qty= abs(int(actions_trade.iloc[-1][ticker])),\n",
    "                side='sell',\n",
    "                type='market',\n",
    "                time_in_force='gtc'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7c54ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_file(directory, file_name):\n",
    "    files = glob.glob(os.path.join(os.getcwd(), directory, file_name))\n",
    "#     files = glob.glob(os.path.join('/Users/evienguyen/Documents/FinRL/Modified FinRL', 'results', 'actions_trade_ensemble*'))\n",
    "\n",
    "    files.sort(key=os.path.getmtime)\n",
    "    print(files)\n",
    "    actions_trade =  sorted(files,key=os.path.getmtime)[-1]\n",
    "    \n",
    "    return actions_trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e1f14066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing data\n",
      "2021-07-06 2021-06-22\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- AGN: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BBT: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BHGE: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CBS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CELG: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CTL: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CXO: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ETFC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FLIR: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HCP: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- JEC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MYL: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- NBL: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RTN: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- STI: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SYMC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TIF: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TSS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- UTX: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- VAR: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- VIAB: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WCG: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (4293, 8)\n",
      "(5402, 478)\n",
      "tic                A       AAL       AAP      AAPL      ABBV       ABC  \\\n",
      "date                                                                     \n",
      "2000-01-03       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2000-01-04 -0.076389       NaN       NaN -0.084310       NaN -0.068273   \n",
      "2000-01-05 -0.062030       NaN       NaN  0.014633       NaN  0.077586   \n",
      "2000-01-06 -0.038076       NaN       NaN -0.086538       NaN  0.076000   \n",
      "2000-01-07  0.083334       NaN       NaN  0.047369       NaN  0.130112   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2021-06-16 -0.007122  0.001755 -0.018638  0.003934 -0.002590 -0.005629   \n",
      "2021-06-17  0.023191 -0.026281 -0.007809  0.012601 -0.005453 -0.002112   \n",
      "2021-06-18 -0.013000  0.002699 -0.005453 -0.010092 -0.015492 -0.031242   \n",
      "2021-06-21  0.009655  0.007178  0.026587  0.014104  0.014233  0.019227   \n",
      "2021-06-22  0.001503 -0.015145  0.007910  0.012698 -0.000262  0.000600   \n",
      "\n",
      "tic             ABMD       ABT       ACN      ADBE  ...       XEL      XLNX  \\\n",
      "date                                                ...                       \n",
      "2000-01-03       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
      "2000-01-04 -0.023973 -0.028571       NaN -0.083889  ...  0.023027 -0.022728   \n",
      "2000-01-05  0.010526 -0.001838       NaN  0.019771  ...  0.038586 -0.021888   \n",
      "2000-01-06  0.001736  0.034991       NaN  0.008163  ... -0.009288 -0.086713   \n",
      "2000-01-07 -0.005199  0.010676       NaN  0.048583  ...  0.000000  0.113323   \n",
      "...              ...       ...       ...       ...  ...       ...       ...   \n",
      "2021-06-16  0.005237 -0.003170 -0.007862 -0.009353  ... -0.020668 -0.006770   \n",
      "2021-06-17  0.030696  0.014265  0.002923  0.014779  ...  0.008707  0.048819   \n",
      "2021-06-18  0.019065 -0.011646 -0.012361  0.025809  ... -0.025604 -0.003174   \n",
      "2021-06-21  0.020466  0.010061  0.015324  0.003112  ...  0.008108 -0.033278   \n",
      "2021-06-22  0.006460 -0.004307  0.000350  0.014788  ... -0.005809  0.019525   \n",
      "\n",
      "tic              XOM      XRAY       XRX       XYL       YUM       ZBH  \\\n",
      "date                                                                     \n",
      "2000-01-03       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2000-01-04 -0.019154  0.000000 -0.046512       NaN -0.020100       NaN   \n",
      "2000-01-05  0.054516  0.017287  0.051491       NaN  0.005128       NaN   \n",
      "2000-01-06  0.051698  0.001307 -0.020619       NaN -0.008504       NaN   \n",
      "2000-01-07 -0.002935 -0.002611  0.023684       NaN -0.022298       NaN   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2021-06-16 -0.003575 -0.005615  0.004073 -0.022017 -0.003627 -0.001958   \n",
      "2021-06-17 -0.032917 -0.006258 -0.041379 -0.013421 -0.011004  0.014934   \n",
      "2021-06-18 -0.025649 -0.029642 -0.008464 -0.004564 -0.018829 -0.011721   \n",
      "2021-06-21  0.036258  0.028648  0.013658  0.025657  0.018493  0.031354   \n",
      "2021-06-22  0.019172 -0.009694 -0.015579  0.000430  0.006338  0.017739   \n",
      "\n",
      "tic             ZION       ZTS  \n",
      "date                            \n",
      "2000-01-03       NaN       NaN  \n",
      "2000-01-04 -0.048423       NaN  \n",
      "2000-01-05 -0.001183       NaN  \n",
      "2000-01-06  0.014218       NaN  \n",
      "2000-01-07  0.002337       NaN  \n",
      "...              ...       ...  \n",
      "2021-06-16  0.011189 -0.008402  \n",
      "2021-06-17 -0.063668  0.012655  \n",
      "2021-06-18 -0.025571 -0.005632  \n",
      "2021-06-21  0.047316  0.006527  \n",
      "2021-06-22  0.002658  0.000107  \n",
      "\n",
      "[5402 rows x 478 columns]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "validation_window = 63\n",
    "rebalance_window = 63\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "beginning = '2000-01-01'\n",
    "train_start = datetime.today() - timedelta(days=validation_window + rebalance_window)\n",
    "\n",
    "val_start = datetime.today() - timedelta(days=validation_window)\n",
    "val_start = val_start.strftime('%Y-%m-%d')\n",
    "\n",
    "val_end = datetime.today()\n",
    "val_end = val_end.strftime('%Y-%m-%d')\n",
    "\n",
    "raw_full_path = os.path.join(os.getcwd(), 'data', 'raw_full.csv')\n",
    "\n",
    "if not os.path.exists(raw_full_path):\n",
    "    print(\"Not found existing data\")\n",
    "    \n",
    "    raw_full = YahooDownloader(start_date = beginning,\n",
    "                         end_date = '2021-06-23',\n",
    "                         ticker_list = config.SP_500_TICKER).fetch_data()\n",
    "\n",
    "    raw_full.to_csv(raw_full_path)\n",
    "else:\n",
    "    print(\"Found existing data\")\n",
    "    raw_full = pd.read_csv(raw_full_path)\n",
    "    \n",
    "    latest_date = raw_full.iloc[-1, :].date\n",
    "    print(today, latest_date)\n",
    "    if today != latest_date:\n",
    "        raw_full.append(\n",
    "            YahooDownloader(start_date = latest_date,\n",
    "                             end_date = today,\n",
    "                             ticker_list = config.SP_500_TICKER).fetch_data()\n",
    "        )\n",
    "\n",
    "init_thresh = calc_turb_thresh(raw_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "27eb4430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_daily_data(train_start, today):\n",
    "    '''\n",
    "        Return full processed 126 days data with turbulence + tech_indicators\n",
    "    '''\n",
    "    \n",
    "    raw_recent_path = os.path.join('data', 'raw_recent')\n",
    "    \n",
    "    if not os.path.exists(raw_recent_path):\n",
    "        \n",
    "        raw_recent = YahooDownloader(start_date = train_start - timedelta(days=365),\n",
    "                         end_date = today,\n",
    "                         ticker_list = config.SP_500_TICKER).fetch_data()\n",
    "    else:\n",
    "        raw_recent = pd.read_csv(raw_recent_path)\n",
    "        \n",
    "        latest_date = raw_recent.iloc[-1, :].date\n",
    "        \n",
    "        if today != latest_date:\n",
    "            raw_recent.append(\n",
    "                YahooDownloader(start_date = latest_date,\n",
    "                                 end_date = today,\n",
    "                                 ticker_list = config.SP_500_TICKER).fetch_data()\n",
    "            )\n",
    "        else:\n",
    "            raw_recent.iloc[-1, :] = YahooDownloader(start_date = today,\n",
    "                                 end_date = today,\n",
    "                                 ticker_list = config.SP_500_TICKER).fetch_data()\n",
    "    \n",
    "    fe = FeatureEngineer(\n",
    "                        use_technical_indicator=True,\n",
    "                        tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                        use_turbulence=True,\n",
    "                        user_defined_feature = False)\n",
    "\n",
    "    processed = fe.preprocess_data(raw_recent)\n",
    "    \n",
    "    list_ticker = processed[\"tic\"].unique().tolist()\n",
    "    list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "    combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "    processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "    processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "    processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "    processed_full = processed_full.fillna(0)\n",
    "    \n",
    "    return processed_full, raw_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7ce82b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_turb_thresh(data):\n",
    "    '''\n",
    "        Input: raw full data df\n",
    "        Return initial turbulence from full data until trading day\n",
    "    '''\n",
    "    \n",
    "    df_price_pivot = data.pivot(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "    # use returns to calculate turbulence\n",
    "    df_price_pivot = df_price_pivot.pct_change()\n",
    "    \n",
    "    print(df_price_pivot.shape)\n",
    "    print(df_price_pivot)\n",
    "    \n",
    "    unique_date = data.date.unique()\n",
    "    # start after a year\n",
    "    start = 252\n",
    "    turbulence_index = [0] * start\n",
    "    # turbulence_index = [0]\n",
    "    count = 0\n",
    "    for i in range(start, len(unique_date)):\n",
    "        current_price = df_price_pivot[df_price_pivot.index == unique_date[i]]\n",
    "        # use one year rolling window to calcualte covariance\n",
    "        hist_price = df_price_pivot[\n",
    "            (df_price_pivot.index < unique_date[i])\n",
    "            & (df_price_pivot.index >= unique_date[i - 252])\n",
    "        ]\n",
    "        # Drop tickers which has number missing values more than the \"oldest\" ticker\n",
    "        filtered_hist_price = hist_price.iloc[hist_price.isna().sum().min():].dropna(axis=1)\n",
    "\n",
    "        cov_temp = filtered_hist_price.cov()\n",
    "        current_temp = current_price[[x for x in filtered_hist_price]] - np.mean(filtered_hist_price, axis=0)\n",
    "        temp = current_temp.values.dot(np.linalg.pinv(cov_temp)).dot(\n",
    "            current_temp.values.T\n",
    "        )\n",
    "        if temp > 0:\n",
    "            count += 1\n",
    "            if count > 2:\n",
    "                turbulence_temp = temp[0][0]\n",
    "            else:\n",
    "                # avoid large outlier because of the calculation just begins\n",
    "                turbulence_temp = 0\n",
    "        else:\n",
    "            turbulence_temp = 0\n",
    "        turbulence_index.append(turbulence_temp)\n",
    "\n",
    "    turbulence_index = pd.DataFrame(\n",
    "        {\"date\": df_price_pivot.index, \"turbulence\": turbulence_index}\n",
    "    )\n",
    "    \n",
    "    data = data.merge(turbulence_index, on=\"date\")\n",
    "    data = data.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n",
    "    \n",
    "    insample_turbulence_threshold = np.quantile(data.turbulence.values, 0.85)\n",
    "    \n",
    "    return insample_turbulence_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2eee93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_predict(df, raw_recent, initial_turbulence):\n",
    "    \n",
    "    timesteps_dict = {'a2c' : 30_000, \n",
    "                 'ppo' : 100_000, \n",
    "                 'ddpg' : 10_000\n",
    "                 }\n",
    "    \n",
    "    last_state_ensemble = []\n",
    "    insample_turbulence_threshold = initial_turbulence\n",
    "\n",
    "    ppo_sharpe_list = []\n",
    "    ddpg_sharpe_list = []\n",
    "    a2c_sharpe_list = []\n",
    "\n",
    "    model_use = ''\n",
    "    # start = time.time()\n",
    "    stock_dimension = len(df.tic.unique())\n",
    "    state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "    print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "\n",
    "    env_kwargs = {\n",
    "        \"hmax\": 100, \n",
    "        \"initial_amount\": 100000, #TODO: dynamic change amount\n",
    "        \"buy_cost_pct\": 0.001, \n",
    "        \"sell_cost_pct\": 0.001, \n",
    "        \"state_space\": state_space, \n",
    "        \"stock_dim\": stock_dimension, \n",
    "        \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "        \"action_space\": stock_dimension, \n",
    "        \"reward_scaling\": 1e-4,\n",
    "        \"print_verbosity\":5\n",
    "\n",
    "    }\n",
    "    ensemble_agent = DRLEnsembleAgent(df=df,\n",
    "                     rebalance_window=rebalance_window, \n",
    "                     validation_window=validation_window, \n",
    "                     **env_kwargs)\n",
    "\n",
    "#     validation_start_date_list.append(val_start)\n",
    "#     validation_end_date_list.append(val_end)\n",
    "    # iteration_list.append(i)\n",
    "\n",
    "    print(\"============================================\")\n",
    "    ## initial state is empty\n",
    "    # if i - self.rebalance_window - self.validation_window == 0:\n",
    "    #     # inital state\n",
    "    #     initial = True\n",
    "    # else:\n",
    "    #     # previous state\n",
    "    #     initial = False\n",
    "\n",
    "    # Tuning trubulence index based on historical data\n",
    "    # Turbulence lookback window is one quarter (63 days)\n",
    "#     end_date_index = df.index[df[\"date\"] == ensemble_agent.unique_trade_date[train_start]].to_list()[-1]\n",
    "#     start_date_index = end_date_index - 63 + 1\n",
    "\n",
    "#     historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n",
    "\n",
    "#     historical_turbulence = historical_turbulence.drop_duplicates(subset=['date'])\n",
    "\n",
    "    historical_turbulence_mean = np.mean(df.iloc[64:, :].turbulence.values)\n",
    "\n",
    "    \n",
    "       \n",
    "    turbulence_index = calc_turb_thresh(raw_recent)\n",
    "    print(historical_turbulence_mean)\n",
    "    print(turbulence_index)\n",
    "    \n",
    "    if historical_turbulence_mean > insample_turbulence_threshold:\n",
    "        # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
    "        # then we assume that the current market is volatile,\n",
    "        # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
    "        # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
    "        turbulence_threshold = insample_turbulence_threshold\n",
    "    else:\n",
    "        # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
    "        # then we tune up the turbulence_threshold, meaning we lower the risk\n",
    "        turbulence_threshold = np.quantile(turbulence_index, 1)\n",
    "    print(\"turbulence_threshold: \", turbulence_threshold)\n",
    "\n",
    "    ############## Environment Setup starts ##############\n",
    "    ## training env\n",
    "#     train = data_split(ensemble_agent.df, start=train_start, end=val_start)\n",
    "#     ensemble_agent.train_env = DummyVecEnv([lambda: StockTradingEnv(train,\n",
    "#                                                         ensemble_agent.stock_dim,\n",
    "#                                                         ensemble_agent.hmax,\n",
    "#                                                         ensemble_agent.initial_amount,\n",
    "#                                                         ensemble_agent.buy_cost_pct,\n",
    "#                                                         ensemble_agent.sell_cost_pct,\n",
    "#                                                         ensemble_agent.reward_scaling,\n",
    "#                                                         ensemble_agent.state_space,\n",
    "#                                                         ensemble_agent.action_space,\n",
    "#                                                         ensemble_agent.tech_indicator_list,\n",
    "#                                                         print_verbosity=ensemble_agent.print_verbosity)])\n",
    "\n",
    "    validation = data_split(ensemble_agent.df, start = df.date.unique()[-63], end = df.date.unique()[-1])\n",
    "    ############## Environment Setup ends ##############\n",
    "\n",
    "    ############## Validation starts ##############\n",
    "\n",
    "    print(\"======A2C Validation from: \", val_start, \"to \",val_end)\n",
    "    val_env_a2c = DummyVecEnv([lambda: StockTradingEnv(validation,\n",
    "                                                        ensemble_agent.stock_dim,\n",
    "                                                        ensemble_agent.hmax,\n",
    "                                                        ensemble_agent.initial_amount,\n",
    "                                                        ensemble_agent.buy_cost_pct,\n",
    "                                                        ensemble_agent.sell_cost_pct,\n",
    "                                                        ensemble_agent.reward_scaling,\n",
    "                                                        ensemble_agent.state_space,\n",
    "                                                        ensemble_agent.action_space,\n",
    "                                                        ensemble_agent.tech_indicator_list,\n",
    "                                                        turbulence_threshold=turbulence_threshold,\n",
    "#                                                         iteration=i,\n",
    "                                                        model_name='A2C',\n",
    "                                                        mode='validation',\n",
    "                                                        print_verbosity=ensemble_agent.print_verbosity)])\n",
    "    val_obs_a2c = val_env_a2c.reset()\n",
    "\n",
    "    model_a2c = load_model('a2c', 'A2C_30k*', env=val_env_a2c)\n",
    "    \n",
    "    val_a2c_model =  ensemble_agent.DRL_validation(model=model_a2c,test_data=validation,test_env=val_env_a2c,test_obs=val_obs_a2c)\n",
    "    sharpe_a2c = ensemble_agent.get_validation_sharpe(model_name=\"A2C\")\n",
    "    print(\"A2C Sharpe Ratio: \", sharpe_a2c)\n",
    "\n",
    "    print(\"======PPO Validation from: \", val_start, \"to \",val_end)\n",
    "    val_env_ppo = DummyVecEnv([lambda: StockTradingEnv(validation,\n",
    "                                                        ensemble_agent.stock_dim,\n",
    "                                                        ensemble_agent.hmax,\n",
    "                                                        ensemble_agent.initial_amount,\n",
    "                                                        ensemble_agent.buy_cost_pct,\n",
    "                                                        ensemble_agent.sell_cost_pct,\n",
    "                                                        ensemble_agent.reward_scaling,\n",
    "                                                        ensemble_agent.state_space,\n",
    "                                                        ensemble_agent.action_space,\n",
    "                                                        ensemble_agent.tech_indicator_list,\n",
    "                                                        turbulence_threshold=turbulence_threshold,\n",
    "#                                                         iteration=i,\n",
    "                                                        model_name='PPO',\n",
    "                                                        mode='validation',\n",
    "                                                        print_verbosity=ensemble_agent.print_verbosity)])\n",
    "    val_obs_ppo = val_env_ppo.reset()\n",
    "    \n",
    "    model_ppo = load_model('ppo', 'PPO_100k*', env=val_env_ppo)\n",
    "    \n",
    "    val_ppo_model = ensemble_agent.DRL_validation(model=model_ppo,test_data=validation,test_env=val_env_ppo,test_obs=val_obs_ppo)\n",
    "    sharpe_ppo = ensemble_agent.get_validation_sharpe(model_name=\"PPO\")\n",
    "    print(\"PPO Sharpe Ratio: \", sharpe_ppo)\n",
    "\n",
    "    print(\"======DDPG Validation from: \", val_start, \"to \",val_end)\n",
    "    val_env_ddpg = DummyVecEnv([lambda: StockTradingEnv(validation,\n",
    "                                                        ensemble_agent.stock_dim,\n",
    "                                                        ensemble_agent.hmax,\n",
    "                                                        ensemble_agent.initial_amount,\n",
    "                                                        ensemble_agent.buy_cost_pct,\n",
    "                                                        ensemble_agent.sell_cost_pct,\n",
    "                                                        ensemble_agent.reward_scaling,\n",
    "                                                        ensemble_agent.state_space,\n",
    "                                                        ensemble_agent.action_space,\n",
    "                                                        ensemble_agent.tech_indicator_list,\n",
    "                                                        turbulence_threshold=turbulence_threshold,\n",
    "#                                                         iteration=i,\n",
    "                                                        model_name='DDPG',\n",
    "                                                        mode='validation',\n",
    "                                                        print_verbosity=ensemble_agent.print_verbosity)])\n",
    "    val_obs_ddpg = val_env_ddpg.reset()\n",
    "    \n",
    "    model_ddpg = load_model('ddpg', 'DDPG_10k*', env=val_env_ddpg)\n",
    "    \n",
    "    val_ddpg_model = ensemble_agent.DRL_validation(model=model_ddpg,test_data=validation,test_env=val_env_ddpg,test_obs=val_obs_ddpg)\n",
    "    sharpe_ddpg = ensemble_agent.get_validation_sharpe(model_name=\"DDPG\")\n",
    "    print(\"DDPG Sharpe Ratio: \", sharpe_ddpg)\n",
    "\n",
    "    ppo_sharpe_list.append(sharpe_ppo)\n",
    "    a2c_sharpe_list.append(sharpe_a2c)\n",
    "    ddpg_sharpe_list.append(sharpe_ddpg)\n",
    "\n",
    "    print(\"======Best Model Retraining from: \", val_start, \"to \",\n",
    "          val_end)\n",
    "    # Environment setup for model retraining up to first trade date\n",
    "    train_full = data_split(ensemble_agent.df, start = df.date.unique()[-63], end = df.date.unique()[-1])\n",
    "    train_full_env = DummyVecEnv([lambda: StockTradingEnv(train_full,\n",
    "                                                        ensemble_agent.stock_dim,\n",
    "                                                        ensemble_agent.hmax,\n",
    "                                                        ensemble_agent.initial_amount,\n",
    "                                                        ensemble_agent.buy_cost_pct,\n",
    "                                                        ensemble_agent.sell_cost_pct,\n",
    "                                                        ensemble_agent.reward_scaling,\n",
    "                                                        ensemble_agent.state_space,\n",
    "                                                        ensemble_agent.action_space,\n",
    "                                                        ensemble_agent.tech_indicator_list,\n",
    "                                                        print_verbosity=ensemble_agent.print_verbosity)])\n",
    "    # Model Selection based on sharpe ratio\n",
    "    if (sharpe_ppo >= sharpe_a2c) & (sharpe_ppo >= sharpe_ddpg):\n",
    "        model_use = 'ppo'\n",
    "        model_ensemble = load_model('ppo', 'PPO_100k*', env=train_full_env)\n",
    "\n",
    "    elif (sharpe_a2c > sharpe_ppo) & (sharpe_a2c > sharpe_ddpg):\n",
    "        model_use = 'a2c'\n",
    "        model_ensemble = load_model('a2c', 'A2C_30k*', env=train_full_env)\n",
    "    else:\n",
    "        model_use = 'ddpg'\n",
    "        model_ensemble = load_model('ddpg', 'DDPG_10k*', env=train_full_env)\n",
    "        \n",
    "    model_ensemble = train_model_daily(model_ensemble, \"ensemble\", tb_log_name=\"ensemble_{}\".format(model_use), total_timesteps=timesteps_dict[model_use]) #50_000\n",
    "    ############## Training and Validation ends ##############\n",
    "\n",
    "    ############## Trading starts ##############\n",
    "    # TODO: Update last state from correct environment\n",
    "    print(\"======Trading from: \", val_start, \"to \", val_end)\n",
    "    #print(\"Used Model: \", model_ensemble)\n",
    "    last_state_ensemble = ensemble_agent.DRL_prediction(model=model_ensemble, name=\"ensemble\",\n",
    "                                             last_state=last_state_ensemble,\n",
    "                                             turbulence_threshold = turbulence_threshold,\n",
    "                                             initial=(len(last_state_ensemble) == 0),\n",
    "                                             trade_data=train_full)\n",
    "    ############## Trading ends #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6670e667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Every 15 minutes do main() (last run: [never], next run: 2021-07-06 12:48:44)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main():\n",
    "    in_trading_time = (\n",
    "        time(hour=9,minute=30) <= datetime.now().time() < time(hour=16, minute=0) and\n",
    "        (datetime.now().date() not in holiday_check)\n",
    "    )\n",
    "    print(\"DATE: {} HOUR: {} \\nHOLIDAY: {}\".format(datetime.now().date(), datetime.now().time(), (datetime.now().date() in holiday_check)))\n",
    "    \n",
    "    if in_trading_time:\n",
    "        \n",
    "        daily_processed_df, raw_recent = refresh_daily_data(train_start, today)\n",
    "        daily_predict(daily_processed_df, raw_recent, init_thresh)\n",
    "\n",
    "        actions_trade = pd.read_csv(get_latest_file('results','actions_trade_ensemble*'))\n",
    "        perform_trade(actions_trade=actions_trade)\n",
    "        \n",
    "    else:\n",
    "        print(\"Trading close\")\n",
    "      \n",
    "schedule.clear()\n",
    "schedule.every(15).minutes.do(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4d8b6378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Every 15 minutes do main() (last run: [never], next run: 2021-07-06 12:48:44)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule.get_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a4f77e7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-2f98cdc8597c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    schedule.run_pending()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "724f4219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 478, State Space: 4781\n",
      "============================================\n",
      "(339, 478)\n",
      "tic                A       AAL       AAP      AAPL      ABBV       ABC  \\\n",
      "date                                                                     \n",
      "2020-03-02       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2020-03-03 -0.020129 -0.053553 -0.020001 -0.031759 -0.012628 -0.014800   \n",
      "2020-03-04  0.050174  0.038095  0.019719  0.046385  0.047733  0.052521   \n",
      "2020-03-05 -0.046117 -0.134377 -0.044996 -0.032437 -0.012425 -0.037730   \n",
      "2020-03-06 -0.023614 -0.004364  0.007800 -0.013280 -0.019755 -0.013338   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2021-06-28  0.004413 -0.037354  0.000391  0.012546  0.000177 -0.013753   \n",
      "2021-06-29  0.005949 -0.014493  0.003863  0.011500 -0.006195 -0.002615   \n",
      "2021-06-30 -0.006720  0.006167 -0.000779  0.004621  0.003028  0.000437   \n",
      "2021-07-01 -0.000135  0.014144  0.018524  0.002263  0.014382  0.017032   \n",
      "2021-07-02  0.008293 -0.001395  0.010099  0.019596  0.007964  0.001546   \n",
      "\n",
      "tic             ABMD       ABT       ACN      ADBE  ...       XEL      XLNX  \\\n",
      "date                                                ...                       \n",
      "2020-03-02       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
      "2020-03-03 -0.038169 -0.044357 -0.038670 -0.033141  ... -0.002429 -0.033211   \n",
      "2020-03-04  0.033852  0.052571  0.036439  0.044525  ...  0.053112  0.019927   \n",
      "2020-03-05  0.001815 -0.019125 -0.033358 -0.035234  ...  0.000722 -0.028407   \n",
      "2020-03-06  0.016633  0.015151 -0.020870 -0.040623  ...  0.012997 -0.014804   \n",
      "...              ...       ...       ...       ...  ...       ...       ...   \n",
      "2021-06-28  0.002889  0.026437 -0.002579  0.015768  ... -0.000596  0.024523   \n",
      "2021-06-29  0.002656  0.013051  0.008608  0.003312  ... -0.020131  0.031102   \n",
      "2021-06-30 -0.003703 -0.010921 -0.005532 -0.008650  ...  0.002587  0.036326   \n",
      "2021-07-01  0.002563  0.010610  0.017674 -0.001554  ...  0.017456 -0.019566   \n",
      "2021-07-02  0.013135  0.007511  0.016133  0.014263  ... -0.003133  0.019392   \n",
      "\n",
      "tic              XOM      XRAY       XRX       XYL       YUM       ZBH  \\\n",
      "date                                                                     \n",
      "2020-03-02       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2020-03-03 -0.047884 -0.049144 -0.048941 -0.029287 -0.013185 -0.038707   \n",
      "2020-03-04  0.021832  0.013345  0.057107  0.068102  0.036360  0.031451   \n",
      "2020-03-05 -0.044067 -0.052676 -0.060255 -0.033521 -0.039205 -0.064315   \n",
      "2020-03-06 -0.048294 -0.013019 -0.011687 -0.015038 -0.016718 -0.039399   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2021-06-28 -0.025518 -0.014958 -0.020551  0.020111 -0.009723 -0.012964   \n",
      "2021-06-29 -0.006189  0.000475 -0.010178  0.000336 -0.004737 -0.015394   \n",
      "2021-06-30  0.007346  0.000158  0.006427  0.006038 -0.004586 -0.002233   \n",
      "2021-07-01  0.002853  0.012172  0.014049  0.001501  0.008520  0.014426   \n",
      "2021-07-02 -0.001423 -0.002186  0.008816  0.006243  0.008103  0.002329   \n",
      "\n",
      "tic             ZION       ZTS  \n",
      "date                            \n",
      "2020-03-02       NaN       NaN  \n",
      "2020-03-03 -0.058111 -0.012022  \n",
      "2020-03-04 -0.010797  0.046488  \n",
      "2020-03-05 -0.061850 -0.028269  \n",
      "2020-03-06 -0.022715 -0.017985  \n",
      "...              ...       ...  \n",
      "2021-06-28 -0.036590 -0.000801  \n",
      "2021-06-29 -0.014032  0.004864  \n",
      "2021-06-30  0.003036 -0.008671  \n",
      "2021-07-01  0.018161  0.015722  \n",
      "2021-07-02 -0.010405  0.018015  \n",
      "\n",
      "[339 rows x 478 columns]\n",
      "70.18823054322797\n",
      "225.89200991925424\n",
      "turbulence_threshold:  225.89200991925424\n",
      "======A2C Validation from:  2021-05-04 to  2021-07-06\n",
      "['/Users/quanphan/Documents/Project Development/finrl_adopt_application/./old_trained_models/A2C_30k_126.zip']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quanphan/Documents/Project Development/finrl_adopt_application/finrl/env/env_stocktrading.py:206: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"index\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig('results/account_value_{}_{}_daily.png'.format(self.mode,self.model_name,),index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C Sharpe Ratio:  0.3635651924839796\n",
      "======PPO Validation from:  2021-05-04 to  2021-07-06\n",
      "['/Users/quanphan/Documents/Project Development/finrl_adopt_application/./old_trained_models/PPO_100k_126.zip']\n",
      "PPO Sharpe Ratio:  -0.06427353013627451\n",
      "======DDPG Validation from:  2021-05-04 to  2021-07-06\n",
      "['/Users/quanphan/Documents/Project Development/finrl_adopt_application/./old_trained_models/DDPG_10k_126.zip']\n",
      "DDPG Sharpe Ratio:  -0.2348438265349017\n",
      "======Best Model Retraining from:  2021-05-04 to  2021-07-06\n",
      "['/Users/quanphan/Documents/Project Development/finrl_adopt_application/./old_trained_models/A2C_30k_126.zip']\n",
      "Logging to tensorboard_log/a2c/ensemble_a2c_3\n",
      "day: 61, episode: 5\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103690.01\n",
      "total_reward: 3690.01\n",
      "total_cost: 157.44\n",
      "total_trades: 14749\n",
      "Sharpe: 0.728\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 126      |\n",
      "|    total_reward       | 290      |\n",
      "|    total_reward_pct   | 0.29     |\n",
      "|    total_trades       | 14778    |\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -720     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 47.4     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.00567  |\n",
      "------------------------------------\n",
      "day: 61, episode: 10\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 107000.35\n",
      "total_reward: 7000.35\n",
      "total_cost: 220.20\n",
      "total_trades: 14811\n",
      "Sharpe: 1.765\n",
      "=================================\n",
      "day: 61, episode: 15\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103864.12\n",
      "total_reward: 3864.12\n",
      "total_cost: 166.49\n",
      "total_trades: 14728\n",
      "Sharpe: 0.841\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 226      |\n",
      "|    total_reward       | 7.88e+03 |\n",
      "|    total_reward_pct   | 7.88     |\n",
      "|    total_trades       | 14783    |\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -724     |\n",
      "|    explained_variance | -0.165   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -296     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.556    |\n",
      "------------------------------------\n",
      "day: 61, episode: 20\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100789.64\n",
      "total_reward: 789.64\n",
      "total_cost: 219.77\n",
      "total_trades: 14659\n",
      "Sharpe: 0.261\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.09e+05  |\n",
      "|    total_cost         | 204       |\n",
      "|    total_reward       | 8.63e+03  |\n",
      "|    total_reward_pct   | 8.63      |\n",
      "|    total_trades       | 14611     |\n",
      "| time/                 |           |\n",
      "|    fps                | 87        |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -727      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 102       |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.0217    |\n",
      "-------------------------------------\n",
      "day: 61, episode: 25\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103626.92\n",
      "total_reward: 3626.92\n",
      "total_cost: 176.97\n",
      "total_trades: 14570\n",
      "Sharpe: 0.695\n",
      "=================================\n",
      "day: 61, episode: 30\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 106796.68\n",
      "total_reward: 6796.68\n",
      "total_cost: 230.38\n",
      "total_trades: 14687\n",
      "Sharpe: 1.507\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+05 |\n",
      "|    total_cost         | 211      |\n",
      "|    total_reward       | 5.37e+03 |\n",
      "|    total_reward_pct   | 5.37     |\n",
      "|    total_trades       | 14654    |\n",
      "| time/                 |          |\n",
      "|    fps                | 90       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -731     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 82.7     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0157   |\n",
      "------------------------------------\n",
      "day: 61, episode: 35\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 102612.17\n",
      "total_reward: 2612.17\n",
      "total_cost: 218.92\n",
      "total_trades: 14686\n",
      "Sharpe: 0.560\n",
      "=================================\n",
      "day: 61, episode: 40\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 110454.45\n",
      "total_reward: 10454.45\n",
      "total_cost: 218.83\n",
      "total_trades: 14596\n",
      "Sharpe: 2.310\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+05  |\n",
      "|    total_cost         | 219      |\n",
      "|    total_reward       | 1.05e+04 |\n",
      "|    total_reward_pct   | 10.5     |\n",
      "|    total_trades       | 14596    |\n",
      "| time/                 |          |\n",
      "|    fps                | 93       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -734     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 142      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0627   |\n",
      "------------------------------------\n",
      "day: 61, episode: 45\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 101386.74\n",
      "total_reward: 1386.74\n",
      "total_cost: 197.33\n",
      "total_trades: 14339\n",
      "Sharpe: 0.351\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.95e+04 |\n",
      "|    total_cost         | 190      |\n",
      "|    total_reward       | -468     |\n",
      "|    total_reward_pct   | -0.468   |\n",
      "|    total_trades       | 14600    |\n",
      "| time/                 |          |\n",
      "|    fps                | 95       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -738     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -128     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0367   |\n",
      "------------------------------------\n",
      "day: 61, episode: 50\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 106830.32\n",
      "total_reward: 6830.32\n",
      "total_cost: 204.30\n",
      "total_trades: 14489\n",
      "Sharpe: 1.389\n",
      "=================================\n",
      "day: 61, episode: 55\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103600.06\n",
      "total_reward: 3600.06\n",
      "total_cost: 222.95\n",
      "total_trades: 14361\n",
      "Sharpe: 0.723\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 198      |\n",
      "|    total_reward       | 1.62e+03 |\n",
      "|    total_reward_pct   | 1.62     |\n",
      "|    total_trades       | 14366    |\n",
      "| time/                 |          |\n",
      "|    fps                | 95       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -741     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 48.5     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.00513  |\n",
      "------------------------------------\n",
      "day: 61, episode: 60\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100605.79\n",
      "total_reward: 605.79\n",
      "total_cost: 212.92\n",
      "total_trades: 14540\n",
      "Sharpe: 0.224\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+05 |\n",
      "|    total_cost         | 201      |\n",
      "|    total_reward       | 923      |\n",
      "|    total_reward_pct   | 0.923    |\n",
      "|    total_trades       | 14626    |\n",
      "| time/                 |          |\n",
      "|    fps                | 95       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -744     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -72.8    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.021    |\n",
      "------------------------------------\n",
      "day: 61, episode: 65\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 102368.72\n",
      "total_reward: 2368.72\n",
      "total_cost: 234.11\n",
      "total_trades: 14541\n",
      "Sharpe: 0.517\n",
      "=================================\n",
      "day: 61, episode: 70\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 106886.55\n",
      "total_reward: 6886.55\n",
      "total_cost: 236.11\n",
      "total_trades: 14507\n",
      "Sharpe: 1.489\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 161      |\n",
      "|    total_reward       | 2.62e+03 |\n",
      "|    total_reward_pct   | 2.62     |\n",
      "|    total_trades       | 14526    |\n",
      "| time/                 |          |\n",
      "|    fps                | 94       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -747     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -35.4    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.00884  |\n",
      "------------------------------------\n",
      "day: 61, episode: 75\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103873.29\n",
      "total_reward: 3873.29\n",
      "total_cost: 175.34\n",
      "total_trades: 14389\n",
      "Sharpe: 0.859\n",
      "=================================\n",
      "day: 61, episode: 80\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103754.57\n",
      "total_reward: 3754.57\n",
      "total_cost: 168.68\n",
      "total_trades: 14377\n",
      "Sharpe: 0.962\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 169      |\n",
      "|    total_reward       | 3.75e+03 |\n",
      "|    total_reward_pct   | 3.75     |\n",
      "|    total_trades       | 14377    |\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -751     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 112      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.035    |\n",
      "------------------------------------\n",
      "day: 61, episode: 85\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 106464.89\n",
      "total_reward: 6464.89\n",
      "total_cost: 219.15\n",
      "total_trades: 14494\n",
      "Sharpe: 1.492\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.95e+04 |\n",
      "|    total_cost         | 176      |\n",
      "|    total_reward       | -500     |\n",
      "|    total_reward_pct   | -0.5     |\n",
      "|    total_trades       | 14467    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -754     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -102     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.0243   |\n",
      "------------------------------------\n",
      "day: 61, episode: 90\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 87499.16\n",
      "total_reward: -12500.84\n",
      "total_cost: 258.42\n",
      "total_trades: 14502\n",
      "Sharpe: -0.597\n",
      "=================================\n",
      "day: 61, episode: 95\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100786.26\n",
      "total_reward: 786.26\n",
      "total_cost: 138.27\n",
      "total_trades: 14482\n",
      "Sharpe: 0.262\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 184      |\n",
      "|    total_reward       | 2.1e+03  |\n",
      "|    total_reward_pct   | 2.1      |\n",
      "|    total_trades       | 14535    |\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -758     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -61.3    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0101   |\n",
      "------------------------------------\n",
      "day: 61, episode: 100\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99323.46\n",
      "total_reward: -676.54\n",
      "total_cost: 230.03\n",
      "total_trades: 14541\n",
      "Sharpe: -0.042\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 214      |\n",
      "|    total_reward       | 3.7e+03  |\n",
      "|    total_reward_pct   | 3.7      |\n",
      "|    total_trades       | 14551    |\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -761     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 89.1     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.0189   |\n",
      "------------------------------------\n",
      "day: 61, episode: 105\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100964.18\n",
      "total_reward: 964.18\n",
      "total_cost: 189.22\n",
      "total_trades: 14645\n",
      "Sharpe: 0.289\n",
      "=================================\n",
      "day: 61, episode: 110\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100528.97\n",
      "total_reward: 528.97\n",
      "total_cost: 329.02\n",
      "total_trades: 14593\n",
      "Sharpe: 0.216\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 235      |\n",
      "|    total_reward       | 4.32e+03 |\n",
      "|    total_reward_pct   | 4.32     |\n",
      "|    total_trades       | 14581    |\n",
      "| time/                 |          |\n",
      "|    fps                | 88       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -764     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -15.1    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.00185  |\n",
      "------------------------------------\n",
      "day: 61, episode: 115\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103172.68\n",
      "total_reward: 3172.68\n",
      "total_cost: 187.98\n",
      "total_trades: 14618\n",
      "Sharpe: 0.677\n",
      "=================================\n",
      "day: 61, episode: 120\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 104268.42\n",
      "total_reward: 4268.42\n",
      "total_cost: 272.76\n",
      "total_trades: 14566\n",
      "Sharpe: 0.862\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 273      |\n",
      "|    total_reward       | 4.27e+03 |\n",
      "|    total_reward_pct   | 4.27     |\n",
      "|    total_trades       | 14566    |\n",
      "| time/                 |          |\n",
      "|    fps                | 87       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -768     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -64.5    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.0172   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 61, episode: 125\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 109434.20\n",
      "total_reward: 9434.20\n",
      "total_cost: 214.82\n",
      "total_trades: 14777\n",
      "Sharpe: 2.198\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 253      |\n",
      "|    total_reward       | 6.33e+03 |\n",
      "|    total_reward_pct   | 6.33     |\n",
      "|    total_trades       | 14658    |\n",
      "| time/                 |          |\n",
      "|    fps                | 87       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -771     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 2.82     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.00401  |\n",
      "------------------------------------\n",
      "day: 61, episode: 130\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 109895.00\n",
      "total_reward: 9895.00\n",
      "total_cost: 212.43\n",
      "total_trades: 14585\n",
      "Sharpe: 2.217\n",
      "=================================\n",
      "day: 61, episode: 135\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 105060.72\n",
      "total_reward: 5060.72\n",
      "total_cost: 195.25\n",
      "total_trades: 14648\n",
      "Sharpe: 1.176\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 205      |\n",
      "|    total_reward       | 8.27e+03 |\n",
      "|    total_reward_pct   | 8.27     |\n",
      "|    total_trades       | 14624    |\n",
      "| time/                 |          |\n",
      "|    fps                | 86       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -774     |\n",
      "|    explained_variance | -1.39    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -529     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.589    |\n",
      "------------------------------------\n",
      "day: 61, episode: 140\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 106417.26\n",
      "total_reward: 6417.26\n",
      "total_cost: 217.68\n",
      "total_trades: 14646\n",
      "Sharpe: 1.450\n",
      "=================================\n",
      "day: 61, episode: 145\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103039.06\n",
      "total_reward: 3039.06\n",
      "total_cost: 217.19\n",
      "total_trades: 14482\n",
      "Sharpe: 0.633\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 217      |\n",
      "|    total_reward       | 3.04e+03 |\n",
      "|    total_reward_pct   | 3.04     |\n",
      "|    total_trades       | 14482    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -777     |\n",
      "|    explained_variance | 0.991    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -24.2    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.00181  |\n",
      "------------------------------------\n",
      "day: 61, episode: 150\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100993.47\n",
      "total_reward: 993.47\n",
      "total_cost: 164.93\n",
      "total_trades: 14516\n",
      "Sharpe: 0.293\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 178      |\n",
      "|    total_reward       | 3.93e+03 |\n",
      "|    total_reward_pct   | 3.93     |\n",
      "|    total_trades       | 14509    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -780     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 77.7     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.016    |\n",
      "------------------------------------\n",
      "day: 61, episode: 155\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 106701.30\n",
      "total_reward: 6701.30\n",
      "total_cost: 193.85\n",
      "total_trades: 14363\n",
      "Sharpe: 1.838\n",
      "=================================\n",
      "day: 61, episode: 160\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100493.03\n",
      "total_reward: 493.03\n",
      "total_cost: 127.23\n",
      "total_trades: 14466\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 197      |\n",
      "|    total_reward       | 6.55e+03 |\n",
      "|    total_reward_pct   | 6.55     |\n",
      "|    total_trades       | 14459    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -784     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 376      |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.237    |\n",
      "------------------------------------\n",
      "day: 61, episode: 165\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 105047.26\n",
      "total_reward: 5047.26\n",
      "total_cost: 187.03\n",
      "total_trades: 14479\n",
      "Sharpe: 1.159\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+05 |\n",
      "|    total_cost         | 198      |\n",
      "|    total_reward       | 4.68e+03 |\n",
      "|    total_reward_pct   | 4.68     |\n",
      "|    total_trades       | 14478    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -787     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 60       |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.0077   |\n",
      "------------------------------------\n",
      "day: 61, episode: 170\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 101345.87\n",
      "total_reward: 1345.87\n",
      "total_cost: 179.87\n",
      "total_trades: 14474\n",
      "Sharpe: 0.364\n",
      "=================================\n",
      "day: 61, episode: 175\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 104109.27\n",
      "total_reward: 4109.27\n",
      "total_cost: 214.85\n",
      "total_trades: 14527\n",
      "Sharpe: 0.759\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.1e+05   |\n",
      "|    total_cost         | 258       |\n",
      "|    total_reward       | 9.6e+03   |\n",
      "|    total_reward_pct   | 9.6       |\n",
      "|    total_trades       | 14439     |\n",
      "| time/                 |           |\n",
      "|    fps                | 84        |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -790      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 7.19      |\n",
      "|    std                | 1.27      |\n",
      "|    value_loss         | 0.000353  |\n",
      "-------------------------------------\n",
      "day: 61, episode: 180\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 104662.91\n",
      "total_reward: 4662.91\n",
      "total_cost: 203.62\n",
      "total_trades: 14515\n",
      "Sharpe: 1.116\n",
      "=================================\n",
      "day: 61, episode: 185\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 112810.20\n",
      "total_reward: 12810.20\n",
      "total_cost: 210.73\n",
      "total_trades: 14290\n",
      "Sharpe: 3.543\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 211      |\n",
      "|    total_reward       | 1.28e+04 |\n",
      "|    total_reward_pct   | 12.8     |\n",
      "|    total_trades       | 14290    |\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -794     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -111     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.0269   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 61, episode: 190\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100917.78\n",
      "total_reward: 917.78\n",
      "total_cost: 157.81\n",
      "total_trades: 14401\n",
      "Sharpe: 0.283\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 340      |\n",
      "|    total_reward       | 6.24e+03 |\n",
      "|    total_reward_pct   | 6.24     |\n",
      "|    total_trades       | 14351    |\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -797     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 29.9     |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.00951  |\n",
      "------------------------------------\n",
      "day: 61, episode: 195\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100541.09\n",
      "total_reward: 541.09\n",
      "total_cost: 109.50\n",
      "total_trades: 14346\n",
      "Sharpe: 0.214\n",
      "=================================\n",
      "day: 61, episode: 200\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 107701.56\n",
      "total_reward: 7701.56\n",
      "total_cost: 316.90\n",
      "total_trades: 14382\n",
      "Sharpe: 2.462\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.98e+04 |\n",
      "|    total_cost         | 104      |\n",
      "|    total_reward       | -221     |\n",
      "|    total_reward_pct   | -0.221   |\n",
      "|    total_trades       | 14484    |\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -800     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 64.3     |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.00799  |\n",
      "------------------------------------\n",
      "day: 61, episode: 205\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 113365.34\n",
      "total_reward: 13365.34\n",
      "total_cost: 366.02\n",
      "total_trades: 14382\n",
      "Sharpe: 3.209\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.04e+05  |\n",
      "|    total_cost         | 213       |\n",
      "|    total_reward       | 4.43e+03  |\n",
      "|    total_reward_pct   | 4.43      |\n",
      "|    total_trades       | 14496     |\n",
      "| time/                 |           |\n",
      "|    fps                | 83        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -804      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | -42.2     |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 0.00565   |\n",
      "-------------------------------------\n",
      "day: 61, episode: 210\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 105940.29\n",
      "total_reward: 5940.29\n",
      "total_cost: 221.28\n",
      "total_trades: 14519\n",
      "Sharpe: 1.379\n",
      "=================================\n",
      "day: 61, episode: 215\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99462.56\n",
      "total_reward: -537.44\n",
      "total_cost: 170.20\n",
      "total_trades: 14427\n",
      "Sharpe: 0.052\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.14e+05  |\n",
      "|    total_cost         | 283       |\n",
      "|    total_reward       | 1.4e+04   |\n",
      "|    total_reward_pct   | 14        |\n",
      "|    total_trades       | 14497     |\n",
      "| time/                 |           |\n",
      "|    fps                | 83        |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -807      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -121      |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 0.0246    |\n",
      "-------------------------------------\n",
      "day: 61, episode: 220\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 98943.95\n",
      "total_reward: -1056.05\n",
      "total_cost: 248.07\n",
      "total_trades: 14446\n",
      "Sharpe: -0.168\n",
      "=================================\n",
      "day: 61, episode: 225\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 108110.25\n",
      "total_reward: 8110.25\n",
      "total_cost: 202.69\n",
      "total_trades: 14455\n",
      "Sharpe: 1.677\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 203      |\n",
      "|    total_reward       | 8.11e+03 |\n",
      "|    total_reward_pct   | 8.11     |\n",
      "|    total_trades       | 14455    |\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -811     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 23.9     |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.00573  |\n",
      "------------------------------------\n",
      "day: 61, episode: 230\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 101071.18\n",
      "total_reward: 1071.18\n",
      "total_cost: 209.49\n",
      "total_trades: 14381\n",
      "Sharpe: 0.306\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 137       |\n",
      "|    total_reward       | 270       |\n",
      "|    total_reward_pct   | 0.27      |\n",
      "|    total_trades       | 14139     |\n",
      "| time/                 |           |\n",
      "|    fps                | 83        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -814      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 59.6      |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 0.00612   |\n",
      "-------------------------------------\n",
      "day: 61, episode: 235\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 109914.35\n",
      "total_reward: 9914.35\n",
      "total_cost: 258.67\n",
      "total_trades: 14278\n",
      "Sharpe: 2.009\n",
      "=================================\n",
      "day: 61, episode: 240\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 102863.72\n",
      "total_reward: 2863.72\n",
      "total_cost: 168.82\n",
      "total_trades: 14278\n",
      "Sharpe: 0.637\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+05 |\n",
      "|    total_cost         | 206      |\n",
      "|    total_reward       | 588      |\n",
      "|    total_reward_pct   | 0.588    |\n",
      "|    total_trades       | 14336    |\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -818     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -34.7    |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.012    |\n",
      "------------------------------------\n",
      "day: 61, episode: 245\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 119902.72\n",
      "total_reward: 19902.72\n",
      "total_cost: 352.69\n",
      "total_trades: 14261\n",
      "Sharpe: 5.085\n",
      "=================================\n",
      "day: 61, episode: 250\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 102695.38\n",
      "total_reward: 2695.38\n",
      "total_cost: 290.87\n",
      "total_trades: 14306\n",
      "Sharpe: 0.581\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 291      |\n",
      "|    total_reward       | 2.7e+03  |\n",
      "|    total_reward_pct   | 2.7      |\n",
      "|    total_trades       | 14306    |\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -821     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 70.2     |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.0107   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 61, episode: 255\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103055.34\n",
      "total_reward: 3055.34\n",
      "total_cost: 181.39\n",
      "total_trades: 14262\n",
      "Sharpe: 0.632\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 192      |\n",
      "|    total_reward       | 2.71e+03 |\n",
      "|    total_reward_pct   | 2.71     |\n",
      "|    total_trades       | 14258    |\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -824     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 90.3     |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.0139   |\n",
      "------------------------------------\n",
      "day: 61, episode: 260\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 101280.15\n",
      "total_reward: 1280.15\n",
      "total_cost: 167.78\n",
      "total_trades: 14094\n",
      "Sharpe: 0.333\n",
      "=================================\n",
      "day: 61, episode: 265\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 105680.65\n",
      "total_reward: 5680.65\n",
      "total_cost: 278.95\n",
      "total_trades: 14216\n",
      "Sharpe: 1.132\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+05 |\n",
      "|    total_cost         | 331      |\n",
      "|    total_reward       | 1.51e+04 |\n",
      "|    total_reward_pct   | 15.1     |\n",
      "|    total_trades       | 14213    |\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -828     |\n",
      "|    explained_variance | 0.298    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -294     |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 0.27     |\n",
      "------------------------------------\n",
      "day: 61, episode: 270\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 102228.36\n",
      "total_reward: 2228.36\n",
      "total_cost: 168.14\n",
      "total_trades: 14244\n",
      "Sharpe: 0.543\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.02e+05  |\n",
      "|    total_cost         | 242       |\n",
      "|    total_reward       | 2.13e+03  |\n",
      "|    total_reward_pct   | 2.13      |\n",
      "|    total_trades       | 14232     |\n",
      "| time/                 |           |\n",
      "|    fps                | 82        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 206       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -832      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 125       |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 0.0238    |\n",
      "-------------------------------------\n",
      "day: 61, episode: 275\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 104929.01\n",
      "total_reward: 4929.01\n",
      "total_cost: 335.19\n",
      "total_trades: 14271\n",
      "Sharpe: 1.038\n",
      "=================================\n",
      "day: 61, episode: 280\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 102802.22\n",
      "total_reward: 2802.22\n",
      "total_cost: 270.56\n",
      "total_trades: 14272\n",
      "Sharpe: 0.585\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.89e+04 |\n",
      "|    total_cost         | 205      |\n",
      "|    total_reward       | -1.1e+03 |\n",
      "|    total_reward_pct   | -1.1     |\n",
      "|    total_trades       | 14194    |\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -835     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 177      |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.053    |\n",
      "------------------------------------\n",
      "day: 61, episode: 285\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 104500.73\n",
      "total_reward: 4500.73\n",
      "total_cost: 195.88\n",
      "total_trades: 14165\n",
      "Sharpe: 1.064\n",
      "=================================\n",
      "day: 61, episode: 290\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 115679.47\n",
      "total_reward: 15679.47\n",
      "total_cost: 266.92\n",
      "total_trades: 14360\n",
      "Sharpe: 4.043\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.16e+05 |\n",
      "|    total_cost         | 267      |\n",
      "|    total_reward       | 1.57e+04 |\n",
      "|    total_reward_pct   | 15.7     |\n",
      "|    total_trades       | 14360    |\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -838     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 190      |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "day: 61, episode: 295\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 104956.08\n",
      "total_reward: 4956.08\n",
      "total_cost: 235.94\n",
      "total_trades: 14378\n",
      "Sharpe: 0.887\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.94e+04  |\n",
      "|    total_cost         | 320       |\n",
      "|    total_reward       | -642      |\n",
      "|    total_reward_pct   | -0.642    |\n",
      "|    total_trades       | 14259     |\n",
      "| time/                 |           |\n",
      "|    fps                | 82        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -842      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 54.4      |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 0.00647   |\n",
      "-------------------------------------\n",
      "day: 61, episode: 300\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103960.06\n",
      "total_reward: 3960.06\n",
      "total_cost: 149.12\n",
      "total_trades: 14360\n",
      "Sharpe: 0.873\n",
      "=================================\n",
      "day: 61, episode: 305\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103843.68\n",
      "total_reward: 3843.68\n",
      "total_cost: 185.87\n",
      "total_trades: 14440\n",
      "Sharpe: 0.792\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 171      |\n",
      "|    total_reward       | 2.55e+03 |\n",
      "|    total_reward_pct   | 2.55     |\n",
      "|    total_trades       | 14456    |\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -846     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 21.4     |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.00424  |\n",
      "------------------------------------\n",
      "day: 61, episode: 310\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 106796.97\n",
      "total_reward: 6796.97\n",
      "total_cost: 185.30\n",
      "total_trades: 14401\n",
      "Sharpe: 1.355\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 240      |\n",
      "|    total_reward       | 5.83e+03 |\n",
      "|    total_reward_pct   | 5.83     |\n",
      "|    total_trades       | 14333    |\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -849     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -24.2    |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 0.0114   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 61, episode: 315\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 98058.59\n",
      "total_reward: -1941.41\n",
      "total_cost: 286.62\n",
      "total_trades: 14451\n",
      "Sharpe: -0.180\n",
      "=================================\n",
      "day: 61, episode: 320\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103031.73\n",
      "total_reward: 3031.73\n",
      "total_cost: 277.39\n",
      "total_trades: 14417\n",
      "Sharpe: 0.586\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.95e+04 |\n",
      "|    total_cost         | 124      |\n",
      "|    total_reward       | -500     |\n",
      "|    total_reward_pct   | -0.5     |\n",
      "|    total_trades       | 14348    |\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -852     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 34.7     |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.00676  |\n",
      "------------------------------------\n",
      "day: 61, episode: 325\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103095.51\n",
      "total_reward: 3095.51\n",
      "total_cost: 202.87\n",
      "total_trades: 14318\n",
      "Sharpe: 0.792\n",
      "=================================\n",
      "day: 61, episode: 330\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 110066.14\n",
      "total_reward: 10066.14\n",
      "total_cost: 190.93\n",
      "total_trades: 14263\n",
      "Sharpe: 2.697\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+05  |\n",
      "|    total_cost         | 191      |\n",
      "|    total_reward       | 1.01e+04 |\n",
      "|    total_reward_pct   | 10.1     |\n",
      "|    total_trades       | 14263    |\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -856     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 140      |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.0485   |\n",
      "------------------------------------\n",
      "day: 61, episode: 335\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 113577.31\n",
      "total_reward: 13577.31\n",
      "total_cost: 258.80\n",
      "total_trades: 14117\n",
      "Sharpe: 2.964\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 269      |\n",
      "|    total_reward       | 1.34e+04 |\n",
      "|    total_reward_pct   | 13.4     |\n",
      "|    total_trades       | 14271    |\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -859     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -92.3    |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.0158   |\n",
      "------------------------------------\n",
      "day: 61, episode: 340\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 104574.89\n",
      "total_reward: 4574.89\n",
      "total_cost: 237.82\n",
      "total_trades: 14146\n",
      "Sharpe: 0.839\n",
      "=================================\n",
      "day: 61, episode: 345\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100045.91\n",
      "total_reward: 45.91\n",
      "total_cost: 142.83\n",
      "total_trades: 14302\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.61e+04  |\n",
      "|    total_cost         | 317       |\n",
      "|    total_reward       | -3.92e+03 |\n",
      "|    total_reward_pct   | -3.92     |\n",
      "|    total_trades       | 14336     |\n",
      "| time/                 |           |\n",
      "|    fps                | 82        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -862      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | -96.6     |\n",
      "|    std                | 1.47      |\n",
      "|    value_loss         | 0.0167    |\n",
      "-------------------------------------\n",
      "day: 61, episode: 350\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 107108.89\n",
      "total_reward: 7108.89\n",
      "total_cost: 300.90\n",
      "total_trades: 14240\n",
      "Sharpe: 1.572\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+05 |\n",
      "|    total_cost         | 266      |\n",
      "|    total_reward       | 1.22e+04 |\n",
      "|    total_reward_pct   | 12.2     |\n",
      "|    total_trades       | 14147    |\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -865     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 211      |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.0774   |\n",
      "------------------------------------\n",
      "day: 61, episode: 355\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 112885.80\n",
      "total_reward: 12885.80\n",
      "total_cost: 285.09\n",
      "total_trades: 14287\n",
      "Sharpe: 2.833\n",
      "=================================\n",
      "day: 61, episode: 360\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 106243.93\n",
      "total_reward: 6243.93\n",
      "total_cost: 249.58\n",
      "total_trades: 14298\n",
      "Sharpe: 1.552\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.96e+04 |\n",
      "|    total_cost         | 210      |\n",
      "|    total_reward       | -431     |\n",
      "|    total_reward_pct   | -0.431   |\n",
      "|    total_trades       | 14361    |\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -869     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 1.56     |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.00187  |\n",
      "------------------------------------\n",
      "day: 61, episode: 365\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 107533.85\n",
      "total_reward: 7533.85\n",
      "total_cost: 272.81\n",
      "total_trades: 14240\n",
      "Sharpe: 2.169\n",
      "=================================\n",
      "day: 61, episode: 370\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99912.08\n",
      "total_reward: -87.92\n",
      "total_cost: 101.14\n",
      "total_trades: 14242\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.99e+04 |\n",
      "|    total_cost         | 101      |\n",
      "|    total_reward       | -87.9    |\n",
      "|    total_reward_pct   | -0.0879  |\n",
      "|    total_trades       | 14242    |\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -872     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -88      |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.0204   |\n",
      "------------------------------------\n",
      "day: 61, episode: 375\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99890.64\n",
      "total_reward: -109.36\n",
      "total_cost: 198.48\n",
      "total_trades: 14320\n",
      "Sharpe: 0.130\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.11e+05  |\n",
      "|    total_cost         | 234       |\n",
      "|    total_reward       | 1.11e+04  |\n",
      "|    total_reward_pct   | 11.1      |\n",
      "|    total_trades       | 14335     |\n",
      "| time/                 |           |\n",
      "|    fps                | 84        |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 279       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -875      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | -9.05     |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 0.00378   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 61, episode: 380\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 105203.95\n",
      "total_reward: 5203.95\n",
      "total_cost: 173.13\n",
      "total_trades: 14219\n",
      "Sharpe: 1.215\n",
      "=================================\n",
      "day: 61, episode: 385\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 109117.15\n",
      "total_reward: 9117.15\n",
      "total_cost: 206.84\n",
      "total_trades: 14122\n",
      "Sharpe: 2.191\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 229      |\n",
      "|    total_reward       | 4.22e+03 |\n",
      "|    total_reward_pct   | 4.22     |\n",
      "|    total_trades       | 14111    |\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -879     |\n",
      "|    explained_variance | -0.672   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -583     |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.49     |\n",
      "------------------------------------\n",
      "day: 61, episode: 390\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 106539.01\n",
      "total_reward: 6539.01\n",
      "total_cost: 202.95\n",
      "total_trades: 14256\n",
      "Sharpe: 1.572\n",
      "=================================\n",
      "day: 61, episode: 395\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 106492.64\n",
      "total_reward: 6492.64\n",
      "total_cost: 190.02\n",
      "total_trades: 14170\n",
      "Sharpe: 1.799\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 190      |\n",
      "|    total_reward       | 6.49e+03 |\n",
      "|    total_reward_pct   | 6.49     |\n",
      "|    total_trades       | 14170    |\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 289      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -882     |\n",
      "|    explained_variance | 0.838    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 61.2     |\n",
      "|    std                | 1.53     |\n",
      "|    value_loss         | 0.0142   |\n",
      "------------------------------------\n",
      "day: 61, episode: 400\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103557.71\n",
      "total_reward: 3557.71\n",
      "total_cost: 239.53\n",
      "total_trades: 14250\n",
      "Sharpe: 0.646\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+05 |\n",
      "|    total_cost         | 233      |\n",
      "|    total_reward       | 5.42e+03 |\n",
      "|    total_reward_pct   | 5.42     |\n",
      "|    total_trades       | 14298    |\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -885     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 72.2     |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 0.00967  |\n",
      "------------------------------------\n",
      "day: 61, episode: 405\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 98851.88\n",
      "total_reward: -1148.12\n",
      "total_cost: 222.49\n",
      "total_trades: 14242\n",
      "Sharpe: -0.030\n",
      "=================================\n",
      "day: 61, episode: 410\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 109934.79\n",
      "total_reward: 9934.79\n",
      "total_cost: 243.49\n",
      "total_trades: 14278\n",
      "Sharpe: 1.857\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+05 |\n",
      "|    total_cost         | 228      |\n",
      "|    total_reward       | 5.26e+03 |\n",
      "|    total_reward_pct   | 5.26     |\n",
      "|    total_trades       | 14334    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 299      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -889     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 378      |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.195    |\n",
      "------------------------------------\n",
      "day: 61, episode: 415\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99253.59\n",
      "total_reward: -746.41\n",
      "total_cost: 184.13\n",
      "total_trades: 14298\n",
      "Sharpe: 0.043\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.99e+04 |\n",
      "|    total_cost         | 101      |\n",
      "|    total_reward       | -83.8    |\n",
      "|    total_reward_pct   | -0.0838  |\n",
      "|    total_trades       | 14323    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -892     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 57.6     |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 0.0108   |\n",
      "------------------------------------\n",
      "day: 61, episode: 420\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103578.89\n",
      "total_reward: 3578.89\n",
      "total_cost: 204.95\n",
      "total_trades: 14190\n",
      "Sharpe: 0.652\n",
      "=================================\n",
      "day: 61, episode: 425\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 112430.65\n",
      "total_reward: 12430.65\n",
      "total_cost: 215.03\n",
      "total_trades: 14341\n",
      "Sharpe: 3.222\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 148      |\n",
      "|    total_reward       | 2.62e+03 |\n",
      "|    total_reward_pct   | 2.62     |\n",
      "|    total_trades       | 14241    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 309      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -895     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -111     |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.017    |\n",
      "------------------------------------\n",
      "day: 61, episode: 430\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 107075.87\n",
      "total_reward: 7075.87\n",
      "total_cost: 301.55\n",
      "total_trades: 14307\n",
      "Sharpe: 1.546\n",
      "=================================\n",
      "day: 61, episode: 435\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 106907.96\n",
      "total_reward: 6907.96\n",
      "total_cost: 240.15\n",
      "total_trades: 14299\n",
      "Sharpe: 1.180\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.07e+05  |\n",
      "|    total_cost         | 240       |\n",
      "|    total_reward       | 6.91e+03  |\n",
      "|    total_reward_pct   | 6.91      |\n",
      "|    total_trades       | 14299     |\n",
      "| time/                 |           |\n",
      "|    fps                | 85        |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 315       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -898      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -91.1     |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 0.013     |\n",
      "-------------------------------------\n",
      "day: 61, episode: 440\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 111411.93\n",
      "total_reward: 11411.93\n",
      "total_cost: 288.59\n",
      "total_trades: 14425\n",
      "Sharpe: 2.518\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.03e+05  |\n",
      "|    total_cost         | 149       |\n",
      "|    total_reward       | 2.61e+03  |\n",
      "|    total_reward_pct   | 2.61      |\n",
      "|    total_trades       | 14213     |\n",
      "| time/                 |           |\n",
      "|    fps                | 85        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 320       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -901      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | 61        |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 0.0149    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 61, episode: 445\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 110061.71\n",
      "total_reward: 10061.71\n",
      "total_cost: 208.20\n",
      "total_trades: 14254\n",
      "Sharpe: 2.169\n",
      "=================================\n",
      "day: 61, episode: 450\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 107791.97\n",
      "total_reward: 7791.97\n",
      "total_cost: 202.87\n",
      "total_trades: 14288\n",
      "Sharpe: 1.958\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 224      |\n",
      "|    total_reward       | 8.44e+03 |\n",
      "|    total_reward_pct   | 8.44     |\n",
      "|    total_trades       | 14386    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 328      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -904     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 76.2     |\n",
      "|    std                | 1.61     |\n",
      "|    value_loss         | 0.0131   |\n",
      "------------------------------------\n",
      "day: 61, episode: 455\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 101466.72\n",
      "total_reward: 1466.72\n",
      "total_cost: 185.71\n",
      "total_trades: 14365\n",
      "Sharpe: 0.374\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+05 |\n",
      "|    total_cost         | 222      |\n",
      "|    total_reward       | 4.8e+03  |\n",
      "|    total_reward_pct   | 4.8      |\n",
      "|    total_trades       | 14441    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -908     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -69.7    |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.00918  |\n",
      "------------------------------------\n",
      "day: 61, episode: 460\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 104059.59\n",
      "total_reward: 4059.59\n",
      "total_cost: 216.22\n",
      "total_trades: 14399\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "day: 61, episode: 465\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 103731.92\n",
      "total_reward: 3731.92\n",
      "total_cost: 313.58\n",
      "total_trades: 14451\n",
      "Sharpe: 0.685\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 188      |\n",
      "|    total_reward       | 395      |\n",
      "|    total_reward_pct   | 0.395    |\n",
      "|    total_trades       | 14346    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 338      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -911     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -150     |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 0.032    |\n",
      "------------------------------------\n",
      "day: 61, episode: 470\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 94944.23\n",
      "total_reward: -5055.77\n",
      "total_cost: 314.93\n",
      "total_trades: 14387\n",
      "Sharpe: -0.676\n",
      "=================================\n",
      "day: 61, episode: 475\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99705.56\n",
      "total_reward: -294.44\n",
      "total_cost: 200.66\n",
      "total_trades: 14394\n",
      "Sharpe: 0.022\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.97e+04  |\n",
      "|    total_cost         | 201       |\n",
      "|    total_reward       | -294      |\n",
      "|    total_reward_pct   | -0.294    |\n",
      "|    total_trades       | 14394     |\n",
      "| time/                 |           |\n",
      "|    fps                | 85        |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 344       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -915      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | 77.6      |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 0.00903   |\n",
      "-------------------------------------\n",
      "day: 61, episode: 480\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 102279.43\n",
      "total_reward: 2279.43\n",
      "total_cost: 271.77\n",
      "total_trades: 14516\n",
      "Sharpe: 0.570\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+05 |\n",
      "|    total_cost         | 416      |\n",
      "|    total_reward       | 825      |\n",
      "|    total_reward_pct   | 0.825    |\n",
      "|    total_trades       | 14405    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 350      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -919     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 90       |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 0.0185   |\n",
      "------------------------------------\n",
      "======Trading from:  2021-05-04 to  2021-07-06\n",
      "['/Users/quanphan/Documents/Project Development/finrl_adopt_application/results/actions_trade_ensemble_daily.csv']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'alpaca_trade_api' has no attribute 'submit_order'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-378ce8e58a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mactions_trade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_latest_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'actions_trade_ensemble*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mperform_trade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions_trade\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactions_trade\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-94-78d383d4f30b>\u001b[0m in \u001b[0;36mperform_trade\u001b[0;34m(actions_trade)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions_trade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mactions_trade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             api.submit_order(\n\u001b[0m\u001b[1;32m      6\u001b[0m                 \u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mqty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions_trade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'alpaca_trade_api' has no attribute 'submit_order'"
     ]
    }
   ],
   "source": [
    "# daily_processed_df, raw_recent = refresh_daily_data(train_start, today)\n",
    "daily_predict(daily_processed_df, raw_recent, init_thresh)\n",
    "\n",
    "actions_trade = pd.read_csv(get_latest_file('results','actions_trade_ensemble*'))\n",
    "perform_trade(actions_trade=actions_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7f18cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/quanphan/Documents/Project Development/finrl_adopt_application/results/actions_trade_ensemble_daily.csv']\n"
     ]
    }
   ],
   "source": [
    "actions_trade = pd.read_csv(get_latest_file('results','actions_trade_ensemble*'))\n",
    "perform_trade(actions_trade=actions_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8b30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
