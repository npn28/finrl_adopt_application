{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL/blob/master/FinRL_ensemble_stock_trading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "dcf73e63-fece-409e-e887-2d33774cdf94"
   },
   "outputs": [],
   "source": [
    "## install finrl library\n",
    "# !pip3 install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/evienguyen/Documents/FinRL/FinRL',\n",
       " '/usr/local/Cellar/python@3.9/3.9.1_6/Frameworks/Python.framework/Versions/3.9/lib/python39.zip',\n",
       " '/usr/local/Cellar/python@3.9/3.9.1_6/Frameworks/Python.framework/Versions/3.9/lib/python3.9',\n",
       " '/usr/local/Cellar/python@3.9/3.9.1_6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/Users/evienguyen/Library/Python/3.9/lib/python/site-packages',\n",
       " '/usr/local/lib/python3.9/site-packages',\n",
       " '/Users/evienguyen/Library/Python/3.9/lib/python/site-packages/IPython/extensions',\n",
       " '/Users/evienguyen/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/evienguyen/Documents/FinRL/FinRL/finrl'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble_agent.print_test()\n",
    "import os\n",
    "os.chdir('/Users/evienguyen/Documents/FinRL/FinRL/finrl')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.trade.backtest import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DRL_prediction', 'DRL_validation', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'get_model', 'get_validation_sharpe', 'print_test', 'run_ensemble_strategy', 'train_model']\n"
     ]
    }
   ],
   "source": [
    " print (dir(DRLEnsembleAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Users/evienguyen/Documents/FinRL/FinRL/finrl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "fe5cd33c-9434-4372-b836-622a50f0d3d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000-01-01'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "a42433a2-c7c9-4c06-b53f-28723b4957af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'MSFT', 'JPM', 'V', 'RTX', 'PG', 'GS', 'NKE', 'DIS', 'AXP', 'HD', 'INTC', 'WMT', 'IBM', 'MRK', 'UNH', 'KO', 'CAT', 'TRV', 'JNJ', 'CVX', 'MCD', 'VZ', 'CSCO', 'XOM', 'BA', 'MMM', 'PFE', 'WBA', 'DD']\n"
     ]
    }
   ],
   "source": [
    "print(config.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "b9293979-3d5b-48f6-9b99-6facf5bc5f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (93960, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = '2009-01-01',\n",
    "                     end_date = '2021-06-14',\n",
    "                     ticker_list = config.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "GiRuFOTOtj1Y",
    "outputId": "015897f3-d0d9-49d6-a28d-d2888e3c7a1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.787006</td>\n",
       "      <td>746015200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>19.520000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>15.698216</td>\n",
       "      <td>10955700.0</td>\n",
       "      <td>AXP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>42.799999</td>\n",
       "      <td>45.560001</td>\n",
       "      <td>42.779999</td>\n",
       "      <td>33.941101</td>\n",
       "      <td>7010200.0</td>\n",
       "      <td>BA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>44.910000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>44.709999</td>\n",
       "      <td>32.830360</td>\n",
       "      <td>7117200.0</td>\n",
       "      <td>CAT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>12.592946</td>\n",
       "      <td>40980600.0</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close       volume   tic  \\\n",
       "0  2009-01-02   3.067143   3.251429   3.041429   2.787006  746015200.0  AAPL   \n",
       "1  2009-01-02  18.570000  19.520000  18.400000  15.698216   10955700.0   AXP   \n",
       "2  2009-01-02  42.799999  45.560001  42.779999  33.941101    7010200.0    BA   \n",
       "3  2009-01-02  44.910000  46.980000  44.709999  32.830360    7117200.0   CAT   \n",
       "4  2009-01-02  16.410000  17.000000  16.250000  12.592946   40980600.0  CSCO   \n",
       "\n",
       "   day  \n",
       "0    4  \n",
       "1    4  \n",
       "2    4  \n",
       "3    4  \n",
       "4    4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "DSw4ZEzVtj1Z",
    "outputId": "517b31f3-e7b4-419b-9322-517babcd5546"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93955</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>234.389999</td>\n",
       "      <td>235.440002</td>\n",
       "      <td>233.710007</td>\n",
       "      <td>234.960007</td>\n",
       "      <td>5376500.0</td>\n",
       "      <td>V</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93956</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>57.490002</td>\n",
       "      <td>57.549999</td>\n",
       "      <td>57.009998</td>\n",
       "      <td>57.330002</td>\n",
       "      <td>12924100.0</td>\n",
       "      <td>VZ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93957</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>55.820000</td>\n",
       "      <td>54.810001</td>\n",
       "      <td>55.310001</td>\n",
       "      <td>3942600.0</td>\n",
       "      <td>WBA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93958</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>140.229996</td>\n",
       "      <td>140.850006</td>\n",
       "      <td>139.860001</td>\n",
       "      <td>140.750000</td>\n",
       "      <td>8408800.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93959</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>63.009998</td>\n",
       "      <td>63.189999</td>\n",
       "      <td>62.139999</td>\n",
       "      <td>62.169998</td>\n",
       "      <td>17618900.0</td>\n",
       "      <td>XOM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date        open        high         low       close      volume  \\\n",
       "93955  2021-06-11  234.389999  235.440002  233.710007  234.960007   5376500.0   \n",
       "93956  2021-06-11   57.490002   57.549999   57.009998   57.330002  12924100.0   \n",
       "93957  2021-06-11   55.580002   55.820000   54.810001   55.310001   3942600.0   \n",
       "93958  2021-06-11  140.229996  140.850006  139.860001  140.750000   8408800.0   \n",
       "93959  2021-06-11   63.009998   63.189999   62.139999   62.169998  17618900.0   \n",
       "\n",
       "       tic  day  \n",
       "93955    V    4  \n",
       "93956   VZ    4  \n",
       "93957  WBA    4  \n",
       "93958  WMT    4  \n",
       "93959  XOM    4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "45525740-8ce0-4031-c2c5-bfd6a7a1cd7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93960, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "4hYkeaPiICHS",
    "outputId": "26d3122c-f143-4671-8891-4ac5ce27d2e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.787006</td>\n",
       "      <td>746015200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>19.520000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>15.698216</td>\n",
       "      <td>10955700.0</td>\n",
       "      <td>AXP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>42.799999</td>\n",
       "      <td>45.560001</td>\n",
       "      <td>42.779999</td>\n",
       "      <td>33.941101</td>\n",
       "      <td>7010200.0</td>\n",
       "      <td>BA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>44.910000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>44.709999</td>\n",
       "      <td>32.830360</td>\n",
       "      <td>7117200.0</td>\n",
       "      <td>CAT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>12.592946</td>\n",
       "      <td>40980600.0</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close       volume   tic  \\\n",
       "0  2009-01-02   3.067143   3.251429   3.041429   2.787006  746015200.0  AAPL   \n",
       "1  2009-01-02  18.570000  19.520000  18.400000  15.698216   10955700.0   AXP   \n",
       "2  2009-01-02  42.799999  45.560001  42.779999  33.941101    7010200.0    BA   \n",
       "3  2009-01-02  44.910000  46.980000  44.709999  32.830360    7117200.0   CAT   \n",
       "4  2009-01-02  16.410000  17.000000  16.250000  12.592946   40980600.0  CSCO   \n",
       "\n",
       "   day  \n",
       "0    4  \n",
       "1    4  \n",
       "2    4  \n",
       "3    4  \n",
       "4    4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgXfBcjxtj1a",
    "outputId": "1a887a88-8cb0-4d02-c518-374278251850",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "R_3v-ycktj1b"
   },
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "grvhGJJII3Xn",
    "outputId": "eded8f63-ac44-4a51-f2bb-4a54a07cbd11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24693</th>\n",
       "      <td>2011-04-05</td>\n",
       "      <td>CAT</td>\n",
       "      <td>112.970001</td>\n",
       "      <td>113.160004</td>\n",
       "      <td>111.910004</td>\n",
       "      <td>84.560265</td>\n",
       "      <td>5338700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.299634</td>\n",
       "      <td>87.505242</td>\n",
       "      <td>73.049325</td>\n",
       "      <td>64.641667</td>\n",
       "      <td>126.048630</td>\n",
       "      <td>27.799825</td>\n",
       "      <td>79.114903</td>\n",
       "      <td>76.458168</td>\n",
       "      <td>20.292536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>2011-03-24</td>\n",
       "      <td>PFE</td>\n",
       "      <td>18.975332</td>\n",
       "      <td>19.316889</td>\n",
       "      <td>18.795067</td>\n",
       "      <td>13.207226</td>\n",
       "      <td>52057692.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.198473</td>\n",
       "      <td>13.253991</td>\n",
       "      <td>12.295813</td>\n",
       "      <td>63.123851</td>\n",
       "      <td>136.845186</td>\n",
       "      <td>42.749706</td>\n",
       "      <td>12.644674</td>\n",
       "      <td>12.254671</td>\n",
       "      <td>23.161591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42987</th>\n",
       "      <td>2012-12-04</td>\n",
       "      <td>WBA</td>\n",
       "      <td>34.279999</td>\n",
       "      <td>34.570000</td>\n",
       "      <td>34.110001</td>\n",
       "      <td>27.658207</td>\n",
       "      <td>7172000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.107974</td>\n",
       "      <td>27.725511</td>\n",
       "      <td>25.638209</td>\n",
       "      <td>51.229074</td>\n",
       "      <td>31.613873</td>\n",
       "      <td>21.146905</td>\n",
       "      <td>27.212261</td>\n",
       "      <td>27.981085</td>\n",
       "      <td>20.886531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53075</th>\n",
       "      <td>2013-11-06</td>\n",
       "      <td>CVX</td>\n",
       "      <td>119.300003</td>\n",
       "      <td>121.410004</td>\n",
       "      <td>118.820000</td>\n",
       "      <td>87.153542</td>\n",
       "      <td>8373200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.183056</td>\n",
       "      <td>87.892443</td>\n",
       "      <td>83.998732</td>\n",
       "      <td>51.535965</td>\n",
       "      <td>39.704693</td>\n",
       "      <td>0.493765</td>\n",
       "      <td>86.000267</td>\n",
       "      <td>86.811443</td>\n",
       "      <td>34.394919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25784</th>\n",
       "      <td>2011-05-11</td>\n",
       "      <td>KO</td>\n",
       "      <td>33.645000</td>\n",
       "      <td>33.834999</td>\n",
       "      <td>33.450001</td>\n",
       "      <td>24.460611</td>\n",
       "      <td>11215400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.094132</td>\n",
       "      <td>24.812551</td>\n",
       "      <td>24.186423</td>\n",
       "      <td>56.335844</td>\n",
       "      <td>0.775246</td>\n",
       "      <td>7.320447</td>\n",
       "      <td>24.464363</td>\n",
       "      <td>23.858302</td>\n",
       "      <td>66.918068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  tic        open        high         low      close  \\\n",
       "24693  2011-04-05  CAT  112.970001  113.160004  111.910004  84.560265   \n",
       "24350  2011-03-24  PFE   18.975332   19.316889   18.795067  13.207226   \n",
       "42987  2012-12-04  WBA   34.279999   34.570000   34.110001  27.658207   \n",
       "53075  2013-11-06  CVX  119.300003  121.410004  118.820000  87.153542   \n",
       "25784  2011-05-11   KO   33.645000   33.834999   33.450001  24.460611   \n",
       "\n",
       "           volume  day      macd    boll_ub    boll_lb     rsi_30      cci_30  \\\n",
       "24693   5338700.0  1.0  2.299634  87.505242  73.049325  64.641667  126.048630   \n",
       "24350  52057692.0  3.0  0.198473  13.253991  12.295813  63.123851  136.845186   \n",
       "42987   7172000.0  1.0 -0.107974  27.725511  25.638209  51.229074   31.613873   \n",
       "53075   8373200.0  2.0 -0.183056  87.892443  83.998732  51.535965   39.704693   \n",
       "25784  11215400.0  2.0  0.094132  24.812551  24.186423  56.335844    0.775246   \n",
       "\n",
       "           dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "24693  27.799825     79.114903     76.458168   20.292536  \n",
       "24350  42.749706     12.644674     12.254671   23.161591  \n",
       "42987  21.146905     27.212261     27.981085   20.886531  \n",
       "53075   0.493765     86.000267     86.811443   34.394919  \n",
       "25784   7.320447     24.464363     23.858302   66.918068  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_full_copy = processed_full\n",
    "processed_full_copy.set_index('date',inplace=True)\n",
    "%matplotlib inline\n",
    "processed_full_copy.turbulence.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "80acc632-dbc2-4de7-b9cd-0685b130fe42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "85af7d0d-3cf3-4473-a62d-e9712c92fe44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, State Space: 301\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001, \n",
    "    \"sell_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_full.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "v-gthCxMtj1d"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "train_start = '2009-01-01'\n",
    "train_end = '2015-10-01'\n",
    "val_test_start = '2015-10-01'\n",
    "val_test_end = '2021-06-14'\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed_full,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KsfEHa_Etj1d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.0005\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      \"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 50_000,\n",
    "                      \"learning_rate\": 0.000005,\n",
    "                      \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 30_000, \n",
    "                 'ppo' : 100_000, \n",
    "                 'ddpg' : 10_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1lyCECstj1e",
    "outputId": "940e556d-8fbd-4112-c463-b155f6a0f581",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "39.45621665227606\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2015-10-02\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_5\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.745   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -114     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.961   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -82.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0666  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -303     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 54.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.52e+06 |\n",
      "|    total_cost         | 8.72e+04 |\n",
      "|    total_reward       | 1.52e+06 |\n",
      "|    total_reward_pct   | 152      |\n",
      "|    total_trades       | 43405    |\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.211    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 38.2     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 17.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.288    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 82.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.48e+06 |\n",
      "|    total_cost         | 3.34e+04 |\n",
      "|    total_reward       | 1.48e+06 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 33596    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0937   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -41.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -97.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0299  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 111      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0521  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 62.2     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.61e+06 |\n",
      "|    total_cost         | 1.56e+04 |\n",
      "|    total_reward       | 1.61e+06 |\n",
      "|    total_reward_pct   | 161      |\n",
      "|    total_trades       | 29842    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 15.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.944    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.18    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 162      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 15.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 39.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.48     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.54e+06 |\n",
      "|    total_cost         | 1e+04    |\n",
      "|    total_reward       | 1.54e+06 |\n",
      "|    total_reward_pct   | 154      |\n",
      "|    total_trades       | 28747    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 50.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 199      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 30.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -125     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.71     |\n",
      "------------------------------------\n",
      "day: 1698, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2479585.26\n",
      "total_reward: 1479585.26\n",
      "total_cost: 7195.89\n",
      "total_trades: 27076\n",
      "Sharpe: 0.851\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.48e+06 |\n",
      "|    total_cost         | 7.2e+03  |\n",
      "|    total_reward       | 1.48e+06 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 27076    |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -332     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 66.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 13.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.228    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -32.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0214  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 26.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 18.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.52e+06 |\n",
      "|    total_cost         | 5.68e+03 |\n",
      "|    total_reward       | 1.52e+06 |\n",
      "|    total_reward_pct   | 152      |\n",
      "|    total_trades       | 25487    |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 50.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0309   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -12.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.11     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 75.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.44      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.59e+06 |\n",
      "|    total_cost         | 5.57e+03 |\n",
      "|    total_reward       | 1.59e+06 |\n",
      "|    total_reward_pct   | 159      |\n",
      "|    total_trades       | 24435    |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00551 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 152      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -85.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.81     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 97.5      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.54      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 33.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.13e+06 |\n",
      "|    total_cost         | 3.55e+03 |\n",
      "|    total_reward       | 1.13e+06 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 24124    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -8.81    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.141    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0457  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -114     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0214   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -441     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 99.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.14e+06 |\n",
      "|    total_cost         | 3.74e+03 |\n",
      "|    total_reward       | 1.14e+06 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 24961    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -40.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.00721  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 120      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 93.5      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 16.4      |\n",
      "-------------------------------------\n",
      "day: 1698, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2277525.63\n",
      "total_reward: 1277525.63\n",
      "total_cost: 5767.96\n",
      "total_trades: 25700\n",
      "Sharpe: 0.747\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.28e+06 |\n",
      "|    total_cost         | 5.77e+03 |\n",
      "|    total_reward       | 1.28e+06 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 25700    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -33.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.14     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 44.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0283  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 26.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.00775 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 148      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 23       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.43e+06 |\n",
      "|    total_cost         | 4.41e+04 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 143      |\n",
      "|    total_trades       | 35400    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -1.65    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 58.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 157      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 18.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -234     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 29.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.17e+06 |\n",
      "|    total_cost         | 2.43e+04 |\n",
      "|    total_reward       | 2.17e+06 |\n",
      "|    total_reward_pct   | 217      |\n",
      "|    total_trades       | 29252    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 5.44     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.407    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -109     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -69.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -32.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.732    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.11e+06  |\n",
      "|    total_cost         | 2.24e+04  |\n",
      "|    total_reward       | 3.11e+06  |\n",
      "|    total_reward_pct   | 311       |\n",
      "|    total_trades       | 28464     |\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -8.49     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.99      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.91     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -35.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.35e+06 |\n",
      "|    total_cost         | 1.08e+04 |\n",
      "|    total_reward       | 2.35e+06 |\n",
      "|    total_reward_pct   | 235      |\n",
      "|    total_trades       | 26477    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.0136  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -156     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 68.9      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 18.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 195      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 28       |\n",
      "------------------------------------\n",
      "day: 1698, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3034787.24\n",
      "total_reward: 2034787.24\n",
      "total_cost: 6180.52\n",
      "total_trades: 24461\n",
      "Sharpe: 0.963\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.03e+06 |\n",
      "|    total_cost         | 6.18e+03 |\n",
      "|    total_reward       | 2.03e+06 |\n",
      "|    total_reward_pct   | 203      |\n",
      "|    total_trades       | 24461    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -1.98    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0429   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -6.51    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.462    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -1.86    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -154     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 14.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.84e+06  |\n",
      "|    total_cost         | 4.51e+03  |\n",
      "|    total_reward       | 1.84e+06  |\n",
      "|    total_reward_pct   | 184       |\n",
      "|    total_trades       | 23192     |\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 8.29      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.132     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -256     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 40.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 188       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 80.7      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5.84      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.77e+06 |\n",
      "|    total_cost         | 4.78e+03 |\n",
      "|    total_reward       | 1.77e+06 |\n",
      "|    total_reward_pct   | 177      |\n",
      "|    total_trades       | 24136    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.00475  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -185     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 20.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 194       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -160      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 16.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -213     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 26.7     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2015-10-02 to  2016-01-04\n",
      "A2C Sharpe Ratio:  0.06591682511726513\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_5\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.83e+06 |\n",
      "|    total_cost       | 1.46e+05 |\n",
      "|    total_reward     | 8.33e+05 |\n",
      "|    total_reward_pct | 83.3     |\n",
      "|    total_trades     | 49221    |\n",
      "| time/               |          |\n",
      "|    fps              | 153      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "day: 1698, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2188217.36\n",
      "total_reward: 1188217.36\n",
      "total_cost: 146613.78\n",
      "total_trades: 49498\n",
      "Sharpe: 0.890\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+06    |\n",
      "|    total_cost           | 1.47e+05    |\n",
      "|    total_reward         | 1.19e+06    |\n",
      "|    total_reward_pct     | 119         |\n",
      "|    total_trades         | 49498       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012810143 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0247     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.13        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 7.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.8e+06     |\n",
      "|    total_cost           | 1.43e+05    |\n",
      "|    total_reward         | 7.95e+05    |\n",
      "|    total_reward_pct     | 79.5        |\n",
      "|    total_trades         | 49078       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007457854 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0311     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.3         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.6e+06     |\n",
      "|    total_cost           | 1.41e+05    |\n",
      "|    total_reward         | 6.04e+05    |\n",
      "|    total_reward_pct     | 60.4        |\n",
      "|    total_trades         | 48886       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016284663 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00786    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.96        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.02e+06    |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 1.02e+06    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 48744       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020416902 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00204     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.69        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1505860.46\n",
      "total_reward: 505860.46\n",
      "total_cost: 130379.13\n",
      "total_trades: 47755\n",
      "Sharpe: 0.443\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.51e+06    |\n",
      "|    total_cost           | 1.3e+05     |\n",
      "|    total_reward         | 5.06e+05    |\n",
      "|    total_reward_pct     | 50.6        |\n",
      "|    total_trades         | 47755       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023908986 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0129     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.2         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.95e+06   |\n",
      "|    total_cost           | 1.43e+05   |\n",
      "|    total_reward         | 9.46e+05   |\n",
      "|    total_reward_pct     | 94.6       |\n",
      "|    total_trades         | 48911      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 90         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02175676 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | 0.0323     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.15       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0197    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 14.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.14e+06    |\n",
      "|    total_cost           | 1.41e+05    |\n",
      "|    total_reward         | 1.14e+06    |\n",
      "|    total_reward_pct     | 114         |\n",
      "|    total_trades         | 48739       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017000742 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00493     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.8         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.25e+06    |\n",
      "|    total_cost           | 1.38e+05    |\n",
      "|    total_reward         | 1.25e+06    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 48473       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020433677 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.006      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.21        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1754553.77\n",
      "total_reward: 754553.77\n",
      "total_cost: 140315.48\n",
      "total_trades: 48550\n",
      "Sharpe: 0.596\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.75e+06    |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 7.55e+05    |\n",
      "|    total_reward_pct     | 75.5        |\n",
      "|    total_trades         | 48550       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020872748 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.00727     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.5         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.21e+06    |\n",
      "|    total_cost           | 1.36e+05    |\n",
      "|    total_reward         | 1.21e+06    |\n",
      "|    total_reward_pct     | 121         |\n",
      "|    total_trades         | 48140       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022979287 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0225      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.27        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.41e+06    |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 1.41e+06    |\n",
      "|    total_reward_pct     | 141         |\n",
      "|    total_trades         | 48524       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021477666 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0322      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.51        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+06    |\n",
      "|    total_cost           | 1.35e+05    |\n",
      "|    total_reward         | 1.19e+06    |\n",
      "|    total_reward_pct     | 119         |\n",
      "|    total_trades         | 48149       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026082704 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0201      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.95        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.22e+06    |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 1.22e+06    |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 48468       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011958886 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0287      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.65        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.35        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2517182.71\n",
      "total_reward: 1517182.71\n",
      "total_cost: 138896.55\n",
      "total_trades: 48516\n",
      "Sharpe: 0.969\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.48e+06   |\n",
      "|    total_cost           | 1.37e+05   |\n",
      "|    total_reward         | 1.48e+06   |\n",
      "|    total_reward_pct     | 148        |\n",
      "|    total_trades         | 48233      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01958318 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0139     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.37       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 12.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+06    |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 1.58e+06    |\n",
      "|    total_reward_pct     | 158         |\n",
      "|    total_trades         | 48308       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024167186 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0201      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.92        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.84e+06   |\n",
      "|    total_cost           | 1.31e+05   |\n",
      "|    total_reward         | 8.4e+05    |\n",
      "|    total_reward_pct     | 84         |\n",
      "|    total_trades         | 47745      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 217        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02328886 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0611     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.31       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.019     |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 14.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.93e+06    |\n",
      "|    total_cost           | 1.27e+05    |\n",
      "|    total_reward         | 9.35e+05    |\n",
      "|    total_reward_pct     | 93.5        |\n",
      "|    total_trades         | 47187       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018143268 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0455      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.83        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1873502.82\n",
      "total_reward: 873502.82\n",
      "total_cost: 126917.64\n",
      "total_trades: 47382\n",
      "Sharpe: 0.636\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.87e+06   |\n",
      "|    total_cost           | 1.27e+05   |\n",
      "|    total_reward         | 8.74e+05   |\n",
      "|    total_reward_pct     | 87.4       |\n",
      "|    total_trades         | 47382      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 243        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01670454 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0774     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.63       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 16.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.92e+06    |\n",
      "|    total_cost           | 1.22e+05    |\n",
      "|    total_reward         | 9.22e+05    |\n",
      "|    total_reward_pct     | 92.2        |\n",
      "|    total_trades         | 46738       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018199667 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0791      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.71e+06    |\n",
      "|    total_cost           | 1.18e+05    |\n",
      "|    total_reward         | 7.09e+05    |\n",
      "|    total_reward_pct     | 70.9        |\n",
      "|    total_trades         | 46132       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027640468 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.02e+06    |\n",
      "|    total_cost           | 1.21e+05    |\n",
      "|    total_reward         | 1.02e+06    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 46704       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030940596 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.71        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1951032.14\n",
      "total_reward: 951032.14\n",
      "total_cost: 122316.67\n",
      "total_trades: 46740\n",
      "Sharpe: 0.694\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.95e+06   |\n",
      "|    total_cost           | 1.22e+05   |\n",
      "|    total_reward         | 9.51e+05   |\n",
      "|    total_reward_pct     | 95.1       |\n",
      "|    total_trades         | 46740      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 294        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02591012 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0826     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.84       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 19.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.63e+06    |\n",
      "|    total_cost           | 1.19e+05    |\n",
      "|    total_reward         | 6.26e+05    |\n",
      "|    total_reward_pct     | 62.6        |\n",
      "|    total_trades         | 46324       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015276477 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.81        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.94e+06    |\n",
      "|    total_cost           | 1.23e+05    |\n",
      "|    total_reward         | 9.39e+05    |\n",
      "|    total_reward_pct     | 93.9        |\n",
      "|    total_trades         | 46636       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021918816 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.5         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.02e+06   |\n",
      "|    total_cost           | 1.22e+05   |\n",
      "|    total_reward         | 1.02e+06   |\n",
      "|    total_reward_pct     | 102        |\n",
      "|    total_trades         | 46377      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 334        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02152297 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.239      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.36       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 16.2       |\n",
      "----------------------------------------\n",
      "day: 1698, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1873810.32\n",
      "total_reward: 873810.32\n",
      "total_cost: 124041.77\n",
      "total_trades: 46356\n",
      "Sharpe: 0.634\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.87e+06    |\n",
      "|    total_cost           | 1.24e+05    |\n",
      "|    total_reward         | 8.74e+05    |\n",
      "|    total_reward_pct     | 87.4        |\n",
      "|    total_trades         | 46356       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022223495 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0956      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.56        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.74e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 7.4e+05     |\n",
      "|    total_reward_pct     | 74          |\n",
      "|    total_trades         | 47195       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022979006 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.96e+06    |\n",
      "|    total_cost           | 1.33e+05    |\n",
      "|    total_reward         | 9.57e+05    |\n",
      "|    total_reward_pct     | 95.7        |\n",
      "|    total_trades         | 47505       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 377         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029512685 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.26        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.13e+06    |\n",
      "|    total_cost           | 1.27e+05    |\n",
      "|    total_reward         | 1.13e+06    |\n",
      "|    total_reward_pct     | 113         |\n",
      "|    total_trades         | 46938       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029637204 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.14        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1780464.17\n",
      "total_reward: 780464.17\n",
      "total_cost: 124041.54\n",
      "total_trades: 46351\n",
      "Sharpe: 0.577\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.78e+06    |\n",
      "|    total_cost           | 1.24e+05    |\n",
      "|    total_reward         | 7.8e+05     |\n",
      "|    total_reward_pct     | 78          |\n",
      "|    total_trades         | 46351       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023088934 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6           |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.05e+06    |\n",
      "|    total_cost           | 1.25e+05    |\n",
      "|    total_reward         | 1.05e+06    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 46450       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023901956 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.73        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.82e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 8.17e+05    |\n",
      "|    total_reward_pct     | 81.7        |\n",
      "|    total_trades         | 46922       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 430         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027529996 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0702      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.58        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.78e+06    |\n",
      "|    total_cost           | 1.24e+05    |\n",
      "|    total_reward         | 7.85e+05    |\n",
      "|    total_reward_pct     | 78.5        |\n",
      "|    total_trades         | 46113       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021588543 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.04        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2142387.32\n",
      "total_reward: 1142387.32\n",
      "total_cost: 131788.28\n",
      "total_trades: 46716\n",
      "Sharpe: 0.735\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.14e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 1.14e+06    |\n",
      "|    total_reward_pct     | 114         |\n",
      "|    total_trades         | 46716       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016389491 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.67e+06  |\n",
      "|    total_cost           | 1.23e+05  |\n",
      "|    total_reward         | 6.71e+05  |\n",
      "|    total_reward_pct     | 67.1      |\n",
      "|    total_trades         | 46137     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 157       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 466       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0348971 |\n",
      "|    clip_fraction        | 0.291     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.1     |\n",
      "|    explained_variance   | 0.183     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 6.45      |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -0.0166   |\n",
      "|    std                  | 1.05      |\n",
      "|    value_loss           | 16.8      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.09e+06    |\n",
      "|    total_cost           | 1.33e+05    |\n",
      "|    total_reward         | 1.09e+06    |\n",
      "|    total_reward_pct     | 109         |\n",
      "|    total_trades         | 47157       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026730875 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.56        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.09e+06    |\n",
      "|    total_cost           | 1.31e+05    |\n",
      "|    total_reward         | 1.09e+06    |\n",
      "|    total_reward_pct     | 109         |\n",
      "|    total_trades         | 46648       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 492         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045134433 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0201      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.68        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1441228.69\n",
      "total_reward: 441228.69\n",
      "total_cost: 122378.92\n",
      "total_trades: 45793\n",
      "Sharpe: 0.384\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.44e+06    |\n",
      "|    total_cost           | 1.22e+05    |\n",
      "|    total_reward         | 4.41e+05    |\n",
      "|    total_reward_pct     | 44.1        |\n",
      "|    total_trades         | 45793       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 504         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034825683 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.74e+06    |\n",
      "|    total_cost           | 1.25e+05    |\n",
      "|    total_reward         | 7.43e+05    |\n",
      "|    total_reward_pct     | 74.3        |\n",
      "|    total_trades         | 46213       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037786588 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.8e+06    |\n",
      "|    total_cost           | 1.34e+05   |\n",
      "|    total_reward         | 7.99e+05   |\n",
      "|    total_reward_pct     | 79.9       |\n",
      "|    total_trades         | 46967      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 529        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02057291 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.291      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.84       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 14         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.01e+06    |\n",
      "|    total_cost           | 1.31e+05    |\n",
      "|    total_reward         | 1.01e+06    |\n",
      "|    total_reward_pct     | 101         |\n",
      "|    total_trades         | 46939       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 542         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034583084 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.86        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 1.29e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 46478       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 554         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032067593 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.73        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2054098.04\n",
      "total_reward: 1054098.04\n",
      "total_cost: 123556.82\n",
      "total_trades: 46040\n",
      "Sharpe: 0.718\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.13e+06   |\n",
      "|    total_cost           | 1.25e+05   |\n",
      "|    total_reward         | 1.13e+06   |\n",
      "|    total_reward_pct     | 113        |\n",
      "|    total_trades         | 46180      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 567        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04135571 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.158      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.74       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 16.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+06    |\n",
      "|    total_cost           | 1.25e+05    |\n",
      "|    total_reward         | 1.45e+06    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 45956       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048877567 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.92        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.4e+06     |\n",
      "|    total_cost           | 1.24e+05    |\n",
      "|    total_reward         | 1.4e+06     |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 46219       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026326079 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0528      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.09        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.93e+06    |\n",
      "|    total_cost           | 1.18e+05    |\n",
      "|    total_reward         | 9.34e+05    |\n",
      "|    total_reward_pct     | 93.4        |\n",
      "|    total_trades         | 45268       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037253268 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0772      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 75\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2457073.85\n",
      "total_reward: 1457073.85\n",
      "total_cost: 126020.20\n",
      "total_trades: 46009\n",
      "Sharpe: 0.893\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.46e+06    |\n",
      "|    total_cost           | 1.26e+05    |\n",
      "|    total_reward         | 1.46e+06    |\n",
      "|    total_reward_pct     | 146         |\n",
      "|    total_trades         | 46009       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049859352 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.21        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+06    |\n",
      "|    total_cost           | 1.31e+05    |\n",
      "|    total_reward         | 1.04e+06    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 46347       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 629         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042113394 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.14        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2015-10-02 to  2016-01-04\n",
      "PPO Sharpe Ratio:  0.018346619446982158\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_5\n",
      "day: 1698, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2540232.04\n",
      "total_reward: 1540232.04\n",
      "total_cost: 2569.81\n",
      "total_trades: 20215\n",
      "Sharpe: 0.871\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.49e+06 |\n",
      "|    total_cost       | 1.16e+03 |\n",
      "|    total_reward     | 1.49e+06 |\n",
      "|    total_reward_pct | 149      |\n",
      "|    total_trades     | 27125    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total timesteps  | 6796     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -201     |\n",
      "|    critic_loss      | 164      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5097     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2015-10-02 to  2016-01-04\n",
      "======Best Model Retraining from:  2009-01-01 to  2016-01-04\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_126_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.12e+06 |\n",
      "|    total_cost       | 2.59e+03 |\n",
      "|    total_reward     | 1.12e+06 |\n",
      "|    total_reward_pct | 112      |\n",
      "|    total_trades     | 15226    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total timesteps  | 7048     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -153     |\n",
      "|    critic_loss      | 275      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5286     |\n",
      "----------------------------------\n",
      "day: 1761, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1899741.72\n",
      "total_reward: 899741.72\n",
      "total_cost: 2407.90\n",
      "total_trades: 16168\n",
      "Sharpe: 0.569\n",
      "=================================\n",
      "======Trading from:  2016-01-04 to  2016-04-05\n",
      "============================================\n",
      "17.701444842812517\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2016-01-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 88       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.438    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -26.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.457    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -117      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 9.39      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.106    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -216     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 28.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.31e+06 |\n",
      "|    total_cost         | 8.72e+04 |\n",
      "|    total_reward       | 1.31e+06 |\n",
      "|    total_reward_pct   | 131      |\n",
      "|    total_trades       | 43865    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.477    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -38.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.000143 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 120      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 130       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 53.2      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.35      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 201      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 35       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.21e+06 |\n",
      "|    total_cost         | 6.3e+04  |\n",
      "|    total_reward       | 2.21e+06 |\n",
      "|    total_reward_pct   | 221      |\n",
      "|    total_trades       | 40665    |\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 2.44e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -116     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00555 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -161     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 25.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 227       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 50.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.82e+06 |\n",
      "|    total_cost         | 5.66e+04 |\n",
      "|    total_reward       | 1.82e+06 |\n",
      "|    total_reward_pct   | 182      |\n",
      "|    total_trades       | 38843    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0884  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -172     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 18.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0138   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 78.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 9.82e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 94.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -40      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.51     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.09e+06 |\n",
      "|    total_cost         | 5.69e+04 |\n",
      "|    total_reward       | 1.09e+06 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 39889    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 40.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 143       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 96.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 5.3       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -118     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "day: 1761, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2310142.48\n",
      "total_reward: 1310142.48\n",
      "total_cost: 53894.28\n",
      "total_trades: 39914\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.31e+06 |\n",
      "|    total_cost         | 5.39e+04 |\n",
      "|    total_reward       | 1.31e+06 |\n",
      "|    total_reward_pct   | 131      |\n",
      "|    total_trades       | 39914    |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.834   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 28       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.072   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -173     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 331      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 57.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -30.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.63e+06 |\n",
      "|    total_cost         | 6.51e+04 |\n",
      "|    total_reward       | 2.63e+06 |\n",
      "|    total_reward_pct   | 263      |\n",
      "|    total_trades       | 40790    |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0446   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 21.3     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.22     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -24.5     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.4       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 63.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.2e+06  |\n",
      "|    total_cost         | 5.08e+04 |\n",
      "|    total_reward       | 3.2e+06  |\n",
      "|    total_reward_pct   | 320      |\n",
      "|    total_trades       | 37006    |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.175    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 78.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 223      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 50.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.369   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -174     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 18.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 80.7      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 7.47      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.05e+06 |\n",
      "|    total_cost         | 6.54e+04 |\n",
      "|    total_reward       | 4.05e+06 |\n",
      "|    total_reward_pct   | 405      |\n",
      "|    total_trades       | 37904    |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00236 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 51.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 385      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 76.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -180     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 18.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.63e+06 |\n",
      "|    total_cost         | 4.82e+04 |\n",
      "|    total_reward       | 2.63e+06 |\n",
      "|    total_reward_pct   | 263      |\n",
      "|    total_trades       | 35713    |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 205      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 34.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0197  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -142     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 15.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 165      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 25.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 73.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.76     |\n",
      "------------------------------------\n",
      "day: 1761, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4868315.90\n",
      "total_reward: 3868315.90\n",
      "total_cost: 26031.87\n",
      "total_trades: 32575\n",
      "Sharpe: 1.295\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.87e+06 |\n",
      "|    total_cost         | 2.6e+04  |\n",
      "|    total_reward       | 3.87e+06 |\n",
      "|    total_reward_pct   | 387      |\n",
      "|    total_trades       | 32575    |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -325     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 65.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -10.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 107      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.57e+06 |\n",
      "|    total_cost         | 2.03e+04 |\n",
      "|    total_reward       | 3.57e+06 |\n",
      "|    total_reward_pct   | 357      |\n",
      "|    total_trades       | 30628    |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0523  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -119     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -54.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.05     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 30.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -18      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.04e+06 |\n",
      "|    total_cost         | 1.59e+04 |\n",
      "|    total_reward       | 3.04e+06 |\n",
      "|    total_reward_pct   | 304      |\n",
      "|    total_trades       | 28308    |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -8.2e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -170     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 20.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -296     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 60.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -75.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.04e+06 |\n",
      "|    total_cost         | 1.56e+04 |\n",
      "|    total_reward       | 3.04e+06 |\n",
      "|    total_reward_pct   | 304      |\n",
      "|    total_trades       | 27202    |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.292   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -116     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -136     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 34.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -185     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 22.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.98e+06  |\n",
      "|    total_cost         | 1.31e+04  |\n",
      "|    total_reward       | 2.98e+06  |\n",
      "|    total_reward_pct   | 298       |\n",
      "|    total_trades       | 27883     |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 19.3      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.934     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 78.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -342     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 79.4     |\n",
      "------------------------------------\n",
      "day: 1761, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3465077.07\n",
      "total_reward: 2465077.07\n",
      "total_cost: 13618.56\n",
      "total_trades: 27731\n",
      "Sharpe: 1.074\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.47e+06 |\n",
      "|    total_cost         | 1.36e+04 |\n",
      "|    total_reward       | 2.47e+06 |\n",
      "|    total_reward_pct   | 247      |\n",
      "|    total_trades       | 27731    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -4.76    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 65.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 32.2     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 13.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -19.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -46.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.04e+06 |\n",
      "|    total_cost         | 2.71e+04 |\n",
      "|    total_reward       | 2.04e+06 |\n",
      "|    total_reward_pct   | 204      |\n",
      "|    total_trades       | 29811    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00909 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 19.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.357    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.241   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 9.87     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 54.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.11e+06 |\n",
      "|    total_cost         | 3.5e+04  |\n",
      "|    total_reward       | 1.11e+06 |\n",
      "|    total_reward_pct   | 111      |\n",
      "|    total_trades       | 34954    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -57      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.92     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2016-01-04 to  2016-04-05\n",
      "A2C Sharpe Ratio:  0.27151042013332227\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.13e+06 |\n",
      "|    total_cost       | 1.54e+05 |\n",
      "|    total_reward     | 1.13e+06 |\n",
      "|    total_reward_pct | 113      |\n",
      "|    total_trades     | 51061    |\n",
      "| time/               |          |\n",
      "|    fps              | 138      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "day: 1761, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2031836.27\n",
      "total_reward: 1031836.27\n",
      "total_cost: 154498.25\n",
      "total_trades: 50976\n",
      "Sharpe: 0.789\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.03e+06    |\n",
      "|    total_cost           | 1.54e+05    |\n",
      "|    total_reward         | 1.03e+06    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 50976       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014194114 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.00113     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.63        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 8.8e+05     |\n",
      "|    total_reward_pct     | 88          |\n",
      "|    total_trades         | 50682       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016162788 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0291     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.37        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.11e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 1.11e+06    |\n",
      "|    total_reward_pct     | 111         |\n",
      "|    total_trades         | 50708       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018690277 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00531    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.83        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 8.9         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 50492       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020003146 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0266     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.33        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.64        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 1.46e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 50127       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016742758 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0207     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.46        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "day: 1761, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2633894.34\n",
      "total_reward: 1633894.34\n",
      "total_cost: 145650.60\n",
      "total_trades: 50059\n",
      "Sharpe: 0.980\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.72e+06    |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | 1.72e+06    |\n",
      "|    total_reward_pct     | 172         |\n",
      "|    total_trades         | 49458       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025251266 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0238      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.75        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.37e+06    |\n",
      "|    total_cost           | 1.47e+05    |\n",
      "|    total_reward         | 1.37e+06    |\n",
      "|    total_reward_pct     | 137         |\n",
      "|    total_trades         | 49875       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027102202 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.00665    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.84        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+06     |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | 1.5e+06     |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 49682       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028540768 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0544     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.65        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.83e+06    |\n",
      "|    total_cost           | 1.47e+05    |\n",
      "|    total_reward         | 1.83e+06    |\n",
      "|    total_reward_pct     | 183         |\n",
      "|    total_trades         | 49678       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024786519 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0221      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.89        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "day: 1761, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2493954.94\n",
      "total_reward: 1493954.94\n",
      "total_cost: 139160.34\n",
      "total_trades: 49242\n",
      "Sharpe: 0.927\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.49e+06    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 1.49e+06    |\n",
      "|    total_reward_pct     | 149         |\n",
      "|    total_trades         | 49242       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019324534 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0302      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.57        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.17e+06    |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | 1.17e+06    |\n",
      "|    total_reward_pct     | 117         |\n",
      "|    total_trades         | 49670       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024939023 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5           |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.47        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.23e+06    |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | 1.23e+06    |\n",
      "|    total_reward_pct     | 123         |\n",
      "|    total_trades         | 49589       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019146422 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0357      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.06        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.65        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.47e+06   |\n",
      "|    total_cost           | 1.44e+05   |\n",
      "|    total_reward         | 1.47e+06   |\n",
      "|    total_reward_pct     | 147        |\n",
      "|    total_trades         | 49507      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 191        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02051768 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | -0.027     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.15       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 10.2       |\n",
      "----------------------------------------\n",
      "day: 1761, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2442009.12\n",
      "total_reward: 1442009.12\n",
      "total_cost: 140004.12\n",
      "total_trades: 49509\n",
      "Sharpe: 0.928\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.44e+06   |\n",
      "|    total_cost           | 1.4e+05    |\n",
      "|    total_reward         | 1.44e+06   |\n",
      "|    total_reward_pct     | 144        |\n",
      "|    total_trades         | 49509      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 205        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02133759 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.0134     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.01       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 9.77       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.58e+06   |\n",
      "|    total_cost           | 1.43e+05   |\n",
      "|    total_reward         | 1.58e+06   |\n",
      "|    total_reward_pct     | 158        |\n",
      "|    total_trades         | 49643      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 218        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02963227 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.0169     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.31       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 11.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.37e+06    |\n",
      "|    total_cost           | 1.36e+05    |\n",
      "|    total_reward         | 1.37e+06    |\n",
      "|    total_reward_pct     | 137         |\n",
      "|    total_trades         | 49184       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023487477 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0329      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.97        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.26e+06    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 1.26e+06    |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 49268       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021979604 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0146      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.88        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.63        |\n",
      "-----------------------------------------\n",
      "day: 1761, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2424241.92\n",
      "total_reward: 1424241.92\n",
      "total_cost: 138961.99\n",
      "total_trades: 49350\n",
      "Sharpe: 0.998\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.42e+06    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 1.42e+06    |\n",
      "|    total_reward_pct     | 142         |\n",
      "|    total_trades         | 49350       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 258         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030258399 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.044       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.32        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.39e+06    |\n",
      "|    total_cost           | 1.36e+05    |\n",
      "|    total_reward         | 1.39e+06    |\n",
      "|    total_reward_pct     | 139         |\n",
      "|    total_trades         | 48926       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013768062 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0576      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.61        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.16e+06    |\n",
      "|    total_cost           | 1.41e+05    |\n",
      "|    total_reward         | 1.16e+06    |\n",
      "|    total_reward_pct     | 116         |\n",
      "|    total_trades         | 49425       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045940384 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0533      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.8         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.25e+06    |\n",
      "|    total_cost           | 1.44e+05    |\n",
      "|    total_reward         | 1.25e+06    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 49908       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022150505 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0401      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.69        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+06    |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | 1.19e+06    |\n",
      "|    total_reward_pct     | 119         |\n",
      "|    total_trades         | 49949       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028797222 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0502      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.61        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.26        |\n",
      "-----------------------------------------\n",
      "day: 1761, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2082670.84\n",
      "total_reward: 1082670.84\n",
      "total_cost: 140501.47\n",
      "total_trades: 49270\n",
      "Sharpe: 0.851\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.08e+06    |\n",
      "|    total_cost           | 1.41e+05    |\n",
      "|    total_reward         | 1.08e+06    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 49270       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030048773 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0685      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.2         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.46e+06    |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 1.46e+06    |\n",
      "|    total_reward_pct     | 146         |\n",
      "|    total_trades         | 49046       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034917627 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.75        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.55e+06    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 1.55e+06    |\n",
      "|    total_reward_pct     | 155         |\n",
      "|    total_trades         | 49051       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040161707 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0336      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.49        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.49e+06    |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 1.49e+06    |\n",
      "|    total_reward_pct     | 149         |\n",
      "|    total_trades         | 49121       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026485264 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0594      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.83        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "day: 1761, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2248573.46\n",
      "total_reward: 1248573.46\n",
      "total_cost: 142235.91\n",
      "total_trades: 49261\n",
      "Sharpe: 0.889\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.25e+06    |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | 1.25e+06    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 49261       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028159002 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0956      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.44        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.49e+06   |\n",
      "|    total_cost           | 1.38e+05   |\n",
      "|    total_reward         | 1.49e+06   |\n",
      "|    total_reward_pct     | 149        |\n",
      "|    total_trades         | 48898      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 391        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02820244 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0358     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.57       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 13.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.17e+06    |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 1.17e+06    |\n",
      "|    total_reward_pct     | 117         |\n",
      "|    total_trades         | 48813       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040664773 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.2         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+06    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 1.61e+06    |\n",
      "|    total_reward_pct     | 161         |\n",
      "|    total_trades         | 48981       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 417         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033148497 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | -0.00765    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.32        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "day: 1761, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2505966.47\n",
      "total_reward: 1505966.47\n",
      "total_cost: 140792.06\n",
      "total_trades: 49226\n",
      "Sharpe: 0.912\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.51e+06   |\n",
      "|    total_cost           | 1.41e+05   |\n",
      "|    total_reward         | 1.51e+06   |\n",
      "|    total_reward_pct     | 151        |\n",
      "|    total_trades         | 49226      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 429        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03929978 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.031      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.21       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 15.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.66e+06   |\n",
      "|    total_cost           | 1.39e+05   |\n",
      "|    total_reward         | 1.66e+06   |\n",
      "|    total_reward_pct     | 166        |\n",
      "|    total_trades         | 49155      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 442        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02830244 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.0843     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.44       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00963   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 14.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.16e+06    |\n",
      "|    total_cost           | 1.33e+05    |\n",
      "|    total_reward         | 1.16e+06    |\n",
      "|    total_reward_pct     | 116         |\n",
      "|    total_trades         | 48114       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035363965 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.08        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.5         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 1.35e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 48596       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 469         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027221136 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.27        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.47e+06    |\n",
      "|    total_cost           | 1.34e+05    |\n",
      "|    total_reward         | 1.47e+06    |\n",
      "|    total_reward_pct     | 147         |\n",
      "|    total_trades         | 48597       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 482         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019574799 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0859      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.8         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1761, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2429573.30\n",
      "total_reward: 1429573.30\n",
      "total_cost: 132146.78\n",
      "total_trades: 48594\n",
      "Sharpe: 0.851\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.66e+06    |\n",
      "|    total_cost           | 1.35e+05    |\n",
      "|    total_reward         | 1.66e+06    |\n",
      "|    total_reward_pct     | 166         |\n",
      "|    total_trades         | 48812       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028158605 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0606      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.31        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.63e+06    |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | 1.63e+06    |\n",
      "|    total_reward_pct     | 163         |\n",
      "|    total_trades         | 49264       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023453506 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0978      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.49        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 1.34e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 48557       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 522         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022195522 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0721      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.88        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.05e+06    |\n",
      "|    total_cost           | 1.33e+05    |\n",
      "|    total_reward         | 1.05e+06    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 48344       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 537         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039081044 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0962      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.33        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "day: 1761, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2333553.00\n",
      "total_reward: 1333553.00\n",
      "total_cost: 136285.58\n",
      "total_trades: 48691\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+06    |\n",
      "|    total_cost           | 1.36e+05    |\n",
      "|    total_reward         | 1.33e+06    |\n",
      "|    total_reward_pct     | 133         |\n",
      "|    total_trades         | 48691       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 551         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014098588 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.4         |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 1.34e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 48695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 564         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039541278 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.67        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.4e+06    |\n",
      "|    total_cost           | 1.22e+05   |\n",
      "|    total_reward         | 1.4e+06    |\n",
      "|    total_reward_pct     | 140        |\n",
      "|    total_trades         | 47518      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 577        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05239425 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.01       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00493   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 13.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.7e+06    |\n",
      "|    total_cost           | 1.27e+05   |\n",
      "|    total_reward         | 1.7e+06    |\n",
      "|    total_reward_pct     | 170        |\n",
      "|    total_trades         | 47925      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 590        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03831254 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.37       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00704   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 16.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1761, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2883651.11\n",
      "total_reward: 1883651.11\n",
      "total_cost: 138798.51\n",
      "total_trades: 48882\n",
      "Sharpe: 1.070\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.88e+06   |\n",
      "|    total_cost           | 1.39e+05   |\n",
      "|    total_reward         | 1.88e+06   |\n",
      "|    total_reward_pct     | 188        |\n",
      "|    total_trades         | 48882      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 603        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03306766 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.217      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.14       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 13         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.82e+06    |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 1.82e+06    |\n",
      "|    total_reward_pct     | 182         |\n",
      "|    total_trades         | 48441       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 617         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030390056 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.03        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.49e+06    |\n",
      "|    total_cost           | 1.34e+05    |\n",
      "|    total_reward         | 1.49e+06    |\n",
      "|    total_reward_pct     | 149         |\n",
      "|    total_trades         | 48276       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 631         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045701683 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.68        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.29e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 1.29e+06    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 48151       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 645         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037214443 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.28        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.96e+06   |\n",
      "|    total_cost           | 1.25e+05   |\n",
      "|    total_reward         | 1.96e+06   |\n",
      "|    total_reward_pct     | 196        |\n",
      "|    total_trades         | 47472      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 659        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05872505 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.292      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.89       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 18.8       |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2016-01-04 to  2016-04-05\n",
      "PPO Sharpe Ratio:  0.41137847265578203\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.12e+06 |\n",
      "|    total_cost       | 1.13e+03 |\n",
      "|    total_reward     | 1.12e+06 |\n",
      "|    total_reward_pct | 112      |\n",
      "|    total_trades     | 24656    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total timesteps  | 7048     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 30.3     |\n",
      "|    critic_loss      | 21.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5286     |\n",
      "----------------------------------\n",
      "day: 1761, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2335900.86\n",
      "total_reward: 1335900.86\n",
      "total_cost: 1072.24\n",
      "total_trades: 24798\n",
      "Sharpe: 0.735\n",
      "=================================\n",
      "======DDPG Validation from:  2016-01-04 to  2016-04-05\n",
      "======Best Model Retraining from:  2009-01-01 to  2016-04-05\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_189_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.43e+06 |\n",
      "|    total_cost       | 1.63e+05 |\n",
      "|    total_reward     | 1.43e+06 |\n",
      "|    total_reward_pct | 143      |\n",
      "|    total_trades     | 52988    |\n",
      "| time/               |          |\n",
      "|    fps              | 140      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.11e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 1.11e+06    |\n",
      "|    total_reward_pct     | 111         |\n",
      "|    total_trades         | 52731       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016137581 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0132      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.51        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+06    |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 1.04e+06    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 52713       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012179358 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0123      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.59        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.01e+06    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | 1.01e+06    |\n",
      "|    total_reward_pct     | 101         |\n",
      "|    total_trades         | 52215       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009587303 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0253      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.16        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1868664.85\n",
      "total_reward: 868664.85\n",
      "total_cost: 152274.05\n",
      "total_trades: 52043\n",
      "Sharpe: 0.621\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.87e+06    |\n",
      "|    total_cost           | 1.52e+05    |\n",
      "|    total_reward         | 8.69e+05    |\n",
      "|    total_reward_pct     | 86.9        |\n",
      "|    total_trades         | 52043       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009744447 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.016      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.86        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.82e+06   |\n",
      "|    total_cost           | 1.55e+05   |\n",
      "|    total_reward         | 8.17e+05   |\n",
      "|    total_reward_pct     | 81.7       |\n",
      "|    total_trades         | 52072      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 144        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 85         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01601925 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | -0.0282    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.42       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0276    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 12.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.85e+06    |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | 8.49e+05    |\n",
      "|    total_reward_pct     | 84.9        |\n",
      "|    total_trades         | 51611       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021087272 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0134     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.63        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.55        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.76e+06   |\n",
      "|    total_cost           | 1.46e+05   |\n",
      "|    total_reward         | 7.64e+05   |\n",
      "|    total_reward_pct     | 76.4       |\n",
      "|    total_trades         | 51364      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 144        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 113        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03202689 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | 3.87e-05   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.54       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.024     |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 12.1       |\n",
      "----------------------------------------\n",
      "day: 1824, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1711395.73\n",
      "total_reward: 711395.73\n",
      "total_cost: 146748.93\n",
      "total_trades: 51313\n",
      "Sharpe: 0.578\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.71e+06    |\n",
      "|    total_cost           | 1.47e+05    |\n",
      "|    total_reward         | 7.11e+05    |\n",
      "|    total_reward_pct     | 71.1        |\n",
      "|    total_trades         | 51313       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023661159 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0156      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.9         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.13e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 1.13e+06    |\n",
      "|    total_reward_pct     | 113         |\n",
      "|    total_trades         | 51543       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021839513 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0127     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.48        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.45        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.91e+06   |\n",
      "|    total_cost           | 1.5e+05    |\n",
      "|    total_reward         | 9.1e+05    |\n",
      "|    total_reward_pct     | 91         |\n",
      "|    total_trades         | 51598      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 153        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02046095 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.0186     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.69       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 14.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.95e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 9.46e+05    |\n",
      "|    total_reward_pct     | 94.6        |\n",
      "|    total_trades         | 51438       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016059695 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00523     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.11        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.02e+06    |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 1.02e+06    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 51538       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010146465 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.012       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.57        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1825909.83\n",
      "total_reward: 825909.83\n",
      "total_cost: 144610.06\n",
      "total_trades: 50922\n",
      "Sharpe: 0.568\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.83e+06    |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | 8.26e+05    |\n",
      "|    total_reward_pct     | 82.6        |\n",
      "|    total_trades         | 50922       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024335677 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.00843     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.69        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.4e+06     |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 1.4e+06     |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 51720       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023556171 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0264      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.15        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.75e+06    |\n",
      "|    total_cost           | 1.43e+05    |\n",
      "|    total_reward         | 7.52e+05    |\n",
      "|    total_reward_pct     | 75.2        |\n",
      "|    total_trades         | 51022       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020762615 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0128      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.04        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.26e+06    |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | 1.26e+06    |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 51177       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024176577 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0386      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.35        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2234823.05\n",
      "total_reward: 1234823.05\n",
      "total_cost: 150887.48\n",
      "total_trades: 51062\n",
      "Sharpe: 0.767\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.23e+06    |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 1.23e+06    |\n",
      "|    total_reward_pct     | 123         |\n",
      "|    total_trades         | 51062       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026410656 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0318      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.55        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.9e+06     |\n",
      "|    total_cost           | 1.44e+05    |\n",
      "|    total_reward         | 8.99e+05    |\n",
      "|    total_reward_pct     | 89.9        |\n",
      "|    total_trades         | 50534       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022111082 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.000693   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.81        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.83e+06    |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | 8.26e+05    |\n",
      "|    total_reward_pct     | 82.6        |\n",
      "|    total_trades         | 50494       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021649335 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.31        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.73e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 1.73e+06    |\n",
      "|    total_reward_pct     | 173         |\n",
      "|    total_trades         | 51394       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027370142 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.00317     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.85        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.67e+06    |\n",
      "|    total_cost           | 1.47e+05    |\n",
      "|    total_reward         | 1.67e+06    |\n",
      "|    total_reward_pct     | 167         |\n",
      "|    total_trades         | 51179       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016729109 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.000297   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.19        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2523740.02\n",
      "total_reward: 1523740.02\n",
      "total_cost: 151187.49\n",
      "total_trades: 51448\n",
      "Sharpe: 0.896\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 51448       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018773472 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.0446     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.26        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.81e+06    |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | 1.81e+06    |\n",
      "|    total_reward_pct     | 181         |\n",
      "|    total_trades         | 51065       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017980771 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.22        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+06    |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 1.65e+06    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 50749       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037713096 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0412      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.76        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.68e+06    |\n",
      "|    total_cost           | 1.46e+05    |\n",
      "|    total_reward         | 1.68e+06    |\n",
      "|    total_reward_pct     | 168         |\n",
      "|    total_trades         | 50845       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 350         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023372734 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.57        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1824, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2789974.56\n",
      "total_reward: 1789974.56\n",
      "total_cost: 143299.18\n",
      "total_trades: 50892\n",
      "Sharpe: 0.953\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.79e+06    |\n",
      "|    total_cost           | 1.43e+05    |\n",
      "|    total_reward         | 1.79e+06    |\n",
      "|    total_reward_pct     | 179         |\n",
      "|    total_trades         | 50892       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025775146 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0194      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.99        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.1e+06    |\n",
      "|    total_cost           | 1.47e+05   |\n",
      "|    total_reward         | 1.1e+06    |\n",
      "|    total_reward_pct     | 110        |\n",
      "|    total_trades         | 50983      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 376        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02950856 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.019      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.25       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 15.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.2e+06     |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | 1.2e+06     |\n",
      "|    total_reward_pct     | 120         |\n",
      "|    total_trades         | 50867       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030930968 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.35e+06    |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | 1.35e+06    |\n",
      "|    total_reward_pct     | 135         |\n",
      "|    total_trades         | 51323       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 402         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021240253 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0581      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.43        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.29e+06    |\n",
      "|    total_cost           | 1.43e+05    |\n",
      "|    total_reward         | 1.29e+06    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 50692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 414         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015540758 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.00742     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.21        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2331280.93\n",
      "total_reward: 1331280.93\n",
      "total_cost: 143558.28\n",
      "total_trades: 50933\n",
      "Sharpe: 0.833\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.33e+06  |\n",
      "|    total_cost           | 1.44e+05  |\n",
      "|    total_reward         | 1.33e+06  |\n",
      "|    total_reward_pct     | 133       |\n",
      "|    total_trades         | 50933     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 153       |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 427       |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0175358 |\n",
      "|    clip_fraction        | 0.271     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.2     |\n",
      "|    explained_variance   | 0.105     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 6.52      |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -0.0178   |\n",
      "|    std                  | 1.06      |\n",
      "|    value_loss           | 15.3      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.29e+06    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 1.29e+06    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 50599       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029721914 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0288      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.17        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.07e+06    |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 1.07e+06    |\n",
      "|    total_reward_pct     | 107         |\n",
      "|    total_trades         | 50759       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025865894 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.022       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.82        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.62e+06    |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 1.62e+06    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 50914       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024920922 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.19        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2208981.43\n",
      "total_reward: 1208981.43\n",
      "total_cost: 141413.01\n",
      "total_trades: 50737\n",
      "Sharpe: 0.768\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.21e+06    |\n",
      "|    total_cost           | 1.41e+05    |\n",
      "|    total_reward         | 1.21e+06    |\n",
      "|    total_reward_pct     | 121         |\n",
      "|    total_trades         | 50737       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 480         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022708882 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.45        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.1e+06    |\n",
      "|    total_cost           | 1.43e+05   |\n",
      "|    total_reward         | 1.1e+06    |\n",
      "|    total_reward_pct     | 110        |\n",
      "|    total_trades         | 50955      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 493        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02431026 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.164      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.82       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 14.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.41e+06    |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | 1.41e+06    |\n",
      "|    total_reward_pct     | 141         |\n",
      "|    total_trades         | 51276       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 506         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037034966 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.28        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.06e+06    |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 1.06e+06    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 49944       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 519         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045766845 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0706      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.54        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.98e+06    |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 9.78e+05    |\n",
      "|    total_reward_pct     | 97.8        |\n",
      "|    total_trades         | 50577       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 532         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034115393 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.32        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2755177.79\n",
      "total_reward: 1755177.79\n",
      "total_cost: 138264.39\n",
      "total_trades: 50337\n",
      "Sharpe: 0.990\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.16e+06  |\n",
      "|    total_cost           | 1.21e+05  |\n",
      "|    total_reward         | 2.16e+06  |\n",
      "|    total_reward_pct     | 216       |\n",
      "|    total_trades         | 48297     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 154       |\n",
      "|    iterations           | 41        |\n",
      "|    time_elapsed         | 544       |\n",
      "|    total_timesteps      | 83968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0350009 |\n",
      "|    clip_fraction        | 0.302     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.7     |\n",
      "|    explained_variance   | 0.0607    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 6.76      |\n",
      "|    n_updates            | 400       |\n",
      "|    policy_gradient_loss | -0.0117   |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 18.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+06    |\n",
      "|    total_cost           | 1.22e+05    |\n",
      "|    total_reward         | 1.65e+06    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 48680       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 557         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042913504 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.00657     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3e+06      |\n",
      "|    total_cost           | 1.3e+05    |\n",
      "|    total_reward         | 2e+06      |\n",
      "|    total_reward_pct     | 200        |\n",
      "|    total_trades         | 49350      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 570        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03666457 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.0837     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.61       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0031    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 18         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.97e+06    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 1.97e+06    |\n",
      "|    total_reward_pct     | 197         |\n",
      "|    total_trades         | 50360       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 583         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036460526 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2665412.85\n",
      "total_reward: 1665412.85\n",
      "total_cost: 133056.55\n",
      "total_trades: 50090\n",
      "Sharpe: 0.945\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.67e+06    |\n",
      "|    total_cost           | 1.33e+05    |\n",
      "|    total_reward         | 1.67e+06    |\n",
      "|    total_reward_pct     | 167         |\n",
      "|    total_trades         | 50090       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036061384 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.89        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.12e+06   |\n",
      "|    total_cost           | 1.32e+05   |\n",
      "|    total_reward         | 2.12e+06   |\n",
      "|    total_reward_pct     | 212        |\n",
      "|    total_trades         | 49917      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 609        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01868031 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.0569     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.93       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 15.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.7e+06     |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 1.7e+06     |\n",
      "|    total_reward_pct     | 170         |\n",
      "|    total_trades         | 49881       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 621         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028070334 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.0411      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.97e+06    |\n",
      "|    total_cost           | 1.31e+05    |\n",
      "|    total_reward         | 1.97e+06    |\n",
      "|    total_reward_pct     | 197         |\n",
      "|    total_trades         | 49785       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 634         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026638232 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.81e+06   |\n",
      "|    total_cost           | 1.29e+05   |\n",
      "|    total_reward         | 1.81e+06   |\n",
      "|    total_reward_pct     | 181        |\n",
      "|    total_trades         | 49873      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 647        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03568913 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | 0.101      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.67       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0082    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 17.5       |\n",
      "----------------------------------------\n",
      "======Trading from:  2016-04-05 to  2016-07-05\n",
      "============================================\n",
      "27.53357532513596\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2016-04-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_4\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.031    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -6.42    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.0645   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -144     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 17.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -154     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.5e+06  |\n",
      "|    total_cost         | 7.82e+04 |\n",
      "|    total_reward       | 1.5e+06  |\n",
      "|    total_reward_pct   | 150      |\n",
      "|    total_trades       | 44315    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.697    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -16.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.526    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -7.51e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 90.4      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 5.73      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.187   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -106     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.19     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 143       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -483      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 153       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.33e+06 |\n",
      "|    total_cost         | 5.44e+04 |\n",
      "|    total_reward       | 1.33e+06 |\n",
      "|    total_reward_pct   | 133      |\n",
      "|    total_trades       | 43913    |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.00131 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -101     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.338   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -105     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 123      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.93e+06 |\n",
      "|    total_cost         | 6.3e+04  |\n",
      "|    total_reward       | 1.93e+06 |\n",
      "|    total_reward_pct   | 193      |\n",
      "|    total_trades       | 42558    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -21.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.464    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.138   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 27.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0606   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -195     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 27.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.09e+06 |\n",
      "|    total_cost         | 5.06e+04 |\n",
      "|    total_reward       | 1.09e+06 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 41724    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0892   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 56.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.17     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0124   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 7.07     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -77.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -118     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.31     |\n",
      "------------------------------------\n",
      "day: 1824, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2358241.06\n",
      "total_reward: 1358241.06\n",
      "total_cost: 53581.30\n",
      "total_trades: 41894\n",
      "Sharpe: 0.817\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.36e+06 |\n",
      "|    total_cost         | 5.36e+04 |\n",
      "|    total_reward       | 1.36e+06 |\n",
      "|    total_reward_pct   | 136      |\n",
      "|    total_trades       | 41894    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.00488  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -44.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.272   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 94.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.242   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -97.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.05e+06 |\n",
      "|    total_cost         | 7.11e+04 |\n",
      "|    total_reward       | 2.05e+06 |\n",
      "|    total_reward_pct   | 205      |\n",
      "|    total_trades       | 42649    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 76.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 79.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -9.93    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -21.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.68e+06 |\n",
      "|    total_cost         | 5.17e+04 |\n",
      "|    total_reward       | 1.68e+06 |\n",
      "|    total_reward_pct   | 168      |\n",
      "|    total_trades       | 40906    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.056   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -108     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.676   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -2.11    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.08e+06 |\n",
      "|    total_cost         | 5.87e+04 |\n",
      "|    total_reward       | 2.08e+06 |\n",
      "|    total_reward_pct   | 208      |\n",
      "|    total_trades       | 41688    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -30.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.779    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.00903 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -118     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0243   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -40.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.4e+06  |\n",
      "|    total_cost         | 5.92e+04 |\n",
      "|    total_reward       | 1.4e+06  |\n",
      "|    total_reward_pct   | 140      |\n",
      "|    total_trades       | 43498    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.336   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 40.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 24.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.583    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -9.18e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 30.8      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.962     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0276  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -40.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.88     |\n",
      "------------------------------------\n",
      "day: 1824, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2932125.97\n",
      "total_reward: 1932125.97\n",
      "total_cost: 56219.49\n",
      "total_trades: 41223\n",
      "Sharpe: 1.068\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.93e+06 |\n",
      "|    total_cost         | 5.62e+04 |\n",
      "|    total_reward       | 1.93e+06 |\n",
      "|    total_reward_pct   | 193      |\n",
      "|    total_trades       | 41223    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 17.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -86.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -171     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 16.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -8.07e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -19.9     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 4.98      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.34e+06 |\n",
      "|    total_cost         | 5.15e+04 |\n",
      "|    total_reward       | 2.34e+06 |\n",
      "|    total_reward_pct   | 234      |\n",
      "|    total_trades       | 40728    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -2.5e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 84.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.0449  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 48.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.39     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -4.05e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 48.3      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.95e+06 |\n",
      "|    total_cost         | 4.13e+04 |\n",
      "|    total_reward       | 1.95e+06 |\n",
      "|    total_reward_pct   | 195      |\n",
      "|    total_trades       | 40628    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.00716 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 21.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.162   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -27.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.48     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 36.1      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.735     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0936   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -26.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.32e+06 |\n",
      "|    total_cost         | 6.1e+04  |\n",
      "|    total_reward       | 1.32e+06 |\n",
      "|    total_reward_pct   | 132      |\n",
      "|    total_trades       | 39989    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -33.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.94     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 13.4      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.405     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -98.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -50.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 9.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.53e+06 |\n",
      "|    total_cost         | 4.45e+04 |\n",
      "|    total_reward       | 1.53e+06 |\n",
      "|    total_reward_pct   | 153      |\n",
      "|    total_trades       | 39777    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 35.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.295    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -24.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.436    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -20.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "day: 1824, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2581801.67\n",
      "total_reward: 1581801.67\n",
      "total_cost: 32253.08\n",
      "total_trades: 35932\n",
      "Sharpe: 0.940\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.58e+06 |\n",
      "|    total_cost         | 3.23e+04 |\n",
      "|    total_reward       | 1.58e+06 |\n",
      "|    total_reward_pct   | 158      |\n",
      "|    total_trades       | 35932    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.0646  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 48.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.47     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 42.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -25.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 28.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.66e+06 |\n",
      "|    total_cost         | 2.18e+04 |\n",
      "|    total_reward       | 1.66e+06 |\n",
      "|    total_reward_pct   | 166      |\n",
      "|    total_trades       | 33858    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.00201 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 37.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.873    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 21.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.331    |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2016-04-05 to  2016-07-05\n",
      "A2C Sharpe Ratio:  -0.019542811655866636\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_252_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.12e+06 |\n",
      "|    total_cost       | 1.59e+05 |\n",
      "|    total_reward     | 1.12e+06 |\n",
      "|    total_reward_pct | 112      |\n",
      "|    total_trades     | 52755    |\n",
      "| time/               |          |\n",
      "|    fps              | 151      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.3e+06      |\n",
      "|    total_cost           | 1.6e+05      |\n",
      "|    total_reward         | 1.3e+06      |\n",
      "|    total_reward_pct     | 130          |\n",
      "|    total_trades         | 52741        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 155          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062437784 |\n",
      "|    clip_fraction        | 0.219        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.00962     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.61         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 12.9         |\n",
      "------------------------------------------\n",
      "day: 1824, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1885406.64\n",
      "total_reward: 885406.64\n",
      "total_cost: 155123.06\n",
      "total_trades: 52741\n",
      "Sharpe: 0.686\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.89e+06    |\n",
      "|    total_cost           | 1.55e+05    |\n",
      "|    total_reward         | 8.85e+05    |\n",
      "|    total_reward_pct     | 88.5        |\n",
      "|    total_trades         | 52741       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023863016 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0165     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.93        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.24e+06    |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 1.24e+06    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 52760       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018123776 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0302     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.32        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.22e+06    |\n",
      "|    total_cost           | 1.55e+05    |\n",
      "|    total_reward         | 1.22e+06    |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 52544       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022928165 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0326     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.93        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.17e+06    |\n",
      "|    total_cost           | 1.53e+05    |\n",
      "|    total_reward         | 1.17e+06    |\n",
      "|    total_reward_pct     | 117         |\n",
      "|    total_trades         | 52115       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018104158 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0332     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.87        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.96e+06    |\n",
      "|    total_cost           | 1.54e+05    |\n",
      "|    total_reward         | 9.6e+05     |\n",
      "|    total_reward_pct     | 96          |\n",
      "|    total_trades         | 52160       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019158866 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0129      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.19        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2327300.45\n",
      "total_reward: 1327300.45\n",
      "total_cost: 150907.86\n",
      "total_trades: 51832\n",
      "Sharpe: 0.891\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+06    |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 1.33e+06    |\n",
      "|    total_reward_pct     | 133         |\n",
      "|    total_trades         | 51832       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021117575 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0298     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.93        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.22e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 1.22e+06    |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 51690       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034745995 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0463      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.6         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.11e+06    |\n",
      "|    total_cost           | 1.44e+05    |\n",
      "|    total_reward         | 1.11e+06    |\n",
      "|    total_reward_pct     | 111         |\n",
      "|    total_trades         | 50963       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024241624 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.74        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.28e+06    |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 1.28e+06    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 51792       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023127977 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0177      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.03        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2586604.60\n",
      "total_reward: 1586604.60\n",
      "total_cost: 151763.92\n",
      "total_trades: 51830\n",
      "Sharpe: 0.989\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.59e+06  |\n",
      "|    total_cost           | 1.52e+05  |\n",
      "|    total_reward         | 1.59e+06  |\n",
      "|    total_reward_pct     | 159       |\n",
      "|    total_trades         | 51830     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 158       |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 154       |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0234145 |\n",
      "|    clip_fraction        | 0.216     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43       |\n",
      "|    explained_variance   | 0.0215    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 3.33      |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | -0.0217   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 9.35      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.12e+06   |\n",
      "|    total_cost           | 1.39e+05   |\n",
      "|    total_reward         | 1.12e+06   |\n",
      "|    total_reward_pct     | 112        |\n",
      "|    total_trades         | 50700      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 167        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01613912 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.0279     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.86       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0208    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 12.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.02e+06    |\n",
      "|    total_cost           | 1.43e+05    |\n",
      "|    total_reward         | 1.02e+06    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 51118       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040548474 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0154      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.92        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.78        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.21e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 1.21e+06    |\n",
      "|    total_reward_pct     | 121         |\n",
      "|    total_trades         | 51509       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026787626 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00901     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.82        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.44e+06    |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | 1.44e+06    |\n",
      "|    total_reward_pct     | 144         |\n",
      "|    total_trades         | 51385       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020824471 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0486      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.13        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2094131.35\n",
      "total_reward: 1094131.35\n",
      "total_cost: 150021.23\n",
      "total_trades: 51340\n",
      "Sharpe: 0.839\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.04e+06   |\n",
      "|    total_cost           | 1.51e+05   |\n",
      "|    total_reward         | 1.04e+06   |\n",
      "|    total_reward_pct     | 104        |\n",
      "|    total_trades         | 51459      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 157        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 220        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03686014 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.0107     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.71       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0235    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 11.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.06e+06    |\n",
      "|    total_cost           | 1.52e+05    |\n",
      "|    total_reward         | 1.06e+06    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 51480       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018703679 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0231      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.99        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.49e+06   |\n",
      "|    total_cost           | 1.42e+05   |\n",
      "|    total_reward         | 4.86e+05   |\n",
      "|    total_reward_pct     | 48.6       |\n",
      "|    total_trades         | 50617      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 157        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 246        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02506102 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0592     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.51       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0233    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 10.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.95e+06    |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 9.46e+05    |\n",
      "|    total_reward_pct     | 94.6        |\n",
      "|    total_trades         | 51303       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018788086 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0399      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.34        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.99        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1903317.99\n",
      "total_reward: 903317.99\n",
      "total_cost: 149046.05\n",
      "total_trades: 50874\n",
      "Sharpe: 0.592\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.9e+06     |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | 9.03e+05    |\n",
      "|    total_reward_pct     | 90.3        |\n",
      "|    total_trades         | 50874       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026808068 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0203      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.59        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.92e+06   |\n",
      "|    total_cost           | 1.48e+05   |\n",
      "|    total_reward         | 9.19e+05   |\n",
      "|    total_reward_pct     | 91.9       |\n",
      "|    total_trades         | 51177      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 284        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02485457 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0658     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.84       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0231    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 16.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.81e+06   |\n",
      "|    total_cost           | 1.48e+05   |\n",
      "|    total_reward         | 8.15e+05   |\n",
      "|    total_reward_pct     | 81.5       |\n",
      "|    total_trades         | 51392      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 297        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02645633 |\n",
      "|    clip_fraction        | 0.257      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | -0.00784   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.63       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0197    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 9.44       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.9e+06     |\n",
      "|    total_cost           | 1.44e+05    |\n",
      "|    total_reward         | 8.99e+05    |\n",
      "|    total_reward_pct     | 89.9        |\n",
      "|    total_trades         | 50802       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029379442 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.051       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.33        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1726728.83\n",
      "total_reward: 726728.83\n",
      "total_cost: 143782.58\n",
      "total_trades: 50425\n",
      "Sharpe: 0.537\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.73e+06   |\n",
      "|    total_cost           | 1.44e+05   |\n",
      "|    total_reward         | 7.27e+05   |\n",
      "|    total_reward_pct     | 72.7       |\n",
      "|    total_trades         | 50425      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 323        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02736284 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0664     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.34       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0216    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 15.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.21e+06    |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 1.21e+06    |\n",
      "|    total_reward_pct     | 121         |\n",
      "|    total_trades         | 50372       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029670164 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0156      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.65        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+06    |\n",
      "|    total_cost           | 1.44e+05    |\n",
      "|    total_reward         | 1.61e+06    |\n",
      "|    total_reward_pct     | 161         |\n",
      "|    total_trades         | 51116       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037660684 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0579      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.62        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.25e+06    |\n",
      "|    total_cost           | 1.29e+05    |\n",
      "|    total_reward         | 1.25e+06    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 49897       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022970159 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0659      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.85        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.29e+06    |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 1.29e+06    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 50685       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034641992 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.4         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1725419.90\n",
      "total_reward: 725419.90\n",
      "total_cost: 142904.49\n",
      "total_trades: 50688\n",
      "Sharpe: 0.529\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.73e+06   |\n",
      "|    total_cost           | 1.43e+05   |\n",
      "|    total_reward         | 7.25e+05   |\n",
      "|    total_reward_pct     | 72.5       |\n",
      "|    total_trades         | 50688      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 387        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03478398 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.2        |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0224    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 13.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.17e+06   |\n",
      "|    total_cost           | 1.37e+05   |\n",
      "|    total_reward         | 1.17e+06   |\n",
      "|    total_reward_pct     | 117        |\n",
      "|    total_trades         | 50232      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 399        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02474437 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.175      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.17       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 11.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.34e+06    |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | 1.34e+06    |\n",
      "|    total_reward_pct     | 134         |\n",
      "|    total_trades         | 51135       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033601336 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.066       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.55        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.31e+06   |\n",
      "|    total_cost           | 1.34e+05   |\n",
      "|    total_reward         | 1.31e+06   |\n",
      "|    total_reward_pct     | 131        |\n",
      "|    total_trades         | 49604      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 425        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03749641 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.178      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.8        |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 14.1       |\n",
      "----------------------------------------\n",
      "day: 1824, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1906684.85\n",
      "total_reward: 906684.85\n",
      "total_cost: 128315.94\n",
      "total_trades: 49268\n",
      "Sharpe: 0.658\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.91e+06   |\n",
      "|    total_cost           | 1.28e+05   |\n",
      "|    total_reward         | 9.07e+05   |\n",
      "|    total_reward_pct     | 90.7       |\n",
      "|    total_trades         | 49268      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 438        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03408136 |\n",
      "|    clip_fraction        | 0.257      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.126      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.04       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 12.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 1.33e+06    |\n",
      "|    total_reward_pct     | 133         |\n",
      "|    total_trades         | 49772       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019581221 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.32        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.12e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 1.12e+06    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 49224       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 464         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016513368 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.26        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.94e+06    |\n",
      "|    total_cost           | 1.31e+05    |\n",
      "|    total_reward         | 9.42e+05    |\n",
      "|    total_reward_pct     | 94.2        |\n",
      "|    total_trades         | 49393       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 477         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023053108 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.75        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.4e+06     |\n",
      "|    total_cost           | 1.38e+05    |\n",
      "|    total_reward         | 1.4e+06     |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 50275       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 489         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025647417 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.92        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1824, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2038313.83\n",
      "total_reward: 1038313.83\n",
      "total_cost: 138582.68\n",
      "total_trades: 50343\n",
      "Sharpe: 0.679\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+06    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 1.04e+06    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 50343       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 502         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049309406 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.15        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.44e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 1.44e+06    |\n",
      "|    total_reward_pct     | 144         |\n",
      "|    total_trades         | 49178       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 515         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035537444 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.00757     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.48        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.74e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 1.74e+06    |\n",
      "|    total_reward_pct     | 174         |\n",
      "|    total_trades         | 49468       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029158914 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.069       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.91        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.03e+06    |\n",
      "|    total_cost           | 1.47e+05    |\n",
      "|    total_reward         | 1.03e+06    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 50650       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 541         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042956166 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | -0.000714   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2628760.06\n",
      "total_reward: 1628760.06\n",
      "total_cost: 137325.70\n",
      "total_trades: 49752\n",
      "Sharpe: 0.959\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.63e+06    |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 1.63e+06    |\n",
      "|    total_reward_pct     | 163         |\n",
      "|    total_trades         | 49752       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 555         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031943828 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.64        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.47e+06    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 1.47e+06    |\n",
      "|    total_reward_pct     | 147         |\n",
      "|    total_trades         | 49821       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031971216 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0932      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.64        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.4e+06     |\n",
      "|    total_cost           | 1.38e+05    |\n",
      "|    total_reward         | 1.4e+06     |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 49805       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 581         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046913944 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0187      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.73        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 50020       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 594         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019647717 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.19        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.54e+06    |\n",
      "|    total_cost           | 1.46e+05    |\n",
      "|    total_reward         | 1.54e+06    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 50696       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 607         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026573356 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.87        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2287562.50\n",
      "total_reward: 1287562.50\n",
      "total_cost: 149053.83\n",
      "total_trades: 50349\n",
      "Sharpe: 0.782\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.29e+06   |\n",
      "|    total_cost           | 1.49e+05   |\n",
      "|    total_reward         | 1.29e+06   |\n",
      "|    total_reward_pct     | 129        |\n",
      "|    total_trades         | 50349      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 620        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04322612 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0329     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.81       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0181    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 14.9       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| environment/            |          |\n",
      "|    portfolio_value      | 1.91e+06 |\n",
      "|    total_cost           | 1.51e+05 |\n",
      "|    total_reward         | 9.1e+05  |\n",
      "|    total_reward_pct     | 91       |\n",
      "|    total_trades         | 50448    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 158      |\n",
      "|    iterations           | 49       |\n",
      "|    time_elapsed         | 632      |\n",
      "|    total_timesteps      | 100352   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.035389 |\n",
      "|    clip_fraction        | 0.344    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -44.6    |\n",
      "|    explained_variance   | 0.105    |\n",
      "|    learning_rate        | 0.00025  |\n",
      "|    loss                 | 7.65     |\n",
      "|    n_updates            | 480      |\n",
      "|    policy_gradient_loss | -0.00499 |\n",
      "|    std                  | 1.07     |\n",
      "|    value_loss           | 15.4     |\n",
      "--------------------------------------\n",
      "======PPO Validation from:  2016-04-05 to  2016-07-05\n",
      "PPO Sharpe Ratio:  0.07885903271298561\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_4\n",
      "day: 1824, episode: 75\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2329204.55\n",
      "total_reward: 1329204.55\n",
      "total_cost: 1687.99\n",
      "total_trades: 32414\n",
      "Sharpe: 0.796\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.26e+06 |\n",
      "|    total_cost       | 1.56e+03 |\n",
      "|    total_reward     | 1.26e+06 |\n",
      "|    total_reward_pct | 126      |\n",
      "|    total_trades     | 30175    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total timesteps  | 7300     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 66.9     |\n",
      "|    critic_loss      | 281      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5475     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2016-04-05 to  2016-07-05\n",
      "======Best Model Retraining from:  2009-01-01 to  2016-07-05\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_252_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.14e+06 |\n",
      "|    total_cost       | 1.18e+03 |\n",
      "|    total_reward     | 2.14e+06 |\n",
      "|    total_reward_pct | 214      |\n",
      "|    total_trades     | 26356    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total timesteps  | 7552     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -68.2    |\n",
      "|    critic_loss      | 60.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5664     |\n",
      "----------------------------------\n",
      "day: 1887, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3080217.35\n",
      "total_reward: 2080217.35\n",
      "total_cost: 1061.61\n",
      "total_trades: 24287\n",
      "Sharpe: 0.950\n",
      "=================================\n",
      "======Trading from:  2016-07-05 to  2016-10-03\n",
      "============================================\n",
      "22.55916810244482\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2016-07-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_315_4\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -107     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0944   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -153     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -215     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 27.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.97e+06 |\n",
      "|    total_cost         | 3.12e+04 |\n",
      "|    total_reward       | 1.97e+06 |\n",
      "|    total_reward_pct   | 197      |\n",
      "|    total_trades       | 35721    |\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00242 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -19.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.736    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -52.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 5.11     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 0.368    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.0037  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 138      |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.41e+06 |\n",
      "|    total_cost         | 2.04e+04 |\n",
      "|    total_reward       | 2.41e+06 |\n",
      "|    total_reward_pct   | 241      |\n",
      "|    total_trades       | 33142    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00998 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 23.4     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 1.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.0481   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 146      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 35.8     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 1.26     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 124       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 20        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.31e+06 |\n",
      "|    total_cost         | 1.92e+04 |\n",
      "|    total_reward       | 2.31e+06 |\n",
      "|    total_reward_pct   | 231      |\n",
      "|    total_trades       | 33317    |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00684 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -58      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -57.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 210      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 29.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 150      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 23.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.41e+06 |\n",
      "|    total_cost         | 2.14e+04 |\n",
      "|    total_reward       | 2.41e+06 |\n",
      "|    total_reward_pct   | 241      |\n",
      "|    total_trades       | 34898    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 65.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -56.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 367      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 78.8     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1887, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3526776.17\n",
      "total_reward: 2526776.17\n",
      "total_cost: 19947.59\n",
      "total_trades: 35416\n",
      "Sharpe: 1.035\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.53e+06 |\n",
      "|    total_cost         | 1.99e+04 |\n",
      "|    total_reward       | 2.53e+06 |\n",
      "|    total_reward_pct   | 253      |\n",
      "|    total_trades       | 35416    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.202   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 105      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.498   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -75.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.41    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 28.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.711    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -289     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 52.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.44e+06 |\n",
      "|    total_cost         | 4.06e+04 |\n",
      "|    total_reward       | 3.44e+06 |\n",
      "|    total_reward_pct   | 344      |\n",
      "|    total_trades       | 38911    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0932   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -152     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 14.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00502 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 142      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 21.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 26.3     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.579    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 89.4     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.42     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.29e+06  |\n",
      "|    total_cost         | 4.1e+04   |\n",
      "|    total_reward       | 2.29e+06  |\n",
      "|    total_reward_pct   | 229       |\n",
      "|    total_trades       | 38992     |\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 63.5      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.61      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 72       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -427     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 92.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -459     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 162      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.39e+06 |\n",
      "|    total_cost         | 1.78e+04 |\n",
      "|    total_reward       | 2.39e+06 |\n",
      "|    total_reward_pct   | 239      |\n",
      "|    total_trades       | 34345    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0634   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 180      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 21.4     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 141      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 124      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.27e+06 |\n",
      "|    total_cost         | 2.61e+04 |\n",
      "|    total_reward       | 3.27e+06 |\n",
      "|    total_reward_pct   | 327      |\n",
      "|    total_trades       | 35555    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.686   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -326     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 106      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00371  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -9.41    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.191    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -105     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 434      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 150      |\n",
      "------------------------------------\n",
      "day: 1887, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3969748.60\n",
      "total_reward: 2969748.60\n",
      "total_cost: 16515.81\n",
      "total_trades: 32872\n",
      "Sharpe: 1.055\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.97e+06 |\n",
      "|    total_cost         | 1.65e+04 |\n",
      "|    total_reward       | 2.97e+06 |\n",
      "|    total_reward_pct   | 297      |\n",
      "|    total_trades       | 32872    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.016   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -56.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.027   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -90.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 115      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -164     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.1e+06  |\n",
      "|    total_cost         | 1.63e+04 |\n",
      "|    total_reward       | 3.1e+06  |\n",
      "|    total_reward_pct   | 310      |\n",
      "|    total_trades       | 33232    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 38.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -208     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 36.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 92.6      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 5.39      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -152     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.82e+06 |\n",
      "|    total_cost         | 2.17e+04 |\n",
      "|    total_reward       | 2.82e+06 |\n",
      "|    total_reward_pct   | 282      |\n",
      "|    total_trades       | 33823    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.000207 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -16      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 25       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -104     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.45     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 64.5      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 11.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -195     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 23.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.37e+06 |\n",
      "|    total_cost         | 1.83e+04 |\n",
      "|    total_reward       | 3.37e+06 |\n",
      "|    total_reward_pct   | 337      |\n",
      "|    total_trades       | 33250    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 115      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -193     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 26       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 98.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.86e+06 |\n",
      "|    total_cost         | 1.59e+04 |\n",
      "|    total_reward       | 2.86e+06 |\n",
      "|    total_reward_pct   | 286      |\n",
      "|    total_trades       | 31507    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -11.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 512      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 177      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 75.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 202      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 26.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 185       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 102       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 20.2      |\n",
      "-------------------------------------\n",
      "day: 1887, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4344078.94\n",
      "total_reward: 3344078.94\n",
      "total_cost: 14283.63\n",
      "total_trades: 28965\n",
      "Sharpe: 1.152\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.34e+06 |\n",
      "|    total_cost         | 1.43e+04 |\n",
      "|    total_reward       | 3.34e+06 |\n",
      "|    total_reward_pct   | 334      |\n",
      "|    total_trades       | 28965    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.000319 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 49.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.00382  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 24.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 281      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 36.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 747      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 374      |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2016-07-05 to  2016-10-03\n",
      "A2C Sharpe Ratio:  0.010096738474208252\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_315_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.03e+06 |\n",
      "|    total_cost       | 1.69e+05 |\n",
      "|    total_reward     | 1.03e+06 |\n",
      "|    total_reward_pct | 103      |\n",
      "|    total_trades     | 54792    |\n",
      "| time/               |          |\n",
      "|    fps              | 147      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.41e+06    |\n",
      "|    total_cost           | 1.7e+05     |\n",
      "|    total_reward         | 1.41e+06    |\n",
      "|    total_reward_pct     | 141         |\n",
      "|    total_trades         | 54692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021290934 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00468    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.71        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.24e+06    |\n",
      "|    total_cost           | 1.65e+05    |\n",
      "|    total_reward         | 1.24e+06    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 54435       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025700927 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00618    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.44        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1900685.95\n",
      "total_reward: 900685.95\n",
      "total_cost: 169474.71\n",
      "total_trades: 54556\n",
      "Sharpe: 0.645\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.9e+06     |\n",
      "|    total_cost           | 1.69e+05    |\n",
      "|    total_reward         | 9.01e+05    |\n",
      "|    total_reward_pct     | 90.1        |\n",
      "|    total_trades         | 54556       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027100816 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.27        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.09e+06     |\n",
      "|    total_cost           | 1.66e+05     |\n",
      "|    total_reward         | 1.09e+06     |\n",
      "|    total_reward_pct     | 109          |\n",
      "|    total_trades         | 54297        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133636035 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.7        |\n",
      "|    explained_variance   | -0.0327      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.4          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0228      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 12.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.05e+06    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 1.05e+06    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 53987       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013221646 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00404    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.55        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2e+06      |\n",
      "|    total_cost           | 1.64e+05   |\n",
      "|    total_reward         | 1e+06      |\n",
      "|    total_reward_pct     | 100        |\n",
      "|    total_trades         | 53864      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01769284 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | 0.0164     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.28       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0247    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 14.1       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.16e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 1.16e+06    |\n",
      "|    total_reward_pct     | 116         |\n",
      "|    total_trades         | 53419       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023037875 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00986    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.64        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2083816.78\n",
      "total_reward: 1083816.78\n",
      "total_cost: 162993.97\n",
      "total_trades: 53423\n",
      "Sharpe: 0.713\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.08e+06    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 1.08e+06    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 53423       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015383476 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0293      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.44        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.06e+06    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 1.06e+06    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 53486       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028494855 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0489      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.25        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.19e+06   |\n",
      "|    total_cost           | 1.58e+05   |\n",
      "|    total_reward         | 1.19e+06   |\n",
      "|    total_reward_pct     | 119        |\n",
      "|    total_trades         | 53316      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 148        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02204628 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | 0.0465     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.9        |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 11.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.84e+06    |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | 8.39e+05    |\n",
      "|    total_reward_pct     | 83.9        |\n",
      "|    total_trades         | 53483       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036680914 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0275      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.7         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1886542.56\n",
      "total_reward: 886542.56\n",
      "total_cost: 161259.73\n",
      "total_trades: 53675\n",
      "Sharpe: 0.660\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.89e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 8.87e+05    |\n",
      "|    total_reward_pct     | 88.7        |\n",
      "|    total_trades         | 53675       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016397474 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0489     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.04        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.48e+06   |\n",
      "|    total_cost           | 1.62e+05   |\n",
      "|    total_reward         | 1.48e+06   |\n",
      "|    total_reward_pct     | 148        |\n",
      "|    total_trades         | 53686      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 188        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02335822 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.0331     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.58       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0214    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 7.71       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.39e+06    |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 1.39e+06    |\n",
      "|    total_reward_pct     | 139         |\n",
      "|    total_trades         | 53021       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021927876 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.00366    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.02        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.43e+06    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | 1.43e+06    |\n",
      "|    total_reward_pct     | 143         |\n",
      "|    total_trades         | 52983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026505576 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0134      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.05        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.99e+06    |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 9.95e+05    |\n",
      "|    total_reward_pct     | 99.5        |\n",
      "|    total_trades         | 52390       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025502075 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.00346    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.23        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2237257.30\n",
      "total_reward: 1237257.30\n",
      "total_cost: 150361.71\n",
      "total_trades: 52306\n",
      "Sharpe: 0.722\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.24e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 1.24e+06    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 52306       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026192227 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00237     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.05        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.13e+06   |\n",
      "|    total_cost           | 1.49e+05   |\n",
      "|    total_reward         | 1.13e+06   |\n",
      "|    total_reward_pct     | 113        |\n",
      "|    total_trades         | 52484      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 258        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02501727 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0467     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.94       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 17         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.03e+06    |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | 1.03e+06    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 51971       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026549822 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0174      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.69        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.82e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 8.18e+05    |\n",
      "|    total_reward_pct     | 81.8        |\n",
      "|    total_trades         | 52372       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027840734 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0681      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.25        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.84e+06    |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | 8.45e+05    |\n",
      "|    total_reward_pct     | 84.5        |\n",
      "|    total_trades         | 52350       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023309974 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0646      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.83        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2591809.20\n",
      "total_reward: 1591809.20\n",
      "total_cost: 142306.70\n",
      "total_trades: 51614\n",
      "Sharpe: 0.829\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.59e+06    |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | 1.59e+06    |\n",
      "|    total_reward_pct     | 159         |\n",
      "|    total_trades         | 51614       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025840083 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.02        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.79e+06    |\n",
      "|    total_cost           | 1.44e+05    |\n",
      "|    total_reward         | 7.88e+05    |\n",
      "|    total_reward_pct     | 78.8        |\n",
      "|    total_trades         | 51798       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023190306 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0585      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.05        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.44e+06    |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | 1.44e+06    |\n",
      "|    total_reward_pct     | 144         |\n",
      "|    total_trades         | 52365       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032866277 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.97        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.06e+06    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 1.06e+06    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 51559       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026435256 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0921      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.76        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2265879.27\n",
      "total_reward: 1265879.27\n",
      "total_cost: 142094.49\n",
      "total_trades: 51827\n",
      "Sharpe: 0.762\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.27e+06    |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | 1.27e+06    |\n",
      "|    total_reward_pct     | 127         |\n",
      "|    total_trades         | 51827       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029970257 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.61        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.37e+06   |\n",
      "|    total_cost           | 1.35e+05   |\n",
      "|    total_reward         | 1.37e+06   |\n",
      "|    total_reward_pct     | 137        |\n",
      "|    total_trades         | 51028      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 377        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02549162 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0832     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.59       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.00819   |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 15.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.37e+06    |\n",
      "|    total_cost           | 1.3e+05     |\n",
      "|    total_reward         | 1.37e+06    |\n",
      "|    total_reward_pct     | 137         |\n",
      "|    total_trades         | 50720       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024646305 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.75        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.46e+06   |\n",
      "|    total_cost           | 1.34e+05   |\n",
      "|    total_reward         | 1.46e+06   |\n",
      "|    total_reward_pct     | 146        |\n",
      "|    total_trades         | 50716      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 403        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03231712 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0407     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.55       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0087    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 23.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.18e+06    |\n",
      "|    total_cost           | 1.36e+05    |\n",
      "|    total_reward         | 1.18e+06    |\n",
      "|    total_reward_pct     | 118         |\n",
      "|    total_trades         | 50975       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023608785 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.46        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1887, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2611879.33\n",
      "total_reward: 1611879.33\n",
      "total_cost: 129909.66\n",
      "total_trades: 50176\n",
      "Sharpe: 0.835\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+06    |\n",
      "|    total_cost           | 1.3e+05     |\n",
      "|    total_reward         | 1.61e+06    |\n",
      "|    total_reward_pct     | 161         |\n",
      "|    total_trades         | 50176       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021117544 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.69e+06    |\n",
      "|    total_cost           | 1.33e+05    |\n",
      "|    total_reward         | 1.69e+06    |\n",
      "|    total_reward_pct     | 169         |\n",
      "|    total_trades         | 50597       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036777504 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0939      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.98        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+06    |\n",
      "|    total_cost           | 1.35e+05    |\n",
      "|    total_reward         | 1.78e+06    |\n",
      "|    total_reward_pct     | 178         |\n",
      "|    total_trades         | 50683       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030385781 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0807      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.9e+06     |\n",
      "|    total_cost           | 1.33e+05    |\n",
      "|    total_reward         | 1.9e+06     |\n",
      "|    total_reward_pct     | 190         |\n",
      "|    total_trades         | 50485       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030543154 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2431091.43\n",
      "total_reward: 1431091.43\n",
      "total_cost: 128065.25\n",
      "total_trades: 50099\n",
      "Sharpe: 0.782\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.43e+06    |\n",
      "|    total_cost           | 1.28e+05    |\n",
      "|    total_reward         | 1.43e+06    |\n",
      "|    total_reward_pct     | 143         |\n",
      "|    total_trades         | 50099       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 481         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028106984 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0694      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 1.22e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 49349       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036710605 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.71e+06   |\n",
      "|    total_cost           | 1.16e+05   |\n",
      "|    total_reward         | 1.71e+06   |\n",
      "|    total_reward_pct     | 171        |\n",
      "|    total_trades         | 48940      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 507        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03692356 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.118      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.86       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.00953   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 21.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+06    |\n",
      "|    total_cost           | 1.34e+05    |\n",
      "|    total_reward         | 1.78e+06    |\n",
      "|    total_reward_pct     | 178         |\n",
      "|    total_trades         | 50913       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022671962 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.000985    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+06    |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 1.58e+06    |\n",
      "|    total_reward_pct     | 158         |\n",
      "|    total_trades         | 51011       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 533         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029462863 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2541700.64\n",
      "total_reward: 1541700.64\n",
      "total_cost: 124808.47\n",
      "total_trades: 50072\n",
      "Sharpe: 0.822\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.54e+06    |\n",
      "|    total_cost           | 1.25e+05    |\n",
      "|    total_reward         | 1.54e+06    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 50072       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019533785 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.83        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+06    |\n",
      "|    total_cost           | 1.35e+05    |\n",
      "|    total_reward         | 1.65e+06    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 50919       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 559         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032748286 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0933      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.69e+06   |\n",
      "|    total_cost           | 1.21e+05   |\n",
      "|    total_reward         | 1.69e+06   |\n",
      "|    total_reward_pct     | 169        |\n",
      "|    total_trades         | 49714      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 572        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03691852 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.72       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00674   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 21.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+06     |\n",
      "|    total_cost           | 1.27e+05    |\n",
      "|    total_reward         | 1.8e+06     |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 50184       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 585         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034702066 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.03e+06    |\n",
      "|    total_cost           | 1.28e+05    |\n",
      "|    total_reward         | 2.03e+06    |\n",
      "|    total_reward_pct     | 203         |\n",
      "|    total_trades         | 50319       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055275567 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0904      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2890029.48\n",
      "total_reward: 1890029.48\n",
      "total_cost: 129813.90\n",
      "total_trades: 50447\n",
      "Sharpe: 0.947\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.89e+06    |\n",
      "|    total_cost           | 1.3e+05     |\n",
      "|    total_reward         | 1.89e+06    |\n",
      "|    total_reward_pct     | 189         |\n",
      "|    total_trades         | 50447       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048635453 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0947      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.99        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.00653     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+06    |\n",
      "|    total_cost           | 1.26e+05    |\n",
      "|    total_reward         | 1.58e+06    |\n",
      "|    total_reward_pct     | 158         |\n",
      "|    total_trades         | 50011       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 624         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039835878 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+06    |\n",
      "|    total_cost           | 1.34e+05    |\n",
      "|    total_reward         | 1.58e+06    |\n",
      "|    total_reward_pct     | 158         |\n",
      "|    total_trades         | 50865       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 637         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038254198 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.066       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.44e+06   |\n",
      "|    total_cost           | 1.38e+05   |\n",
      "|    total_reward         | 1.44e+06   |\n",
      "|    total_reward_pct     | 144        |\n",
      "|    total_trades         | 51077      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 650        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04117301 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00295   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 21.8       |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2016-07-05 to  2016-10-03\n",
      "PPO Sharpe Ratio:  -0.05990032899437205\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_3\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.34e+06 |\n",
      "|    total_cost       | 1.33e+03 |\n",
      "|    total_reward     | 1.34e+06 |\n",
      "|    total_reward_pct | 134      |\n",
      "|    total_trades     | 20018    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total timesteps  | 7552     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -10.7    |\n",
      "|    critic_loss      | 66.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5664     |\n",
      "----------------------------------\n",
      "day: 1887, episode: 75\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2379195.69\n",
      "total_reward: 1379195.69\n",
      "total_cost: 999.00\n",
      "total_trades: 24432\n",
      "Sharpe: 0.869\n",
      "=================================\n",
      "======DDPG Validation from:  2016-07-05 to  2016-10-03\n",
      "======Best Model Retraining from:  2009-01-01 to  2016-10-03\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_315_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.391   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -10.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.135    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00118  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -29.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.957    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -405     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 94.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.52e+06 |\n",
      "|    total_cost         | 7.66e+04 |\n",
      "|    total_reward       | 1.52e+06 |\n",
      "|    total_reward_pct   | 152      |\n",
      "|    total_trades       | 45493    |\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -30.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 37.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 97.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 84       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.85e+06 |\n",
      "|    total_cost         | 5.55e+04 |\n",
      "|    total_reward       | 1.85e+06 |\n",
      "|    total_reward_pct   | 185      |\n",
      "|    total_trades       | 42797    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.031    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 75.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.42     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 5.77     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.524    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 55.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 77.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.59e+06 |\n",
      "|    total_cost         | 1.27e+04 |\n",
      "|    total_reward       | 1.59e+06 |\n",
      "|    total_reward_pct   | 159      |\n",
      "|    total_trades       | 34486    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0323   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 41       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 180      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 28.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 45.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 209      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 30.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.61e+06 |\n",
      "|    total_cost         | 1.34e+04 |\n",
      "|    total_reward       | 1.61e+06 |\n",
      "|    total_reward_pct   | 161      |\n",
      "|    total_trades       | 31818    |\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0847  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 53.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 41.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.24     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -5.09     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.78      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -109     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.98     |\n",
      "------------------------------------\n",
      "day: 1950, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3153045.44\n",
      "total_reward: 2153045.44\n",
      "total_cost: 10112.88\n",
      "total_trades: 32276\n",
      "Sharpe: 1.095\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.15e+06 |\n",
      "|    total_cost         | 1.01e+04 |\n",
      "|    total_reward       | 2.15e+06 |\n",
      "|    total_reward_pct   | 215      |\n",
      "|    total_trades       | 32276    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0325   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 63.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -26      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.781    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -120     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.06     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 139       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 36.2      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.84      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.49e+06 |\n",
      "|    total_cost         | 9.31e+03 |\n",
      "|    total_reward       | 2.49e+06 |\n",
      "|    total_reward_pct   | 249      |\n",
      "|    total_trades       | 32221    |\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -68.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.15     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 139       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 35.1      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.16      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -158     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 16       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -192     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 28       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.52e+06 |\n",
      "|    total_cost         | 8.42e+03 |\n",
      "|    total_reward       | 2.52e+06 |\n",
      "|    total_reward_pct   | 252      |\n",
      "|    total_trades       | 31116    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.00379 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -253     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 45.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.66     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -24.7     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.725     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -159     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 35       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.49e+06 |\n",
      "|    total_cost         | 8.11e+03 |\n",
      "|    total_reward       | 2.49e+06 |\n",
      "|    total_reward_pct   | 249      |\n",
      "|    total_trades       | 31759    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -108     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -160     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -73      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 169      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 25.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.2e+06  |\n",
      "|    total_cost         | 8.44e+03 |\n",
      "|    total_reward       | 2.2e+06  |\n",
      "|    total_reward_pct   | 220      |\n",
      "|    total_trades       | 32820    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 49.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.92     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 142       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 74.1      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 6.15      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 131      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 142       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -315      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 94.5      |\n",
      "-------------------------------------\n",
      "day: 1950, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4762240.40\n",
      "total_reward: 3762240.40\n",
      "total_cost: 67371.35\n",
      "total_trades: 40988\n",
      "Sharpe: 1.308\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.76e+06 |\n",
      "|    total_cost         | 6.74e+04 |\n",
      "|    total_reward       | 3.76e+06 |\n",
      "|    total_reward_pct   | 376      |\n",
      "|    total_trades       | 40988    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0832  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 129      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 20.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.032   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -22.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.702    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -91.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.05e+06 |\n",
      "|    total_cost         | 5.95e+04 |\n",
      "|    total_reward       | 2.05e+06 |\n",
      "|    total_reward_pct   | 205      |\n",
      "|    total_trades       | 40703    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -113     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -7.35    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 66.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 195      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 41.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.02e+06 |\n",
      "|    total_cost         | 7.39e+04 |\n",
      "|    total_reward       | 2.02e+06 |\n",
      "|    total_reward_pct   | 202      |\n",
      "|    total_trades       | 42700    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -9.74    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 204      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 31.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.000296 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 99.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.00126  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 81.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 27.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.87     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.34e+06 |\n",
      "|    total_cost         | 8.9e+04  |\n",
      "|    total_reward       | 2.34e+06 |\n",
      "|    total_reward_pct   | 234      |\n",
      "|    total_trades       | 44760    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.0435   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 66.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.0989  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 136      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 15       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.372    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.0399  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -298     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 51.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.45e+06 |\n",
      "|    total_cost         | 7.58e+04 |\n",
      "|    total_reward       | 1.45e+06 |\n",
      "|    total_reward_pct   | 145      |\n",
      "|    total_trades       | 44474    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.169   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -7.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.441    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 214      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 24.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 90.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 7.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.000276 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 16.1     |\n",
      "------------------------------------\n",
      "day: 1950, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3637099.73\n",
      "total_reward: 2637099.73\n",
      "total_cost: 53956.43\n",
      "total_trades: 39929\n",
      "Sharpe: 1.107\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.64e+06 |\n",
      "|    total_cost         | 5.4e+04  |\n",
      "|    total_reward       | 2.64e+06 |\n",
      "|    total_reward_pct   | 264      |\n",
      "|    total_trades       | 39929    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.00604 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 44       |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0.0674   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -232     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 31       |\n",
      "------------------------------------\n",
      "======Trading from:  2016-10-03 to  2017-01-03\n",
      "============================================\n",
      "16.887756699950526\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2016-10-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_378_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.114    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -25.8    |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 0.499    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.0913   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -14.7    |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 0.415    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -233     |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 32.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.92e+06 |\n",
      "|    total_cost         | 1.07e+05 |\n",
      "|    total_reward       | 1.92e+06 |\n",
      "|    total_reward_pct   | 192      |\n",
      "|    total_trades       | 50234    |\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.0954   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -129     |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 9.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.031   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 11.2     |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 0.722    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 92.1     |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 7.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 157      |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.53e+06 |\n",
      "|    total_cost         | 9.14e+04 |\n",
      "|    total_reward       | 2.53e+06 |\n",
      "|    total_reward_pct   | 253      |\n",
      "|    total_trades       | 47712    |\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.00312 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 148      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -40.4    |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.147    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 158      |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 14.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.129    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -47.5    |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 2.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.8e+06  |\n",
      "|    total_cost         | 8.22e+04 |\n",
      "|    total_reward       | 1.8e+06  |\n",
      "|    total_reward_pct   | 180      |\n",
      "|    total_trades       | 45210    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -3.35    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 164      |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 20.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.296   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 161      |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 17.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 20.7     |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 0.484    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.909   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 157      |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 18.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.45e+06 |\n",
      "|    total_cost         | 9.64e+04 |\n",
      "|    total_reward       | 1.45e+06 |\n",
      "|    total_reward_pct   | 145      |\n",
      "|    total_trades       | 47319    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.000127 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 43.7     |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 3.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.308    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 145      |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 14.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 142       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -95.9     |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 6.57      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.0753  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -84.3    |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 7.66     |\n",
      "------------------------------------\n",
      "day: 1950, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2359306.54\n",
      "total_reward: 1359306.54\n",
      "total_cost: 60001.65\n",
      "total_trades: 40384\n",
      "Sharpe: 0.650\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.36e+06 |\n",
      "|    total_cost         | 6e+04    |\n",
      "|    total_reward       | 1.36e+06 |\n",
      "|    total_reward_pct   | 136      |\n",
      "|    total_trades       | 40384    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.114    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 22       |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -52.2    |\n",
      "|    std                | 0.995    |\n",
      "|    value_loss         | 6.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | -3.37    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -146     |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 11.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 146      |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.11e+06 |\n",
      "|    total_cost         | 5.61e+04 |\n",
      "|    total_reward       | 1.11e+06 |\n",
      "|    total_reward_pct   | 111      |\n",
      "|    total_trades       | 40154    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 0.0956   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -5.49    |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 0.404    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 123      |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 7.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 185      |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 27.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -223     |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 34.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.71e+06 |\n",
      "|    total_cost         | 4.47e+04 |\n",
      "|    total_reward       | 2.71e+06 |\n",
      "|    total_reward_pct   | 271      |\n",
      "|    total_trades       | 38898    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.0539   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -269     |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 46.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 63.2     |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 3.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.0487  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 64.5     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 3.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.0909  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -361     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 82.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.68e+06 |\n",
      "|    total_cost         | 7.34e+04 |\n",
      "|    total_reward       | 2.68e+06 |\n",
      "|    total_reward_pct   | 268      |\n",
      "|    total_trades       | 40648    |\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0185  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -50.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.00765  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -178     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 20.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.0121  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -72.6    |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 4.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 366      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 106      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.14e+06 |\n",
      "|    total_cost         | 5.36e+04 |\n",
      "|    total_reward       | 3.14e+06 |\n",
      "|    total_reward_pct   | 314      |\n",
      "|    total_trades       | 38023    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -13.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.604    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -7.08     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 5.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -1.29    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.23    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -142     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 19.7     |\n",
      "------------------------------------\n",
      "day: 1950, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2644304.36\n",
      "total_reward: 1644304.36\n",
      "total_cost: 29466.36\n",
      "total_trades: 36913\n",
      "Sharpe: 0.792\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.64e+06 |\n",
      "|    total_cost         | 2.95e+04 |\n",
      "|    total_reward       | 1.64e+06 |\n",
      "|    total_reward_pct   | 164      |\n",
      "|    total_trades       | 36913    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 88.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 24.2     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 7.6      |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 3.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.51e+06 |\n",
      "|    total_cost         | 3.7e+04  |\n",
      "|    total_reward       | 1.51e+06 |\n",
      "|    total_reward_pct   | 151      |\n",
      "|    total_trades       | 40348    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.689    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -190     |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 18.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 8.93     |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 1.99     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 141       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -11.4     |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 0.876     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 141       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 162       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 164       |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 30.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.98e+06 |\n",
      "|    total_cost         | 2.02e+04 |\n",
      "|    total_reward       | 1.98e+06 |\n",
      "|    total_reward_pct   | 198      |\n",
      "|    total_trades       | 39387    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00109 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 127      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.4      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 141       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 169       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 194       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 26.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 202      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 22.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 43.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.56e+06 |\n",
      "|    total_cost         | 1.42e+04 |\n",
      "|    total_reward       | 1.56e+06 |\n",
      "|    total_reward_pct   | 156      |\n",
      "|    total_trades       | 39749    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.00958  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 72.3     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 75.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.3      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 142       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 185       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 14.2      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.303     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -263     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 39.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.93e+06 |\n",
      "|    total_cost         | 9.67e+03 |\n",
      "|    total_reward       | 1.93e+06 |\n",
      "|    total_reward_pct   | 193      |\n",
      "|    total_trades       | 38947    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.174    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -7.36    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.267    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 163      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 17.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 143       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 52.3      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 4.39      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 143       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 202       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 89.3      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 12.7      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1950, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2725652.08\n",
      "total_reward: 1725652.08\n",
      "total_cost: 6731.30\n",
      "total_trades: 37374\n",
      "Sharpe: 0.815\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.73e+06 |\n",
      "|    total_cost         | 6.73e+03 |\n",
      "|    total_reward       | 1.73e+06 |\n",
      "|    total_reward_pct   | 173      |\n",
      "|    total_trades       | 37374    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0631   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 0.214    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -230     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 32.6     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2016-10-03 to  2017-01-03\n",
      "A2C Sharpe Ratio:  0.704110361735709\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_378_3\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.84e+06 |\n",
      "|    total_cost       | 1.76e+05 |\n",
      "|    total_reward     | 8.36e+05 |\n",
      "|    total_reward_pct | 83.6     |\n",
      "|    total_trades     | 56452    |\n",
      "| time/               |          |\n",
      "|    fps              | 139      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 1.77e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 56453       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 143         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014139708 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.000727   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.75        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 8.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.4e+06     |\n",
      "|    total_cost           | 1.76e+05    |\n",
      "|    total_reward         | 1.4e+06     |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 56286       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018747004 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00216    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.78        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "day: 1950, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2624517.25\n",
      "total_reward: 1624517.25\n",
      "total_cost: 170492.95\n",
      "total_trades: 55982\n",
      "Sharpe: 0.916\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.62e+06   |\n",
      "|    total_cost           | 1.7e+05    |\n",
      "|    total_reward         | 1.62e+06   |\n",
      "|    total_reward_pct     | 162        |\n",
      "|    total_trades         | 55982      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02043933 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.00289   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.72       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 11.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.27e+06    |\n",
      "|    total_cost           | 1.69e+05    |\n",
      "|    total_reward         | 1.27e+06    |\n",
      "|    total_reward_pct     | 127         |\n",
      "|    total_trades         | 55645       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023611134 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0008     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.82        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.03e+06    |\n",
      "|    total_cost           | 1.72e+05    |\n",
      "|    total_reward         | 1.03e+06    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 55724       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018853808 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.00759    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.71        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.6e+06    |\n",
      "|    total_cost           | 1.75e+05   |\n",
      "|    total_reward         | 1.6e+06    |\n",
      "|    total_reward_pct     | 160        |\n",
      "|    total_trades         | 55895      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 96         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02533636 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | -0.0547    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.17       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 8.35       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.17e+06    |\n",
      "|    total_cost           | 1.7e+05     |\n",
      "|    total_reward         | 1.17e+06    |\n",
      "|    total_reward_pct     | 117         |\n",
      "|    total_trades         | 55362       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026640724 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00486    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.93        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "day: 1950, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2720905.78\n",
      "total_reward: 1720905.78\n",
      "total_cost: 163791.53\n",
      "total_trades: 54632\n",
      "Sharpe: 0.926\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.72e+06    |\n",
      "|    total_cost           | 1.64e+05    |\n",
      "|    total_reward         | 1.72e+06    |\n",
      "|    total_reward_pct     | 172         |\n",
      "|    total_trades         | 54632       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030214544 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0189      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.75        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.25e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 1.25e+06    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 55760       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021208381 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0188      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.89        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.32e+06    |\n",
      "|    total_cost           | 1.65e+05    |\n",
      "|    total_reward         | 1.32e+06    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 55066       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026586533 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.00351     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.29        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.91e+06    |\n",
      "|    total_cost           | 1.67e+05    |\n",
      "|    total_reward         | 1.91e+06    |\n",
      "|    total_reward_pct     | 191         |\n",
      "|    total_trades         | 55246       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023828264 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0153      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.41        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.48e+06   |\n",
      "|    total_cost           | 1.66e+05   |\n",
      "|    total_reward         | 1.48e+06   |\n",
      "|    total_reward_pct     | 148        |\n",
      "|    total_trades         | 54883      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 178        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04369414 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.000549   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.11       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 16.3       |\n",
      "----------------------------------------\n",
      "day: 1950, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2095857.33\n",
      "total_reward: 1095857.33\n",
      "total_cost: 167340.68\n",
      "total_trades: 55305\n",
      "Sharpe: 0.736\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 1.67e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 55305       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017121857 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0295      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.85        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.93e+06   |\n",
      "|    total_cost           | 1.63e+05   |\n",
      "|    total_reward         | 9.34e+05   |\n",
      "|    total_reward_pct     | 93.4       |\n",
      "|    total_trades         | 54987      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 205        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01787655 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.0356     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.73       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0185    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 9.64       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 54960       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018580085 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0872      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.58        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.47e+06    |\n",
      "|    total_cost           | 1.66e+05    |\n",
      "|    total_reward         | 1.47e+06    |\n",
      "|    total_reward_pct     | 147         |\n",
      "|    total_trades         | 55031       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025887422 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0267      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.73        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.92e+06    |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | 9.24e+05    |\n",
      "|    total_reward_pct     | 92.4        |\n",
      "|    total_trades         | 54252       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024358314 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0166      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.7         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "day: 1950, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2193644.81\n",
      "total_reward: 1193644.81\n",
      "total_cost: 166211.32\n",
      "total_trades: 55078\n",
      "Sharpe: 0.736\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.19e+06   |\n",
      "|    total_cost           | 1.66e+05   |\n",
      "|    total_reward         | 1.19e+06   |\n",
      "|    total_reward_pct     | 119        |\n",
      "|    total_trades         | 55078      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 261        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03711527 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0493     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.96       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 13.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.29e+06    |\n",
      "|    total_cost           | 1.64e+05    |\n",
      "|    total_reward         | 1.29e+06    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 54813       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016168555 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.00764    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.1         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.39e+06    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | 1.39e+06    |\n",
      "|    total_reward_pct     | 139         |\n",
      "|    total_trades         | 53540       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030138412 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.093       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.55        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.44e+06    |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | 1.44e+06    |\n",
      "|    total_reward_pct     | 144         |\n",
      "|    total_trades         | 52904       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025104506 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0105      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "day: 1950, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2396615.88\n",
      "total_reward: 1396615.88\n",
      "total_cost: 157798.22\n",
      "total_trades: 53509\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.4e+06     |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 1.4e+06     |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 53509       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 315         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036728036 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0248      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.41        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.97e+06  |\n",
      "|    total_cost           | 1.73e+05  |\n",
      "|    total_reward         | 1.97e+06  |\n",
      "|    total_reward_pct     | 197       |\n",
      "|    total_trades         | 54887     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 329       |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0554604 |\n",
      "|    clip_fraction        | 0.301     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.6     |\n",
      "|    explained_variance   | -0.00936  |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 11.8      |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -0.00722  |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 19.9      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.55e+06  |\n",
      "|    total_cost           | 1.68e+05  |\n",
      "|    total_reward         | 1.55e+06  |\n",
      "|    total_reward_pct     | 155       |\n",
      "|    total_trades         | 54074     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 342       |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0445612 |\n",
      "|    clip_fraction        | 0.294     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.7     |\n",
      "|    explained_variance   | 0.0437    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 7.33      |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -0.013    |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 21.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.66e+06    |\n",
      "|    total_cost           | 1.62e+05    |\n",
      "|    total_reward         | 1.66e+06    |\n",
      "|    total_reward_pct     | 166         |\n",
      "|    total_trades         | 53940       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 356         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017972535 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0327      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.66        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+06    |\n",
      "|    total_cost           | 1.54e+05    |\n",
      "|    total_reward         | 1.45e+06    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 53723       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023758303 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0801      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.77        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "day: 1950, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2513559.86\n",
      "total_reward: 1513559.86\n",
      "total_cost: 154209.55\n",
      "total_trades: 53576\n",
      "Sharpe: 0.852\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.51e+06   |\n",
      "|    total_cost           | 1.54e+05   |\n",
      "|    total_reward         | 1.51e+06   |\n",
      "|    total_reward_pct     | 151        |\n",
      "|    total_trades         | 53576      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 383        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02728886 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | -0.0139    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.28       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 19.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.67e+06   |\n",
      "|    total_cost           | 1.67e+05   |\n",
      "|    total_reward         | 1.67e+06   |\n",
      "|    total_reward_pct     | 167        |\n",
      "|    total_trades         | 54292      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 397        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03414829 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.037      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.42       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 20.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.88e+06    |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 1.88e+06    |\n",
      "|    total_reward_pct     | 188         |\n",
      "|    total_trades         | 53850       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024561968 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0019      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.03        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.68e+06    |\n",
      "|    total_cost           | 1.53e+05    |\n",
      "|    total_reward         | 1.68e+06    |\n",
      "|    total_reward_pct     | 168         |\n",
      "|    total_trades         | 53824       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034992456 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0129      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.64        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.6e+06    |\n",
      "|    total_cost           | 1.5e+05    |\n",
      "|    total_reward         | 1.6e+06    |\n",
      "|    total_reward_pct     | 160        |\n",
      "|    total_trades         | 53607      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 438        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01698359 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.0604     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.8       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 19.5       |\n",
      "----------------------------------------\n",
      "day: 1950, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2095100.66\n",
      "total_reward: 1095100.66\n",
      "total_cost: 144947.11\n",
      "total_trades: 52612\n",
      "Sharpe: 0.690\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 52612       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 453         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020703696 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | -0.0281     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.02e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 1.02e+06    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 53121       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 466         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039188832 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.00543     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.26        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 53057       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 480         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024830444 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.9         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.8e+06   |\n",
      "|    total_cost           | 1.45e+05  |\n",
      "|    total_reward         | 1.8e+06   |\n",
      "|    total_reward_pct     | 180       |\n",
      "|    total_trades         | 52356     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 494       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0314743 |\n",
      "|    clip_fraction        | 0.197     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.2     |\n",
      "|    explained_variance   | -0.0251   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 7.9       |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -0.0164   |\n",
      "|    std                  | 1.06      |\n",
      "|    value_loss           | 17.6      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.22e+06   |\n",
      "|    total_cost           | 1.28e+05   |\n",
      "|    total_reward         | 1.22e+06   |\n",
      "|    total_reward_pct     | 122        |\n",
      "|    total_trades         | 51663      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 507        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02990865 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.0321     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.2       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 21.3       |\n",
      "----------------------------------------\n",
      "day: 1950, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2942374.85\n",
      "total_reward: 1942374.85\n",
      "total_cost: 157656.56\n",
      "total_trades: 53322\n",
      "Sharpe: 1.016\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.94e+06    |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 1.94e+06    |\n",
      "|    total_reward_pct     | 194         |\n",
      "|    total_trades         | 53322       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040122326 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.5         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.37e+06   |\n",
      "|    total_cost           | 1.39e+05   |\n",
      "|    total_reward         | 1.37e+06   |\n",
      "|    total_reward_pct     | 137        |\n",
      "|    total_trades         | 52399      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 534        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01691963 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.0835     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 18.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.56e+06   |\n",
      "|    total_cost           | 1.54e+05   |\n",
      "|    total_reward         | 1.56e+06   |\n",
      "|    total_reward_pct     | 156        |\n",
      "|    total_trades         | 53255      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 548        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02880692 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.0651     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.43       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 17.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.43e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 1.43e+06    |\n",
      "|    total_reward_pct     | 143         |\n",
      "|    total_trades         | 51666       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 562         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036845617 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0354      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.57        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "day: 1950, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2601552.87\n",
      "total_reward: 1601552.87\n",
      "total_cost: 153147.82\n",
      "total_trades: 52845\n",
      "Sharpe: 0.836\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.6e+06     |\n",
      "|    total_cost           | 1.53e+05    |\n",
      "|    total_reward         | 1.6e+06     |\n",
      "|    total_reward_pct     | 160         |\n",
      "|    total_trades         | 52845       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032452047 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0294      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.73        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.37e+06   |\n",
      "|    total_cost           | 1.65e+05   |\n",
      "|    total_reward         | 1.37e+06   |\n",
      "|    total_reward_pct     | 137        |\n",
      "|    total_trades         | 54312      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 589        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03095073 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.0313     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.71       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 16.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.54e+06    |\n",
      "|    total_cost           | 1.47e+05    |\n",
      "|    total_reward         | 1.54e+06    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 52675       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022934716 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0807      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.63        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.49e+06    |\n",
      "|    total_cost           | 1.43e+05    |\n",
      "|    total_reward         | 1.49e+06    |\n",
      "|    total_reward_pct     | 149         |\n",
      "|    total_trades         | 52296       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 620         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017443234 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.8         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+06    |\n",
      "|    total_cost           | 1.34e+05    |\n",
      "|    total_reward         | 1.45e+06    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 51807       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 634         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019559754 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.5         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "day: 1950, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2651327.44\n",
      "total_reward: 1651327.44\n",
      "total_cost: 161021.62\n",
      "total_trades: 53277\n",
      "Sharpe: 0.865\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 1.65e+06    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 53277       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 647         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022291524 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.016       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.66        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.22e+06   |\n",
      "|    total_cost           | 1.26e+05   |\n",
      "|    total_reward         | 1.22e+06   |\n",
      "|    total_reward_pct     | 122        |\n",
      "|    total_trades         | 51264      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 661        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04309316 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.0197     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.25       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 16.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.41e+06    |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | 1.41e+06    |\n",
      "|    total_reward_pct     | 141         |\n",
      "|    total_trades         | 52755       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 674         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024831772 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0956      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.27        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2016-10-03 to  2017-01-03\n",
      "PPO Sharpe Ratio:  0.5217899734832385\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_3\n",
      "day: 1950, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2923496.41\n",
      "total_reward: 1923496.41\n",
      "total_cost: 1824.46\n",
      "total_trades: 31395\n",
      "Sharpe: 0.928\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.78e+06 |\n",
      "|    total_cost       | 1.2e+03  |\n",
      "|    total_reward     | 1.78e+06 |\n",
      "|    total_reward_pct | 178      |\n",
      "|    total_trades     | 35071    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total timesteps  | 7804     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -38.4    |\n",
      "|    critic_loss      | 261      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5853     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2016-10-03 to  2017-01-03\n",
      "======Best Model Retraining from:  2009-01-01 to  2017-01-03\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_378_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.753   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -53.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0133  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -24.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.612    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0385   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -329     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 72.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0135  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 102      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.17e+06 |\n",
      "|    total_cost         | 1.03e+05 |\n",
      "|    total_reward       | 1.17e+06 |\n",
      "|    total_reward_pct   | 117      |\n",
      "|    total_trades       | 50162    |\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0444   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -48.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 187      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 22.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 96.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 300      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 122      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.17e+06 |\n",
      "|    total_cost         | 1.18e+05 |\n",
      "|    total_reward       | 2.17e+06 |\n",
      "|    total_reward_pct   | 217      |\n",
      "|    total_trades       | 51245    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.00877  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -24.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -10.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.143   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 325      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 49.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.881   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -143     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.28e+06 |\n",
      "|    total_cost         | 1.1e+05  |\n",
      "|    total_reward       | 2.28e+06 |\n",
      "|    total_reward_pct   | 228      |\n",
      "|    total_trades       | 49010    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 33.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.13     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -80.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -67.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.9      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 141       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 99.9      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 7.9       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.41e+06 |\n",
      "|    total_cost         | 5.28e+04 |\n",
      "|    total_reward       | 2.41e+06 |\n",
      "|    total_reward_pct   | 241      |\n",
      "|    total_trades       | 42742    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 1.79     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -95.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.91     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 142       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -160      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 18.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 24       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.42     |\n",
      "------------------------------------\n",
      "day: 2013, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2218506.76\n",
      "total_reward: 1218506.76\n",
      "total_cost: 45202.32\n",
      "total_trades: 40523\n",
      "Sharpe: 0.622\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.22e+06 |\n",
      "|    total_cost         | 4.52e+04 |\n",
      "|    total_reward       | 1.22e+06 |\n",
      "|    total_reward_pct   | 122      |\n",
      "|    total_trades       | 40523    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.192   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 76.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.19     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -128     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -29.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.682    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -56.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.69e+06 |\n",
      "|    total_cost         | 5.71e+04 |\n",
      "|    total_reward       | 1.69e+06 |\n",
      "|    total_reward_pct   | 169      |\n",
      "|    total_trades       | 42283    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0222   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -96.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 5.34     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 59.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 237      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 33.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.05e+06 |\n",
      "|    total_cost         | 7.28e+04 |\n",
      "|    total_reward       | 2.05e+06 |\n",
      "|    total_reward_pct   | 205      |\n",
      "|    total_trades       | 45634    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.73e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 59.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0422   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -123     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0276   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -91.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 1.31     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.09e+06 |\n",
      "|    total_cost         | 7.6e+04  |\n",
      "|    total_reward       | 2.09e+06 |\n",
      "|    total_reward_pct   | 209      |\n",
      "|    total_trades       | 46332    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0815   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 140      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 16.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 64.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 37.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.939    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -300     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 60.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.13e+06 |\n",
      "|    total_cost         | 3.21e+04 |\n",
      "|    total_reward       | 2.13e+06 |\n",
      "|    total_reward_pct   | 213      |\n",
      "|    total_trades       | 38209    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -69.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0193  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 104      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -101     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 134      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "day: 2013, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3530958.60\n",
      "total_reward: 2530958.60\n",
      "total_cost: 39918.58\n",
      "total_trades: 37216\n",
      "Sharpe: 1.036\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.53e+06  |\n",
      "|    total_cost         | 3.99e+04  |\n",
      "|    total_reward       | 2.53e+06  |\n",
      "|    total_reward_pct   | 253       |\n",
      "|    total_trades       | 37216     |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 17.3      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.63      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0841   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 65       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.2      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -8.81     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.731     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -157     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 14.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.21e+06 |\n",
      "|    total_cost         | 2.35e+04 |\n",
      "|    total_reward       | 2.21e+06 |\n",
      "|    total_reward_pct   | 221      |\n",
      "|    total_trades       | 35824    |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.045    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 63.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -125     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.69    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 45.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 51.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.63e+06 |\n",
      "|    total_cost         | 6.81e+04 |\n",
      "|    total_reward       | 1.63e+06 |\n",
      "|    total_reward_pct   | 163      |\n",
      "|    total_trades       | 43562    |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0983   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 10.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.433    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 31.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.034    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -129     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 11.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.571    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.57e+06 |\n",
      "|    total_cost         | 3.57e+04 |\n",
      "|    total_reward       | 1.57e+06 |\n",
      "|    total_reward_pct   | 157      |\n",
      "|    total_trades       | 39473    |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 59.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 47.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -35.8    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 117      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.72e+06 |\n",
      "|    total_cost         | 1.34e+04 |\n",
      "|    total_reward       | 1.72e+06 |\n",
      "|    total_reward_pct   | 172      |\n",
      "|    total_trades       | 32976    |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -13.7    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.207    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 200       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -126      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 8.14      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 13.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.636    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -55      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.85     |\n",
      "------------------------------------\n",
      "======Trading from:  2017-01-03 to  2017-04-04\n",
      "============================================\n",
      "17.14024297613398\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2017-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_441_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 13.4     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.193    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.2      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -39.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0323  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -263     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 35.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 54.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.78e+06 |\n",
      "|    total_cost         | 1.46e+05 |\n",
      "|    total_reward       | 2.78e+06 |\n",
      "|    total_reward_pct   | 278      |\n",
      "|    total_trades       | 53927    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0387  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -28.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0183   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -50.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 220      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 31.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.05e+06 |\n",
      "|    total_cost         | 8.34e+04 |\n",
      "|    total_reward       | 2.05e+06 |\n",
      "|    total_reward_pct   | 205      |\n",
      "|    total_trades       | 47223    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.133    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -10.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 32.2     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 172      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 23.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 201      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 56.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.38e+06 |\n",
      "|    total_cost         | 7.72e+04 |\n",
      "|    total_reward       | 2.38e+06 |\n",
      "|    total_reward_pct   | 238      |\n",
      "|    total_trades       | 46102    |\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.133    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 20.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.701    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0195  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -54.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00973 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -190     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 26.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00367 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 119      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.1e+06  |\n",
      "|    total_cost         | 1.06e+05 |\n",
      "|    total_reward       | 2.1e+06  |\n",
      "|    total_reward_pct   | 210      |\n",
      "|    total_trades       | 49389    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -64.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.35     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.43    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -166     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -13.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0183  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -46.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "day: 2013, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3198587.28\n",
      "total_reward: 2198587.28\n",
      "total_cost: 99959.81\n",
      "total_trades: 49382\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.2e+06  |\n",
      "|    total_cost         | 1e+05    |\n",
      "|    total_reward       | 2.2e+06  |\n",
      "|    total_reward_pct   | 220      |\n",
      "|    total_trades       | 49382    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 42.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 29.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.05     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 141       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 9.81      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.124     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -82.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.95     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.81e+06  |\n",
      "|    total_cost         | 4.38e+04  |\n",
      "|    total_reward       | 1.81e+06  |\n",
      "|    total_reward_pct   | 181       |\n",
      "|    total_trades       | 43623     |\n",
      "| time/                 |           |\n",
      "|    fps                | 142       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -67.4     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.77      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -76.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0318   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 57.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0207   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 100      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.21e+06 |\n",
      "|    total_cost         | 4e+04    |\n",
      "|    total_reward       | 2.21e+06 |\n",
      "|    total_reward_pct   | 221      |\n",
      "|    total_trades       | 41882    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00195 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 48.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 8.17e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -54.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.00729 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -14.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 58.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.61e+06 |\n",
      "|    total_cost         | 4.59e+04 |\n",
      "|    total_reward       | 2.61e+06 |\n",
      "|    total_reward_pct   | 261      |\n",
      "|    total_trades       | 42541    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.00455 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 201      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 28       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 50.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 70.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.00157  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -589     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 177      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.63e+06 |\n",
      "|    total_cost         | 6.46e+04 |\n",
      "|    total_reward       | 2.63e+06 |\n",
      "|    total_reward_pct   | 263      |\n",
      "|    total_trades       | 42929    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.121   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -88.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.00628 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 126      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.00937  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -47.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.418   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 73.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.46     |\n",
      "------------------------------------\n",
      "day: 2013, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3936067.15\n",
      "total_reward: 2936067.15\n",
      "total_cost: 80273.30\n",
      "total_trades: 45737\n",
      "Sharpe: 1.158\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.94e+06 |\n",
      "|    total_cost         | 8.03e+04 |\n",
      "|    total_reward       | 2.94e+06 |\n",
      "|    total_reward_pct   | 294      |\n",
      "|    total_trades       | 45737    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.208   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 42.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 35.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 93.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -198     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 22.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.41e+06 |\n",
      "|    total_cost         | 6.44e+04 |\n",
      "|    total_reward       | 2.41e+06 |\n",
      "|    total_reward_pct   | 241      |\n",
      "|    total_trades       | 44877    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0162   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 92.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.69     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.249    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -109     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0439   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 16.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 7.71     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.07e+06 |\n",
      "|    total_cost         | 6.56e+04 |\n",
      "|    total_reward       | 2.07e+06 |\n",
      "|    total_reward_pct   | 207      |\n",
      "|    total_trades       | 45870    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 20.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.555    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0113  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 34.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -76.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -114     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.3e+06  |\n",
      "|    total_cost         | 5.29e+04 |\n",
      "|    total_reward       | 2.3e+06  |\n",
      "|    total_reward_pct   | 230      |\n",
      "|    total_trades       | 43504    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 13.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.207    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.741   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 78.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0352   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 52.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 174      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 25.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.5e+06  |\n",
      "|    total_cost         | 7.29e+04 |\n",
      "|    total_reward       | 3.5e+06  |\n",
      "|    total_reward_pct   | 350      |\n",
      "|    total_trades       | 45858    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.016   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -23.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.554    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.00151  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -186     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 19.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 244      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 35.5     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 81.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 10.1     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2017-01-03 to  2017-04-04\n",
      "A2C Sharpe Ratio:  0.41372824336187464\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_441_3\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.32e+06 |\n",
      "|    total_cost       | 1.89e+05 |\n",
      "|    total_reward     | 1.32e+06 |\n",
      "|    total_reward_pct | 132      |\n",
      "|    total_trades     | 58587    |\n",
      "| time/               |          |\n",
      "|    fps              | 142      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.54e+06    |\n",
      "|    total_cost           | 1.85e+05    |\n",
      "|    total_reward         | 1.54e+06    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 58365       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017216302 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0139     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.88        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.46e+06   |\n",
      "|    total_cost           | 1.81e+05   |\n",
      "|    total_reward         | 1.46e+06   |\n",
      "|    total_reward_pct     | 146        |\n",
      "|    total_trades         | 58100      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01297489 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.00325   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.99       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0264    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 13.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.59e+06   |\n",
      "|    total_cost           | 1.81e+05   |\n",
      "|    total_reward         | 1.59e+06   |\n",
      "|    total_reward_pct     | 159        |\n",
      "|    total_trades         | 57922      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01614527 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.0176    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.25       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0237    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 12.6       |\n",
      "----------------------------------------\n",
      "day: 2013, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2416899.35\n",
      "total_reward: 1416899.35\n",
      "total_cost: 175094.57\n",
      "total_trades: 57700\n",
      "Sharpe: 0.836\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.42e+06    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 1.42e+06    |\n",
      "|    total_reward_pct     | 142         |\n",
      "|    total_trades         | 57700       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016327782 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00904     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.22        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.72e+06    |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 1.72e+06    |\n",
      "|    total_reward_pct     | 172         |\n",
      "|    total_trades         | 57796       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010044076 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0352     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.01        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.76e+06    |\n",
      "|    total_cost           | 1.76e+05    |\n",
      "|    total_reward         | 1.76e+06    |\n",
      "|    total_reward_pct     | 176         |\n",
      "|    total_trades         | 57505       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019788172 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0117     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.5e+06   |\n",
      "|    total_cost           | 1.74e+05  |\n",
      "|    total_reward         | 1.5e+06   |\n",
      "|    total_reward_pct     | 150       |\n",
      "|    total_trades         | 57213     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 148       |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 110       |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0204322 |\n",
      "|    clip_fraction        | 0.198     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -42.9     |\n",
      "|    explained_variance   | -0.0113   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 6.59      |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -0.0215   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 18.9      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.35e+06    |\n",
      "|    total_cost           | 1.66e+05    |\n",
      "|    total_reward         | 1.35e+06    |\n",
      "|    total_reward_pct     | 135         |\n",
      "|    total_trades         | 56674       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021222059 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00323     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.87        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2755450.64\n",
      "total_reward: 1755450.64\n",
      "total_cost: 175847.50\n",
      "total_trades: 57355\n",
      "Sharpe: 0.934\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.76e+06   |\n",
      "|    total_cost           | 1.76e+05   |\n",
      "|    total_reward         | 1.76e+06   |\n",
      "|    total_reward_pct     | 176        |\n",
      "|    total_trades         | 57355      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02462021 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | 0.0282     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.15       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 13.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.43e+06    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 1.43e+06    |\n",
      "|    total_reward_pct     | 143         |\n",
      "|    total_trades         | 57235       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022693554 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.00155    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.85        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+06    |\n",
      "|    total_cost           | 1.76e+05    |\n",
      "|    total_reward         | 1.61e+06    |\n",
      "|    total_reward_pct     | 161         |\n",
      "|    total_trades         | 57290       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027055636 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0119     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.95        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.97e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 1.97e+06    |\n",
      "|    total_reward_pct     | 197         |\n",
      "|    total_trades         | 56990       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028354287 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.015       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.18        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.91e+06    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 1.91e+06    |\n",
      "|    total_reward_pct     | 191         |\n",
      "|    total_trades         | 57147       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029023217 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0251      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.16        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2366902.81\n",
      "total_reward: 1366902.81\n",
      "total_cost: 174037.40\n",
      "total_trades: 57014\n",
      "Sharpe: 0.761\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.37e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 1.37e+06    |\n",
      "|    total_reward_pct     | 137         |\n",
      "|    total_trades         | 57014       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026191011 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0146     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.34        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.99e+06    |\n",
      "|    total_cost           | 1.71e+05    |\n",
      "|    total_reward         | 1.99e+06    |\n",
      "|    total_reward_pct     | 199         |\n",
      "|    total_trades         | 56781       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024125384 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.00169     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.48        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.86e+06    |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 1.86e+06    |\n",
      "|    total_reward_pct     | 186         |\n",
      "|    total_trades         | 57556       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026584307 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0355      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.8         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.74e+06   |\n",
      "|    total_cost           | 1.63e+05   |\n",
      "|    total_reward         | 1.74e+06   |\n",
      "|    total_reward_pct     | 174        |\n",
      "|    total_trades         | 55965      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 247        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03318432 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.00232    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.74       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 18.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.97e+06   |\n",
      "|    total_cost           | 1.72e+05   |\n",
      "|    total_reward         | 1.97e+06   |\n",
      "|    total_reward_pct     | 197        |\n",
      "|    total_trades         | 57080      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 261        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01579271 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0123     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 19.5       |\n",
      "----------------------------------------\n",
      "day: 2013, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2925496.00\n",
      "total_reward: 1925496.00\n",
      "total_cost: 167228.35\n",
      "total_trades: 56049\n",
      "Sharpe: 0.948\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.93e+06   |\n",
      "|    total_cost           | 1.67e+05   |\n",
      "|    total_reward         | 1.93e+06   |\n",
      "|    total_reward_pct     | 193        |\n",
      "|    total_trades         | 56049      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 274        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03800883 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0439     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.58       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 19         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.25e+06    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 2.25e+06    |\n",
      "|    total_reward_pct     | 225         |\n",
      "|    total_trades         | 57073       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019106504 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0089      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.96        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.86e+06   |\n",
      "|    total_cost           | 1.7e+05    |\n",
      "|    total_reward         | 1.86e+06   |\n",
      "|    total_reward_pct     | 186        |\n",
      "|    total_trades         | 56527      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 303        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01963576 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | -0.00787   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.2        |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 19.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.01e+06   |\n",
      "|    total_cost           | 1.68e+05   |\n",
      "|    total_reward         | 2.01e+06   |\n",
      "|    total_reward_pct     | 201        |\n",
      "|    total_trades         | 56368      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 316        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02368867 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0806     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.2       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0194    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 18.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.31e+06    |\n",
      "|    total_cost           | 1.69e+05    |\n",
      "|    total_reward         | 2.31e+06    |\n",
      "|    total_reward_pct     | 231         |\n",
      "|    total_trades         | 56229       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032499596 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.0196     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.85        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2013, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2976154.14\n",
      "total_reward: 1976154.14\n",
      "total_cost: 157291.70\n",
      "total_trades: 55024\n",
      "Sharpe: 0.929\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.98e+06    |\n",
      "|    total_cost           | 1.57e+05    |\n",
      "|    total_reward         | 1.98e+06    |\n",
      "|    total_reward_pct     | 198         |\n",
      "|    total_trades         | 55024       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039913137 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0198      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.45        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.3e+06    |\n",
      "|    total_cost           | 1.64e+05   |\n",
      "|    total_reward         | 2.3e+06    |\n",
      "|    total_reward_pct     | 230        |\n",
      "|    total_trades         | 56094      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 357        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03896126 |\n",
      "|    clip_fraction        | 0.257      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.071      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18         |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0073    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 27.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.91e+06    |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 1.91e+06    |\n",
      "|    total_reward_pct     | 191         |\n",
      "|    total_trades         | 54209       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 371         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030669294 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.5e+06     |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | 2.5e+06     |\n",
      "|    total_reward_pct     | 250         |\n",
      "|    total_trades         | 54207       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 384         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016440988 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0635      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.34e+06    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 2.34e+06    |\n",
      "|    total_reward_pct     | 234         |\n",
      "|    total_trades         | 52871       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025095237 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0174      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2781857.73\n",
      "total_reward: 1781857.73\n",
      "total_cost: 154114.66\n",
      "total_trades: 54465\n",
      "Sharpe: 0.822\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+06    |\n",
      "|    total_cost           | 1.54e+05    |\n",
      "|    total_reward         | 1.78e+06    |\n",
      "|    total_reward_pct     | 178         |\n",
      "|    total_trades         | 54465       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024853349 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0383      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.13e+06   |\n",
      "|    total_cost           | 1.52e+05   |\n",
      "|    total_reward         | 2.13e+06   |\n",
      "|    total_reward_pct     | 213        |\n",
      "|    total_trades         | 54280      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 426        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01904793 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0815     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.56       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.00862   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 26.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.26e+06   |\n",
      "|    total_cost           | 1.55e+05   |\n",
      "|    total_reward         | 2.26e+06   |\n",
      "|    total_reward_pct     | 226        |\n",
      "|    total_trades         | 54469      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 440        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02407359 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.0805     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.8       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.00984   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 29.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.2e+06    |\n",
      "|    total_cost           | 1.47e+05   |\n",
      "|    total_reward         | 2.2e+06    |\n",
      "|    total_reward_pct     | 220        |\n",
      "|    total_trades         | 53700      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 453        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02355014 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.0894     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.2       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 34         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.43e+06    |\n",
      "|    total_cost           | 1.35e+05    |\n",
      "|    total_reward         | 2.43e+06    |\n",
      "|    total_reward_pct     | 243         |\n",
      "|    total_trades         | 52318       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 467         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014020212 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0855      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3622621.53\n",
      "total_reward: 2622621.53\n",
      "total_cost: 127587.33\n",
      "total_trades: 51798\n",
      "Sharpe: 0.970\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.62e+06    |\n",
      "|    total_cost           | 1.28e+05    |\n",
      "|    total_reward         | 2.62e+06    |\n",
      "|    total_reward_pct     | 262         |\n",
      "|    total_trades         | 51798       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 480         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007672146 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.39e+06    |\n",
      "|    total_cost           | 1.47e+05    |\n",
      "|    total_reward         | 2.39e+06    |\n",
      "|    total_reward_pct     | 239         |\n",
      "|    total_trades         | 53803       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016595881 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.48e+06    |\n",
      "|    total_cost           | 1.33e+05    |\n",
      "|    total_reward         | 2.48e+06    |\n",
      "|    total_reward_pct     | 248         |\n",
      "|    total_trades         | 52453       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 507         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022492824 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0782      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.31e+06    |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | 2.31e+06    |\n",
      "|    total_reward_pct     | 231         |\n",
      "|    total_trades         | 53548       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032100633 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0601      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.43e+06    |\n",
      "|    total_cost           | 1.26e+05    |\n",
      "|    total_reward         | 2.43e+06    |\n",
      "|    total_reward_pct     | 243         |\n",
      "|    total_trades         | 51918       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021468416 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3304620.14\n",
      "total_reward: 2304620.14\n",
      "total_cost: 140139.19\n",
      "total_trades: 52953\n",
      "Sharpe: 0.986\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.3e+06     |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 2.3e+06     |\n",
      "|    total_reward_pct     | 230         |\n",
      "|    total_trades         | 52953       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035570048 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0432      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.7e+06     |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 2.7e+06     |\n",
      "|    total_reward_pct     | 270         |\n",
      "|    total_trades         | 53393       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 562         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025761463 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0755      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.99e+06    |\n",
      "|    total_cost           | 1.35e+05    |\n",
      "|    total_reward         | 1.99e+06    |\n",
      "|    total_reward_pct     | 199         |\n",
      "|    total_trades         | 52919       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039287727 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0631      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.39e+06    |\n",
      "|    total_cost           | 1.21e+05    |\n",
      "|    total_reward         | 2.39e+06    |\n",
      "|    total_reward_pct     | 239         |\n",
      "|    total_trades         | 51746       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017328955 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.38e+06    |\n",
      "|    total_cost           | 1.3e+05     |\n",
      "|    total_reward         | 2.38e+06    |\n",
      "|    total_reward_pct     | 238         |\n",
      "|    total_trades         | 52393       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 602         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044421405 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0454      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00148     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2984901.07\n",
      "total_reward: 1984901.07\n",
      "total_cost: 113406.34\n",
      "total_trades: 50391\n",
      "Sharpe: 0.926\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.98e+06    |\n",
      "|    total_cost           | 1.13e+05    |\n",
      "|    total_reward         | 1.98e+06    |\n",
      "|    total_reward_pct     | 198         |\n",
      "|    total_trades         | 50391       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039134637 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0979      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.45e+06    |\n",
      "|    total_cost           | 1.23e+05    |\n",
      "|    total_reward         | 2.45e+06    |\n",
      "|    total_reward_pct     | 245         |\n",
      "|    total_trades         | 51389       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043200474 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.00245     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.16e+06   |\n",
      "|    total_cost           | 1.28e+05   |\n",
      "|    total_reward         | 2.16e+06   |\n",
      "|    total_reward_pct     | 216        |\n",
      "|    total_trades         | 51887      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 644        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03745542 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.17       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.66       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.00504   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 26.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.03e+06    |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | 2.03e+06    |\n",
      "|    total_reward_pct     | 203         |\n",
      "|    total_trades         | 53904       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 657         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021872357 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | -0.0041     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.09e+06    |\n",
      "|    total_cost           | 1.57e+05    |\n",
      "|    total_reward         | 2.09e+06    |\n",
      "|    total_reward_pct     | 209         |\n",
      "|    total_trades         | 55156       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 673         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032041267 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0393      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2017-01-03 to  2017-04-04\n",
      "PPO Sharpe Ratio:  0.3485930435500636\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_3\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.46e+06 |\n",
      "|    total_cost       | 2.49e+03 |\n",
      "|    total_reward     | 2.46e+06 |\n",
      "|    total_reward_pct | 246      |\n",
      "|    total_trades     | 18360    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total timesteps  | 8056     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -109     |\n",
      "|    critic_loss      | 69.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6042     |\n",
      "----------------------------------\n",
      "day: 2013, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3466896.58\n",
      "total_reward: 2466896.58\n",
      "total_cost: 3192.14\n",
      "total_trades: 18563\n",
      "Sharpe: 1.014\n",
      "=================================\n",
      "======DDPG Validation from:  2017-01-03 to  2017-04-04\n",
      "======Best Model Retraining from:  2009-01-01 to  2017-04-04\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_441_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.04e+06 |\n",
      "|    total_cost       | 1.12e+03 |\n",
      "|    total_reward     | 2.04e+06 |\n",
      "|    total_reward_pct | 204      |\n",
      "|    total_trades     | 25758    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total timesteps  | 8308     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 186      |\n",
      "|    critic_loss      | 144      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6231     |\n",
      "----------------------------------\n",
      "day: 2076, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3086136.12\n",
      "total_reward: 2086136.12\n",
      "total_cost: 999.00\n",
      "total_trades: 24876\n",
      "Sharpe: 0.887\n",
      "=================================\n",
      "======Trading from:  2017-04-04 to  2017-07-05\n",
      "============================================\n",
      "11.2902715795974\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2017-04-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_504_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.343   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -11.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.107    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.189    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -36.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.171   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -217     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 27.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 65.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.06     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.14e+06  |\n",
      "|    total_cost         | 1.44e+05  |\n",
      "|    total_reward       | 2.14e+06  |\n",
      "|    total_reward_pct   | 214       |\n",
      "|    total_trades       | 55295     |\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -65.1     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.17      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -35.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.713    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 49.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.75     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0401   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 42.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.42e+06 |\n",
      "|    total_cost         | 8.45e+04 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 142      |\n",
      "|    total_trades       | 48074    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0168  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 118      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -75.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.00422  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 45.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 133      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.41e+06 |\n",
      "|    total_cost         | 4.78e+04 |\n",
      "|    total_reward       | 2.41e+06 |\n",
      "|    total_reward_pct   | 241      |\n",
      "|    total_trades       | 43347    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -132     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0835  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -34.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0367  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 46.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -207     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 28.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.93e+06 |\n",
      "|    total_cost         | 3.05e+04 |\n",
      "|    total_reward       | 1.93e+06 |\n",
      "|    total_reward_pct   | 193      |\n",
      "|    total_trades       | 38904    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0814  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 70       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -215     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 39.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 27.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 210      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 24.6     |\n",
      "------------------------------------\n",
      "day: 2076, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2249213.43\n",
      "total_reward: 1249213.43\n",
      "total_cost: 22847.74\n",
      "total_trades: 36823\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.25e+06 |\n",
      "|    total_cost         | 2.28e+04 |\n",
      "|    total_reward       | 1.25e+06 |\n",
      "|    total_reward_pct   | 125      |\n",
      "|    total_trades       | 36823    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -1.99    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -37.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -102     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 7.47     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -14.2     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.2       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.64e+06 |\n",
      "|    total_cost         | 1.96e+04 |\n",
      "|    total_reward       | 1.64e+06 |\n",
      "|    total_reward_pct   | 164      |\n",
      "|    total_trades       | 37020    |\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -52.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0293  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -34.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 43.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -114     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 32.5      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.781     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.59e+06 |\n",
      "|    total_cost         | 1.79e+04 |\n",
      "|    total_reward       | 1.59e+06 |\n",
      "|    total_reward_pct   | 159      |\n",
      "|    total_trades       | 38727    |\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 43.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0359   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 102      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.9      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 130       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -382      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 91.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 167      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 14.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.49e+06 |\n",
      "|    total_cost         | 2.15e+04 |\n",
      "|    total_reward       | 2.49e+06 |\n",
      "|    total_reward_pct   | 249      |\n",
      "|    total_trades       | 39000    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.23    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 120      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 16.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.891    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -20      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 131       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -40.9     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 4.45      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.57e+06 |\n",
      "|    total_cost         | 2.04e+04 |\n",
      "|    total_reward       | 1.57e+06 |\n",
      "|    total_reward_pct   | 157      |\n",
      "|    total_trades       | 39473    |\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 54       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 39.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 22.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 152      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 20.6     |\n",
      "------------------------------------\n",
      "day: 2076, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3027477.23\n",
      "total_reward: 2027477.23\n",
      "total_cost: 31637.74\n",
      "total_trades: 40561\n",
      "Sharpe: 0.833\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.03e+06 |\n",
      "|    total_cost         | 3.16e+04 |\n",
      "|    total_reward       | 2.03e+06 |\n",
      "|    total_reward_pct   | 203      |\n",
      "|    total_trades       | 40561    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.127   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -12.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.37     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 133       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -62.1     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 3.4       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 89.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -238     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 37.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.13e+06 |\n",
      "|    total_cost         | 2.02e+04 |\n",
      "|    total_reward       | 2.13e+06 |\n",
      "|    total_reward_pct   | 213      |\n",
      "|    total_trades       | 40178    |\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 12.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.191    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -142     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 133       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -6.44e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 30.7      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.92      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -129     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 15.4     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.39e+06 |\n",
      "|    total_cost         | 1.18e+04 |\n",
      "|    total_reward       | 2.39e+06 |\n",
      "|    total_reward_pct   | 239      |\n",
      "|    total_trades       | 36021    |\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.0126  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 11.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -10.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.139    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 33       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.734    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -130     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 134       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 200       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -29.7     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 3.31      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.44e+06 |\n",
      "|    total_cost         | 1.15e+04 |\n",
      "|    total_reward       | 2.44e+06 |\n",
      "|    total_reward_pct   | 244      |\n",
      "|    total_trades       | 33987    |\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -14.2    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.176    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 133       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -60.2     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.06      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -36.5    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 23.2     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.23e+06 |\n",
      "|    total_cost         | 1.12e+04 |\n",
      "|    total_reward       | 3.23e+06 |\n",
      "|    total_reward_pct   | 323      |\n",
      "|    total_trades       | 33620    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -32.9    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 13.5     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.559    |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2017-04-04 to  2017-07-05\n",
      "A2C Sharpe Ratio:  0.4785315744972272\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_504_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 127  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 16   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.62e+06    |\n",
      "|    total_cost           | 1.97e+05    |\n",
      "|    total_reward         | 1.62e+06    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 60169       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012126546 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00538    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.92        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.38e+06    |\n",
      "|    total_cost           | 1.92e+05    |\n",
      "|    total_reward         | 1.38e+06    |\n",
      "|    total_reward_pct     | 138         |\n",
      "|    total_trades         | 59789       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025471412 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0305     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.28e+06    |\n",
      "|    total_cost           | 1.94e+05    |\n",
      "|    total_reward         | 1.28e+06    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 59636       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018619807 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00734     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.65        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3e+06       |\n",
      "|    total_cost           | 1.9e+05     |\n",
      "|    total_reward         | 2e+06       |\n",
      "|    total_reward_pct     | 200         |\n",
      "|    total_trades         | 59289       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020927412 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0312     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.01        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "day: 2076, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2908655.83\n",
      "total_reward: 1908655.83\n",
      "total_cost: 183052.78\n",
      "total_trades: 58712\n",
      "Sharpe: 0.944\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.91e+06     |\n",
      "|    total_cost           | 1.83e+05     |\n",
      "|    total_reward         | 1.91e+06     |\n",
      "|    total_reward_pct     | 191          |\n",
      "|    total_trades         | 58712        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 137          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076270234 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.9        |\n",
      "|    explained_variance   | 0.000772     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.03         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0193      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3e+06      |\n",
      "|    total_cost           | 1.8e+05    |\n",
      "|    total_reward         | 2e+06      |\n",
      "|    total_reward_pct     | 200        |\n",
      "|    total_trades         | 58235      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 137        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 104        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02822405 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | 0.000923   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.33       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 16.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+06    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 1.61e+06    |\n",
      "|    total_reward_pct     | 161         |\n",
      "|    total_trades         | 58227       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015064422 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.03       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.52        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.2e+06     |\n",
      "|    total_cost           | 1.8e+05     |\n",
      "|    total_reward         | 2.2e+06     |\n",
      "|    total_reward_pct     | 220         |\n",
      "|    total_trades         | 57969       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017680038 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.00352    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.97        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.84e+06   |\n",
      "|    total_cost           | 1.82e+05   |\n",
      "|    total_reward         | 1.84e+06   |\n",
      "|    total_reward_pct     | 184        |\n",
      "|    total_trades         | 58146      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 136        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 149        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03353208 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | -0.00477   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.48       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0216    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 17.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2076, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2469833.98\n",
      "total_reward: 1469833.98\n",
      "total_cost: 184310.26\n",
      "total_trades: 58334\n",
      "Sharpe: 0.853\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.47e+06    |\n",
      "|    total_cost           | 1.84e+05    |\n",
      "|    total_reward         | 1.47e+06    |\n",
      "|    total_reward_pct     | 147         |\n",
      "|    total_trades         | 58334       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018876903 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.022      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.95        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+06    |\n",
      "|    total_cost           | 1.77e+05    |\n",
      "|    total_reward         | 1.65e+06    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 57636       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020648275 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0111     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.68        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.68e+06    |\n",
      "|    total_cost           | 1.81e+05    |\n",
      "|    total_reward         | 1.68e+06    |\n",
      "|    total_reward_pct     | 168         |\n",
      "|    total_trades         | 58419       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020791609 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0159      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5           |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.03e+06    |\n",
      "|    total_cost           | 1.89e+05    |\n",
      "|    total_reward         | 2.03e+06    |\n",
      "|    total_reward_pct     | 203         |\n",
      "|    total_trades         | 58758       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021799233 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0089      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.43        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.27e+06    |\n",
      "|    total_cost           | 1.8e+05     |\n",
      "|    total_reward         | 2.27e+06    |\n",
      "|    total_reward_pct     | 227         |\n",
      "|    total_trades         | 58152       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036538824 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.00622    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.5         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "day: 2076, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2498046.54\n",
      "total_reward: 1498046.54\n",
      "total_cost: 183098.25\n",
      "total_trades: 58289\n",
      "Sharpe: 0.864\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+06     |\n",
      "|    total_cost           | 1.83e+05    |\n",
      "|    total_reward         | 1.5e+06     |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 58289       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029936653 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0166      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.09        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.54e+06    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 1.54e+06    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 58347       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028505927 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0365      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.72        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.9e+06    |\n",
      "|    total_cost           | 1.82e+05   |\n",
      "|    total_reward         | 1.9e+06    |\n",
      "|    total_reward_pct     | 190        |\n",
      "|    total_trades         | 58134      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 262        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02273829 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | -0.0094    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.45       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0258    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 17.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.15e+06    |\n",
      "|    total_cost           | 1.78e+05    |\n",
      "|    total_reward         | 2.15e+06    |\n",
      "|    total_reward_pct     | 215         |\n",
      "|    total_trades         | 57829       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036616597 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.00388    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.17e+06  |\n",
      "|    total_cost           | 1.81e+05  |\n",
      "|    total_reward         | 2.17e+06  |\n",
      "|    total_reward_pct     | 217       |\n",
      "|    total_trades         | 58562     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 141       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 290       |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0212764 |\n",
      "|    clip_fraction        | 0.195     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.7     |\n",
      "|    explained_variance   | -0.0217   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 11        |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -0.0159   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 20.1      |\n",
      "---------------------------------------\n",
      "day: 2076, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2636021.38\n",
      "total_reward: 1636021.38\n",
      "total_cost: 172570.03\n",
      "total_trades: 58168\n",
      "Sharpe: 0.869\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.64e+06   |\n",
      "|    total_cost           | 1.73e+05   |\n",
      "|    total_reward         | 1.64e+06   |\n",
      "|    total_reward_pct     | 164        |\n",
      "|    total_trades         | 58168      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 304        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02410202 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0123     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.1        |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 19.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.14e+06    |\n",
      "|    total_cost           | 1.76e+05    |\n",
      "|    total_reward         | 2.14e+06    |\n",
      "|    total_reward_pct     | 214         |\n",
      "|    total_trades         | 57906       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019521886 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0632      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.21        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.53e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 1.53e+06    |\n",
      "|    total_reward_pct     | 153         |\n",
      "|    total_trades         | 57718       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024678534 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0162      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.61        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.91e+06    |\n",
      "|    total_cost           | 1.73e+05    |\n",
      "|    total_reward         | 1.91e+06    |\n",
      "|    total_reward_pct     | 191         |\n",
      "|    total_trades         | 57801       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020982299 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | -0.0152     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.76        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.35e+06   |\n",
      "|    total_cost           | 1.74e+05   |\n",
      "|    total_reward         | 1.35e+06   |\n",
      "|    total_reward_pct     | 135        |\n",
      "|    total_trades         | 57822      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 362        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01812134 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | -0.00468   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.87       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 18.6       |\n",
      "----------------------------------------\n",
      "day: 2076, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3694136.26\n",
      "total_reward: 2694136.26\n",
      "total_cost: 187551.15\n",
      "total_trades: 58714\n",
      "Sharpe: 1.178\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.69e+06    |\n",
      "|    total_cost           | 1.88e+05    |\n",
      "|    total_reward         | 2.69e+06    |\n",
      "|    total_reward_pct     | 269         |\n",
      "|    total_trades         | 58714       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028656062 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0476      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.72        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.44e+06    |\n",
      "|    total_cost           | 1.72e+05    |\n",
      "|    total_reward         | 2.44e+06    |\n",
      "|    total_reward_pct     | 244         |\n",
      "|    total_trades         | 57729       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024644097 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0301      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.36e+06    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 1.36e+06    |\n",
      "|    total_reward_pct     | 136         |\n",
      "|    total_trades         | 58102       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025319958 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0644      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.24        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.68e+06    |\n",
      "|    total_cost           | 1.78e+05    |\n",
      "|    total_reward         | 2.68e+06    |\n",
      "|    total_reward_pct     | 268         |\n",
      "|    total_trades         | 58265       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024391089 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.64        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.83e+06    |\n",
      "|    total_cost           | 1.83e+05    |\n",
      "|    total_reward         | 2.83e+06    |\n",
      "|    total_reward_pct     | 283         |\n",
      "|    total_trades         | 58435       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038978655 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.00514     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "day: 2076, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3679663.00\n",
      "total_reward: 2679663.00\n",
      "total_cost: 179092.87\n",
      "total_trades: 58395\n",
      "Sharpe: 1.127\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.68e+06    |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 2.68e+06    |\n",
      "|    total_reward_pct     | 268         |\n",
      "|    total_trades         | 58395       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 445         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023832884 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0425      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.33e+06    |\n",
      "|    total_cost           | 1.73e+05    |\n",
      "|    total_reward         | 3.33e+06    |\n",
      "|    total_reward_pct     | 333         |\n",
      "|    total_trades         | 57361       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031088974 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0585      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.4e+06    |\n",
      "|    total_cost           | 1.75e+05   |\n",
      "|    total_reward         | 3.4e+06    |\n",
      "|    total_reward_pct     | 340        |\n",
      "|    total_trades         | 57795      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 142        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 475        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06401491 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0283     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13         |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00675   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 29.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.3e+06     |\n",
      "|    total_cost           | 1.67e+05    |\n",
      "|    total_reward         | 3.3e+06     |\n",
      "|    total_reward_pct     | 330         |\n",
      "|    total_trades         | 56659       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 489         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034432188 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0565      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.46e+06    |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 3.46e+06    |\n",
      "|    total_reward_pct     | 346         |\n",
      "|    total_trades         | 56863       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038882405 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0526      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "day: 2076, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2643826.79\n",
      "total_reward: 1643826.79\n",
      "total_cost: 173901.54\n",
      "total_trades: 58467\n",
      "Sharpe: 0.887\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.64e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 1.64e+06    |\n",
      "|    total_reward_pct     | 164         |\n",
      "|    total_trades         | 58467       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 517         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040130086 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.15e+06   |\n",
      "|    total_cost           | 1.6e+05    |\n",
      "|    total_reward         | 2.15e+06   |\n",
      "|    total_reward_pct     | 215        |\n",
      "|    total_trades         | 56453      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 142        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 531        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02272435 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.0302     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.41       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 15.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.13e+06    |\n",
      "|    total_cost           | 1.71e+05    |\n",
      "|    total_reward         | 2.13e+06    |\n",
      "|    total_reward_pct     | 213         |\n",
      "|    total_trades         | 57429       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 545         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027494391 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.48        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.6e+06     |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 2.6e+06     |\n",
      "|    total_reward_pct     | 260         |\n",
      "|    total_trades         | 53493       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 559         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034781024 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.38        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.49e+06   |\n",
      "|    total_cost           | 1.58e+05   |\n",
      "|    total_reward         | 2.49e+06   |\n",
      "|    total_reward_pct     | 249        |\n",
      "|    total_trades         | 55738      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 142        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 573        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02192275 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0502     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.00704   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 25.7       |\n",
      "----------------------------------------\n",
      "day: 2076, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3666992.36\n",
      "total_reward: 2666992.36\n",
      "total_cost: 161462.04\n",
      "total_trades: 56110\n",
      "Sharpe: 1.086\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.67e+06   |\n",
      "|    total_cost           | 1.61e+05   |\n",
      "|    total_reward         | 2.67e+06   |\n",
      "|    total_reward_pct     | 267        |\n",
      "|    total_trades         | 56110      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 142        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 589        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03549862 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0498     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.1       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.00607   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 22.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.95e+06    |\n",
      "|    total_cost           | 1.43e+05    |\n",
      "|    total_reward         | 2.95e+06    |\n",
      "|    total_reward_pct     | 295         |\n",
      "|    total_trades         | 54068       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022702679 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0572      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.83e+06    |\n",
      "|    total_cost           | 1.27e+05    |\n",
      "|    total_reward         | 2.83e+06    |\n",
      "|    total_reward_pct     | 283         |\n",
      "|    total_trades         | 52515       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 617         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015391327 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0256      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.14e+06   |\n",
      "|    total_cost           | 1.4e+05    |\n",
      "|    total_reward         | 3.14e+06   |\n",
      "|    total_reward_pct     | 314        |\n",
      "|    total_trades         | 53658      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 142        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 631        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02806077 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.0888     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.7       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0087    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 24.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.46e+06    |\n",
      "|    total_cost           | 1.47e+05    |\n",
      "|    total_reward         | 3.46e+06    |\n",
      "|    total_reward_pct     | 346         |\n",
      "|    total_trades         | 54100       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 645         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031284362 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0475      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "day: 2076, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4653968.26\n",
      "total_reward: 3653968.26\n",
      "total_cost: 140506.84\n",
      "total_trades: 53602\n",
      "Sharpe: 1.214\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.65e+06    |\n",
      "|    total_cost           | 1.41e+05    |\n",
      "|    total_reward         | 3.65e+06    |\n",
      "|    total_reward_pct     | 365         |\n",
      "|    total_trades         | 53602       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 658         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018217497 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0848      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.68e+06    |\n",
      "|    total_cost           | 1.18e+05    |\n",
      "|    total_reward         | 2.68e+06    |\n",
      "|    total_reward_pct     | 268         |\n",
      "|    total_trades         | 51354       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 143         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 672         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021416176 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.98e+06     |\n",
      "|    total_cost           | 1.35e+05     |\n",
      "|    total_reward         | 1.98e+06     |\n",
      "|    total_reward_pct     | 198          |\n",
      "|    total_trades         | 52893        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 143          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 686          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072575863 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.8        |\n",
      "|    explained_variance   | 0.134        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.42         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.65e+06   |\n",
      "|    total_cost           | 1.55e+05   |\n",
      "|    total_reward         | 3.65e+06   |\n",
      "|    total_reward_pct     | 365        |\n",
      "|    total_trades         | 54852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 143        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 701        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01871199 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.156      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.48       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00772   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 18.8       |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2017-04-04 to  2017-07-05\n",
      "PPO Sharpe Ratio:  0.3798182781537425\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_3\n",
      "day: 2076, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3176818.16\n",
      "total_reward: 2176818.16\n",
      "total_cost: 5188.41\n",
      "total_trades: 40499\n",
      "Sharpe: 1.023\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.6e+06  |\n",
      "|    total_cost       | 1.88e+03 |\n",
      "|    total_reward     | 2.6e+06  |\n",
      "|    total_reward_pct | 260      |\n",
      "|    total_trades     | 33459    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total timesteps  | 8308     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -6.94    |\n",
      "|    critic_loss      | 93.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6231     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2017-04-04 to  2017-07-05\n",
      "======Best Model Retraining from:  2009-01-01 to  2017-07-05\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_504_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -4.34    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -30.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.916    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.105    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -56.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -260     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 35.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.137   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -24.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.31e+06 |\n",
      "|    total_cost         | 1.5e+05  |\n",
      "|    total_reward       | 2.31e+06 |\n",
      "|    total_reward_pct   | 231      |\n",
      "|    total_trades       | 56411    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.333    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 71.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -1.02    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 38.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.105   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 77.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.03    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -55.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.15e+06 |\n",
      "|    total_cost         | 9.99e+04 |\n",
      "|    total_reward       | 2.15e+06 |\n",
      "|    total_reward_pct   | 215      |\n",
      "|    total_trades       | 51998    |\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 191      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 21.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -106     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 5.6e-05  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -1.91    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.658    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -31.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.88e+06 |\n",
      "|    total_cost         | 2.85e+04 |\n",
      "|    total_reward       | 1.88e+06 |\n",
      "|    total_reward_pct   | 188      |\n",
      "|    total_trades       | 42993    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -71.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.17     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00776  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -35.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.838    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 65.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.1      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 134       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -7.63     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.741     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 114      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.55e+06 |\n",
      "|    total_cost         | 1.28e+04 |\n",
      "|    total_reward       | 1.55e+06 |\n",
      "|    total_reward_pct   | 155      |\n",
      "|    total_trades       | 39953    |\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 78.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 13.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 28.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.938    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -235     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 26.6     |\n",
      "------------------------------------\n",
      "day: 2139, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2990122.32\n",
      "total_reward: 1990122.32\n",
      "total_cost: 10410.36\n",
      "total_trades: 39918\n",
      "Sharpe: 0.830\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.99e+06 |\n",
      "|    total_cost         | 1.04e+04 |\n",
      "|    total_reward       | 1.99e+06 |\n",
      "|    total_reward_pct   | 199      |\n",
      "|    total_trades       | 39918    |\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 76.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.14     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 135       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -34.7     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.09      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 69.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 147      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.63e+06  |\n",
      "|    total_cost         | 8.72e+03  |\n",
      "|    total_reward       | 1.63e+06  |\n",
      "|    total_reward_pct   | 163       |\n",
      "|    total_trades       | 40825     |\n",
      "| time/                 |           |\n",
      "|    fps                | 136       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -6.32e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 0.126     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.492     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -144     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 31.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.572   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -14.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 136       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 27.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.02      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.34e+06 |\n",
      "|    total_cost         | 2.13e+04 |\n",
      "|    total_reward       | 1.34e+06 |\n",
      "|    total_reward_pct   | 134      |\n",
      "|    total_trades       | 41945    |\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -5.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.152    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -27.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.912    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 27.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.845    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 2.74e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 74.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 115      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.98e+06 |\n",
      "|    total_cost         | 2.46e+04 |\n",
      "|    total_reward       | 1.98e+06 |\n",
      "|    total_reward_pct   | 198      |\n",
      "|    total_trades       | 42663    |\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -182     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 22.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -58.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 45.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -174     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 19.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.36e+06 |\n",
      "|    total_cost         | 1.01e+04 |\n",
      "|    total_reward       | 1.36e+06 |\n",
      "|    total_reward_pct   | 136      |\n",
      "|    total_trades       | 38779    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -87.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0478   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 179      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 27       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 18.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.01     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -144     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n",
      "day: 2139, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2736181.13\n",
      "total_reward: 1736181.13\n",
      "total_cost: 58036.21\n",
      "total_trades: 41807\n",
      "Sharpe: 0.818\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.74e+06 |\n",
      "|    total_cost         | 5.8e+04  |\n",
      "|    total_reward       | 1.74e+06 |\n",
      "|    total_reward_pct   | 174      |\n",
      "|    total_trades       | 41807    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 4.11e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -8.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -9.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 14.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 2.8      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.105    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -31.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -14.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.947    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.31e+06 |\n",
      "|    total_cost         | 4.43e+04 |\n",
      "|    total_reward       | 2.31e+06 |\n",
      "|    total_reward_pct   | 231      |\n",
      "|    total_trades       | 41303    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 8.81     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 117      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.00536 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -244     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 45.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -12.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.476    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.1e+06  |\n",
      "|    total_cost         | 2.99e+04 |\n",
      "|    total_reward       | 2.1e+06  |\n",
      "|    total_reward_pct   | 210      |\n",
      "|    total_trades       | 38658    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 42.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.37     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -34.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -24.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0821  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 197      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 27.3     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.64e+06 |\n",
      "|    total_cost         | 1.67e+04 |\n",
      "|    total_reward       | 1.64e+06 |\n",
      "|    total_reward_pct   | 164      |\n",
      "|    total_trades       | 37416    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 9.29     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.879    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 52.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 121      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.46     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 214       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.96e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 251       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 66        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.81e+06 |\n",
      "|    total_cost         | 2.12e+04 |\n",
      "|    total_reward       | 1.81e+06 |\n",
      "|    total_reward_pct   | 181      |\n",
      "|    total_trades       | 36251    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 14.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.4      |\n",
      "------------------------------------\n",
      "======Trading from:  2017-07-05 to  2017-10-03\n",
      "============================================\n",
      "63.29814197861714\n",
      "turbulence_threshold:  52.314193250419386\n",
      "======Model training from:  2009-01-01 to  2017-07-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_567_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -21      |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 0.258    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.421   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -48.5    |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 1.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -322     |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 69       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.136   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.502   |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.23e+06 |\n",
      "|    total_cost         | 1.29e+05 |\n",
      "|    total_reward       | 2.23e+06 |\n",
      "|    total_reward_pct   | 223      |\n",
      "|    total_trades       | 54399    |\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.235    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 97.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.25     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 131       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -3.81e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 47.7      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.57      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.153   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 51.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -215     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 27.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.19e+06 |\n",
      "|    total_cost         | 1.28e+05 |\n",
      "|    total_reward       | 2.19e+06 |\n",
      "|    total_reward_pct   | 219      |\n",
      "|    total_trades       | 54566    |\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.111   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 123      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -73.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.29    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -20.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.387   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 68.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.64e+06 |\n",
      "|    total_cost         | 8.12e+04 |\n",
      "|    total_reward       | 1.64e+06 |\n",
      "|    total_reward_pct   | 164      |\n",
      "|    total_trades       | 48035    |\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -1.84    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -63.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.289    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -43.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.386   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 82.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.149    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 69.3     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -5.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.71e+06 |\n",
      "|    total_cost         | 1.34e+05 |\n",
      "|    total_reward       | 1.71e+06 |\n",
      "|    total_reward_pct   | 171      |\n",
      "|    total_trades       | 53171    |\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.281   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 9.08     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.578    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.582   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 53.4     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.464   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 37.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.593   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -175     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 17.5     |\n",
      "------------------------------------\n",
      "day: 2139, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2526445.93\n",
      "total_reward: 1526445.93\n",
      "total_cost: 132927.62\n",
      "total_trades: 53382\n",
      "Sharpe: 0.804\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.53e+06 |\n",
      "|    total_cost         | 1.33e+05 |\n",
      "|    total_reward       | 1.53e+06 |\n",
      "|    total_reward_pct   | 153      |\n",
      "|    total_trades       | 53382    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.801   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 36.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.82     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 5.94     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.678    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.15    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -11.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0462   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 216      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 33.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.8e+06  |\n",
      "|    total_cost         | 1.23e+05 |\n",
      "|    total_reward       | 1.8e+06  |\n",
      "|    total_reward_pct   | 180      |\n",
      "|    total_trades       | 53529    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.279   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -35.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00834 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -78.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 22.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0739   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -31.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00207 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 109      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.61e+06  |\n",
      "|    total_cost         | 1.14e+05  |\n",
      "|    total_reward       | 2.61e+06  |\n",
      "|    total_reward_pct   | 261       |\n",
      "|    total_trades       | 52436     |\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 15.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.333     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.142   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 7.3      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0912  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 76.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0269  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 86.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 24.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 140      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.46e+06  |\n",
      "|    total_cost         | 9.43e+04  |\n",
      "|    total_reward       | 3.46e+06  |\n",
      "|    total_reward_pct   | 346       |\n",
      "|    total_trades       | 50321     |\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -0.000172 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -165      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 17.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0134  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -33      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.04     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 75.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -273     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 49.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.49e+06 |\n",
      "|    total_cost         | 4.81e+04 |\n",
      "|    total_reward       | 2.49e+06 |\n",
      "|    total_reward_pct   | 249      |\n",
      "|    total_trades       | 43331    |\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0312   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -105     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 212      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 37.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 33.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 35       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.26     |\n",
      "------------------------------------\n",
      "day: 2139, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4089687.63\n",
      "total_reward: 3089687.63\n",
      "total_cost: 35401.07\n",
      "total_trades: 41057\n",
      "Sharpe: 0.966\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.09e+06 |\n",
      "|    total_cost         | 3.54e+04 |\n",
      "|    total_reward       | 3.09e+06 |\n",
      "|    total_reward_pct   | 309      |\n",
      "|    total_trades       | 41057    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.127   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 26.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00052 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -94.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 1.64     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.541    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -123     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 27.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.24e+06  |\n",
      "|    total_cost         | 5.43e+04  |\n",
      "|    total_reward       | 2.24e+06  |\n",
      "|    total_reward_pct   | 224       |\n",
      "|    total_trades       | 44205     |\n",
      "| time/                 |           |\n",
      "|    fps                | 136       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 14.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.03      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0884   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 78.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -367     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 80.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -28.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.8e+06  |\n",
      "|    total_cost         | 7.04e+04 |\n",
      "|    total_reward       | 2.8e+06  |\n",
      "|    total_reward_pct   | 280      |\n",
      "|    total_trades       | 46477    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.152   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 46.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.00114  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -54.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0771   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 29.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.2e+06  |\n",
      "|    total_cost         | 7.33e+04 |\n",
      "|    total_reward       | 2.2e+06  |\n",
      "|    total_reward_pct   | 220      |\n",
      "|    total_trades       | 46419    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.31     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 115      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 35.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.5      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 136       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 212       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 39.8      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.48      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0149  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 436      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 136      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.8e+06  |\n",
      "|    total_cost         | 8.37e+04 |\n",
      "|    total_reward       | 1.8e+06  |\n",
      "|    total_reward_pct   | 180      |\n",
      "|    total_trades       | 47120    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 54.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.34     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2017-07-05 to  2017-10-03\n",
      "A2C Sharpe Ratio:  0.009192015448392255\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_567_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 131  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 15   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.63e+06   |\n",
      "|    total_cost           | 2.07e+05   |\n",
      "|    total_reward         | 1.63e+06   |\n",
      "|    total_reward_pct     | 163        |\n",
      "|    total_trades         | 62155      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 136        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01968457 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | -0.00074   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.48       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0254    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 13.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.4e+06    |\n",
      "|    total_cost           | 2.05e+05   |\n",
      "|    total_reward         | 1.4e+06    |\n",
      "|    total_reward_pct     | 140        |\n",
      "|    total_trades         | 62064      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 139        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01194072 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.0325    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.85       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0227    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 10.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.91e+06   |\n",
      "|    total_cost           | 1.99e+05   |\n",
      "|    total_reward         | 9.12e+05   |\n",
      "|    total_reward_pct     | 91.2       |\n",
      "|    total_trades         | 61319      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 139        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 58         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01813791 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | 0.00652    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.22       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0258    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 8.94       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.07e+06    |\n",
      "|    total_cost           | 2.02e+05    |\n",
      "|    total_reward         | 1.07e+06    |\n",
      "|    total_reward_pct     | 107         |\n",
      "|    total_trades         | 61618       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011837332 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0201     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.34        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.66        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2450619.30\n",
      "total_reward: 1450619.30\n",
      "total_cost: 199246.58\n",
      "total_trades: 61258\n",
      "Sharpe: 0.825\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+06    |\n",
      "|    total_cost           | 1.99e+05    |\n",
      "|    total_reward         | 1.45e+06    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 61258       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026939139 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00483     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.09        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.7         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.41e+06   |\n",
      "|    total_cost           | 1.97e+05   |\n",
      "|    total_reward         | 1.41e+06   |\n",
      "|    total_reward_pct     | 141        |\n",
      "|    total_trades         | 61321      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 101        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02544669 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | 0.00819    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.34       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0201    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 9.51       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.77e+06    |\n",
      "|    total_cost           | 1.98e+05    |\n",
      "|    total_reward         | 1.77e+06    |\n",
      "|    total_reward_pct     | 177         |\n",
      "|    total_trades         | 61281       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016748177 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00895    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.36        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.95        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.59e+06    |\n",
      "|    total_cost           | 1.96e+05    |\n",
      "|    total_reward         | 1.59e+06    |\n",
      "|    total_reward_pct     | 159         |\n",
      "|    total_trades         | 61059       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022419969 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0116      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.02        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+06    |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | 1.58e+06    |\n",
      "|    total_reward_pct     | 158         |\n",
      "|    total_trades         | 60937       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013000619 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0123     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.45        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2341615.26\n",
      "total_reward: 1341615.26\n",
      "total_cost: 195220.94\n",
      "total_trades: 61221\n",
      "Sharpe: 0.819\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.34e+06    |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | 1.34e+06    |\n",
      "|    total_reward_pct     | 134         |\n",
      "|    total_trades         | 61221       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025216676 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0164      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.65        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.12e+06    |\n",
      "|    total_cost           | 1.88e+05    |\n",
      "|    total_reward         | 1.12e+06    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 60733       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019415706 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0252      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.23        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.16e+06    |\n",
      "|    total_cost           | 1.89e+05    |\n",
      "|    total_reward         | 1.16e+06    |\n",
      "|    total_reward_pct     | 116         |\n",
      "|    total_trades         | 60157       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020845829 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.00403    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.16        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.3e+06    |\n",
      "|    total_cost           | 1.88e+05   |\n",
      "|    total_reward         | 2.3e+06    |\n",
      "|    total_reward_pct     | 230        |\n",
      "|    total_trades         | 60384      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 203        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02415966 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.0504     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.03       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0266    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 12.3       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.03e+06  |\n",
      "|    total_cost           | 1.85e+05  |\n",
      "|    total_reward         | 2.03e+06  |\n",
      "|    total_reward_pct     | 203       |\n",
      "|    total_trades         | 59998     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 141       |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 217       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0274055 |\n",
      "|    clip_fraction        | 0.222     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.3     |\n",
      "|    explained_variance   | -0.0272   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 11.1      |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -0.0175   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 18.7      |\n",
      "---------------------------------------\n",
      "day: 2139, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2748653.37\n",
      "total_reward: 1748653.37\n",
      "total_cost: 178634.57\n",
      "total_trades: 59570\n",
      "Sharpe: 0.859\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.75e+06    |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 1.75e+06    |\n",
      "|    total_reward_pct     | 175         |\n",
      "|    total_trades         | 59570       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025094872 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0122      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.87        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.4e+06     |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 2.4e+06     |\n",
      "|    total_reward_pct     | 240         |\n",
      "|    total_trades         | 59732       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019570326 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0212      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.09        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.82e+06   |\n",
      "|    total_cost           | 1.84e+05   |\n",
      "|    total_reward         | 1.82e+06   |\n",
      "|    total_reward_pct     | 182        |\n",
      "|    total_trades         | 59606      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 261        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01656546 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0183     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.4       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 22.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.43e+06    |\n",
      "|    total_cost           | 1.77e+05    |\n",
      "|    total_reward         | 2.43e+06    |\n",
      "|    total_reward_pct     | 243         |\n",
      "|    total_trades         | 59442       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021937955 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0542      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.48e+06    |\n",
      "|    total_cost           | 1.88e+05    |\n",
      "|    total_reward         | 2.48e+06    |\n",
      "|    total_reward_pct     | 248         |\n",
      "|    total_trades         | 60291       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028584834 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.00983     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.83        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3111215.35\n",
      "total_reward: 2111215.35\n",
      "total_cost: 187426.30\n",
      "total_trades: 60049\n",
      "Sharpe: 0.925\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.11e+06    |\n",
      "|    total_cost           | 1.87e+05    |\n",
      "|    total_reward         | 2.11e+06    |\n",
      "|    total_reward_pct     | 211         |\n",
      "|    total_trades         | 60049       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037877046 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0234     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.22e+06    |\n",
      "|    total_cost           | 1.96e+05    |\n",
      "|    total_reward         | 2.22e+06    |\n",
      "|    total_reward_pct     | 222         |\n",
      "|    total_trades         | 60603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 320         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026842242 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0368      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.32e+06    |\n",
      "|    total_cost           | 1.84e+05    |\n",
      "|    total_reward         | 1.32e+06    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 59184       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022757435 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.024       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.51        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 348        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02927658 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0091     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.13       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 16.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.25e+06    |\n",
      "|    total_cost           | 1.9e+05     |\n",
      "|    total_reward         | 1.25e+06    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 60156       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031401724 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.0182     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.41        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.48e+06   |\n",
      "|    total_cost           | 1.85e+05   |\n",
      "|    total_reward         | 1.48e+06   |\n",
      "|    total_reward_pct     | 148        |\n",
      "|    total_trades         | 59682      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 377        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05833502 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0259     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.29       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 12.2       |\n",
      "----------------------------------------\n",
      "day: 2139, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2451699.02\n",
      "total_reward: 1451699.02\n",
      "total_cost: 191721.21\n",
      "total_trades: 59689\n",
      "Sharpe: 0.820\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.45e+06   |\n",
      "|    total_cost           | 1.92e+05   |\n",
      "|    total_reward         | 1.45e+06   |\n",
      "|    total_reward_pct     | 145        |\n",
      "|    total_trades         | 59689      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 391        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01965058 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | -0.0112    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.19       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0181    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 11.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.23e+06    |\n",
      "|    total_cost           | 1.83e+05    |\n",
      "|    total_reward         | 1.23e+06    |\n",
      "|    total_reward_pct     | 123         |\n",
      "|    total_trades         | 59426       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 406         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024599979 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0391      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.58        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.63e+06   |\n",
      "|    total_cost           | 1.78e+05   |\n",
      "|    total_reward         | 1.63e+06   |\n",
      "|    total_reward_pct     | 163        |\n",
      "|    total_trades         | 58842      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 420        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03804359 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0383     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.92       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 12.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.68e+06   |\n",
      "|    total_cost           | 1.84e+05   |\n",
      "|    total_reward         | 1.68e+06   |\n",
      "|    total_reward_pct     | 168        |\n",
      "|    total_trades         | 59315      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 435        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04266025 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.00448    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.29       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0196    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 13.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.75e+06    |\n",
      "|    total_cost           | 1.87e+05    |\n",
      "|    total_reward         | 1.75e+06    |\n",
      "|    total_reward_pct     | 175         |\n",
      "|    total_trades         | 59612       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 449         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037156545 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | -0.00854    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.94        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2319154.18\n",
      "total_reward: 1319154.18\n",
      "total_cost: 187216.68\n",
      "total_trades: 59425\n",
      "Sharpe: 0.702\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.32e+06   |\n",
      "|    total_cost           | 1.87e+05   |\n",
      "|    total_reward         | 1.32e+06   |\n",
      "|    total_reward_pct     | 132        |\n",
      "|    total_trades         | 59425      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 463        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02598946 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.043      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.41       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 16.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.28e+06    |\n",
      "|    total_cost           | 1.81e+05    |\n",
      "|    total_reward         | 1.28e+06    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 58534       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 477         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014907625 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0111      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.16        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.35e+06    |\n",
      "|    total_cost           | 1.84e+05    |\n",
      "|    total_reward         | 1.35e+06    |\n",
      "|    total_reward_pct     | 135         |\n",
      "|    total_trades         | 58799       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 491         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033098493 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.13        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.41e+06    |\n",
      "|    total_cost           | 1.81e+05    |\n",
      "|    total_reward         | 1.41e+06    |\n",
      "|    total_reward_pct     | 141         |\n",
      "|    total_trades         | 58986       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 506         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020780424 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0195      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.55        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.36e+06   |\n",
      "|    total_cost           | 1.86e+05   |\n",
      "|    total_reward         | 1.36e+06   |\n",
      "|    total_reward_pct     | 136        |\n",
      "|    total_trades         | 59202      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 521        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02116757 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.0407     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.79       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 15.9       |\n",
      "----------------------------------------\n",
      "day: 2139, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2100523.54\n",
      "total_reward: 1100523.54\n",
      "total_cost: 180929.93\n",
      "total_trades: 58922\n",
      "Sharpe: 0.621\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 1.81e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 58922       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026631314 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.00618     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.26        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.82e+06    |\n",
      "|    total_cost           | 1.87e+05    |\n",
      "|    total_reward         | 1.82e+06    |\n",
      "|    total_reward_pct     | 182         |\n",
      "|    total_trades         | 59555       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 550         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020275205 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.017       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.43        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.71e+06    |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 1.71e+06    |\n",
      "|    total_reward_pct     | 171         |\n",
      "|    total_trades         | 58904       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 564         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018804831 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0667      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+06    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 1.19e+06    |\n",
      "|    total_reward_pct     | 119         |\n",
      "|    total_trades         | 58328       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033482116 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.00673     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.08e+06    |\n",
      "|    total_cost           | 1.81e+05    |\n",
      "|    total_reward         | 1.08e+06    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 59026       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 593         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029522868 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0422      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.06        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2195654.45\n",
      "total_reward: 1195654.45\n",
      "total_cost: 185368.97\n",
      "total_trades: 59269\n",
      "Sharpe: 0.670\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.2e+06     |\n",
      "|    total_cost           | 1.85e+05    |\n",
      "|    total_reward         | 1.2e+06     |\n",
      "|    total_reward_pct     | 120         |\n",
      "|    total_trades         | 59269       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 607         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020289937 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0693      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.98e+06    |\n",
      "|    total_cost           | 1.57e+05    |\n",
      "|    total_reward         | 9.77e+05    |\n",
      "|    total_reward_pct     | 97.7        |\n",
      "|    total_trades         | 57153       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031097712 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0416      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.58        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.97e+06   |\n",
      "|    total_cost           | 1.41e+05   |\n",
      "|    total_reward         | 9.65e+05   |\n",
      "|    total_reward_pct     | 96.5       |\n",
      "|    total_trades         | 55230      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 637        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03755846 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.118      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.14       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 12         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.02e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 1.02e+06    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 58156       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 651         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028478187 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.37        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.3e+06     |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 1.3e+06     |\n",
      "|    total_reward_pct     | 130         |\n",
      "|    total_trades         | 58172       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 665         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027668586 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.49        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 680         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034494333 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0148      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.35        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1716583.16\n",
      "total_reward: 716583.16\n",
      "total_cost: 155230.36\n",
      "total_trades: 56068\n",
      "Sharpe: 0.461\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.72e+06    |\n",
      "|    total_cost           | 1.55e+05    |\n",
      "|    total_reward         | 7.17e+05    |\n",
      "|    total_reward_pct     | 71.7        |\n",
      "|    total_trades         | 56068       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 694         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018400973 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0575      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.83        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.97e+06  |\n",
      "|    total_cost           | 1.64e+05  |\n",
      "|    total_reward         | 9.65e+05  |\n",
      "|    total_reward_pct     | 96.5      |\n",
      "|    total_trades         | 57298     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 141       |\n",
      "|    iterations           | 49        |\n",
      "|    time_elapsed         | 708       |\n",
      "|    total_timesteps      | 100352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0291898 |\n",
      "|    clip_fraction        | 0.276     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.7     |\n",
      "|    explained_variance   | 0.127     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 4.17      |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | -0.014    |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 10.4      |\n",
      "---------------------------------------\n",
      "======PPO Validation from:  2017-07-05 to  2017-10-03\n",
      "PPO Sharpe Ratio:  -0.07725097037594013\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_567_3\n",
      "day: 2139, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3465147.73\n",
      "total_reward: 2465147.73\n",
      "total_cost: 1241.11\n",
      "total_trades: 44683\n",
      "Sharpe: 0.962\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.38e+06 |\n",
      "|    total_cost       | 1.51e+03 |\n",
      "|    total_reward     | 2.38e+06 |\n",
      "|    total_reward_pct | 238      |\n",
      "|    total_trades     | 42333    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total timesteps  | 8560     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -101     |\n",
      "|    critic_loss      | 133      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6420     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2017-07-05 to  2017-10-03\n",
      "======Best Model Retraining from:  2009-01-01 to  2017-10-03\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_567_2\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.97e+06 |\n",
      "|    total_cost       | 1.62e+03 |\n",
      "|    total_reward     | 2.97e+06 |\n",
      "|    total_reward_pct | 297      |\n",
      "|    total_trades     | 25283    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total timesteps  | 8812     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 20       |\n",
      "|    critic_loss      | 10.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6609     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2202, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3758707.20\n",
      "total_reward: 2758707.20\n",
      "total_cost: 1398.82\n",
      "total_trades: 28593\n",
      "Sharpe: 1.011\n",
      "=================================\n",
      "======Trading from:  2017-10-03 to  2018-01-03\n",
      "============================================\n",
      "16.813210198800224\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2017-10-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_630_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.269    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 18.3     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.281    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.196    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -23      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.584    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0268  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -327     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 73.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0529   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 2.52     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.32e+06 |\n",
      "|    total_cost         | 1.46e+05 |\n",
      "|    total_reward       | 3.32e+06 |\n",
      "|    total_reward_pct   | 332      |\n",
      "|    total_trades       | 55593    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0252  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 49.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0368  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 74.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 55.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 663      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 271      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.75e+06 |\n",
      "|    total_cost         | 8.15e+04 |\n",
      "|    total_reward       | 3.75e+06 |\n",
      "|    total_reward_pct   | 375      |\n",
      "|    total_trades       | 47308    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00174 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -25.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.97e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -152     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 14       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 61       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.014    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -104     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 11.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -66.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 15.3     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.89e+06 |\n",
      "|    total_cost         | 7.77e+04 |\n",
      "|    total_reward       | 3.89e+06 |\n",
      "|    total_reward_pct   | 389      |\n",
      "|    total_trades       | 47174    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.329   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -114     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.134    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -209     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 28.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00166 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -38.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0899   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 147      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 30.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.14e+06 |\n",
      "|    total_cost         | 1.35e+05 |\n",
      "|    total_reward       | 2.14e+06 |\n",
      "|    total_reward_pct   | 214      |\n",
      "|    total_trades       | 53900    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00513 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -99.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 69.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 331      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 69       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 44.3     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -16.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.95     |\n",
      "------------------------------------\n",
      "day: 2202, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4549279.30\n",
      "total_reward: 3549279.30\n",
      "total_cost: 70757.53\n",
      "total_trades: 48211\n",
      "Sharpe: 1.143\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.55e+06 |\n",
      "|    total_cost         | 7.08e+04 |\n",
      "|    total_reward       | 3.55e+06 |\n",
      "|    total_reward_pct   | 355      |\n",
      "|    total_trades       | 48211    |\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00415  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -34.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0114  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 160      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 15.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 177      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 21       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 132       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 436       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 158       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.86e+06 |\n",
      "|    total_cost         | 4.39e+04 |\n",
      "|    total_reward       | 4.86e+06 |\n",
      "|    total_reward_pct   | 486      |\n",
      "|    total_trades       | 44026    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.00521  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -28.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.32     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 15.3     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.568    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -433     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 128      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 246      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 43.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.23e+06 |\n",
      "|    total_cost         | 2.19e+04 |\n",
      "|    total_reward       | 4.23e+06 |\n",
      "|    total_reward_pct   | 423      |\n",
      "|    total_trades       | 38713    |\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -30.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -135     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 148      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 213      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 28.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.1e+06  |\n",
      "|    total_cost         | 1.68e+04 |\n",
      "|    total_reward       | 4.1e+06  |\n",
      "|    total_reward_pct   | 410      |\n",
      "|    total_trades       | 37784    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -163     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 15.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 43.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.59     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 132       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 143       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -94.6     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 5.9       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -60.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.99e+06 |\n",
      "|    total_cost         | 3.04e+04 |\n",
      "|    total_reward       | 2.99e+06 |\n",
      "|    total_reward_pct   | 299      |\n",
      "|    total_trades       | 40375    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.00048  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -209     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 26.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 132       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 229       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 35.8      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 36.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -155     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 13.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -40.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 20.5     |\n",
      "------------------------------------\n",
      "day: 2202, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4779821.65\n",
      "total_reward: 3779821.65\n",
      "total_cost: 27763.79\n",
      "total_trades: 39028\n",
      "Sharpe: 0.956\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.78e+06 |\n",
      "|    total_cost         | 2.78e+04 |\n",
      "|    total_reward       | 3.78e+06 |\n",
      "|    total_reward_pct   | 378      |\n",
      "|    total_trades       | 39028    |\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.00167 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 246      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 32.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -4.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 219      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 31.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.00204 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 34.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.06e+06 |\n",
      "|    total_cost         | 2.31e+04 |\n",
      "|    total_reward       | 4.06e+06 |\n",
      "|    total_reward_pct   | 406      |\n",
      "|    total_trades       | 40320    |\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.00159  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -39.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.76     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 133       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 50.6      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.79      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 45.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.65     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 133       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 194       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -513      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 152       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.23e+06  |\n",
      "|    total_cost         | 1.62e+04  |\n",
      "|    total_reward       | 4.23e+06  |\n",
      "|    total_reward_pct   | 423       |\n",
      "|    total_trades       | 38649     |\n",
      "| time/                 |           |\n",
      "|    fps                | 133       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 198       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -147      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 11.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 145      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -64.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.76     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 55       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.21     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 133       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 213       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -71.8     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5.69      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.98e+06 |\n",
      "|    total_cost         | 1.35e+04 |\n",
      "|    total_reward       | 3.98e+06 |\n",
      "|    total_reward_pct   | 398      |\n",
      "|    total_trades       | 37001    |\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -0.477   |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -58.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 140      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2017-10-03 to  2018-01-03\n",
      "A2C Sharpe Ratio:  0.6485252195815674\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_630_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 135  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 15   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "day: 2202, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2588154.23\n",
      "total_reward: 1588154.23\n",
      "total_cost: 217609.04\n",
      "total_trades: 63960\n",
      "Sharpe: 0.874\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.59e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 1.59e+06    |\n",
      "|    total_reward_pct     | 159         |\n",
      "|    total_trades         | 63960       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015915386 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0303     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.46        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.54e+06    |\n",
      "|    total_cost           | 2.1e+05     |\n",
      "|    total_reward         | 1.54e+06    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 63397       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006757114 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.00802     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.88        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+06     |\n",
      "|    total_cost           | 2.08e+05    |\n",
      "|    total_reward         | 1.5e+06     |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 63247       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021932049 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0251      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.57        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.03e+06    |\n",
      "|    total_cost           | 2.08e+05    |\n",
      "|    total_reward         | 2.03e+06    |\n",
      "|    total_reward_pct     | 203         |\n",
      "|    total_trades         | 63195       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015296629 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0221     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.79        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+06     |\n",
      "|    total_cost           | 2.06e+05    |\n",
      "|    total_reward         | 1.8e+06     |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 63034       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026065232 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.015       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.19        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2202, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2471881.36\n",
      "total_reward: 1471881.36\n",
      "total_cost: 207398.00\n",
      "total_trades: 63054\n",
      "Sharpe: 0.764\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.47e+06   |\n",
      "|    total_cost           | 2.07e+05   |\n",
      "|    total_reward         | 1.47e+06   |\n",
      "|    total_reward_pct     | 147        |\n",
      "|    total_trades         | 63054      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 137        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 104        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02345867 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | 0.00994    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.01       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0226    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 14.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.28e+06    |\n",
      "|    total_cost           | 2.09e+05    |\n",
      "|    total_reward         | 2.28e+06    |\n",
      "|    total_reward_pct     | 228         |\n",
      "|    total_trades         | 63196       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014356239 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00962    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.77        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+06    |\n",
      "|    total_cost           | 2.03e+05    |\n",
      "|    total_reward         | 1.61e+06    |\n",
      "|    total_reward_pct     | 161         |\n",
      "|    total_trades         | 62643       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032874305 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.83        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.4e+06      |\n",
      "|    total_cost           | 2.06e+05     |\n",
      "|    total_reward         | 1.4e+06      |\n",
      "|    total_reward_pct     | 140          |\n",
      "|    total_trades         | 62673        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 136          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155766085 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43          |\n",
      "|    explained_variance   | -0.00128     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.47         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0202      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 12.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.04e+06    |\n",
      "|    total_cost           | 2.1e+05     |\n",
      "|    total_reward         | 2.04e+06    |\n",
      "|    total_reward_pct     | 204         |\n",
      "|    total_trades         | 63031       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029502595 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0206     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.63        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "day: 2202, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3450215.82\n",
      "total_reward: 2450215.82\n",
      "total_cost: 197242.55\n",
      "total_trades: 62232\n",
      "Sharpe: 1.022\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.45e+06    |\n",
      "|    total_cost           | 1.97e+05    |\n",
      "|    total_reward         | 2.45e+06    |\n",
      "|    total_reward_pct     | 245         |\n",
      "|    total_trades         | 62232       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025788968 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.00318     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.58        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.1e+06     |\n",
      "|    total_cost           | 1.89e+05    |\n",
      "|    total_reward         | 2.1e+06     |\n",
      "|    total_reward_pct     | 210         |\n",
      "|    total_trades         | 61280       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026449442 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00257     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.52        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.23e+06    |\n",
      "|    total_cost           | 1.98e+05    |\n",
      "|    total_reward         | 2.23e+06    |\n",
      "|    total_reward_pct     | 223         |\n",
      "|    total_trades         | 62102       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017885504 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0229     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.54        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022914123 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.037      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.94        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.9e+06     |\n",
      "|    total_cost           | 1.94e+05    |\n",
      "|    total_reward         | 2.9e+06     |\n",
      "|    total_reward_pct     | 290         |\n",
      "|    total_trades         | 61364       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017945355 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0245      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.76        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.44e+06    |\n",
      "|    total_cost           | 1.87e+05    |\n",
      "|    total_reward         | 2.44e+06    |\n",
      "|    total_reward_pct     | 244         |\n",
      "|    total_trades         | 61300       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019068945 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0454      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.56        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "day: 2202, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3686785.01\n",
      "total_reward: 2686785.01\n",
      "total_cost: 180435.29\n",
      "total_trades: 60580\n",
      "Sharpe: 1.036\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.69e+06    |\n",
      "|    total_cost           | 1.8e+05     |\n",
      "|    total_reward         | 2.69e+06    |\n",
      "|    total_reward_pct     | 269         |\n",
      "|    total_trades         | 60580       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031515867 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.83e+06    |\n",
      "|    total_cost           | 1.81e+05    |\n",
      "|    total_reward         | 2.83e+06    |\n",
      "|    total_reward_pct     | 283         |\n",
      "|    total_trades         | 60783       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029948683 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0327      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.57        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.98e+06    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 2.98e+06    |\n",
      "|    total_reward_pct     | 298         |\n",
      "|    total_trades         | 60296       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029091354 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0345      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.67e+06  |\n",
      "|    total_cost           | 1.78e+05  |\n",
      "|    total_reward         | 2.67e+06  |\n",
      "|    total_reward_pct     | 267       |\n",
      "|    total_trades         | 60409     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 135       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 317       |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0323693 |\n",
      "|    clip_fraction        | 0.265     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.5     |\n",
      "|    explained_variance   | 0.0723    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 10.5      |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -0.0196   |\n",
      "|    std                  | 1.03      |\n",
      "|    value_loss           | 26.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.27e+06    |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 3.27e+06    |\n",
      "|    total_reward_pct     | 327         |\n",
      "|    total_trades         | 59620       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020852437 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0391      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.06        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2202, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4203200.45\n",
      "total_reward: 3203200.45\n",
      "total_cost: 182113.99\n",
      "total_trades: 60974\n",
      "Sharpe: 1.102\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.2e+06     |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 3.2e+06     |\n",
      "|    total_reward_pct     | 320         |\n",
      "|    total_trades         | 60974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026803287 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0901      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.91e+06    |\n",
      "|    total_cost           | 1.71e+05    |\n",
      "|    total_reward         | 3.91e+06    |\n",
      "|    total_reward_pct     | 391         |\n",
      "|    total_trades         | 60299       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023961486 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0511      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.65e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 3.65e+06    |\n",
      "|    total_reward_pct     | 365         |\n",
      "|    total_trades         | 60660       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035126366 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.06        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.85e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 3.85e+06    |\n",
      "|    total_reward_pct     | 385         |\n",
      "|    total_trades         | 60531       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019538697 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.13e+06    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 4.13e+06    |\n",
      "|    total_reward_pct     | 413         |\n",
      "|    total_trades         | 60327       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027050598 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "day: 2202, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5032135.80\n",
      "total_reward: 4032135.80\n",
      "total_cost: 172899.62\n",
      "total_trades: 60267\n",
      "Sharpe: 1.175\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.03e+06    |\n",
      "|    total_cost           | 1.73e+05    |\n",
      "|    total_reward         | 4.03e+06    |\n",
      "|    total_reward_pct     | 403         |\n",
      "|    total_trades         | 60267       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030274855 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 436         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018131409 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.25e+06    |\n",
      "|    total_cost           | 1.64e+05    |\n",
      "|    total_reward         | 3.25e+06    |\n",
      "|    total_reward_pct     | 325         |\n",
      "|    total_trades         | 59102       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018469354 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0866      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.1e+06    |\n",
      "|    total_cost           | 1.64e+05   |\n",
      "|    total_reward         | 4.1e+06    |\n",
      "|    total_reward_pct     | 410        |\n",
      "|    total_trades         | 59584      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 467        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02395535 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.166      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.7       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 36.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.64e+06    |\n",
      "|    total_cost           | 1.67e+05    |\n",
      "|    total_reward         | 3.64e+06    |\n",
      "|    total_reward_pct     | 364         |\n",
      "|    total_trades         | 59082       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 482         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029341875 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.47e+06    |\n",
      "|    total_cost           | 1.76e+05    |\n",
      "|    total_reward         | 3.47e+06    |\n",
      "|    total_reward_pct     | 347         |\n",
      "|    total_trades         | 60403       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 497         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029586727 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "day: 2202, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4483803.42\n",
      "total_reward: 3483803.42\n",
      "total_cost: 179616.11\n",
      "total_trades: 60344\n",
      "Sharpe: 1.176\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.48e+06   |\n",
      "|    total_cost           | 1.8e+05    |\n",
      "|    total_reward         | 3.48e+06   |\n",
      "|    total_reward_pct     | 348        |\n",
      "|    total_trades         | 60344      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 514        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03193533 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.266      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.1       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.00938   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 31         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.09e+06    |\n",
      "|    total_cost           | 1.81e+05    |\n",
      "|    total_reward         | 3.09e+06    |\n",
      "|    total_reward_pct     | 309         |\n",
      "|    total_trades         | 60563       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 531         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021989694 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.53e+06    |\n",
      "|    total_cost           | 1.8e+05     |\n",
      "|    total_reward         | 3.53e+06    |\n",
      "|    total_reward_pct     | 353         |\n",
      "|    total_trades         | 60302       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016457617 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.95e+06   |\n",
      "|    total_cost           | 1.75e+05   |\n",
      "|    total_reward         | 2.95e+06   |\n",
      "|    total_reward_pct     | 295        |\n",
      "|    total_trades         | 60421      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 562        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03191975 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.122      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.8       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.00944   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 31.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.06e+06    |\n",
      "|    total_cost           | 1.66e+05    |\n",
      "|    total_reward         | 4.06e+06    |\n",
      "|    total_reward_pct     | 406         |\n",
      "|    total_trades         | 59465       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 576         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026400749 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2202, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4325787.48\n",
      "total_reward: 3325787.48\n",
      "total_cost: 161720.07\n",
      "total_trades: 58678\n",
      "Sharpe: 1.118\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.33e+06   |\n",
      "|    total_cost           | 1.62e+05   |\n",
      "|    total_reward         | 3.33e+06   |\n",
      "|    total_reward_pct     | 333        |\n",
      "|    total_trades         | 58678      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 591        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04302796 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.279      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.9       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00809   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 42.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.81e+06    |\n",
      "|    total_cost           | 1.54e+05    |\n",
      "|    total_reward         | 3.81e+06    |\n",
      "|    total_reward_pct     | 381         |\n",
      "|    total_trades         | 58004       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 606         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029553477 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.92e+06    |\n",
      "|    total_cost           | 1.85e+05    |\n",
      "|    total_reward         | 2.92e+06    |\n",
      "|    total_reward_pct     | 292         |\n",
      "|    total_trades         | 60496       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 620         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026976898 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.65e+06   |\n",
      "|    total_cost           | 1.49e+05   |\n",
      "|    total_reward         | 3.65e+06   |\n",
      "|    total_reward_pct     | 365        |\n",
      "|    total_trades         | 57958      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 635        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03999853 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.081      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.5       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.00246   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 26.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 649         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017821983 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.95e+06   |\n",
      "|    total_cost           | 1.52e+05   |\n",
      "|    total_reward         | 3.95e+06   |\n",
      "|    total_reward_pct     | 395        |\n",
      "|    total_trades         | 58241      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 663        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02911595 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.223      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.9       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00873   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 40.5       |\n",
      "----------------------------------------\n",
      "day: 2202, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4519928.58\n",
      "total_reward: 3519928.58\n",
      "total_cost: 143053.92\n",
      "total_trades: 57624\n",
      "Sharpe: 1.120\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.52e+06    |\n",
      "|    total_cost           | 1.43e+05    |\n",
      "|    total_reward         | 3.52e+06    |\n",
      "|    total_reward_pct     | 352         |\n",
      "|    total_trades         | 57624       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 678         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043276235 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.02e+06    |\n",
      "|    total_cost           | 1.33e+05    |\n",
      "|    total_reward         | 4.02e+06    |\n",
      "|    total_reward_pct     | 402         |\n",
      "|    total_trades         | 56357       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 692         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032133706 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0882      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.0034      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.96e+06   |\n",
      "|    total_cost           | 1.37e+05   |\n",
      "|    total_reward         | 3.96e+06   |\n",
      "|    total_reward_pct     | 396        |\n",
      "|    total_trades         | 56836      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 136        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 707        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04356288 |\n",
      "|    clip_fraction        | 0.338      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.16       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.7       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | 0.00388    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 33.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.42e+06    |\n",
      "|    total_cost           | 1.26e+05    |\n",
      "|    total_reward         | 4.42e+06    |\n",
      "|    total_reward_pct     | 442         |\n",
      "|    total_trades         | 55706       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 721         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038292374 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.02e+06    |\n",
      "|    total_cost           | 1.44e+05    |\n",
      "|    total_reward         | 4.02e+06    |\n",
      "|    total_reward_pct     | 402         |\n",
      "|    total_trades         | 57480       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 736         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038278293 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2017-10-03 to  2018-01-03\n",
      "PPO Sharpe Ratio:  0.7148912440534766\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_630_3\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.36e+06 |\n",
      "|    total_cost       | 1.68e+03 |\n",
      "|    total_reward     | 2.36e+06 |\n",
      "|    total_reward_pct | 236      |\n",
      "|    total_trades     | 33476    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total timesteps  | 8812     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 56.4     |\n",
      "|    critic_loss      | 8.72     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6609     |\n",
      "----------------------------------\n",
      "day: 2202, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3357655.49\n",
      "total_reward: 2357655.49\n",
      "total_cost: 1884.15\n",
      "total_trades: 30939\n",
      "Sharpe: 0.929\n",
      "=================================\n",
      "======DDPG Validation from:  2017-10-03 to  2018-01-03\n",
      "======Best Model Retraining from:  2009-01-01 to  2018-01-03\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_630_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 126  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 16   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.65e+06     |\n",
      "|    total_cost           | 2.26e+05     |\n",
      "|    total_reward         | 1.65e+06     |\n",
      "|    total_reward_pct     | 165          |\n",
      "|    total_trades         | 65393        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023322534 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.0644      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3            |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0289      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 9.95         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 3.19e+06     |\n",
      "|    total_cost           | 2.26e+05     |\n",
      "|    total_reward         | 2.19e+06     |\n",
      "|    total_reward_pct     | 219          |\n",
      "|    total_trades         | 65475        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075089335 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.7        |\n",
      "|    explained_variance   | -0.0204      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.01         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0213      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 10.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.34e+06    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 2.34e+06    |\n",
      "|    total_reward_pct     | 234         |\n",
      "|    total_trades         | 65051       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019068737 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0449     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.86        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 3.53e+06     |\n",
      "|    total_cost           | 2.22e+05     |\n",
      "|    total_reward         | 2.53e+06     |\n",
      "|    total_reward_pct     | 253          |\n",
      "|    total_trades         | 65085        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 132          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128499735 |\n",
      "|    clip_fraction        | 0.169        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.8        |\n",
      "|    explained_variance   | -0.00362     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0201      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 17           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2265, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3549508.32\n",
      "total_reward: 2549508.32\n",
      "total_cost: 214297.35\n",
      "total_trades: 64615\n",
      "Sharpe: 1.094\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.55e+06    |\n",
      "|    total_cost           | 2.14e+05    |\n",
      "|    total_reward         | 2.55e+06    |\n",
      "|    total_reward_pct     | 255         |\n",
      "|    total_trades         | 64615       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012886558 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0349     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.86        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.59e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 2.59e+06    |\n",
      "|    total_reward_pct     | 259         |\n",
      "|    total_trades         | 64900       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021302674 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.036      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.53        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.22e+06    |\n",
      "|    total_cost           | 2.14e+05    |\n",
      "|    total_reward         | 2.22e+06    |\n",
      "|    total_reward_pct     | 222         |\n",
      "|    total_trades         | 64554       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021724332 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00964    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.29        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.62e+06    |\n",
      "|    total_cost           | 2.12e+05    |\n",
      "|    total_reward         | 1.62e+06    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 64317       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030165626 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.015       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.75        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.69e+06    |\n",
      "|    total_cost           | 2.12e+05    |\n",
      "|    total_reward         | 2.69e+06    |\n",
      "|    total_reward_pct     | 269         |\n",
      "|    total_trades         | 64477       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017245265 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0126      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.95        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018093377 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.014      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.35        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3072503.72\n",
      "total_reward: 2072503.72\n",
      "total_cost: 218225.72\n",
      "total_trades: 64525\n",
      "Sharpe: 0.995\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.07e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 2.07e+06    |\n",
      "|    total_reward_pct     | 207         |\n",
      "|    total_trades         | 64525       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029956052 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.00167     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.46        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.29e+06   |\n",
      "|    total_cost           | 2.05e+05   |\n",
      "|    total_reward         | 2.29e+06   |\n",
      "|    total_reward_pct     | 229        |\n",
      "|    total_trades         | 63486      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 198        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02489615 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | -0.0155    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.04       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0194    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 15.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.89e+06    |\n",
      "|    total_cost           | 2.14e+05    |\n",
      "|    total_reward         | 1.89e+06    |\n",
      "|    total_reward_pct     | 189         |\n",
      "|    total_trades         | 64388       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026227983 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0021     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.84        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.44e+06   |\n",
      "|    total_cost           | 2.1e+05    |\n",
      "|    total_reward         | 2.44e+06   |\n",
      "|    total_reward_pct     | 244        |\n",
      "|    total_trades         | 64125      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 133        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 229        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01972799 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | -0.0233    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.19       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 11.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.46e+06    |\n",
      "|    total_cost           | 2.2e+05     |\n",
      "|    total_reward         | 2.46e+06    |\n",
      "|    total_reward_pct     | 246         |\n",
      "|    total_trades         | 64791       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013278617 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0506     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.22        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2955267.66\n",
      "total_reward: 1955267.66\n",
      "total_cost: 216266.28\n",
      "total_trades: 64422\n",
      "Sharpe: 0.952\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.96e+06   |\n",
      "|    total_cost           | 2.16e+05   |\n",
      "|    total_reward         | 1.96e+06   |\n",
      "|    total_reward_pct     | 196        |\n",
      "|    total_trades         | 64422      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 259        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02715912 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | -0.105     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.14       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 14         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.21e+06    |\n",
      "|    total_cost           | 2.19e+05    |\n",
      "|    total_reward         | 2.21e+06    |\n",
      "|    total_reward_pct     | 221         |\n",
      "|    total_trades         | 64642       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021740776 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0272      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.65        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.3e+06     |\n",
      "|    total_cost           | 2.06e+05    |\n",
      "|    total_reward         | 2.3e+06     |\n",
      "|    total_reward_pct     | 230         |\n",
      "|    total_trades         | 63892       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028343027 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.0316     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.1         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.75e+06    |\n",
      "|    total_cost           | 2.08e+05    |\n",
      "|    total_reward         | 1.75e+06    |\n",
      "|    total_reward_pct     | 175         |\n",
      "|    total_trades         | 63456       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021921823 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.00625     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.45        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 318        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03608767 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0298     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.99       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 10.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.72e+06    |\n",
      "|    total_cost           | 2.07e+05    |\n",
      "|    total_reward         | 1.72e+06    |\n",
      "|    total_reward_pct     | 172         |\n",
      "|    total_trades         | 63587       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023126481 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.0152     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.29        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2582996.65\n",
      "total_reward: 1582996.65\n",
      "total_cost: 194549.44\n",
      "total_trades: 62162\n",
      "Sharpe: 0.849\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+06    |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | 1.58e+06    |\n",
      "|    total_reward_pct     | 158         |\n",
      "|    total_trades         | 62162       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022571072 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.000333   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.35        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.96e+06  |\n",
      "|    total_cost           | 2.14e+05  |\n",
      "|    total_reward         | 1.96e+06  |\n",
      "|    total_reward_pct     | 196       |\n",
      "|    total_trades         | 63663     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 134       |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 364       |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0327871 |\n",
      "|    clip_fraction        | 0.239     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.8     |\n",
      "|    explained_variance   | -0.076    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 5.33      |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -0.0171   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.23e+06  |\n",
      "|    total_cost           | 2.1e+05   |\n",
      "|    total_reward         | 2.23e+06  |\n",
      "|    total_reward_pct     | 223       |\n",
      "|    total_trades         | 63656     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 135       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 378       |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0328928 |\n",
      "|    clip_fraction        | 0.298     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.8     |\n",
      "|    explained_variance   | -0.00922  |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 4.89      |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -0.0214   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 11.3      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.92e+06   |\n",
      "|    total_cost           | 2.06e+05   |\n",
      "|    total_reward         | 1.92e+06   |\n",
      "|    total_reward_pct     | 192        |\n",
      "|    total_trades         | 62884      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 393        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02483315 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.011      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.51       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 14.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.03e+06    |\n",
      "|    total_cost           | 1.97e+05    |\n",
      "|    total_reward         | 2.03e+06    |\n",
      "|    total_reward_pct     | 203         |\n",
      "|    total_trades         | 62573       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024727441 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.00082     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3014451.09\n",
      "total_reward: 2014451.09\n",
      "total_cost: 206047.05\n",
      "total_trades: 62669\n",
      "Sharpe: 0.930\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.01e+06   |\n",
      "|    total_cost           | 2.06e+05   |\n",
      "|    total_reward         | 2.01e+06   |\n",
      "|    total_reward_pct     | 201        |\n",
      "|    total_trades         | 62669      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 423        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04323539 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | -0.0203    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.28       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.00932   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 14.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.65e+06    |\n",
      "|    total_cost           | 2.1e+05     |\n",
      "|    total_reward         | 2.65e+06    |\n",
      "|    total_reward_pct     | 265         |\n",
      "|    total_trades         | 63215       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 438         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029356634 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | -0.0377     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.42        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.05e+06    |\n",
      "|    total_cost           | 2.07e+05    |\n",
      "|    total_reward         | 3.05e+06    |\n",
      "|    total_reward_pct     | 305         |\n",
      "|    total_trades         | 62933       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025727972 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0665      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.82        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.28e+06    |\n",
      "|    total_cost           | 2.06e+05    |\n",
      "|    total_reward         | 2.28e+06    |\n",
      "|    total_reward_pct     | 228         |\n",
      "|    total_trades         | 62492       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 469         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026758015 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | -0.00152    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019108877 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0268      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.43        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.67e+06    |\n",
      "|    total_cost           | 1.96e+05    |\n",
      "|    total_reward         | 2.67e+06    |\n",
      "|    total_reward_pct     | 267         |\n",
      "|    total_trades         | 61794       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 498         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027343519 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0461      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.8         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3349911.38\n",
      "total_reward: 2349911.38\n",
      "total_cost: 202762.19\n",
      "total_trades: 62450\n",
      "Sharpe: 0.937\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.35e+06   |\n",
      "|    total_cost           | 2.03e+05   |\n",
      "|    total_reward         | 2.35e+06   |\n",
      "|    total_reward_pct     | 235        |\n",
      "|    total_trades         | 62450      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 513        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02684107 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.0529     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.14       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 16.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.69e+06    |\n",
      "|    total_cost           | 1.88e+05    |\n",
      "|    total_reward         | 2.69e+06    |\n",
      "|    total_reward_pct     | 269         |\n",
      "|    total_trades         | 61102       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024613574 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0846      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.48        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.53e+06    |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | 2.53e+06    |\n",
      "|    total_reward_pct     | 253         |\n",
      "|    total_trades         | 61706       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 543         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017508533 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0995      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.9         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.24e+06    |\n",
      "|    total_cost           | 1.8e+05     |\n",
      "|    total_reward         | 2.24e+06    |\n",
      "|    total_reward_pct     | 224         |\n",
      "|    total_trades         | 60715       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032479383 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0261      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.95        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.8e+06    |\n",
      "|    total_cost           | 1.94e+05   |\n",
      "|    total_reward         | 2.8e+06    |\n",
      "|    total_reward_pct     | 280        |\n",
      "|    total_trades         | 61751      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 574        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04263774 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.153      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.8        |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 16.7       |\n",
      "----------------------------------------\n",
      "day: 2265, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4094626.64\n",
      "total_reward: 3094626.64\n",
      "total_cost: 185389.37\n",
      "total_trades: 60824\n",
      "Sharpe: 1.078\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.09e+06   |\n",
      "|    total_cost           | 1.85e+05   |\n",
      "|    total_reward         | 3.09e+06   |\n",
      "|    total_reward_pct     | 309        |\n",
      "|    total_trades         | 60824      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 588        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02803908 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0663     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.84       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 20.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.03e+06    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | 3.03e+06    |\n",
      "|    total_reward_pct     | 303         |\n",
      "|    total_trades         | 58595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045589395 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.58e+06   |\n",
      "|    total_cost           | 1.71e+05   |\n",
      "|    total_reward         | 2.58e+06   |\n",
      "|    total_reward_pct     | 258        |\n",
      "|    total_trades         | 59538      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 617        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02350488 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.228      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.33       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.00837   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 20.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 632         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026338909 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.28e+06    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | 2.28e+06    |\n",
      "|    total_reward_pct     | 228         |\n",
      "|    total_trades         | 58393       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 646         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024995405 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0276      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.52        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.76e+06    |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 2.76e+06    |\n",
      "|    total_reward_pct     | 276         |\n",
      "|    total_trades         | 56384       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 661         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018613504 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0281      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.67        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2886976.23\n",
      "total_reward: 1886976.23\n",
      "total_cost: 118643.81\n",
      "total_trades: 54677\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.89e+06    |\n",
      "|    total_cost           | 1.19e+05    |\n",
      "|    total_reward         | 1.89e+06    |\n",
      "|    total_reward_pct     | 189         |\n",
      "|    total_trades         | 54677       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 676         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021581236 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.75        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.06e+06    |\n",
      "|    total_cost           | 1.31e+05    |\n",
      "|    total_reward         | 2.06e+06    |\n",
      "|    total_reward_pct     | 206         |\n",
      "|    total_trades         | 55786       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 693         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025464687 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0846      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.44        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.7e+06     |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 2.7e+06     |\n",
      "|    total_reward_pct     | 270         |\n",
      "|    total_trades         | 55894       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 707         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027049575 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0871      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.05        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.44e+06    |\n",
      "|    total_cost           | 1.33e+05    |\n",
      "|    total_reward         | 2.44e+06    |\n",
      "|    total_reward_pct     | 244         |\n",
      "|    total_trades         | 55964       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 722         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016572779 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.17        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.9e+06    |\n",
      "|    total_cost           | 1.44e+05   |\n",
      "|    total_reward         | 2.9e+06    |\n",
      "|    total_reward_pct     | 290        |\n",
      "|    total_trades         | 57036      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 136        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 736        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03841883 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.0774     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.14       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00446   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 16.7       |\n",
      "----------------------------------------\n",
      "======Trading from:  2018-01-03 to  2018-04-05\n",
      "============================================\n",
      "51.44269269004415\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2018-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_693_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.000258 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -22.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -2.18e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -37.1     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.997     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00566  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -272     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 41.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 117       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -7.22e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 131       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 13.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.89e+06 |\n",
      "|    total_cost         | 1.22e+05 |\n",
      "|    total_reward       | 2.89e+06 |\n",
      "|    total_reward_pct   | 289      |\n",
      "|    total_trades       | 52282    |\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0545   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -26.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0673   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -192     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 24.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 119      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -413     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 106      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -49.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.62     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.05e+06  |\n",
      "|    total_cost         | 1.14e+05  |\n",
      "|    total_reward       | 4.05e+06  |\n",
      "|    total_reward_pct   | 405       |\n",
      "|    total_trades       | 50667     |\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 64.2      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.71      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 127       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -50.2     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.45      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 42.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.326   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -59.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.71e+06 |\n",
      "|    total_cost         | 8.53e+04 |\n",
      "|    total_reward       | 2.71e+06 |\n",
      "|    total_reward_pct   | 271      |\n",
      "|    total_trades       | 46651    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -4.53    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 105      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 98.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -61      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 2.09     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0398  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 118      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.24e+06 |\n",
      "|    total_cost         | 8.57e+04 |\n",
      "|    total_reward       | 3.24e+06 |\n",
      "|    total_reward_pct   | 324      |\n",
      "|    total_trades       | 48333    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 58.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.112    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 76.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.641   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -20.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.23     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 86        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -0.000191 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 70.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.6       |\n",
      "-------------------------------------\n",
      "day: 2265, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3559148.49\n",
      "total_reward: 2559148.49\n",
      "total_cost: 120848.10\n",
      "total_trades: 53519\n",
      "Sharpe: 0.892\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.56e+06 |\n",
      "|    total_cost         | 1.21e+05 |\n",
      "|    total_reward       | 2.56e+06 |\n",
      "|    total_reward_pct   | 256      |\n",
      "|    total_trades       | 53519    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -8.46    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.381    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.459   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -49.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0211  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -115     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -27.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.51     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 48.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.09      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3e+06    |\n",
      "|    total_cost         | 1.06e+05 |\n",
      "|    total_reward       | 2e+06    |\n",
      "|    total_reward_pct   | 200      |\n",
      "|    total_trades       | 53550    |\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0387   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 45.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0666  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 250      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 37.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -50.4     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.79      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 53.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.73e+06 |\n",
      "|    total_cost         | 4.78e+04 |\n",
      "|    total_reward       | 2.73e+06 |\n",
      "|    total_reward_pct   | 273      |\n",
      "|    total_trades       | 45904    |\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 246      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 36.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 73.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 5.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 129       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 68.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -233     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 47.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -196     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 31.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.37e+06 |\n",
      "|    total_cost         | 4.25e+04 |\n",
      "|    total_reward       | 2.37e+06 |\n",
      "|    total_reward_pct   | 237      |\n",
      "|    total_trades       | 44669    |\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 85.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.65     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 129       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 28.4      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.29      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 129       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 90.5      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 11.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -1.2e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -52.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.73e+06 |\n",
      "|    total_cost         | 5.32e+04 |\n",
      "|    total_reward       | 2.73e+06 |\n",
      "|    total_reward_pct   | 273      |\n",
      "|    total_trades       | 45761    |\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0415  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 73.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0179  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 116      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 83.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 48.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "day: 2265, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2872047.88\n",
      "total_reward: 1872047.88\n",
      "total_cost: 63531.68\n",
      "total_trades: 46955\n",
      "Sharpe: 0.714\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.87e+06 |\n",
      "|    total_cost         | 6.35e+04 |\n",
      "|    total_reward       | 1.87e+06 |\n",
      "|    total_reward_pct   | 187      |\n",
      "|    total_trades       | 46955    |\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.00101 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -138     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 14.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 120      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 159      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 17       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -35.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.14     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.57e+06 |\n",
      "|    total_cost         | 3.85e+04 |\n",
      "|    total_reward       | 2.57e+06 |\n",
      "|    total_reward_pct   | 257      |\n",
      "|    total_trades       | 43542    |\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -12.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 288      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 68.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0531  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 56.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -49.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -28.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 19.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -179     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 24.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.88e+06  |\n",
      "|    total_cost         | 6.95e+04  |\n",
      "|    total_reward       | 1.88e+06  |\n",
      "|    total_reward_pct   | 188       |\n",
      "|    total_trades       | 44740     |\n",
      "| time/                 |           |\n",
      "|    fps                | 129       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 211       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 45.7      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.46      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 129       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 215       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 60.9      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.68      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -21.7    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 157      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 20       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.09e+06 |\n",
      "|    total_cost         | 5.48e+04 |\n",
      "|    total_reward       | 2.09e+06 |\n",
      "|    total_reward_pct   | 209      |\n",
      "|    total_trades       | 43324    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -52.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.251    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 1.61     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0168   |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2018-01-03 to  2018-04-05\n",
      "A2C Sharpe Ratio:  -0.09128354602414536\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_693_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 132  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 15   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "day: 2265, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3311343.15\n",
      "total_reward: 2311343.15\n",
      "total_cost: 229561.34\n",
      "total_trades: 65816\n",
      "Sharpe: 1.086\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.31e+06    |\n",
      "|    total_cost           | 2.3e+05     |\n",
      "|    total_reward         | 2.31e+06    |\n",
      "|    total_reward_pct     | 231         |\n",
      "|    total_trades         | 65816       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014100548 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.00507     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.48        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.84e+06    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 1.84e+06    |\n",
      "|    total_reward_pct     | 184         |\n",
      "|    total_trades         | 65116       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018205836 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0257     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.12        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.54e+06    |\n",
      "|    total_cost           | 2.26e+05    |\n",
      "|    total_reward         | 2.54e+06    |\n",
      "|    total_reward_pct     | 254         |\n",
      "|    total_trades         | 65639       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008430174 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0832     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.37        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+06    |\n",
      "|    total_cost           | 2.2e+05     |\n",
      "|    total_reward         | 1.78e+06    |\n",
      "|    total_reward_pct     | 178         |\n",
      "|    total_trades         | 64815       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015037332 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0293      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.63        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.36e+06    |\n",
      "|    total_cost           | 2.23e+05    |\n",
      "|    total_reward         | 2.36e+06    |\n",
      "|    total_reward_pct     | 236         |\n",
      "|    total_trades         | 65027       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017257206 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0128     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.65        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2952661.99\n",
      "total_reward: 1952661.99\n",
      "total_cost: 213758.43\n",
      "total_trades: 64540\n",
      "Sharpe: 0.934\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.95e+06    |\n",
      "|    total_cost           | 2.14e+05    |\n",
      "|    total_reward         | 1.95e+06    |\n",
      "|    total_reward_pct     | 195         |\n",
      "|    total_trades         | 64540       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021507658 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0398     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.34e+06    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 2.34e+06    |\n",
      "|    total_reward_pct     | 234         |\n",
      "|    total_trades         | 64625       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023114182 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00582     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.7         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.31e+06    |\n",
      "|    total_cost           | 2.03e+05    |\n",
      "|    total_reward         | 1.31e+06    |\n",
      "|    total_reward_pct     | 131         |\n",
      "|    total_trades         | 62811       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020352043 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.00406    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.99        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.74e+06    |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | 1.74e+06    |\n",
      "|    total_reward_pct     | 174         |\n",
      "|    total_trades         | 62647       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008544203 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0173      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.47        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 136        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 165        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01185252 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | -0.0236    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.7        |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 15.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.36e+06    |\n",
      "|    total_cost           | 1.97e+05    |\n",
      "|    total_reward         | 1.36e+06    |\n",
      "|    total_reward_pct     | 136         |\n",
      "|    total_trades         | 62490       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023051986 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0566      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.7         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3137511.69\n",
      "total_reward: 2137511.69\n",
      "total_cost: 208402.84\n",
      "total_trades: 63410\n",
      "Sharpe: 1.021\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.14e+06    |\n",
      "|    total_cost           | 2.08e+05    |\n",
      "|    total_reward         | 2.14e+06    |\n",
      "|    total_reward_pct     | 214         |\n",
      "|    total_trades         | 63410       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031192658 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00906    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.45        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.57e+06   |\n",
      "|    total_cost           | 2.01e+05   |\n",
      "|    total_reward         | 1.57e+06   |\n",
      "|    total_reward_pct     | 157        |\n",
      "|    total_trades         | 62936      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 210        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01838635 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | -0.0692    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.42       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0228    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 13.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.93e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 1.93e+06    |\n",
      "|    total_reward_pct     | 193         |\n",
      "|    total_trades         | 64118       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026762486 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0221     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.78        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.08e+06    |\n",
      "|    total_cost           | 2.05e+05    |\n",
      "|    total_reward         | 2.08e+06    |\n",
      "|    total_reward_pct     | 208         |\n",
      "|    total_trades         | 62754       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030262886 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.00422    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.82        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.46e+06  |\n",
      "|    total_cost           | 2.07e+05  |\n",
      "|    total_reward         | 2.46e+06  |\n",
      "|    total_reward_pct     | 246       |\n",
      "|    total_trades         | 63691     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 134       |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 258       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0194174 |\n",
      "|    clip_fraction        | 0.214     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.1     |\n",
      "|    explained_variance   | 0.0138    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 7.57      |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -0.0229   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 14.5      |\n",
      "---------------------------------------\n",
      "day: 2265, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3091833.09\n",
      "total_reward: 2091833.09\n",
      "total_cost: 214765.66\n",
      "total_trades: 63770\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.09e+06   |\n",
      "|    total_cost           | 2.15e+05   |\n",
      "|    total_reward         | 2.09e+06   |\n",
      "|    total_reward_pct     | 209        |\n",
      "|    total_trades         | 63770      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 273        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03750673 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.0425     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.3        |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0224    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 17.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.9e+06    |\n",
      "|    total_cost           | 2.05e+05   |\n",
      "|    total_reward         | 1.9e+06    |\n",
      "|    total_reward_pct     | 190        |\n",
      "|    total_trades         | 63170      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 288        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03470871 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.0101     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.74       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 11.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.18e+06    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 2.18e+06    |\n",
      "|    total_reward_pct     | 218         |\n",
      "|    total_trades         | 63521       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031011887 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0427      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.43        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021103486 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.053       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.75        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.86e+06    |\n",
      "|    total_cost           | 2.03e+05    |\n",
      "|    total_reward         | 1.86e+06    |\n",
      "|    total_reward_pct     | 186         |\n",
      "|    total_trades         | 62747       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026892673 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.000462   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.64        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+06     |\n",
      "|    total_cost           | 1.94e+05    |\n",
      "|    total_reward         | 1.8e+06     |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 62183       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017726189 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.00452     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.81        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3169183.14\n",
      "total_reward: 2169183.14\n",
      "total_cost: 190019.55\n",
      "total_trades: 61742\n",
      "Sharpe: 0.903\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.17e+06    |\n",
      "|    total_cost           | 1.9e+05     |\n",
      "|    total_reward         | 2.17e+06    |\n",
      "|    total_reward_pct     | 217         |\n",
      "|    total_trades         | 61742       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015974665 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.33        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.81e+06    |\n",
      "|    total_cost           | 1.93e+05    |\n",
      "|    total_reward         | 1.81e+06    |\n",
      "|    total_reward_pct     | 181         |\n",
      "|    total_trades         | 61987       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025637541 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0412     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.55        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.87e+06   |\n",
      "|    total_cost           | 1.61e+05   |\n",
      "|    total_reward         | 1.87e+06   |\n",
      "|    total_reward_pct     | 187        |\n",
      "|    total_trades         | 59649      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 124        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 428        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03710318 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0387     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.74       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 15.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.36e+06    |\n",
      "|    total_cost           | 1.71e+05    |\n",
      "|    total_reward         | 1.36e+06    |\n",
      "|    total_reward_pct     | 136         |\n",
      "|    total_trades         | 60236       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 447         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009840561 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0195      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.48        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.64e+06   |\n",
      "|    total_cost           | 1.6e+05    |\n",
      "|    total_reward         | 1.64e+06   |\n",
      "|    total_reward_pct     | 164        |\n",
      "|    total_trades         | 59272      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 463        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01632546 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.102      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.48       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 14.5       |\n",
      "----------------------------------------\n",
      "day: 2265, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2399284.22\n",
      "total_reward: 1399284.22\n",
      "total_cost: 160226.01\n",
      "total_trades: 59538\n",
      "Sharpe: 0.694\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.4e+06     |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | 1.4e+06     |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 59538       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020902077 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.0317     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.06e+06    |\n",
      "|    total_cost           | 1.84e+05    |\n",
      "|    total_reward         | 2.06e+06    |\n",
      "|    total_reward_pct     | 206         |\n",
      "|    total_trades         | 61282       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021148907 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.00701    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.92        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -4.26e-05   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.85e+06    |\n",
      "|    total_cost           | 1.88e+05    |\n",
      "|    total_reward         | 1.85e+06    |\n",
      "|    total_reward_pct     | 185         |\n",
      "|    total_trades         | 61769       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019923236 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.079       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.83        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 526         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012885785 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.0012     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.71        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.17e+06    |\n",
      "|    total_cost           | 1.78e+05    |\n",
      "|    total_reward         | 2.17e+06    |\n",
      "|    total_reward_pct     | 217         |\n",
      "|    total_trades         | 61376       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 543         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019636512 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.058       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.47        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.55e+06    |\n",
      "|    total_cost           | 1.81e+05    |\n",
      "|    total_reward         | 1.55e+06    |\n",
      "|    total_reward_pct     | 155         |\n",
      "|    total_trades         | 61287       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031703185 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0366      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.65        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2265, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3530240.92\n",
      "total_reward: 2530240.92\n",
      "total_cost: 202763.85\n",
      "total_trades: 62632\n",
      "Sharpe: 1.072\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.53e+06  |\n",
      "|    total_cost           | 2.03e+05  |\n",
      "|    total_reward         | 2.53e+06  |\n",
      "|    total_reward_pct     | 253       |\n",
      "|    total_trades         | 62632     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 122       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 583       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0302907 |\n",
      "|    clip_fraction        | 0.262     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.8     |\n",
      "|    explained_variance   | 0.0525    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 5.97      |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -0.0182   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 13.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.86e+06    |\n",
      "|    total_cost           | 1.86e+05    |\n",
      "|    total_reward         | 1.86e+06    |\n",
      "|    total_reward_pct     | 186         |\n",
      "|    total_trades         | 61669       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028777517 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.039       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.42        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.7e+06    |\n",
      "|    total_cost           | 2.1e+05    |\n",
      "|    total_reward         | 1.7e+06    |\n",
      "|    total_reward_pct     | 170        |\n",
      "|    total_trades         | 62994      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 613        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02208837 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | -0.0365    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.24       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0181    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 12.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.51e+06    |\n",
      "|    total_cost           | 2.04e+05    |\n",
      "|    total_reward         | 1.51e+06    |\n",
      "|    total_reward_pct     | 151         |\n",
      "|    total_trades         | 62489       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 628         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035504885 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | -0.0296     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.69        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.82e+06    |\n",
      "|    total_cost           | 1.88e+05    |\n",
      "|    total_reward         | 1.82e+06    |\n",
      "|    total_reward_pct     | 182         |\n",
      "|    total_trades         | 61953       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 644         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018904427 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0827      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.99        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2963517.89\n",
      "total_reward: 1963517.89\n",
      "total_cost: 211848.32\n",
      "total_trades: 63596\n",
      "Sharpe: 0.889\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.96e+06   |\n",
      "|    total_cost           | 2.12e+05   |\n",
      "|    total_reward         | 1.96e+06   |\n",
      "|    total_reward_pct     | 196        |\n",
      "|    total_trades         | 63596      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 124        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 659        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01768247 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.139      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.12       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 14.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.78e+06   |\n",
      "|    total_cost           | 1.98e+05   |\n",
      "|    total_reward         | 1.78e+06   |\n",
      "|    total_reward_pct     | 178        |\n",
      "|    total_trades         | 62090      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 124        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 674        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04210049 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.00558    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.27       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 13.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 690         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017771058 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | -0.0255     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.89        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.99e+06   |\n",
      "|    total_cost           | 1.9e+05    |\n",
      "|    total_reward         | 1.99e+06   |\n",
      "|    total_reward_pct     | 199        |\n",
      "|    total_trades         | 61935      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 124        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 706        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03968448 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.041      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.32       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 15.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.41e+06   |\n",
      "|    total_cost           | 2.11e+05   |\n",
      "|    total_reward         | 2.41e+06   |\n",
      "|    total_reward_pct     | 241        |\n",
      "|    total_trades         | 62967      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 124        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 722        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04104114 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0353     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.42       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 11.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.31e+06   |\n",
      "|    total_cost           | 2.06e+05   |\n",
      "|    total_reward         | 2.31e+06   |\n",
      "|    total_reward_pct     | 231        |\n",
      "|    total_trades         | 62490      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 124        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 737        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03018127 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | -0.0119    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.89       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 12.3       |\n",
      "----------------------------------------\n",
      "day: 2265, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2823121.32\n",
      "total_reward: 1823121.32\n",
      "total_cost: 185240.49\n",
      "total_trades: 60987\n",
      "Sharpe: 0.829\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.82e+06   |\n",
      "|    total_cost           | 1.85e+05   |\n",
      "|    total_reward         | 1.82e+06   |\n",
      "|    total_reward_pct     | 182        |\n",
      "|    total_trades         | 60987      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 752        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03829954 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.0502     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.08       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0222    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 11.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.27e+06   |\n",
      "|    total_cost           | 1.92e+05   |\n",
      "|    total_reward         | 1.27e+06   |\n",
      "|    total_reward_pct     | 127        |\n",
      "|    total_trades         | 61710      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 767        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04711763 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.145      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.45       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 12.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.55e+06    |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | 1.55e+06    |\n",
      "|    total_reward_pct     | 155         |\n",
      "|    total_trades         | 61644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030663922 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.045       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.15        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 9.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.98e+06    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 1.98e+06    |\n",
      "|    total_reward_pct     | 198         |\n",
      "|    total_trades         | 60354       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046923645 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0778      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.31        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 10          |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2018-01-03 to  2018-04-05\n",
      "PPO Sharpe Ratio:  -0.16484959338263763\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_693_3\n",
      "day: 2265, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4321677.03\n",
      "total_reward: 3321677.03\n",
      "total_cost: 6194.70\n",
      "total_trades: 34353\n",
      "Sharpe: 1.143\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.8e+06  |\n",
      "|    total_cost       | 1.64e+03 |\n",
      "|    total_reward     | 2.8e+06  |\n",
      "|    total_reward_pct | 280      |\n",
      "|    total_trades     | 32562    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total timesteps  | 9064     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 33       |\n",
      "|    critic_loss      | 116      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6798     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======DDPG Validation from:  2018-01-03 to  2018-04-05\n",
      "======Best Model Retraining from:  2009-01-01 to  2018-04-05\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_693_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 93       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -1.66    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -12.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -52.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.012   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -333     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 80.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -1.38    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.811    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.39e+06 |\n",
      "|    total_cost         | 1.63e+05 |\n",
      "|    total_reward       | 3.39e+06 |\n",
      "|    total_reward_pct   | 339      |\n",
      "|    total_trades       | 61018    |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.244    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -5.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.133    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 118       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 217       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 34.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0573  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -77.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0748  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 21       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.668    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -169     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.05e+06 |\n",
      "|    total_cost         | 1.36e+05 |\n",
      "|    total_reward       | 3.05e+06 |\n",
      "|    total_reward_pct   | 305      |\n",
      "|    total_trades       | 58707    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0843   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -367     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 93.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -76.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0298  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 6.87     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -114     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.79e+06 |\n",
      "|    total_cost         | 7.47e+04 |\n",
      "|    total_reward       | 2.79e+06 |\n",
      "|    total_reward_pct   | 279      |\n",
      "|    total_trades       | 50958    |\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -31.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.569    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 18.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 190      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 32.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 7.55     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.461    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0789   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -51.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.92e+06 |\n",
      "|    total_cost         | 6.52e+04 |\n",
      "|    total_reward       | 2.92e+06 |\n",
      "|    total_reward_pct   | 292      |\n",
      "|    total_trades       | 47900    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0408   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 41.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 2.8e-06  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -65.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 187      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -89.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 9.6e-05  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 21.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.561    |\n",
      "------------------------------------\n",
      "day: 2328, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3247391.33\n",
      "total_reward: 2247391.33\n",
      "total_cost: 60769.36\n",
      "total_trades: 46026\n",
      "Sharpe: 0.781\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.25e+06  |\n",
      "|    total_cost         | 6.08e+04  |\n",
      "|    total_reward       | 2.25e+06  |\n",
      "|    total_reward_pct   | 225       |\n",
      "|    total_trades       | 46026     |\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -134      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 16.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -192      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 22.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -143     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 102      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.65e+06 |\n",
      "|    total_cost         | 4.97e+04 |\n",
      "|    total_reward       | 2.65e+06 |\n",
      "|    total_reward_pct   | 265      |\n",
      "|    total_trades       | 44289    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -8.24    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.372    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 117      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.122    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -146     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -43.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.854   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.403    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.93e+06 |\n",
      "|    total_cost         | 3.12e+04 |\n",
      "|    total_reward       | 2.93e+06 |\n",
      "|    total_reward_pct   | 293      |\n",
      "|    total_trades       | 43992    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.00562  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 60.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -129     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -94.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -194     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 26.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -19.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.21e+06 |\n",
      "|    total_cost         | 2.83e+04 |\n",
      "|    total_reward       | 3.21e+06 |\n",
      "|    total_reward_pct   | 321      |\n",
      "|    total_trades       | 40441    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 159      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 127       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 45.2      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 24        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 143      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 13.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 243      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 51.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.24e+06  |\n",
      "|    total_cost         | 2.63e+04  |\n",
      "|    total_reward       | 4.24e+06  |\n",
      "|    total_reward_pct   | 424       |\n",
      "|    total_trades       | 38452     |\n",
      "| time/                 |           |\n",
      "|    fps                | 127       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -130      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 11.1      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 2.18     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -36.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.00241  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 129      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 25       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 127       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 82        |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 7.12      |\n",
      "-------------------------------------\n",
      "day: 2328, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3733529.31\n",
      "total_reward: 2733529.31\n",
      "total_cost: 25243.94\n",
      "total_trades: 38829\n",
      "Sharpe: 0.873\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.73e+06 |\n",
      "|    total_cost         | 2.52e+04 |\n",
      "|    total_reward       | 2.73e+06 |\n",
      "|    total_reward_pct   | 273      |\n",
      "|    total_trades       | 38829    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -87.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -133     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 90.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 36.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 42.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.75e+06  |\n",
      "|    total_cost         | 1.79e+04  |\n",
      "|    total_reward       | 1.75e+06  |\n",
      "|    total_reward_pct   | 175       |\n",
      "|    total_trades       | 37845     |\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 202       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -189      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 23.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -186     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 21.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 12       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.197    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 127       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 215       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -2.77     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.65      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.76e+06 |\n",
      "|    total_cost         | 1.35e+04 |\n",
      "|    total_reward       | 1.76e+06 |\n",
      "|    total_reward_pct   | 176      |\n",
      "|    total_trades       | 38648    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.865   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 335      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 70.8     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.00013  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -43      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 22.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 127       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 230       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 10.7      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.86      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 172      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 19.9     |\n",
      "------------------------------------\n",
      "======Trading from:  2018-04-05 to  2018-07-05\n",
      "============================================\n",
      "36.94596100672523\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2018-04-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_756_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 94       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.386   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -48.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.458   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -43.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.196   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -120     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0427   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -39.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.47e+06 |\n",
      "|    total_cost         | 1.92e+05 |\n",
      "|    total_reward       | 2.47e+06 |\n",
      "|    total_reward_pct   | 247      |\n",
      "|    total_trades       | 62024    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.374   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -31.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.163    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 102      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.273   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 81.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 5.51      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0815   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -47.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.32e+06 |\n",
      "|    total_cost         | 1.57e+05 |\n",
      "|    total_reward       | 2.32e+06 |\n",
      "|    total_reward_pct   | 232      |\n",
      "|    total_trades       | 58315    |\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -238     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 32.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00352 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 29.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.9      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 134       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 11.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -1.07    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -145     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.26e+06 |\n",
      "|    total_cost         | 1.3e+05  |\n",
      "|    total_reward       | 2.26e+06 |\n",
      "|    total_reward_pct   | 226      |\n",
      "|    total_trades       | 55354    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -32.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.552    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -50.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0288   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 150      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 18.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.155    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -30.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.559    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -2.59    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -18.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.77e+06 |\n",
      "|    total_cost         | 1.73e+05 |\n",
      "|    total_reward       | 2.77e+06 |\n",
      "|    total_reward_pct   | 277      |\n",
      "|    total_trades       | 59008    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.263   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 45.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0083  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -32.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 144      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -37      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.74     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -13.3     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.11      |\n",
      "-------------------------------------\n",
      "day: 2328, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3117250.29\n",
      "total_reward: 2117250.29\n",
      "total_cost: 103687.87\n",
      "total_trades: 51689\n",
      "Sharpe: 0.924\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.12e+06  |\n",
      "|    total_cost         | 1.04e+05  |\n",
      "|    total_reward       | 2.12e+06  |\n",
      "|    total_reward_pct   | 212       |\n",
      "|    total_trades       | 51689     |\n",
      "| time/                 |           |\n",
      "|    fps                | 127       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 94        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -123      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 15.4      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 88.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -227     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 28.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 130      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.86e+06  |\n",
      "|    total_cost         | 6.47e+04  |\n",
      "|    total_reward       | 1.86e+06  |\n",
      "|    total_reward_pct   | 186       |\n",
      "|    total_trades       | 44660     |\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -8.39     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.233     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.158    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 48.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 43       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 18.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -105     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.81e+06 |\n",
      "|    total_cost         | 6.15e+04 |\n",
      "|    total_reward       | 1.81e+06 |\n",
      "|    total_reward_pct   | 181      |\n",
      "|    total_trades       | 47505    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.165    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 78.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -61.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -101     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -179     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 25.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 122       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 11.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.65e+06 |\n",
      "|    total_cost         | 7.74e+04 |\n",
      "|    total_reward       | 1.65e+06 |\n",
      "|    total_reward_pct   | 165      |\n",
      "|    total_trades       | 49631    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 54.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.94     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 72.2      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 5.47      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 42.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.00748  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 153      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 15.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.22e+06  |\n",
      "|    total_cost         | 5.23e+04  |\n",
      "|    total_reward       | 2.22e+06  |\n",
      "|    total_reward_pct   | 222       |\n",
      "|    total_trades       | 45442     |\n",
      "| time/                 |           |\n",
      "|    fps                | 127       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -103      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6.94      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -57      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.236    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 35.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.731    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.0458  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 250      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 34.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -209     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 21.8     |\n",
      "------------------------------------\n",
      "day: 2328, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2916062.59\n",
      "total_reward: 1916062.59\n",
      "total_cost: 38410.86\n",
      "total_trades: 43563\n",
      "Sharpe: 0.797\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.92e+06  |\n",
      "|    total_cost         | 3.84e+04  |\n",
      "|    total_reward       | 1.92e+06  |\n",
      "|    total_reward_pct   | 192       |\n",
      "|    total_trades       | 43563     |\n",
      "| time/                 |           |\n",
      "|    fps                | 127       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -114      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 7.39      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 43.8     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 3.46e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 78.3     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 4.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.0345   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 50       |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 40.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.48e+06 |\n",
      "|    total_cost         | 3.04e+04 |\n",
      "|    total_reward       | 1.48e+06 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 43667    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.0159   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -125     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 11.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.0137  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -133     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 15.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -12.2    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 5        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 70.7     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 18.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.62e+06 |\n",
      "|    total_cost         | 1.97e+04 |\n",
      "|    total_reward       | 1.62e+06 |\n",
      "|    total_reward_pct   | 162      |\n",
      "|    total_trades       | 41842    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | -0.364   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 232      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 33.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -71.6    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 43.3     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -19      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.568    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -88      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 6.05     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2018-04-05 to  2018-07-05\n",
      "A2C Sharpe Ratio:  -0.04705429670098756\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_756_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 129  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 15   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.05e+06   |\n",
      "|    total_cost           | 2.41e+05   |\n",
      "|    total_reward         | 2.05e+06   |\n",
      "|    total_reward_pct     | 205        |\n",
      "|    total_trades         | 67570      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02153084 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | -0.0155    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.99       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0264    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 13         |\n",
      "----------------------------------------\n",
      "day: 2328, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2999162.33\n",
      "total_reward: 1999162.33\n",
      "total_cost: 233930.88\n",
      "total_trades: 67113\n",
      "Sharpe: 0.913\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3e+06       |\n",
      "|    total_cost           | 2.34e+05    |\n",
      "|    total_reward         | 2e+06       |\n",
      "|    total_reward_pct     | 200         |\n",
      "|    total_trades         | 67113       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013407096 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.00365     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.28        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.63e+06     |\n",
      "|    total_cost           | 2.33e+05     |\n",
      "|    total_reward         | 1.63e+06     |\n",
      "|    total_reward_pct     | 163          |\n",
      "|    total_trades         | 67224        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 132          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147578325 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.7        |\n",
      "|    explained_variance   | -0.101       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.63         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0269      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 13.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.69e+06    |\n",
      "|    total_cost           | 2.26e+05    |\n",
      "|    total_reward         | 1.69e+06    |\n",
      "|    total_reward_pct     | 169         |\n",
      "|    total_trades         | 66957       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026146121 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.000893   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.72        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.07e+06    |\n",
      "|    total_cost           | 2.33e+05    |\n",
      "|    total_reward         | 2.07e+06    |\n",
      "|    total_reward_pct     | 207         |\n",
      "|    total_trades         | 66992       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015793173 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.032      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.97        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+06    |\n",
      "|    total_cost           | 2.25e+05    |\n",
      "|    total_reward         | 1.61e+06    |\n",
      "|    total_reward_pct     | 161         |\n",
      "|    total_trades         | 66291       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026769316 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00755     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.31        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2763453.64\n",
      "total_reward: 1763453.64\n",
      "total_cost: 229617.40\n",
      "total_trades: 66441\n",
      "Sharpe: 0.829\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.76e+06   |\n",
      "|    total_cost           | 2.3e+05    |\n",
      "|    total_reward         | 1.76e+06   |\n",
      "|    total_reward_pct     | 176        |\n",
      "|    total_trades         | 66441      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02568859 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | -0.014     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.97       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0293    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 14.8       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 132       |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 138       |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0169347 |\n",
      "|    clip_fraction        | 0.18      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -42.9     |\n",
      "|    explained_variance   | -0.0104   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 7.15      |\n",
      "|    n_updates            | 80        |\n",
      "|    policy_gradient_loss | -0.0225   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 14.4      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.97e+06   |\n",
      "|    total_cost           | 2.24e+05   |\n",
      "|    total_reward         | 1.97e+06   |\n",
      "|    total_reward_pct     | 197        |\n",
      "|    total_trades         | 66228      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 154        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02469309 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | -0.0108    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.63       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0232    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 12.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.05e+06    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 2.05e+06    |\n",
      "|    total_reward_pct     | 205         |\n",
      "|    total_trades         | 65472       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017455734 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0127     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.01        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+06     |\n",
      "|    total_cost           | 2.19e+05    |\n",
      "|    total_reward         | 1.8e+06     |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 65263       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027215362 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.00965    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.08        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.15e+06    |\n",
      "|    total_cost           | 2.23e+05    |\n",
      "|    total_reward         | 2.15e+06    |\n",
      "|    total_reward_pct     | 215         |\n",
      "|    total_trades         | 65868       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028542073 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0157      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.48        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3204957.35\n",
      "total_reward: 2204957.35\n",
      "total_cost: 218115.33\n",
      "total_trades: 65622\n",
      "Sharpe: 0.977\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.2e+06     |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 2.2e+06     |\n",
      "|    total_reward_pct     | 220         |\n",
      "|    total_trades         | 65622       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025874157 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0206      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.71        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+06     |\n",
      "|    total_cost           | 2.14e+05    |\n",
      "|    total_reward         | 1.8e+06     |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 65078       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027975341 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.011       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.47        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.94e+06   |\n",
      "|    total_cost           | 2.05e+05   |\n",
      "|    total_reward         | 1.94e+06   |\n",
      "|    total_reward_pct     | 194        |\n",
      "|    total_trades         | 64501      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 133        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 245        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04007816 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.00752    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.5       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 16.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018778218 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.000896   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.03e+06    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 1.03e+06    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 65105       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020804062 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.00664    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.4         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.27        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.16e+06  |\n",
      "|    total_cost           | 2.22e+05  |\n",
      "|    total_reward         | 2.16e+06  |\n",
      "|    total_reward_pct     | 216       |\n",
      "|    total_trades         | 65535     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 133       |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 291       |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0342197 |\n",
      "|    clip_fraction        | 0.293     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.4     |\n",
      "|    explained_variance   | 0.0128    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 7.98      |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -0.0174   |\n",
      "|    std                  | 1.03      |\n",
      "|    value_loss           | 17.2      |\n",
      "---------------------------------------\n",
      "day: 2328, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3235067.25\n",
      "total_reward: 2235067.25\n",
      "total_cost: 219169.52\n",
      "total_trades: 64993\n",
      "Sharpe: 0.929\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.24e+06   |\n",
      "|    total_cost           | 2.19e+05   |\n",
      "|    total_reward         | 2.24e+06   |\n",
      "|    total_reward_pct     | 224        |\n",
      "|    total_trades         | 64993      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 133        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 306        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03171818 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.00275    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.01       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 16.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.19e+06    |\n",
      "|    total_cost           | 2.32e+05    |\n",
      "|    total_reward         | 2.19e+06    |\n",
      "|    total_reward_pct     | 219         |\n",
      "|    total_trades         | 66478       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021330817 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.000817    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.26e+06    |\n",
      "|    total_cost           | 2.2e+05     |\n",
      "|    total_reward         | 2.26e+06    |\n",
      "|    total_reward_pct     | 226         |\n",
      "|    total_trades         | 65181       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030475307 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.000426    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.66        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.01e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 2.01e+06    |\n",
      "|    total_reward_pct     | 201         |\n",
      "|    total_trades         | 64925       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 353         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040164456 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.043       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.28        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.01e+06    |\n",
      "|    total_cost           | 2.2e+05     |\n",
      "|    total_reward         | 2.01e+06    |\n",
      "|    total_reward_pct     | 201         |\n",
      "|    total_trades         | 64880       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032559488 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0446      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.8         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033527188 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.00927    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.72        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2455511.68\n",
      "total_reward: 1455511.68\n",
      "total_cost: 211364.90\n",
      "total_trades: 64184\n",
      "Sharpe: 0.690\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.46e+06    |\n",
      "|    total_cost           | 2.11e+05    |\n",
      "|    total_reward         | 1.46e+06    |\n",
      "|    total_reward_pct     | 146         |\n",
      "|    total_trades         | 64184       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028417725 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.00302    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.75        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.47e+06    |\n",
      "|    total_cost           | 2.02e+05    |\n",
      "|    total_reward         | 2.47e+06    |\n",
      "|    total_reward_pct     | 247         |\n",
      "|    total_trades         | 63591       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030135488 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.0152     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00779    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.61e+06    |\n",
      "|    total_cost           | 2.04e+05    |\n",
      "|    total_reward         | 2.61e+06    |\n",
      "|    total_reward_pct     | 261         |\n",
      "|    total_trades         | 63778       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037852675 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.03e+06    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 3.03e+06    |\n",
      "|    total_reward_pct     | 303         |\n",
      "|    total_trades         | 64818       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026502257 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.69        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.29e+06    |\n",
      "|    total_cost           | 2.09e+05    |\n",
      "|    total_reward         | 3.29e+06    |\n",
      "|    total_reward_pct     | 329         |\n",
      "|    total_trades         | 64342       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026297377 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | -0.0259     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4263262.57\n",
      "total_reward: 3263262.57\n",
      "total_cost: 214521.46\n",
      "total_trades: 64790\n",
      "Sharpe: 1.113\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.26e+06   |\n",
      "|    total_cost           | 2.15e+05   |\n",
      "|    total_reward         | 3.26e+06   |\n",
      "|    total_reward_pct     | 326        |\n",
      "|    total_trades         | 64790      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 133        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 474        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02884838 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | -0.0147    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.2       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 28         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.41e+06    |\n",
      "|    total_cost           | 2.17e+05    |\n",
      "|    total_reward         | 3.41e+06    |\n",
      "|    total_reward_pct     | 341         |\n",
      "|    total_trades         | 64826       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 489         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025471102 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.000806    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.79e+06    |\n",
      "|    total_cost           | 2.17e+05    |\n",
      "|    total_reward         | 2.79e+06    |\n",
      "|    total_reward_pct     | 279         |\n",
      "|    total_trades         | 64674       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 504         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023232104 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0421      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 133        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 520        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03655558 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.00642    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.71       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 23.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.96e+06    |\n",
      "|    total_cost           | 2.06e+05    |\n",
      "|    total_reward         | 2.96e+06    |\n",
      "|    total_reward_pct     | 296         |\n",
      "|    total_trades         | 63770       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034369048 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | -0.0719     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.72e+06    |\n",
      "|    total_cost           | 2.2e+05     |\n",
      "|    total_reward         | 2.72e+06    |\n",
      "|    total_reward_pct     | 272         |\n",
      "|    total_trades         | 64899       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 550         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032390866 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | -0.0209     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.85        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 19.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2328, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4172020.31\n",
      "total_reward: 3172020.31\n",
      "total_cost: 205971.33\n",
      "total_trades: 63739\n",
      "Sharpe: 1.078\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.17e+06   |\n",
      "|    total_cost           | 2.06e+05   |\n",
      "|    total_reward         | 3.17e+06   |\n",
      "|    total_reward_pct     | 317        |\n",
      "|    total_trades         | 63739      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 133        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 565        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03442744 |\n",
      "|    clip_fraction        | 0.338      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.0144     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.39       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0181    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 17.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.3e+06     |\n",
      "|    total_cost           | 1.99e+05    |\n",
      "|    total_reward         | 3.3e+06     |\n",
      "|    total_reward_pct     | 330         |\n",
      "|    total_trades         | 62821       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 581         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045640178 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0164      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.59        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.71e+06    |\n",
      "|    total_cost           | 2e+05       |\n",
      "|    total_reward         | 3.71e+06    |\n",
      "|    total_reward_pct     | 371         |\n",
      "|    total_trades         | 63018       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 597         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031076917 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0177      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.72e+06    |\n",
      "|    total_cost           | 1.94e+05    |\n",
      "|    total_reward         | 2.72e+06    |\n",
      "|    total_reward_pct     | 272         |\n",
      "|    total_trades         | 62804       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 612         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024808431 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0305      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.74e+06    |\n",
      "|    total_cost           | 2.04e+05    |\n",
      "|    total_reward         | 3.74e+06    |\n",
      "|    total_reward_pct     | 374         |\n",
      "|    total_trades         | 63346       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 627         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032673508 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 642         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027316751 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0755      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4415959.31\n",
      "total_reward: 3415959.31\n",
      "total_cost: 192650.81\n",
      "total_trades: 62638\n",
      "Sharpe: 1.119\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.42e+06    |\n",
      "|    total_cost           | 1.93e+05    |\n",
      "|    total_reward         | 3.42e+06    |\n",
      "|    total_reward_pct     | 342         |\n",
      "|    total_trades         | 62638       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 657         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030609734 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.081       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.02        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.4e+06     |\n",
      "|    total_cost           | 2.09e+05    |\n",
      "|    total_reward         | 2.4e+06     |\n",
      "|    total_reward_pct     | 240         |\n",
      "|    total_trades         | 64406       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 672         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020029342 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0937      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.99e+06    |\n",
      "|    total_cost           | 2.08e+05    |\n",
      "|    total_reward         | 1.99e+06    |\n",
      "|    total_reward_pct     | 199         |\n",
      "|    total_trades         | 64544       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 688         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038965266 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0239      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.62        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.94e+06    |\n",
      "|    total_cost           | 2e+05       |\n",
      "|    total_reward         | 2.94e+06    |\n",
      "|    total_reward_pct     | 294         |\n",
      "|    total_trades         | 63036       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 705         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029732807 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0706      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.44        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.75e+06    |\n",
      "|    total_cost           | 2.06e+05    |\n",
      "|    total_reward         | 2.75e+06    |\n",
      "|    total_reward_pct     | 275         |\n",
      "|    total_trades         | 63814       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 720         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026664536 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2849775.13\n",
      "total_reward: 1849775.13\n",
      "total_cost: 203564.34\n",
      "total_trades: 63694\n",
      "Sharpe: 0.821\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.85e+06    |\n",
      "|    total_cost           | 2.04e+05    |\n",
      "|    total_reward         | 1.85e+06    |\n",
      "|    total_reward_pct     | 185         |\n",
      "|    total_trades         | 63694       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 736         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046640947 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.75        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.06e+06    |\n",
      "|    total_cost           | 2.17e+05    |\n",
      "|    total_reward         | 2.06e+06    |\n",
      "|    total_reward_pct     | 206         |\n",
      "|    total_trades         | 64693       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 751         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042508967 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.00257     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.05        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -3.03e-05   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2018-04-05 to  2018-07-05\n",
      "PPO Sharpe Ratio:  -0.008816494798850662\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_756_3\n",
      "day: 2328, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3596538.14\n",
      "total_reward: 2596538.14\n",
      "total_cost: 2046.31\n",
      "total_trades: 42377\n",
      "Sharpe: 0.838\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.03e+06 |\n",
      "|    total_cost       | 2.04e+03 |\n",
      "|    total_reward     | 2.03e+06 |\n",
      "|    total_reward_pct | 203      |\n",
      "|    total_trades     | 44636    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total timesteps  | 9316     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 33.5     |\n",
      "|    critic_loss      | 264      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6987     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2018-04-05 to  2018-07-05\n",
      "======Best Model Retraining from:  2009-01-01 to  2018-07-05\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_756_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.01e+06 |\n",
      "|    total_cost       | 1.61e+03 |\n",
      "|    total_reward     | 3.01e+06 |\n",
      "|    total_reward_pct | 301      |\n",
      "|    total_trades     | 41339    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total timesteps  | 9568     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 25       |\n",
      "|    critic_loss      | 233      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7176     |\n",
      "----------------------------------\n",
      "day: 2391, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4048452.65\n",
      "total_reward: 3048452.65\n",
      "total_cost: 1228.60\n",
      "total_trades: 43060\n",
      "Sharpe: 0.987\n",
      "=================================\n",
      "======Trading from:  2018-07-05 to  2018-10-03\n",
      "============================================\n",
      "19.69340107412405\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2018-07-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_819_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0825   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 19.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.279    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -12.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.503    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00829 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -215     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 26.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00458 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 133      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.22e+06 |\n",
      "|    total_cost         | 1.65e+05 |\n",
      "|    total_reward       | 2.22e+06 |\n",
      "|    total_reward_pct   | 222      |\n",
      "|    total_trades       | 58746    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 40.2     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0775   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -26.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0629   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -9.91    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 42       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -5.89    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.74e+06 |\n",
      "|    total_cost         | 8.67e+04 |\n",
      "|    total_reward       | 3.74e+06 |\n",
      "|    total_reward_pct   | 374      |\n",
      "|    total_trades       | 52244    |\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00473  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -89      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0173   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 219      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 33.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 271      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 53.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 213      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 43.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0108   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -37.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.02     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.26e+06  |\n",
      "|    total_cost         | 6.34e+04  |\n",
      "|    total_reward       | 5.26e+06  |\n",
      "|    total_reward_pct   | 526       |\n",
      "|    total_trades       | 48224     |\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 36.4      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.08      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 30.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.739    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -227     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 45       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -82.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.87e+06 |\n",
      "|    total_cost         | 6.21e+04 |\n",
      "|    total_reward       | 3.87e+06 |\n",
      "|    total_reward_pct   | 387      |\n",
      "|    total_trades       | 47807    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 81.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 124      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -83.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.36     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -87       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.6       |\n",
      "-------------------------------------\n",
      "day: 2391, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5001484.62\n",
      "total_reward: 4001484.62\n",
      "total_cost: 30993.04\n",
      "total_trades: 42029\n",
      "Sharpe: 1.102\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5e+06    |\n",
      "|    total_cost         | 3.1e+04  |\n",
      "|    total_reward       | 4e+06    |\n",
      "|    total_reward_pct   | 400      |\n",
      "|    total_trades       | 42029    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 69.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.38     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 44.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.47      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -9.84    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.167    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 47.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -44.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.62     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.16e+06 |\n",
      "|    total_cost         | 7.46e+04 |\n",
      "|    total_reward       | 3.16e+06 |\n",
      "|    total_reward_pct   | 316      |\n",
      "|    total_trades       | 50138    |\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -42.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 83.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00388 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 68.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 114      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 124       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 57.2      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 3.15      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.8e+06  |\n",
      "|    total_cost         | 6.98e+04 |\n",
      "|    total_reward       | 2.8e+06  |\n",
      "|    total_reward_pct   | 280      |\n",
      "|    total_trades       | 48223    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -28.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.515    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00248 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 232      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 32.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 143       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -0.000698 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 244       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 51.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.06    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -123     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 20.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0655  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 170      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 15.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.32e+06  |\n",
      "|    total_cost         | 9.53e+04  |\n",
      "|    total_reward       | 3.32e+06  |\n",
      "|    total_reward_pct   | 332       |\n",
      "|    total_trades       | 51217     |\n",
      "| time/                 |           |\n",
      "|    fps                | 124       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -3.65e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -122      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 16.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.021    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -134     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 14.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 124       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 36.5      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.894     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -28.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 153      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 17.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.29e+06 |\n",
      "|    total_cost         | 1.26e+05 |\n",
      "|    total_reward       | 2.29e+06 |\n",
      "|    total_reward_pct   | 229      |\n",
      "|    total_trades       | 55826    |\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00823 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 4.97     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0591   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -92.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00193 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 46.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -32      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "day: 2391, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2514684.24\n",
      "total_reward: 1514684.24\n",
      "total_cost: 93182.48\n",
      "total_trades: 53165\n",
      "Sharpe: 0.625\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.51e+06 |\n",
      "|    total_cost         | 9.32e+04 |\n",
      "|    total_reward       | 1.51e+06 |\n",
      "|    total_reward_pct   | 151      |\n",
      "|    total_trades       | 53165    |\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -36      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -108     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0676  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 44.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 35.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -6.05    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.42e+06 |\n",
      "|    total_cost         | 7.93e+04 |\n",
      "|    total_reward       | 2.42e+06 |\n",
      "|    total_reward_pct   | 242      |\n",
      "|    total_trades       | 51442    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0239   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -124     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00158 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 47.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 222      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 35.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 124       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 71.9      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 9.61      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0699   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -89.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.74e+06 |\n",
      "|    total_cost         | 6.67e+04 |\n",
      "|    total_reward       | 5.74e+06 |\n",
      "|    total_reward_pct   | 574      |\n",
      "|    total_trades       | 47673    |\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.126   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 45.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.054    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 140      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.163    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 126      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2018-07-05 to  2018-10-03\n",
      "A2C Sharpe Ratio:  0.44824550703409816\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_819_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 124  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 16   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.04e+06    |\n",
      "|    total_cost           | 2.52e+05    |\n",
      "|    total_reward         | 2.04e+06    |\n",
      "|    total_reward_pct     | 204         |\n",
      "|    total_trades         | 69365       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014989838 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00436    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.8         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3176506.40\n",
      "total_reward: 2176506.40\n",
      "total_cost: 242608.56\n",
      "total_trades: 68798\n",
      "Sharpe: 0.900\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.18e+06    |\n",
      "|    total_cost           | 2.43e+05    |\n",
      "|    total_reward         | 2.18e+06    |\n",
      "|    total_reward_pct     | 218         |\n",
      "|    total_trades         | 68798       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018144712 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00147    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.42        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.69e+06    |\n",
      "|    total_cost           | 2.43e+05    |\n",
      "|    total_reward         | 1.69e+06    |\n",
      "|    total_reward_pct     | 169         |\n",
      "|    total_trades         | 68610       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012785338 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0187      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.3         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.26e+06   |\n",
      "|    total_cost           | 2.39e+05   |\n",
      "|    total_reward         | 3.26e+06   |\n",
      "|    total_reward_pct     | 326        |\n",
      "|    total_trades         | 68041      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 79         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01654547 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | -0.0687    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.39       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0229    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 15.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.99e+06    |\n",
      "|    total_cost           | 2.44e+05    |\n",
      "|    total_reward         | 1.99e+06    |\n",
      "|    total_reward_pct     | 199         |\n",
      "|    total_trades         | 68509       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021315206 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00232     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031237556 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0292     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.43        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.48e+06    |\n",
      "|    total_cost           | 2.44e+05    |\n",
      "|    total_reward         | 1.48e+06    |\n",
      "|    total_reward_pct     | 148         |\n",
      "|    total_trades         | 68302       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011460615 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0112     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.57        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3750751.76\n",
      "total_reward: 2750751.76\n",
      "total_cost: 237217.01\n",
      "total_trades: 67889\n",
      "Sharpe: 1.052\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.75e+06    |\n",
      "|    total_cost           | 2.37e+05    |\n",
      "|    total_reward         | 2.75e+06    |\n",
      "|    total_reward_pct     | 275         |\n",
      "|    total_trades         | 67889       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021629676 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00584    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.88        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.04e+06    |\n",
      "|    total_cost           | 2.39e+05    |\n",
      "|    total_reward         | 3.04e+06    |\n",
      "|    total_reward_pct     | 304         |\n",
      "|    total_trades         | 67921       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026070235 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0218      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.14        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.15e+06    |\n",
      "|    total_cost           | 2.35e+05    |\n",
      "|    total_reward         | 2.15e+06    |\n",
      "|    total_reward_pct     | 215         |\n",
      "|    total_trades         | 67905       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024872437 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0237      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.9         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.53e+06    |\n",
      "|    total_cost           | 2.28e+05    |\n",
      "|    total_reward         | 3.53e+06    |\n",
      "|    total_reward_pct     | 353         |\n",
      "|    total_trades         | 66742       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018877942 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.78        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.98e+06   |\n",
      "|    total_cost           | 2.37e+05   |\n",
      "|    total_reward         | 1.98e+06   |\n",
      "|    total_reward_pct     | 198        |\n",
      "|    total_trades         | 67873      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 207        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02848246 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | -0.00347   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.1       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 30         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020763773 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0212      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.23        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2901226.83\n",
      "total_reward: 1901226.83\n",
      "total_cost: 234267.01\n",
      "total_trades: 67130\n",
      "Sharpe: 0.837\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.9e+06     |\n",
      "|    total_cost           | 2.34e+05    |\n",
      "|    total_reward         | 1.9e+06     |\n",
      "|    total_reward_pct     | 190         |\n",
      "|    total_trades         | 67130       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033602204 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0477     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.92        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.63e+06    |\n",
      "|    total_cost           | 2.31e+05    |\n",
      "|    total_reward         | 2.63e+06    |\n",
      "|    total_reward_pct     | 263         |\n",
      "|    total_trades         | 66928       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020339513 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0293      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.23        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.92e+06   |\n",
      "|    total_cost           | 2.14e+05   |\n",
      "|    total_reward         | 2.92e+06   |\n",
      "|    total_reward_pct     | 292        |\n",
      "|    total_trades         | 65477      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 273        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03253246 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | -0.0218    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 28.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.55e+06   |\n",
      "|    total_cost           | 2.2e+05    |\n",
      "|    total_reward         | 2.55e+06   |\n",
      "|    total_reward_pct     | 255        |\n",
      "|    total_trades         | 65738      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 289        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03402257 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | -0.03      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.6       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.018     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 26.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.98e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 1.98e+06    |\n",
      "|    total_reward_pct     | 198         |\n",
      "|    total_trades         | 66101       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027456217 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0204     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2775329.24\n",
      "total_reward: 1775329.24\n",
      "total_cost: 215522.16\n",
      "total_trades: 65891\n",
      "Sharpe: 0.778\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+06    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 1.78e+06    |\n",
      "|    total_reward_pct     | 178         |\n",
      "|    total_trades         | 65891       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028127272 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0595     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.61        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028454121 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0193     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.98        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.13e+06    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 2.13e+06    |\n",
      "|    total_reward_pct     | 213         |\n",
      "|    total_trades         | 66002       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019425469 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.00404     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.99e+06   |\n",
      "|    total_cost           | 2.1e+05    |\n",
      "|    total_reward         | 1.99e+06   |\n",
      "|    total_reward_pct     | 199        |\n",
      "|    total_trades         | 65721      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 369        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02141309 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.00223    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.98       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 15.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.64e+06    |\n",
      "|    total_cost           | 2.07e+05    |\n",
      "|    total_reward         | 1.64e+06    |\n",
      "|    total_reward_pct     | 164         |\n",
      "|    total_trades         | 65461       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025613675 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.9         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.9e+06     |\n",
      "|    total_cost           | 2.2e+05     |\n",
      "|    total_reward         | 2.9e+06     |\n",
      "|    total_reward_pct     | 290         |\n",
      "|    total_trades         | 66432       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 400         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023991592 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0759      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.1         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4302449.88\n",
      "total_reward: 3302449.88\n",
      "total_cost: 228361.85\n",
      "total_trades: 66777\n",
      "Sharpe: 1.112\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.3e+06     |\n",
      "|    total_cost           | 2.28e+05    |\n",
      "|    total_reward         | 3.3e+06     |\n",
      "|    total_reward_pct     | 330         |\n",
      "|    total_trades         | 66777       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027126245 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0348      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.73e+06   |\n",
      "|    total_cost           | 2.24e+05   |\n",
      "|    total_reward         | 1.73e+06   |\n",
      "|    total_reward_pct     | 173        |\n",
      "|    total_trades         | 66371      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 432        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02651001 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0322     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.01       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 24.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 448        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02866986 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0309     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.7       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 17.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.77e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 1.77e+06    |\n",
      "|    total_reward_pct     | 177         |\n",
      "|    total_trades         | 66059       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 464         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032549415 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0773      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.68        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.67e+06    |\n",
      "|    total_cost           | 2.1e+05     |\n",
      "|    total_reward         | 1.67e+06    |\n",
      "|    total_reward_pct     | 167         |\n",
      "|    total_trades         | 65407       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 482         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019444844 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0788      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.97        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.89e+06  |\n",
      "|    total_cost           | 2.03e+05  |\n",
      "|    total_reward         | 1.89e+06  |\n",
      "|    total_reward_pct     | 189       |\n",
      "|    total_trades         | 64648     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 127       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 499       |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0214673 |\n",
      "|    clip_fraction        | 0.21      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.7     |\n",
      "|    explained_variance   | -0.0131   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 5.51      |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -0.0169   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 15.4      |\n",
      "---------------------------------------\n",
      "day: 2391, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2827433.87\n",
      "total_reward: 1827433.87\n",
      "total_cost: 214919.61\n",
      "total_trades: 65443\n",
      "Sharpe: 0.774\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.83e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 1.83e+06    |\n",
      "|    total_reward_pct     | 183         |\n",
      "|    total_trades         | 65443       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 515         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025155015 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0417      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.21        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.15e+06    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 2.15e+06    |\n",
      "|    total_reward_pct     | 215         |\n",
      "|    total_trades         | 66628       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 530         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015652105 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0144      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.71        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.48e+06    |\n",
      "|    total_cost           | 2.14e+05    |\n",
      "|    total_reward         | 3.48e+06    |\n",
      "|    total_reward_pct     | 348         |\n",
      "|    total_trades         | 65695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045013465 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0617      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.67        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 563        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02028203 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.5       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 31.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.79e+06    |\n",
      "|    total_cost           | 2.23e+05    |\n",
      "|    total_reward         | 1.79e+06    |\n",
      "|    total_reward_pct     | 179         |\n",
      "|    total_trades         | 66417       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 580         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028338347 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0734      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.5         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.42e+06    |\n",
      "|    total_cost           | 2.37e+05    |\n",
      "|    total_reward         | 2.42e+06    |\n",
      "|    total_reward_pct     | 242         |\n",
      "|    total_trades         | 67288       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 595         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036190867 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0115      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.52        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3221604.43\n",
      "total_reward: 2221604.43\n",
      "total_cost: 225298.73\n",
      "total_trades: 66437\n",
      "Sharpe: 0.868\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.22e+06    |\n",
      "|    total_cost           | 2.25e+05    |\n",
      "|    total_reward         | 2.22e+06    |\n",
      "|    total_reward_pct     | 222         |\n",
      "|    total_trades         | 66437       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041056503 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0165      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.4         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.94e+06   |\n",
      "|    total_cost           | 2.26e+05   |\n",
      "|    total_reward         | 1.94e+06   |\n",
      "|    total_reward_pct     | 194        |\n",
      "|    total_trades         | 66527      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 627        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03307359 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.0178     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00631   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 24         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.84e+06    |\n",
      "|    total_cost           | 2.28e+05    |\n",
      "|    total_reward         | 1.84e+06    |\n",
      "|    total_reward_pct     | 184         |\n",
      "|    total_trades         | 66624       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 642         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020174822 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0466      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.14        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.41e+06    |\n",
      "|    total_cost           | 2.2e+05     |\n",
      "|    total_reward         | 1.41e+06    |\n",
      "|    total_reward_pct     | 141         |\n",
      "|    total_trades         | 65814       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 658         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027584909 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | -0.0154     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.79        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 673         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023476701 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0518      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.62        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.13e+06    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 2.13e+06    |\n",
      "|    total_reward_pct     | 213         |\n",
      "|    total_trades         | 66274       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 691         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023795474 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.00392     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.66        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3998466.01\n",
      "total_reward: 2998466.01\n",
      "total_cost: 230037.45\n",
      "total_trades: 66501\n",
      "Sharpe: 1.059\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4e+06       |\n",
      "|    total_cost           | 2.3e+05     |\n",
      "|    total_reward         | 3e+06       |\n",
      "|    total_reward_pct     | 300         |\n",
      "|    total_trades         | 66501       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 706         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039674703 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0424      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.3         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 1.61e+06    |\n",
      "|    total_reward_pct     | 161         |\n",
      "|    total_trades         | 64979       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 722         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029713366 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.057       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.78        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.6e+06    |\n",
      "|    total_cost           | 2.19e+05   |\n",
      "|    total_reward         | 1.6e+06    |\n",
      "|    total_reward_pct     | 160        |\n",
      "|    total_trades         | 65790      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 738        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02986449 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | -0.00841   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.2        |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0171    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 15.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.97e+06    |\n",
      "|    total_cost           | 2.24e+05    |\n",
      "|    total_reward         | 2.97e+06    |\n",
      "|    total_reward_pct     | 297         |\n",
      "|    total_trades         | 66067       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 754         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025048554 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.57        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.04e+06   |\n",
      "|    total_cost           | 2.21e+05   |\n",
      "|    total_reward         | 2.04e+06   |\n",
      "|    total_reward_pct     | 204        |\n",
      "|    total_trades         | 65715      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 769        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04338748 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | -0.0201    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.5       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00876   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 25.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 787         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035445273 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0222      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.36        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2018-07-05 to  2018-10-03\n",
      "PPO Sharpe Ratio:  0.5790534635636786\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_819_3\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.27e+06 |\n",
      "|    total_cost       | 2.41e+03 |\n",
      "|    total_reward     | 2.27e+06 |\n",
      "|    total_reward_pct | 227      |\n",
      "|    total_trades     | 40595    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total timesteps  | 9568     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -2.29    |\n",
      "|    critic_loss      | 11.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7176     |\n",
      "----------------------------------\n",
      "day: 2391, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3509588.85\n",
      "total_reward: 2509588.85\n",
      "total_cost: 1817.35\n",
      "total_trades: 32597\n",
      "Sharpe: 0.802\n",
      "=================================\n",
      "======DDPG Validation from:  2018-07-05 to  2018-10-03\n",
      "======Best Model Retraining from:  2009-01-01 to  2018-10-03\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_819_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 123  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 16   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.7e+06     |\n",
      "|    total_cost           | 2.71e+05    |\n",
      "|    total_reward         | 2.7e+06     |\n",
      "|    total_reward_pct     | 270         |\n",
      "|    total_trades         | 71616       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011130845 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.00172     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.52        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.66e+06    |\n",
      "|    total_cost           | 2.55e+05    |\n",
      "|    total_reward         | 1.66e+06    |\n",
      "|    total_reward_pct     | 166         |\n",
      "|    total_trades         | 70571       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012547491 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.000536   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.53        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.8e+06     |\n",
      "|    total_cost           | 2.53e+05    |\n",
      "|    total_reward         | 2.8e+06     |\n",
      "|    total_reward_pct     | 280         |\n",
      "|    total_trades         | 70534       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011049937 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0109     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.04        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.7e+06     |\n",
      "|    total_cost           | 2.46e+05    |\n",
      "|    total_reward         | 1.7e+06     |\n",
      "|    total_reward_pct     | 170         |\n",
      "|    total_trades         | 69755       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017154062 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00364     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2454, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2874588.69\n",
      "total_reward: 1874588.69\n",
      "total_cost: 247240.46\n",
      "total_trades: 69711\n",
      "Sharpe: 0.820\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.87e+06    |\n",
      "|    total_cost           | 2.47e+05    |\n",
      "|    total_reward         | 1.87e+06    |\n",
      "|    total_reward_pct     | 187         |\n",
      "|    total_trades         | 69711       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013680575 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0127     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.1         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008177239 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00312     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.73        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.56e+06    |\n",
      "|    total_cost           | 2.42e+05    |\n",
      "|    total_reward         | 1.56e+06    |\n",
      "|    total_reward_pct     | 156         |\n",
      "|    total_trades         | 69074       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015357824 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0351     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.67        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.31e+06    |\n",
      "|    total_cost           | 2.5e+05     |\n",
      "|    total_reward         | 2.31e+06    |\n",
      "|    total_reward_pct     | 231         |\n",
      "|    total_trades         | 69673       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020319406 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0349      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.05        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.86e+06    |\n",
      "|    total_cost           | 2.45e+05    |\n",
      "|    total_reward         | 1.86e+06    |\n",
      "|    total_reward_pct     | 186         |\n",
      "|    total_trades         | 69051       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019610284 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0485     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.43        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.22e+06    |\n",
      "|    total_cost           | 2.47e+05    |\n",
      "|    total_reward         | 2.22e+06    |\n",
      "|    total_reward_pct     | 222         |\n",
      "|    total_trades         | 69412       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036624573 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.42        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3339421.50\n",
      "total_reward: 2339421.50\n",
      "total_cost: 245170.73\n",
      "total_trades: 69181\n",
      "Sharpe: 0.956\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.34e+06    |\n",
      "|    total_cost           | 2.45e+05    |\n",
      "|    total_reward         | 2.34e+06    |\n",
      "|    total_reward_pct     | 234         |\n",
      "|    total_trades         | 69181       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008532222 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.00529    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.42        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016236484 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.00966    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5           |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.14e+06    |\n",
      "|    total_cost           | 2.44e+05    |\n",
      "|    total_reward         | 2.14e+06    |\n",
      "|    total_reward_pct     | 214         |\n",
      "|    total_trades         | 69066       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028167723 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.00838     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.49        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.51e+06    |\n",
      "|    total_cost           | 2.4e+05     |\n",
      "|    total_reward         | 1.51e+06    |\n",
      "|    total_reward_pct     | 151         |\n",
      "|    total_trades         | 69028       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034249492 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.00449    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.69        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.16e+06    |\n",
      "|    total_cost           | 2.39e+05    |\n",
      "|    total_reward         | 2.16e+06    |\n",
      "|    total_reward_pct     | 216         |\n",
      "|    total_trades         | 68622       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018498011 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0155      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.15e+06    |\n",
      "|    total_cost           | 2.37e+05    |\n",
      "|    total_reward         | 3.15e+06    |\n",
      "|    total_reward_pct     | 315         |\n",
      "|    total_trades         | 68254       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027702278 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0103     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.59        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3924856.78\n",
      "total_reward: 2924856.78\n",
      "total_cost: 230269.55\n",
      "total_trades: 68248\n",
      "Sharpe: 0.921\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.92e+06    |\n",
      "|    total_cost           | 2.3e+05     |\n",
      "|    total_reward         | 2.92e+06    |\n",
      "|    total_reward_pct     | 292         |\n",
      "|    total_trades         | 68248       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021382857 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | -0.0152     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021195246 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0373      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.27e+06    |\n",
      "|    total_cost           | 2.28e+05    |\n",
      "|    total_reward         | 2.27e+06    |\n",
      "|    total_reward_pct     | 227         |\n",
      "|    total_trades         | 68045       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024123205 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0379      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.09        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.66e+06    |\n",
      "|    total_cost           | 2.33e+05    |\n",
      "|    total_reward         | 3.66e+06    |\n",
      "|    total_reward_pct     | 366         |\n",
      "|    total_trades         | 68291       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020862473 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0656      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.71        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.11e+06    |\n",
      "|    total_cost           | 2.37e+05    |\n",
      "|    total_reward         | 2.11e+06    |\n",
      "|    total_reward_pct     | 211         |\n",
      "|    total_trades         | 68399       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029902477 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.0868     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.53e+06    |\n",
      "|    total_cost           | 2.2e+05     |\n",
      "|    total_reward         | 2.53e+06    |\n",
      "|    total_reward_pct     | 253         |\n",
      "|    total_trades         | 67287       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027724607 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.00969    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.56        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4191341.23\n",
      "total_reward: 3191341.23\n",
      "total_cost: 231558.54\n",
      "total_trades: 68026\n",
      "Sharpe: 0.976\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.19e+06    |\n",
      "|    total_cost           | 2.32e+05    |\n",
      "|    total_reward         | 3.19e+06    |\n",
      "|    total_reward_pct     | 319         |\n",
      "|    total_trades         | 68026       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029260017 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.00859     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022783933 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.000796    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.55e+06    |\n",
      "|    total_cost           | 1.98e+05    |\n",
      "|    total_reward         | 1.55e+06    |\n",
      "|    total_reward_pct     | 155         |\n",
      "|    total_trades         | 65080       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013533825 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.00237    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.5e+06     |\n",
      "|    total_cost           | 2.33e+05    |\n",
      "|    total_reward         | 2.5e+06     |\n",
      "|    total_reward_pct     | 250         |\n",
      "|    total_trades         | 67766       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 467         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024274122 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0854      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.87        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.75e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 2.75e+06    |\n",
      "|    total_reward_pct     | 275         |\n",
      "|    total_trades         | 66681       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 490         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023985036 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.00279    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.43e+06    |\n",
      "|    total_cost           | 2.17e+05    |\n",
      "|    total_reward         | 2.43e+06    |\n",
      "|    total_reward_pct     | 243         |\n",
      "|    total_trades         | 66466       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 508         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027079528 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0837      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2454, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4014117.72\n",
      "total_reward: 3014117.72\n",
      "total_cost: 221503.60\n",
      "total_trades: 67033\n",
      "Sharpe: 0.903\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.01e+06   |\n",
      "|    total_cost           | 2.22e+05   |\n",
      "|    total_reward         | 3.01e+06   |\n",
      "|    total_reward_pct     | 301        |\n",
      "|    total_trades         | 67033      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 526        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01745853 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0795     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0176    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 27         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029723758 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0513      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.04e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 2.04e+06    |\n",
      "|    total_reward_pct     | 204         |\n",
      "|    total_trades         | 66301       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021772286 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.42e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 2.42e+06    |\n",
      "|    total_reward_pct     | 242         |\n",
      "|    total_trades         | 66315       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 584         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014230795 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | -0.00471    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.88        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.2e+06    |\n",
      "|    total_cost           | 2e+05      |\n",
      "|    total_reward         | 1.2e+06    |\n",
      "|    total_reward_pct     | 120        |\n",
      "|    total_trades         | 64294      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 601        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02296749 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.172      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0215    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 30.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+06    |\n",
      "|    total_cost           | 2.36e+05    |\n",
      "|    total_reward         | 1.45e+06    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 67846       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 617         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028927123 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0425      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.03        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3260093.14\n",
      "total_reward: 2260093.14\n",
      "total_cost: 224087.08\n",
      "total_trades: 66674\n",
      "Sharpe: 0.739\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.26e+06   |\n",
      "|    total_cost           | 2.24e+05   |\n",
      "|    total_reward         | 2.26e+06   |\n",
      "|    total_reward_pct     | 226        |\n",
      "|    total_trades         | 66674      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 635        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03916412 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.0388     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.76       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 17         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 663         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022332426 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0742      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.96e+06    |\n",
      "|    total_cost           | 2.23e+05    |\n",
      "|    total_reward         | 2.96e+06    |\n",
      "|    total_reward_pct     | 296         |\n",
      "|    total_trades         | 66296       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 683         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013280118 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0414      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.91        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.57e+06    |\n",
      "|    total_cost           | 2.19e+05    |\n",
      "|    total_reward         | 2.57e+06    |\n",
      "|    total_reward_pct     | 257         |\n",
      "|    total_trades         | 66669       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 704         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034261115 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0512      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.76e+06    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 1.76e+06    |\n",
      "|    total_reward_pct     | 176         |\n",
      "|    total_trades         | 65949       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 723         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033458237 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+06     |\n",
      "|    total_cost           | 2.27e+05    |\n",
      "|    total_reward         | 1.8e+06     |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 66636       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 742         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030952387 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.000112    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2278749.64\n",
      "total_reward: 1278749.64\n",
      "total_cost: 196819.97\n",
      "total_trades: 63509\n",
      "Sharpe: 0.505\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.28e+06    |\n",
      "|    total_cost           | 1.97e+05    |\n",
      "|    total_reward         | 1.28e+06    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 63509       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 760         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023423761 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0178      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019472912 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.49e+06    |\n",
      "|    total_cost           | 2.06e+05    |\n",
      "|    total_reward         | 1.49e+06    |\n",
      "|    total_reward_pct     | 149         |\n",
      "|    total_trades         | 64182       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 800         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017958658 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0673      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.47e+06    |\n",
      "|    total_cost           | 1.9e+05     |\n",
      "|    total_reward         | 1.47e+06    |\n",
      "|    total_reward_pct     | 147         |\n",
      "|    total_trades         | 63253       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 818         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018957775 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.88        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.32e+06    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 1.32e+06    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 61704       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 838         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015215389 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0614      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.05e+06    |\n",
      "|    total_cost           | 2.24e+05    |\n",
      "|    total_reward         | 1.05e+06    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 66024       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 855         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018675586 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2357643.10\n",
      "total_reward: 1357643.10\n",
      "total_cost: 219673.66\n",
      "total_trades: 66223\n",
      "Sharpe: 0.617\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.36e+06   |\n",
      "|    total_cost           | 2.2e+05    |\n",
      "|    total_reward         | 1.36e+06   |\n",
      "|    total_reward_pct     | 136        |\n",
      "|    total_trades         | 66223      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 877        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04503665 |\n",
      "|    clip_fraction        | 0.368      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0503     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.67       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 10.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 900        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03103327 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.13       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.06       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 13.5       |\n",
      "----------------------------------------\n",
      "======Trading from:  2018-10-03 to  2019-01-04\n",
      "============================================\n",
      "24.34258398865855\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2018-10-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_882_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.194    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -88.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 88       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -59.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -173     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 18.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -39.2     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.38      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.3e+06  |\n",
      "|    total_cost         | 1.06e+05 |\n",
      "|    total_reward       | 4.3e+06  |\n",
      "|    total_reward_pct   | 430      |\n",
      "|    total_trades       | 52394    |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -70.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.000653 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -80.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0344  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -230     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 30.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0194  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 115      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 20.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0163   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 74.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.37e+06 |\n",
      "|    total_cost         | 1.14e+05 |\n",
      "|    total_reward       | 6.37e+06 |\n",
      "|    total_reward_pct   | 637      |\n",
      "|    total_trades       | 50978    |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 27.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.611    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 116       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 37.3      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.52      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 40.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 104      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.1e+06  |\n",
      "|    total_cost         | 9.63e+04 |\n",
      "|    total_reward       | 5.1e+06  |\n",
      "|    total_reward_pct   | 510      |\n",
      "|    total_trades       | 50400    |\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -17.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.222    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0491   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 104      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 88.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -106     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0131   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -204     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 34       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.98e+06 |\n",
      "|    total_cost         | 5.81e+04 |\n",
      "|    total_reward       | 3.98e+06 |\n",
      "|    total_reward_pct   | 398      |\n",
      "|    total_trades       | 44730    |\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.238    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 1.1      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.233    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 5.3      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.08     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 15       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.422    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0061  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 385      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 181      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -80.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 18.8     |\n",
      "------------------------------------\n",
      "day: 2454, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7146156.07\n",
      "total_reward: 6146156.07\n",
      "total_cost: 33526.42\n",
      "total_trades: 40352\n",
      "Sharpe: 1.351\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.15e+06 |\n",
      "|    total_cost         | 3.35e+04 |\n",
      "|    total_reward       | 6.15e+06 |\n",
      "|    total_reward_pct   | 615      |\n",
      "|    total_trades       | 40352    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.428   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 40.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -70.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.177   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -27.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.615    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 20.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 355      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 73.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.7e+06  |\n",
      "|    total_cost         | 3.22e+04 |\n",
      "|    total_reward       | 5.7e+06  |\n",
      "|    total_reward_pct   | 570      |\n",
      "|    total_trades       | 41004    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.00839 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -132     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 8.2      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.132    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0986   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -140     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0218  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -649     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 232      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -273     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 42.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.38e+06 |\n",
      "|    total_cost         | 2.22e+04 |\n",
      "|    total_reward       | 4.38e+06 |\n",
      "|    total_reward_pct   | 438      |\n",
      "|    total_trades       | 40167    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 22.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.338    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.26     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -27.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.439    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -66.2     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5.98      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 281      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 50.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 71.5      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 21.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.36e+06  |\n",
      "|    total_cost         | 1.84e+04  |\n",
      "|    total_reward       | 6.36e+06  |\n",
      "|    total_reward_pct   | 636       |\n",
      "|    total_trades       | 40448     |\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 162       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -0.000914 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 44.2      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.93      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 166       |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 92.7      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6.65      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 85.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.43     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -215      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 31        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 424      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 123      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.91e+06 |\n",
      "|    total_cost         | 1.05e+04 |\n",
      "|    total_reward       | 6.91e+06 |\n",
      "|    total_reward_pct   | 691      |\n",
      "|    total_trades       | 40278    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.55    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.883    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 129      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 190       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -151      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 16.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 194       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | -47.8     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.43      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 198       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 506       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 180       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2454, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7613317.50\n",
      "total_reward: 6613317.50\n",
      "total_cost: 9494.15\n",
      "total_trades: 42077\n",
      "Sharpe: 1.322\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.61e+06 |\n",
      "|    total_cost         | 9.49e+03 |\n",
      "|    total_reward       | 6.61e+06 |\n",
      "|    total_reward_pct   | 661      |\n",
      "|    total_trades       | 42077    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 51.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -39.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -40.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 108      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 339      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 76.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.77e+06 |\n",
      "|    total_cost         | 7.62e+03 |\n",
      "|    total_reward       | 5.77e+06 |\n",
      "|    total_reward_pct   | 577      |\n",
      "|    total_trades       | 40307    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -58.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 51.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -58.8    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 97       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.28e+06 |\n",
      "|    total_cost         | 1.34e+04 |\n",
      "|    total_reward       | 5.28e+06 |\n",
      "|    total_reward_pct   | 528      |\n",
      "|    total_trades       | 40751    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 16.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.671    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -15.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.637    |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2018-10-03 to  2019-01-04\n",
      "A2C Sharpe Ratio:  -0.17872166971494702\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_882_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 124  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 16   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 3.44e+06     |\n",
      "|    total_cost           | 2.6e+05      |\n",
      "|    total_reward         | 2.44e+06     |\n",
      "|    total_reward_pct     | 244          |\n",
      "|    total_trades         | 71029        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 125          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036296286 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.0112      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.13         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0302      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 14.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2454, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3452916.41\n",
      "total_reward: 2452916.41\n",
      "total_cost: 259886.35\n",
      "total_trades: 71225\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.45e+06   |\n",
      "|    total_cost           | 2.6e+05    |\n",
      "|    total_reward         | 2.45e+06   |\n",
      "|    total_reward_pct     | 245        |\n",
      "|    total_trades         | 71225      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 48         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01372424 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | 0.00809    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.85       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0224    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 13.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.08e+06    |\n",
      "|    total_cost           | 2.48e+05    |\n",
      "|    total_reward         | 2.08e+06    |\n",
      "|    total_reward_pct     | 208         |\n",
      "|    total_trades         | 70395       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020992208 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0137     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.64e+06    |\n",
      "|    total_cost           | 2.46e+05    |\n",
      "|    total_reward         | 1.64e+06    |\n",
      "|    total_reward_pct     | 164         |\n",
      "|    total_trades         | 69878       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020931657 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0112     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.53        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.64e+06    |\n",
      "|    total_cost           | 2.39e+05    |\n",
      "|    total_reward         | 1.64e+06    |\n",
      "|    total_reward_pct     | 164         |\n",
      "|    total_trades         | 69383       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023604244 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00175     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.02        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016054172 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0157      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.1         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.69e+06    |\n",
      "|    total_cost           | 2.47e+05    |\n",
      "|    total_reward         | 1.69e+06    |\n",
      "|    total_reward_pct     | 169         |\n",
      "|    total_trades         | 70249       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015938137 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00617     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.86        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.5         |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3004013.91\n",
      "total_reward: 2004013.91\n",
      "total_cost: 246422.01\n",
      "total_trades: 70269\n",
      "Sharpe: 0.831\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3e+06       |\n",
      "|    total_cost           | 2.46e+05    |\n",
      "|    total_reward         | 2e+06       |\n",
      "|    total_reward_pct     | 200         |\n",
      "|    total_trades         | 70269       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024634361 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00723     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.6         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+06     |\n",
      "|    total_cost           | 2.33e+05    |\n",
      "|    total_reward         | 1.5e+06     |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 69037       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019185299 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0137     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.77        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.73e+06    |\n",
      "|    total_cost           | 2.46e+05    |\n",
      "|    total_reward         | 1.73e+06    |\n",
      "|    total_reward_pct     | 173         |\n",
      "|    total_trades         | 69977       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020784901 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0062     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.73        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.96e+06    |\n",
      "|    total_cost           | 2.38e+05    |\n",
      "|    total_reward         | 1.96e+06    |\n",
      "|    total_reward_pct     | 196         |\n",
      "|    total_trades         | 68978       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024808388 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0244      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.39        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021351863 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00648     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.48        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.85e+06    |\n",
      "|    total_cost           | 2.41e+05    |\n",
      "|    total_reward         | 1.85e+06    |\n",
      "|    total_reward_pct     | 185         |\n",
      "|    total_trades         | 69476       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028593335 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0371      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.61        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2739498.24\n",
      "total_reward: 1739498.24\n",
      "total_cost: 250711.53\n",
      "total_trades: 70115\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.74e+06    |\n",
      "|    total_cost           | 2.51e+05    |\n",
      "|    total_reward         | 1.74e+06    |\n",
      "|    total_reward_pct     | 174         |\n",
      "|    total_trades         | 70115       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024897924 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0651      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.92        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.51e+06    |\n",
      "|    total_cost           | 2.5e+05     |\n",
      "|    total_reward         | 2.51e+06    |\n",
      "|    total_reward_pct     | 251         |\n",
      "|    total_trades         | 69865       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023375437 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0142     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.41        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.52e+06    |\n",
      "|    total_cost           | 2.45e+05    |\n",
      "|    total_reward         | 2.52e+06    |\n",
      "|    total_reward_pct     | 252         |\n",
      "|    total_trades         | 69644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029832058 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0336     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.16        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.06e+06   |\n",
      "|    total_cost           | 2.38e+05   |\n",
      "|    total_reward         | 2.06e+06   |\n",
      "|    total_reward_pct     | 206        |\n",
      "|    total_trades         | 69372      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 124        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 296        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02315171 |\n",
      "|    clip_fraction        | 0.257      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0393     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10         |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 19.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 124        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 312        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03393507 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | -0.013     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.52       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 18.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.82e+06    |\n",
      "|    total_cost           | 2.42e+05    |\n",
      "|    total_reward         | 2.82e+06    |\n",
      "|    total_reward_pct     | 282         |\n",
      "|    total_trades         | 69802       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023613708 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.56        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3418616.32\n",
      "total_reward: 2418616.32\n",
      "total_cost: 224328.06\n",
      "total_trades: 68606\n",
      "Sharpe: 0.981\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.42e+06    |\n",
      "|    total_cost           | 2.24e+05    |\n",
      "|    total_reward         | 2.42e+06    |\n",
      "|    total_reward_pct     | 242         |\n",
      "|    total_trades         | 68606       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034554623 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.0204     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6           |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.47e+06    |\n",
      "|    total_cost           | 2.27e+05    |\n",
      "|    total_reward         | 2.47e+06    |\n",
      "|    total_reward_pct     | 247         |\n",
      "|    total_trades         | 68578       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013975898 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.00827    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.01        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.59e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 2.59e+06    |\n",
      "|    total_reward_pct     | 259         |\n",
      "|    total_trades         | 67407       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019255307 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.0445     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.09e+06    |\n",
      "|    total_cost           | 2.39e+05    |\n",
      "|    total_reward         | 3.09e+06    |\n",
      "|    total_reward_pct     | 309         |\n",
      "|    total_trades         | 69378       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028480401 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.000438   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 124       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 411       |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0526885 |\n",
      "|    clip_fraction        | 0.295     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.8     |\n",
      "|    explained_variance   | -0.0528   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 10.3      |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -0.0146   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 26.2      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.99e+06    |\n",
      "|    total_cost           | 2.21e+05    |\n",
      "|    total_reward         | 2.99e+06    |\n",
      "|    total_reward_pct     | 299         |\n",
      "|    total_trades         | 67914       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021401698 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0395      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.35        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3532863.21\n",
      "total_reward: 2532863.21\n",
      "total_cost: 203278.27\n",
      "total_trades: 66288\n",
      "Sharpe: 0.869\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.53e+06    |\n",
      "|    total_cost           | 2.03e+05    |\n",
      "|    total_reward         | 2.53e+06    |\n",
      "|    total_reward_pct     | 253         |\n",
      "|    total_trades         | 66288       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 445         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024050705 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0291      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.82e+06    |\n",
      "|    total_cost           | 2.03e+05    |\n",
      "|    total_reward         | 2.82e+06    |\n",
      "|    total_reward_pct     | 282         |\n",
      "|    total_trades         | 65938       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022837654 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | -0.0199     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.65e+06    |\n",
      "|    total_cost           | 1.96e+05    |\n",
      "|    total_reward         | 2.65e+06    |\n",
      "|    total_reward_pct     | 265         |\n",
      "|    total_trades         | 65671       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 480         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011605853 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.013       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0085     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4e+06       |\n",
      "|    total_cost           | 2.05e+05    |\n",
      "|    total_reward         | 3e+06       |\n",
      "|    total_reward_pct     | 300         |\n",
      "|    total_trades         | 66264       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008140456 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0172      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 513         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021879707 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.00632     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4e+06       |\n",
      "|    total_cost           | 1.96e+05    |\n",
      "|    total_reward         | 3e+06       |\n",
      "|    total_reward_pct     | 300         |\n",
      "|    total_trades         | 65602       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 529         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028075224 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0254      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.16        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4133000.05\n",
      "total_reward: 3133000.05\n",
      "total_cost: 189202.25\n",
      "total_trades: 65108\n",
      "Sharpe: 0.975\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.13e+06    |\n",
      "|    total_cost           | 1.89e+05    |\n",
      "|    total_reward         | 3.13e+06    |\n",
      "|    total_reward_pct     | 313         |\n",
      "|    total_trades         | 65108       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021968005 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0187      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.06e+06    |\n",
      "|    total_cost           | 1.96e+05    |\n",
      "|    total_reward         | 3.06e+06    |\n",
      "|    total_reward_pct     | 306         |\n",
      "|    total_trades         | 65595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 563         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021096146 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0277      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.83e+06    |\n",
      "|    total_cost           | 1.99e+05    |\n",
      "|    total_reward         | 2.83e+06    |\n",
      "|    total_reward_pct     | 283         |\n",
      "|    total_trades         | 65763       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020412378 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.029       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.88e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 3.88e+06    |\n",
      "|    total_reward_pct     | 388         |\n",
      "|    total_trades         | 67056       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041270047 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0174      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 614         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020214252 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.032       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.95e+06   |\n",
      "|    total_cost           | 2.14e+05   |\n",
      "|    total_reward         | 3.95e+06   |\n",
      "|    total_reward_pct     | 395        |\n",
      "|    total_trades         | 66997      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 631        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03023576 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0889     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.92       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.00731   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 23.3       |\n",
      "----------------------------------------\n",
      "day: 2454, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3988668.21\n",
      "total_reward: 2988668.21\n",
      "total_cost: 203925.77\n",
      "total_trades: 66214\n",
      "Sharpe: 0.984\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.99e+06    |\n",
      "|    total_cost           | 2.04e+05    |\n",
      "|    total_reward         | 2.99e+06    |\n",
      "|    total_reward_pct     | 299         |\n",
      "|    total_trades         | 66214       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 647         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033455364 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0902      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.07e+06   |\n",
      "|    total_cost           | 1.8e+05    |\n",
      "|    total_reward         | 3.07e+06   |\n",
      "|    total_reward_pct     | 307        |\n",
      "|    total_trades         | 63787      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 664        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02896944 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | -0.0249    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.5       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.00604   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 31.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.16e+06    |\n",
      "|    total_cost           | 2.13e+05    |\n",
      "|    total_reward         | 2.16e+06    |\n",
      "|    total_reward_pct     | 216         |\n",
      "|    total_trades         | 66944       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 680         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017375344 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0364      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.47e+06    |\n",
      "|    total_cost           | 1.96e+05    |\n",
      "|    total_reward         | 3.47e+06    |\n",
      "|    total_reward_pct     | 347         |\n",
      "|    total_trades         | 65806       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 696         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029189132 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.35        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 712        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02625479 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.089      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.9       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00457   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 54.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.77e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 2.77e+06    |\n",
      "|    total_reward_pct     | 277         |\n",
      "|    total_trades         | 66964       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 728         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024606898 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.00742     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3826479.89\n",
      "total_reward: 2826479.89\n",
      "total_cost: 216839.44\n",
      "total_trades: 66722\n",
      "Sharpe: 0.960\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.83e+06    |\n",
      "|    total_cost           | 2.17e+05    |\n",
      "|    total_reward         | 2.83e+06    |\n",
      "|    total_reward_pct     | 283         |\n",
      "|    total_trades         | 66722       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 745         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031072969 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.03e+06   |\n",
      "|    total_cost           | 2.01e+05   |\n",
      "|    total_reward         | 3.03e+06   |\n",
      "|    total_reward_pct     | 303        |\n",
      "|    total_trades         | 65759      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 761        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03755903 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0622     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.35       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 19.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.76e+06   |\n",
      "|    total_cost           | 1.86e+05   |\n",
      "|    total_reward         | 2.76e+06   |\n",
      "|    total_reward_pct     | 276        |\n",
      "|    total_trades         | 64917      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 778        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06812003 |\n",
      "|    clip_fraction        | 0.35       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.0124     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.6       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | 0.00542    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 36.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.51e+06    |\n",
      "|    total_cost           | 1.7e+05     |\n",
      "|    total_reward         | 2.51e+06    |\n",
      "|    total_reward_pct     | 251         |\n",
      "|    total_trades         | 63099       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 796         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026866538 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0561      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 813         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021392161 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0652      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2018-10-03 to  2019-01-04\n",
      "PPO Sharpe Ratio:  -0.2882869498943497\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_882_3\n",
      "day: 2454, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4546992.26\n",
      "total_reward: 3546992.26\n",
      "total_cost: 5126.12\n",
      "total_trades: 52609\n",
      "Sharpe: 1.145\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.45e+06 |\n",
      "|    total_cost       | 1.33e+03 |\n",
      "|    total_reward     | 3.45e+06 |\n",
      "|    total_reward_pct | 345      |\n",
      "|    total_trades     | 43950    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total timesteps  | 9820     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 69.1     |\n",
      "|    critic_loss      | 20.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7365     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======DDPG Validation from:  2018-10-03 to  2019-01-04\n",
      "======Best Model Retraining from:  2009-01-01 to  2019-01-04\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_882_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 86       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0483   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -14.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.251    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.241    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -86      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.163    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -304     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 61.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0684  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -43.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0108  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 460      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 155      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.56e+06 |\n",
      "|    total_cost         | 2.18e+05 |\n",
      "|    total_reward       | 4.56e+06 |\n",
      "|    total_reward_pct   | 456      |\n",
      "|    total_trades       | 67919    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0186   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -71.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 113      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 102      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0401  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 266      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 38.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 483       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 194       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.23e+06 |\n",
      "|    total_cost         | 1.2e+05  |\n",
      "|    total_reward       | 4.23e+06 |\n",
      "|    total_reward_pct   | 423      |\n",
      "|    total_trades       | 59500    |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.145    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -81.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.45     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -39.9     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.24      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 78.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -59.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.28     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00328  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -289     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 64.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.29e+06 |\n",
      "|    total_cost         | 5.1e+04  |\n",
      "|    total_reward       | 3.29e+06 |\n",
      "|    total_reward_pct   | 329      |\n",
      "|    total_trades       | 50572    |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -74.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -135     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 63.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -62.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 49.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.53     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.84e+06  |\n",
      "|    total_cost         | 3.09e+04  |\n",
      "|    total_reward       | 1.84e+06  |\n",
      "|    total_reward_pct   | 184       |\n",
      "|    total_trades       | 48353     |\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.07e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 57        |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.05      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -166     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 35.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.23     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -31.5     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.3       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 133      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "day: 2517, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2891745.53\n",
      "total_reward: 1891745.53\n",
      "total_cost: 15097.91\n",
      "total_trades: 45571\n",
      "Sharpe: 0.815\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.89e+06 |\n",
      "|    total_cost         | 1.51e+04 |\n",
      "|    total_reward       | 1.89e+06 |\n",
      "|    total_reward_pct   | 189      |\n",
      "|    total_trades       | 45571    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -116     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -21      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.99     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -166      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 26.5      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -350     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 102      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 10       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.759    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.48e+06  |\n",
      "|    total_cost         | 1.11e+04  |\n",
      "|    total_reward       | 2.48e+06  |\n",
      "|    total_reward_pct   | 248       |\n",
      "|    total_trades       | 44025     |\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -102      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.93      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0138   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -115     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -49      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 185      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 29.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -217     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 24.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.99e+06 |\n",
      "|    total_cost         | 8.56e+03 |\n",
      "|    total_reward       | 2.99e+06 |\n",
      "|    total_reward_pct   | 299      |\n",
      "|    total_trades       | 42861    |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -77.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 121      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -127     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0543  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 32.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 105      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.61e+06 |\n",
      "|    total_cost         | 8.94e+03 |\n",
      "|    total_reward       | 2.61e+06 |\n",
      "|    total_reward_pct   | 261      |\n",
      "|    total_trades       | 41229    |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.00036 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -105     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -255     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 42       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -1.54    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.73     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 192       |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | -36.9     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 4.2       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -109     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 14.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.8e+06   |\n",
      "|    total_cost         | 1.1e+04   |\n",
      "|    total_reward       | 2.8e+06   |\n",
      "|    total_reward_pct   | 280       |\n",
      "|    total_trades       | 42697     |\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 202       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -59.3     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.34      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 8.52e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -47.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.99     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 131       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 15.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -15.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -87.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 13.2     |\n",
      "------------------------------------\n",
      "day: 2517, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3775198.43\n",
      "total_reward: 2775198.43\n",
      "total_cost: 6564.71\n",
      "total_trades: 40812\n",
      "Sharpe: 1.026\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.78e+06 |\n",
      "|    total_cost         | 6.56e+03 |\n",
      "|    total_reward       | 2.78e+06 |\n",
      "|    total_reward_pct   | 278      |\n",
      "|    total_trades       | 40812    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 2.44e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -44.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 56.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -37.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 73.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -141     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 16.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.75e+06 |\n",
      "|    total_cost         | 6.19e+03 |\n",
      "|    total_reward       | 2.75e+06 |\n",
      "|    total_reward_pct   | 275      |\n",
      "|    total_trades       | 41108    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -20.8    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.437    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -25.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.381    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 104      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 277      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 48.1     |\n",
      "------------------------------------\n",
      "======Trading from:  2019-01-04 to  2019-04-05\n",
      "============================================\n",
      "45.21128772353635\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2019-01-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_945_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0975   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -93.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.257   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -83.4    |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 4.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -184     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 20.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 144      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 13.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 432      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 139      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.21e+06 |\n",
      "|    total_cost         | 1.07e+05 |\n",
      "|    total_reward       | 3.21e+06 |\n",
      "|    total_reward_pct   | 321      |\n",
      "|    total_trades       | 57061    |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -82.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 86.4     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.135   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 5.48     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.13     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 238       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 30.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0525  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 158      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 30.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4e+06    |\n",
      "|    total_cost         | 9.86e+04 |\n",
      "|    total_reward       | 3e+06    |\n",
      "|    total_reward_pct   | 300      |\n",
      "|    total_trades       | 54564    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0542   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 7.8      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.442    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0803   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -132     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0176  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 231      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 37.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -154     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 17.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -434     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 140      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.73e+06 |\n",
      "|    total_cost         | 8.18e+04 |\n",
      "|    total_reward       | 3.73e+06 |\n",
      "|    total_reward_pct   | 373      |\n",
      "|    total_trades       | 53962    |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -2.28    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -119     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.21     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -94.8     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 5.21      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 8.48e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 11.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 14.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 367      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 90.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.07e+06  |\n",
      "|    total_cost         | 7.46e+04  |\n",
      "|    total_reward       | 4.07e+06  |\n",
      "|    total_reward_pct   | 407       |\n",
      "|    total_trades       | 54709     |\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | -37       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.64      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -54.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -79.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.53     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 11.4      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.84      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 360      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 73       |\n",
      "------------------------------------\n",
      "day: 2517, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5412818.14\n",
      "total_reward: 4412818.14\n",
      "total_cost: 47012.32\n",
      "total_trades: 51094\n",
      "Sharpe: 1.098\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.41e+06 |\n",
      "|    total_cost         | 4.7e+04  |\n",
      "|    total_reward       | 4.41e+06 |\n",
      "|    total_reward_pct   | 441      |\n",
      "|    total_trades       | 51094    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -157     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 18.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.2       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0186   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -184     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 33       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -2.25e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -44.5     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 3.25      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 24.4      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 8.26      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.3e+06  |\n",
      "|    total_cost         | 7.33e+04 |\n",
      "|    total_reward       | 3.3e+06  |\n",
      "|    total_reward_pct   | 330      |\n",
      "|    total_trades       | 52782    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00451  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -140     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 14       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -82.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -23.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.898    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 227      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 35.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -76.7     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 5.98      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.69e+06  |\n",
      "|    total_cost         | 9.31e+04  |\n",
      "|    total_reward       | 2.69e+06  |\n",
      "|    total_reward_pct   | 269       |\n",
      "|    total_trades       | 55048     |\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -46.4     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.38      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.338   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 110      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -152     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 8.66     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 111      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.44e+06 |\n",
      "|    total_cost         | 8.22e+04 |\n",
      "|    total_reward       | 3.44e+06 |\n",
      "|    total_reward_pct   | 344      |\n",
      "|    total_trades       | 53112    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00433 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -89.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -189     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 24.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -60.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -164     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 18.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 196       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 113       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 14.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.67e+06 |\n",
      "|    total_cost         | 5.74e+04 |\n",
      "|    total_reward       | 2.67e+06 |\n",
      "|    total_reward_pct   | 267      |\n",
      "|    total_trades       | 50622    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0145  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -101     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 11       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.434    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0135  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 89       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0365   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 77.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.149    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 120      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 15       |\n",
      "------------------------------------\n",
      "day: 2517, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3184849.10\n",
      "total_reward: 2184849.10\n",
      "total_cost: 75248.23\n",
      "total_trades: 50023\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.18e+06 |\n",
      "|    total_cost         | 7.52e+04 |\n",
      "|    total_reward       | 2.18e+06 |\n",
      "|    total_reward_pct   | 218      |\n",
      "|    total_trades       | 50023    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.232   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -7.85    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.318    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -26.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.111   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -102     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 157      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 20.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -78.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.57e+06 |\n",
      "|    total_cost         | 7.95e+04 |\n",
      "|    total_reward       | 1.57e+06 |\n",
      "|    total_reward_pct   | 157      |\n",
      "|    total_trades       | 51144    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0379  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 33.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -28.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.539    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 56.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.49     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 257       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 50.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.63      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00607 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 283      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 58.3     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-01-04 to  2019-04-05\n",
      "A2C Sharpe Ratio:  0.34580155763224796\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_945_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 108  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 18   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.56e+06    |\n",
      "|    total_cost           | 2.68e+05    |\n",
      "|    total_reward         | 1.56e+06    |\n",
      "|    total_reward_pct     | 156         |\n",
      "|    total_trades         | 72489       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019970756 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0154      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.26        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3e+06       |\n",
      "|    total_cost           | 2.67e+05    |\n",
      "|    total_reward         | 2e+06       |\n",
      "|    total_reward_pct     | 200         |\n",
      "|    total_trades         | 72531       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018779913 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0296     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2297895.60\n",
      "total_reward: 1297895.60\n",
      "total_cost: 258533.32\n",
      "total_trades: 71580\n",
      "Sharpe: 0.616\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.3e+06     |\n",
      "|    total_cost           | 2.59e+05    |\n",
      "|    total_reward         | 1.3e+06     |\n",
      "|    total_reward_pct     | 130         |\n",
      "|    total_trades         | 71580       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018373987 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00441    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.39e+06    |\n",
      "|    total_cost           | 2.65e+05    |\n",
      "|    total_reward         | 2.39e+06    |\n",
      "|    total_reward_pct     | 239         |\n",
      "|    total_trades         | 72064       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012348773 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0327      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.92        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008661643 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.000609   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.63e+06    |\n",
      "|    total_cost           | 2.62e+05    |\n",
      "|    total_reward         | 1.63e+06    |\n",
      "|    total_reward_pct     | 163         |\n",
      "|    total_trades         | 71843       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021245738 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0099     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.73        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.91e+06    |\n",
      "|    total_cost           | 2.54e+05    |\n",
      "|    total_reward         | 9.11e+05    |\n",
      "|    total_reward_pct     | 91.1        |\n",
      "|    total_trades         | 71130       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009646811 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0139      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.98e+06    |\n",
      "|    total_cost           | 2.44e+05    |\n",
      "|    total_reward         | 9.84e+05    |\n",
      "|    total_reward_pct     | 98.4        |\n",
      "|    total_trades         | 70155       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017626768 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0865      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.26        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2612017.68\n",
      "total_reward: 1612017.68\n",
      "total_cost: 260955.81\n",
      "total_trades: 71778\n",
      "Sharpe: 0.737\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.61e+06   |\n",
      "|    total_cost           | 2.61e+05   |\n",
      "|    total_reward         | 1.61e+06   |\n",
      "|    total_reward_pct     | 161        |\n",
      "|    total_trades         | 71778      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 118        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 173        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01985296 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.00981    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11         |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0215    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 21.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016187206 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0377     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.89        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.26e+06   |\n",
      "|    total_cost           | 2.6e+05    |\n",
      "|    total_reward         | 2.26e+06   |\n",
      "|    total_reward_pct     | 226        |\n",
      "|    total_trades         | 71931      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 119        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 205        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02137545 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.029      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.66       |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0185    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 19.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.05e+06    |\n",
      "|    total_cost           | 2.49e+05    |\n",
      "|    total_reward         | 2.05e+06    |\n",
      "|    total_reward_pct     | 205         |\n",
      "|    total_trades         | 70932       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023901291 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0175      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.79        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.62e+06    |\n",
      "|    total_cost           | 2.44e+05    |\n",
      "|    total_reward         | 1.62e+06    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 70227       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017210098 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00983     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+06    |\n",
      "|    total_cost           | 2.57e+05    |\n",
      "|    total_reward         | 1.61e+06    |\n",
      "|    total_reward_pct     | 161         |\n",
      "|    total_trades         | 71695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021558644 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0223     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.32        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2584069.23\n",
      "total_reward: 1584069.23\n",
      "total_cost: 246473.52\n",
      "total_trades: 70621\n",
      "Sharpe: 0.673\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+06    |\n",
      "|    total_cost           | 2.46e+05    |\n",
      "|    total_reward         | 1.58e+06    |\n",
      "|    total_reward_pct     | 158         |\n",
      "|    total_trades         | 70621       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016051661 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0369      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.82        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017380858 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0148      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.98e+06   |\n",
      "|    total_cost           | 2.43e+05   |\n",
      "|    total_reward         | 1.98e+06   |\n",
      "|    total_reward_pct     | 198        |\n",
      "|    total_trades         | 70801      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 120        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 304        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04073157 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | -0.0498    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.1        |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0227    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 10.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.19e+06   |\n",
      "|    total_cost           | 2.53e+05   |\n",
      "|    total_reward         | 2.19e+06   |\n",
      "|    total_reward_pct     | 219        |\n",
      "|    total_trades         | 71209      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 320        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03639131 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0366     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.72       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 21.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.4e+06     |\n",
      "|    total_cost           | 2.57e+05    |\n",
      "|    total_reward         | 2.4e+06     |\n",
      "|    total_reward_pct     | 240         |\n",
      "|    total_trades         | 71502       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 336         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024990417 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.0152     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.84e+06    |\n",
      "|    total_cost           | 2.43e+05    |\n",
      "|    total_reward         | 1.84e+06    |\n",
      "|    total_reward_pct     | 184         |\n",
      "|    total_trades         | 70568       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035250194 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.022      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036061853 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.022       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3498865.03\n",
      "total_reward: 2498865.03\n",
      "total_cost: 254506.45\n",
      "total_trades: 71518\n",
      "Sharpe: 0.917\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.5e+06     |\n",
      "|    total_cost           | 2.55e+05    |\n",
      "|    total_reward         | 2.5e+06     |\n",
      "|    total_reward_pct     | 250         |\n",
      "|    total_trades         | 71518       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036140926 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.0187     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.45        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.81e+06    |\n",
      "|    total_cost           | 2.35e+05    |\n",
      "|    total_reward         | 1.81e+06    |\n",
      "|    total_reward_pct     | 181         |\n",
      "|    total_trades         | 70379       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 401         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014671914 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.00444    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.82e+06   |\n",
      "|    total_cost           | 2.43e+05   |\n",
      "|    total_reward         | 1.82e+06   |\n",
      "|    total_reward_pct     | 182        |\n",
      "|    total_trades         | 70952      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 418        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03573694 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | -0.00812   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.1       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.00839   |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 21.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.26e+06    |\n",
      "|    total_cost           | 2.35e+05    |\n",
      "|    total_reward         | 2.26e+06    |\n",
      "|    total_reward_pct     | 226         |\n",
      "|    total_trades         | 70216       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 434         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023202814 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | -0.00779    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041884694 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | -0.0204     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.29e+06    |\n",
      "|    total_cost           | 2.36e+05    |\n",
      "|    total_reward         | 1.29e+06    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 69754       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 466         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025298981 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | -0.000135   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.93        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3275079.00\n",
      "total_reward: 2275079.00\n",
      "total_cost: 238926.78\n",
      "total_trades: 70281\n",
      "Sharpe: 0.819\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.28e+06   |\n",
      "|    total_cost           | 2.39e+05   |\n",
      "|    total_reward         | 2.28e+06   |\n",
      "|    total_reward_pct     | 228        |\n",
      "|    total_trades         | 70281      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 482        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02433094 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.0159     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.71       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 24.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.78e+06   |\n",
      "|    total_cost           | 2.42e+05   |\n",
      "|    total_reward         | 1.78e+06   |\n",
      "|    total_reward_pct     | 178        |\n",
      "|    total_trades         | 70482      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 499        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03257757 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.0045     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14         |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 31.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.17e+06    |\n",
      "|    total_cost           | 2.32e+05    |\n",
      "|    total_reward         | 2.17e+06    |\n",
      "|    total_reward_pct     | 217         |\n",
      "|    total_trades         | 69612       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 515         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019215237 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0365      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.89e+06    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 1.89e+06    |\n",
      "|    total_reward_pct     | 189         |\n",
      "|    total_trades         | 69584       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 531         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032348618 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.00592     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 547         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025991391 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.00148     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.93e+06    |\n",
      "|    total_cost           | 2.42e+05    |\n",
      "|    total_reward         | 1.93e+06    |\n",
      "|    total_reward_pct     | 193         |\n",
      "|    total_trades         | 70518       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 563         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026647411 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | -0.0292     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.78        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3507968.79\n",
      "total_reward: 2507968.79\n",
      "total_cost: 222732.76\n",
      "total_trades: 69352\n",
      "Sharpe: 0.848\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.51e+06   |\n",
      "|    total_cost           | 2.23e+05   |\n",
      "|    total_reward         | 2.51e+06   |\n",
      "|    total_reward_pct     | 251        |\n",
      "|    total_trades         | 69352      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 579        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02366419 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.0734     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 30         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.1e+06     |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 2.1e+06     |\n",
      "|    total_reward_pct     | 210         |\n",
      "|    total_trades         | 68756       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027080262 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.00341     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.24e+06    |\n",
      "|    total_cost           | 2.26e+05    |\n",
      "|    total_reward         | 2.24e+06    |\n",
      "|    total_reward_pct     | 224         |\n",
      "|    total_trades         | 69626       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 615         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022326706 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0285      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 631         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024130316 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.00312     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.31e+06    |\n",
      "|    total_cost           | 2.27e+05    |\n",
      "|    total_reward         | 2.31e+06    |\n",
      "|    total_reward_pct     | 231         |\n",
      "|    total_trades         | 69930       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 647         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022113344 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0674      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.79        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.15e+06    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 2.15e+06    |\n",
      "|    total_reward_pct     | 215         |\n",
      "|    total_trades         | 69384       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 663         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022465477 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0539      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3072451.16\n",
      "total_reward: 2072451.16\n",
      "total_cost: 222701.56\n",
      "total_trades: 69000\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.07e+06    |\n",
      "|    total_cost           | 2.23e+05    |\n",
      "|    total_reward         | 2.07e+06    |\n",
      "|    total_reward_pct     | 207         |\n",
      "|    total_trades         | 69000       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 679         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051533572 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.032       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.17e+06    |\n",
      "|    total_cost           | 2.28e+05    |\n",
      "|    total_reward         | 2.17e+06    |\n",
      "|    total_reward_pct     | 217         |\n",
      "|    total_trades         | 69067       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 695         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016595121 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0285      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 711         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025706144 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0656      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.08e+06   |\n",
      "|    total_cost           | 2.18e+05   |\n",
      "|    total_reward         | 2.08e+06   |\n",
      "|    total_reward_pct     | 208        |\n",
      "|    total_trades         | 68485      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 729        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03416756 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.00219    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.3       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00819   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 21.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.09e+06   |\n",
      "|    total_cost           | 2.13e+05   |\n",
      "|    total_reward         | 2.09e+06   |\n",
      "|    total_reward_pct     | 209        |\n",
      "|    total_trades         | 67945      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 746        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04103875 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | -0.0538    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.06       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 21.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4e+06      |\n",
      "|    total_cost           | 2.26e+05   |\n",
      "|    total_reward         | 3e+06      |\n",
      "|    total_reward_pct     | 300        |\n",
      "|    total_trades         | 69007      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 762        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03901592 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | -0.041     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.8       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 25.1       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2517, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3280460.55\n",
      "total_reward: 2280460.55\n",
      "total_cost: 200642.49\n",
      "total_trades: 66715\n",
      "Sharpe: 0.884\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.28e+06    |\n",
      "|    total_cost           | 2.01e+05    |\n",
      "|    total_reward         | 2.28e+06    |\n",
      "|    total_reward_pct     | 228         |\n",
      "|    total_trades         | 66715       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 778         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052277844 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0128      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.00518     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.62e+06   |\n",
      "|    total_cost           | 2.24e+05   |\n",
      "|    total_reward         | 2.62e+06   |\n",
      "|    total_reward_pct     | 262        |\n",
      "|    total_trades         | 67964      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 794        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04250456 |\n",
      "|    clip_fraction        | 0.446      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.0137     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | 0.00494    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 26.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 810         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024176227 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0218      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-01-04 to  2019-04-05\n",
      "PPO Sharpe Ratio:  0.2120534727993615\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_945_3\n",
      "day: 2517, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4066875.98\n",
      "total_reward: 3066875.98\n",
      "total_cost: 2238.28\n",
      "total_trades: 35483\n",
      "Sharpe: 0.963\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.48e+06 |\n",
      "|    total_cost       | 1.62e+03 |\n",
      "|    total_reward     | 2.48e+06 |\n",
      "|    total_reward_pct | 248      |\n",
      "|    total_trades     | 40382    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total timesteps  | 10072    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -143     |\n",
      "|    critic_loss      | 361      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7554     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2019-01-04 to  2019-04-05\n",
      "======Best Model Retraining from:  2009-01-01 to  2019-04-05\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_945_2\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.34e+06 |\n",
      "|    total_cost       | 1.41e+03 |\n",
      "|    total_reward     | 3.34e+06 |\n",
      "|    total_reward_pct | 334      |\n",
      "|    total_trades     | 27112    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total timesteps  | 10324    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 18.3     |\n",
      "|    critic_loss      | 23       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7743     |\n",
      "----------------------------------\n",
      "======Trading from:  2019-04-05 to  2019-07-08\n",
      "============================================\n",
      "17.68894224154312\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2019-04-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_1008_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 93       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.219   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -22.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.523    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 14.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.953    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.585    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -237     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 34.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 34.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.951    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 188      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 41.2     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.18e+06 |\n",
      "|    total_cost         | 1.69e+05 |\n",
      "|    total_reward       | 3.18e+06 |\n",
      "|    total_reward_pct   | 318      |\n",
      "|    total_trades       | 64593    |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.188    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -80.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 94.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0257  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 93.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 14.4     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 148      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 13.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.72e+06 |\n",
      "|    total_cost         | 1.12e+05 |\n",
      "|    total_reward       | 3.72e+06 |\n",
      "|    total_reward_pct   | 372      |\n",
      "|    total_trades       | 55960    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0822   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -95.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.44    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -2.34    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.327    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 117      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 14       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 171      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 28.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 5.96e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -70.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 15.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.33e+06 |\n",
      "|    total_cost         | 7.64e+04 |\n",
      "|    total_reward       | 3.33e+06 |\n",
      "|    total_reward_pct   | 333      |\n",
      "|    total_trades       | 49020    |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 52.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.00821  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 169      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 28.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 134      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 17.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0133  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -9.26    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 151      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 15.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.88e+06 |\n",
      "|    total_cost         | 1.78e+05 |\n",
      "|    total_reward       | 2.88e+06 |\n",
      "|    total_reward_pct   | 288      |\n",
      "|    total_trades       | 61617    |\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0177   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 82.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0643   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 109      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -180     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -933     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 550      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 118       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -101      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8.89      |\n",
      "-------------------------------------\n",
      "day: 2580, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5865817.60\n",
      "total_reward: 4865817.60\n",
      "total_cost: 86311.89\n",
      "total_trades: 60599\n",
      "Sharpe: 1.125\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.87e+06 |\n",
      "|    total_cost         | 8.63e+04 |\n",
      "|    total_reward       | 4.87e+06 |\n",
      "|    total_reward_pct   | 487      |\n",
      "|    total_trades       | 60599    |\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00672  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -110     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0389   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 2.46     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.411    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.163   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 157      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0947  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -135     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.036   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 280      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 48       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.71e+06 |\n",
      "|    total_cost         | 1.31e+05 |\n",
      "|    total_reward       | 6.71e+06 |\n",
      "|    total_reward_pct   | 671      |\n",
      "|    total_trades       | 60339    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -32.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.663    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 9.54e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 43.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 16.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.48     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -164     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 107      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 118       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -969      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 575       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.82e+06  |\n",
      "|    total_cost         | 9.92e+04  |\n",
      "|    total_reward       | 7.82e+06  |\n",
      "|    total_reward_pct   | 782       |\n",
      "|    total_trades       | 56236     |\n",
      "| time/                 |           |\n",
      "|    fps                | 118       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -7.25     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.32      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 161      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -12.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -6.01    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.00243  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -96.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.95     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.07e+06  |\n",
      "|    total_cost         | 8.66e+04  |\n",
      "|    total_reward       | 4.07e+06  |\n",
      "|    total_reward_pct   | 407       |\n",
      "|    total_trades       | 54873     |\n",
      "| time/                 |           |\n",
      "|    fps                | 118       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -308      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 56.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.081    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -157     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.035    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 61.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.286   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -64.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0669  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -67.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.76e+06 |\n",
      "|    total_cost         | 1.13e+05 |\n",
      "|    total_reward       | 2.76e+06 |\n",
      "|    total_reward_pct   | 276      |\n",
      "|    total_trades       | 56492    |\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0398  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -162     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 87.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -99.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.252   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -511     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 147      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 304      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 50.7     |\n",
      "------------------------------------\n",
      "day: 2580, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4393630.37\n",
      "total_reward: 3393630.37\n",
      "total_cost: 65617.50\n",
      "total_trades: 56683\n",
      "Sharpe: 0.942\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.39e+06 |\n",
      "|    total_cost         | 6.56e+04 |\n",
      "|    total_reward       | 3.39e+06 |\n",
      "|    total_reward_pct   | 339      |\n",
      "|    total_trades       | 56683    |\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.00792  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 4.28     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -312     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 60.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.025    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 13       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.759    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 129      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 31.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00808 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -97.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.06e+06 |\n",
      "|    total_cost         | 9e+04    |\n",
      "|    total_reward       | 7.06e+06 |\n",
      "|    total_reward_pct   | 706      |\n",
      "|    total_trades       | 55212    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 56.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.032    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -43.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -54      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 168      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 16.4     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-04-05 to  2019-07-08\n",
      "A2C Sharpe Ratio:  0.1261943243409066\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_1008_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 116  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 17   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.18e+06    |\n",
      "|    total_cost           | 2.9e+05     |\n",
      "|    total_reward         | 2.18e+06    |\n",
      "|    total_reward_pct     | 218         |\n",
      "|    total_trades         | 75006       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017105993 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00532    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.77        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.07e+06    |\n",
      "|    total_cost           | 2.83e+05    |\n",
      "|    total_reward         | 2.07e+06    |\n",
      "|    total_reward_pct     | 207         |\n",
      "|    total_trades         | 74728       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008261567 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00714     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.53        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "day: 2580, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3023264.73\n",
      "total_reward: 2023264.73\n",
      "total_cost: 285387.19\n",
      "total_trades: 74494\n",
      "Sharpe: 0.858\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.02e+06    |\n",
      "|    total_cost           | 2.85e+05    |\n",
      "|    total_reward         | 2.02e+06    |\n",
      "|    total_reward_pct     | 202         |\n",
      "|    total_trades         | 74494       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009441407 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0377     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.56        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007711705 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0177     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.77e+06   |\n",
      "|    total_cost           | 2.79e+05   |\n",
      "|    total_reward         | 1.77e+06   |\n",
      "|    total_reward_pct     | 177        |\n",
      "|    total_trades         | 74031      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 99         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02858217 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | -0.0139    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.56       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0251    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 14.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.15e+06    |\n",
      "|    total_cost           | 2.69e+05    |\n",
      "|    total_reward         | 2.15e+06    |\n",
      "|    total_reward_pct     | 215         |\n",
      "|    total_trades         | 72892       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015377076 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.57        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.59e+06    |\n",
      "|    total_cost           | 2.72e+05    |\n",
      "|    total_reward         | 2.59e+06    |\n",
      "|    total_reward_pct     | 259         |\n",
      "|    total_trades         | 73584       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029390732 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.00153    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.08        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.95e+06    |\n",
      "|    total_cost           | 2.65e+05    |\n",
      "|    total_reward         | 1.95e+06    |\n",
      "|    total_reward_pct     | 195         |\n",
      "|    total_trades         | 73002       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018706022 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.00372     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 124        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 165        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03207874 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | -0.00912   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.8        |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0211    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 16.5       |\n",
      "----------------------------------------\n",
      "day: 2580, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3116005.40\n",
      "total_reward: 2116005.40\n",
      "total_cost: 276321.86\n",
      "total_trades: 73868\n",
      "Sharpe: 0.897\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.12e+06    |\n",
      "|    total_cost           | 2.76e+05    |\n",
      "|    total_reward         | 2.12e+06    |\n",
      "|    total_reward_pct     | 212         |\n",
      "|    total_trades         | 73868       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024473157 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0117     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.17        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.35e+06    |\n",
      "|    total_cost           | 2.68e+05    |\n",
      "|    total_reward         | 2.35e+06    |\n",
      "|    total_reward_pct     | 235         |\n",
      "|    total_trades         | 73182       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032007527 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.00429    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.33        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4e+06       |\n",
      "|    total_cost           | 2.71e+05    |\n",
      "|    total_reward         | 3e+06       |\n",
      "|    total_reward_pct     | 300         |\n",
      "|    total_trades         | 73195       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016902901 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0206      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.09        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.92e+06    |\n",
      "|    total_cost           | 2.65e+05    |\n",
      "|    total_reward         | 1.92e+06    |\n",
      "|    total_reward_pct     | 192         |\n",
      "|    total_trades         | 72948       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033074304 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.00576     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027818104 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0101     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.29        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.46e+06    |\n",
      "|    total_cost           | 2.66e+05    |\n",
      "|    total_reward         | 2.46e+06    |\n",
      "|    total_reward_pct     | 246         |\n",
      "|    total_trades         | 72475       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026836375 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.00157    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.44        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "day: 2580, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4210239.85\n",
      "total_reward: 3210239.85\n",
      "total_cost: 263659.85\n",
      "total_trades: 72918\n",
      "Sharpe: 1.065\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.21e+06    |\n",
      "|    total_cost           | 2.64e+05    |\n",
      "|    total_reward         | 3.21e+06    |\n",
      "|    total_reward_pct     | 321         |\n",
      "|    total_trades         | 72918       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021566734 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0156      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.28        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.84e+06    |\n",
      "|    total_cost           | 2.57e+05    |\n",
      "|    total_reward         | 2.84e+06    |\n",
      "|    total_reward_pct     | 284         |\n",
      "|    total_trades         | 71914       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019017812 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | -0.0604     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.73e+06    |\n",
      "|    total_cost           | 2.61e+05    |\n",
      "|    total_reward         | 2.73e+06    |\n",
      "|    total_reward_pct     | 273         |\n",
      "|    total_trades         | 72608       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030170653 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.00108     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.24        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024917036 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0138      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.55        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.19e+06    |\n",
      "|    total_cost           | 2.37e+05    |\n",
      "|    total_reward         | 4.19e+06    |\n",
      "|    total_reward_pct     | 419         |\n",
      "|    total_trades         | 70871       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029561788 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.0591     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.35e+06    |\n",
      "|    total_cost           | 2.59e+05    |\n",
      "|    total_reward         | 2.35e+06    |\n",
      "|    total_reward_pct     | 235         |\n",
      "|    total_trades         | 72386       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029950077 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.00278     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "day: 2580, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3099427.42\n",
      "total_reward: 2099427.42\n",
      "total_cost: 259407.83\n",
      "total_trades: 72156\n",
      "Sharpe: 0.855\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.1e+06     |\n",
      "|    total_cost           | 2.59e+05    |\n",
      "|    total_reward         | 2.1e+06     |\n",
      "|    total_reward_pct     | 210         |\n",
      "|    total_trades         | 72156       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030305212 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0296      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.6e+06    |\n",
      "|    total_cost           | 2.58e+05   |\n",
      "|    total_reward         | 2.6e+06    |\n",
      "|    total_reward_pct     | 260        |\n",
      "|    total_trades         | 72221      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 391        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02421804 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0128     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.29       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.018     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 17.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023951784 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0136      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.99        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.9e+06    |\n",
      "|    total_cost           | 2.65e+05   |\n",
      "|    total_reward         | 2.9e+06    |\n",
      "|    total_reward_pct     | 290        |\n",
      "|    total_trades         | 72641      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 423        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04101654 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.0521     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.54       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 11.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.97e+06    |\n",
      "|    total_cost           | 2.58e+05    |\n",
      "|    total_reward         | 2.97e+06    |\n",
      "|    total_reward_pct     | 297         |\n",
      "|    total_trades         | 71659       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 439         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032984935 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.025       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.85e+06    |\n",
      "|    total_cost           | 2.44e+05    |\n",
      "|    total_reward         | 3.85e+06    |\n",
      "|    total_reward_pct     | 385         |\n",
      "|    total_trades         | 71172       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044230796 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0233      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.21        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "day: 2580, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5246578.62\n",
      "total_reward: 4246578.62\n",
      "total_cost: 251244.11\n",
      "total_trades: 71294\n",
      "Sharpe: 1.126\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.25e+06   |\n",
      "|    total_cost           | 2.51e+05   |\n",
      "|    total_reward         | 4.25e+06   |\n",
      "|    total_reward_pct     | 425        |\n",
      "|    total_trades         | 71294      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 471        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03792589 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | -0.0244    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.5       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 31.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 487         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020240972 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.053       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.64e+06   |\n",
      "|    total_cost           | 2.62e+05   |\n",
      "|    total_reward         | 4.64e+06   |\n",
      "|    total_reward_pct     | 464        |\n",
      "|    total_trades         | 72461      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 126        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 503        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02189583 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.035      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.83       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 23.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.07e+06    |\n",
      "|    total_cost           | 2.55e+05    |\n",
      "|    total_reward         | 2.07e+06    |\n",
      "|    total_reward_pct     | 207         |\n",
      "|    total_trades         | 71906       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 520         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038922995 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0715      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.59e+06    |\n",
      "|    total_cost           | 2.51e+05    |\n",
      "|    total_reward         | 2.59e+06    |\n",
      "|    total_reward_pct     | 259         |\n",
      "|    total_trades         | 72026       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 536         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025685502 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0123      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 552         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027358718 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.75e+06    |\n",
      "|    total_cost           | 2.62e+05    |\n",
      "|    total_reward         | 2.75e+06    |\n",
      "|    total_reward_pct     | 275         |\n",
      "|    total_trades         | 72411       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033037886 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | -0.00459    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2580, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4299370.41\n",
      "total_reward: 3299370.41\n",
      "total_cost: 247282.15\n",
      "total_trades: 71344\n",
      "Sharpe: 1.019\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.3e+06    |\n",
      "|    total_cost           | 2.47e+05   |\n",
      "|    total_reward         | 3.3e+06    |\n",
      "|    total_reward_pct     | 330        |\n",
      "|    total_trades         | 71344      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 126        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 584        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03030827 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0331     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.74       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 14.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.13e+06    |\n",
      "|    total_cost           | 2.47e+05    |\n",
      "|    total_reward         | 3.13e+06    |\n",
      "|    total_reward_pct     | 313         |\n",
      "|    total_trades         | 71840       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 600         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034147367 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0089      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.96e+06    |\n",
      "|    total_cost           | 2.59e+05    |\n",
      "|    total_reward         | 2.96e+06    |\n",
      "|    total_reward_pct     | 296         |\n",
      "|    total_trades         | 72163       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 617         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048082154 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0426      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 634         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048820302 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.59e+06    |\n",
      "|    total_cost           | 2.49e+05    |\n",
      "|    total_reward         | 2.59e+06    |\n",
      "|    total_reward_pct     | 259         |\n",
      "|    total_trades         | 71629       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 650         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028869106 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | -0.0251     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.23e+06   |\n",
      "|    total_cost           | 2.44e+05   |\n",
      "|    total_reward         | 3.23e+06   |\n",
      "|    total_reward_pct     | 323        |\n",
      "|    total_trades         | 71167      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 126        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 666        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04118087 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.0289     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.04       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0097    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 16.2       |\n",
      "----------------------------------------\n",
      "day: 2580, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3539091.85\n",
      "total_reward: 2539091.85\n",
      "total_cost: 241760.67\n",
      "total_trades: 71275\n",
      "Sharpe: 0.914\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.54e+06    |\n",
      "|    total_cost           | 2.42e+05    |\n",
      "|    total_reward         | 2.54e+06    |\n",
      "|    total_reward_pct     | 254         |\n",
      "|    total_trades         | 71275       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 682         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026266096 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0724      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.71        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.53e+06   |\n",
      "|    total_cost           | 2.32e+05   |\n",
      "|    total_reward         | 2.53e+06   |\n",
      "|    total_reward_pct     | 253        |\n",
      "|    total_trades         | 70596      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 126        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 698        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03231348 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0956     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.7        |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00264   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 17.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 126        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 714        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02503867 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.065      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.7        |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 21.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.41e+06    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 2.41e+06    |\n",
      "|    total_reward_pct     | 241         |\n",
      "|    total_trades         | 69209       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031587865 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0521      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.7         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.23e+06   |\n",
      "|    total_cost           | 2.15e+05   |\n",
      "|    total_reward         | 2.23e+06   |\n",
      "|    total_reward_pct     | 223        |\n",
      "|    total_trades         | 68385      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 748        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02584639 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.0705     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.12       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 16.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.72e+06    |\n",
      "|    total_cost           | 2.21e+05    |\n",
      "|    total_reward         | 2.72e+06    |\n",
      "|    total_reward_pct     | 272         |\n",
      "|    total_trades         | 68692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 764         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060001343 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.85        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "day: 2580, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2887541.21\n",
      "total_reward: 1887541.21\n",
      "total_cost: 231089.75\n",
      "total_trades: 69459\n",
      "Sharpe: 0.756\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.89e+06   |\n",
      "|    total_cost           | 2.31e+05   |\n",
      "|    total_reward         | 1.89e+06   |\n",
      "|    total_reward_pct     | 189        |\n",
      "|    total_trades         | 69459      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 780        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03055041 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.0439     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.7        |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 20.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 126        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 796        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04714571 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.0277     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.86       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0068    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 17.7       |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2019-04-05 to  2019-07-08\n",
      "PPO Sharpe Ratio:  0.1821381871902407\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1008_3\n",
      "day: 2580, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3047160.47\n",
      "total_reward: 2047160.47\n",
      "total_cost: 1583.77\n",
      "total_trades: 49337\n",
      "Sharpe: 0.654\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.05e+06 |\n",
      "|    total_cost       | 1.58e+03 |\n",
      "|    total_reward     | 2.05e+06 |\n",
      "|    total_reward_pct | 205      |\n",
      "|    total_trades     | 49337    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total timesteps  | 10324    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -35.2    |\n",
      "|    critic_loss      | 32.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7743     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2019-04-05 to  2019-07-08\n",
      "======Best Model Retraining from:  2009-01-01 to  2019-07-08\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_1008_2\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.23e+06 |\n",
      "|    total_cost       | 1.12e+03 |\n",
      "|    total_reward     | 2.23e+06 |\n",
      "|    total_reward_pct | 223      |\n",
      "|    total_trades     | 39647    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total timesteps  | 10576    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -8.73    |\n",
      "|    critic_loss      | 80.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7932     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Trading from:  2019-07-08 to  2019-10-04\n",
      "============================================\n",
      "16.502334183745877\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2019-07-08\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_1071_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.94    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 12.4     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.271    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00737 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -15      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.724    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.179   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -251     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 38.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.027   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -38.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00478 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 789      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 479      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.3e+06  |\n",
      "|    total_cost         | 2.28e+05 |\n",
      "|    total_reward       | 4.3e+06  |\n",
      "|    total_reward_pct   | 430      |\n",
      "|    total_trades       | 69658    |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0145   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -67.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -178     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.124   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 64       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0194   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -64.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -83.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.6e+06  |\n",
      "|    total_cost         | 1.59e+05 |\n",
      "|    total_reward       | 4.6e+06  |\n",
      "|    total_reward_pct   | 460      |\n",
      "|    total_trades       | 60856    |\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0384   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -140     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.353   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 215      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 28.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 12.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.255   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 70.2     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.6e+06  |\n",
      "|    total_cost         | 2e+05    |\n",
      "|    total_reward       | 3.6e+06  |\n",
      "|    total_reward_pct   | 360      |\n",
      "|    total_trades       | 64643    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 68.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0832   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 24.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.529    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 90.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 122      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00104  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 105      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 170      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 15.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.02e+06 |\n",
      "|    total_cost         | 1.48e+05 |\n",
      "|    total_reward       | 3.02e+06 |\n",
      "|    total_reward_pct   | 302      |\n",
      "|    total_trades       | 58840    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0387  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 65.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 21.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.398    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 184      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 35.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -67.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.328   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -250     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 35.7     |\n",
      "------------------------------------\n",
      "day: 2643, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5380245.56\n",
      "total_reward: 4380245.56\n",
      "total_cost: 112492.01\n",
      "total_trades: 53785\n",
      "Sharpe: 1.187\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.38e+06 |\n",
      "|    total_cost         | 1.12e+05 |\n",
      "|    total_reward       | 4.38e+06 |\n",
      "|    total_reward_pct   | 438      |\n",
      "|    total_trades       | 53785    |\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0431  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -81.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -54      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.38     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0492  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -137     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 27.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0369   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 317      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 64.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.25e+06 |\n",
      "|    total_cost         | 9.27e+04 |\n",
      "|    total_reward       | 3.25e+06 |\n",
      "|    total_reward_pct   | 325      |\n",
      "|    total_trades       | 53390    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.147    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 57.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 72.2     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0456  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 30.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 17.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 38.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 96.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.9e+06  |\n",
      "|    total_cost         | 6.39e+04 |\n",
      "|    total_reward       | 2.9e+06  |\n",
      "|    total_reward_pct   | 290      |\n",
      "|    total_trades       | 50184    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0133  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -5.09    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.207    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -1.07    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -13.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.139   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -136     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 13       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.133    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.235   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 179      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 18.5     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.03e+06 |\n",
      "|    total_cost         | 1.4e+05  |\n",
      "|    total_reward       | 2.03e+06 |\n",
      "|    total_reward_pct   | 203      |\n",
      "|    total_trades       | 60420    |\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0404   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -77      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0168   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -149     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -98.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.02     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 120       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 191       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -92.4     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 5.42      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -200     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 30.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.13e+06 |\n",
      "|    total_cost         | 8.94e+04 |\n",
      "|    total_reward       | 3.13e+06 |\n",
      "|    total_reward_pct   | 313      |\n",
      "|    total_trades       | 54021    |\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.121    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -45.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0171   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 107      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -92.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.23     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 120       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 211       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 155       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 14.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -268     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 46.6     |\n",
      "------------------------------------\n",
      "day: 2643, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3841275.82\n",
      "total_reward: 2841275.82\n",
      "total_cost: 35986.34\n",
      "total_trades: 49585\n",
      "Sharpe: 1.055\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.84e+06 |\n",
      "|    total_cost         | 3.6e+04  |\n",
      "|    total_reward       | 2.84e+06 |\n",
      "|    total_reward_pct   | 284      |\n",
      "|    total_trades       | 49585    |\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 40.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.166   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -150     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 20.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 67.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -278     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 43.5     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 120       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 237       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 32        |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.89      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 50.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.15e+06 |\n",
      "|    total_cost         | 3.25e+04 |\n",
      "|    total_reward       | 3.15e+06 |\n",
      "|    total_reward_pct   | 315      |\n",
      "|    total_trades       | 48804    |\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0417   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -54.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -15.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.17     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-07-08 to  2019-10-04\n",
      "A2C Sharpe Ratio:  -0.09680456342317283\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_1071_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 118  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 17   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.35e+06    |\n",
      "|    total_cost           | 2.96e+05    |\n",
      "|    total_reward         | 2.35e+06    |\n",
      "|    total_reward_pct     | 235         |\n",
      "|    total_trades         | 76314       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019922739 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.031      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.09        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.76e+06    |\n",
      "|    total_cost           | 2.88e+05    |\n",
      "|    total_reward         | 2.76e+06    |\n",
      "|    total_reward_pct     | 276         |\n",
      "|    total_trades         | 76177       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018573834 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0207      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.73        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "day: 2643, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3780961.55\n",
      "total_reward: 2780961.55\n",
      "total_cost: 287579.56\n",
      "total_trades: 75307\n",
      "Sharpe: 0.930\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.78e+06    |\n",
      "|    total_cost           | 2.88e+05    |\n",
      "|    total_reward         | 2.78e+06    |\n",
      "|    total_reward_pct     | 278         |\n",
      "|    total_trades         | 75307       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015428249 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00213    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017166683 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0129     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.4e+06    |\n",
      "|    total_cost           | 2.85e+05   |\n",
      "|    total_reward         | 2.4e+06    |\n",
      "|    total_reward_pct     | 240        |\n",
      "|    total_trades         | 75428      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 100        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02328534 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | -0.00013   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.81       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0226    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 21.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.81e+06    |\n",
      "|    total_cost           | 2.84e+05    |\n",
      "|    total_reward         | 1.81e+06    |\n",
      "|    total_reward_pct     | 181         |\n",
      "|    total_trades         | 75040       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021320423 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0278      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.92        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.58e+06   |\n",
      "|    total_cost           | 2.86e+05   |\n",
      "|    total_reward         | 2.58e+06   |\n",
      "|    total_reward_pct     | 258        |\n",
      "|    total_trades         | 75110      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 134        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01184457 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | -0.0184    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.6       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 20.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 151        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02162418 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | -0.0039    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.2       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0226    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 24         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.72e+06    |\n",
      "|    total_cost           | 2.85e+05    |\n",
      "|    total_reward         | 2.72e+06    |\n",
      "|    total_reward_pct     | 272         |\n",
      "|    total_trades         | 75315       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016406972 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0205      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "day: 2643, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3818312.93\n",
      "total_reward: 2818312.93\n",
      "total_cost: 276920.27\n",
      "total_trades: 74934\n",
      "Sharpe: 0.912\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.82e+06    |\n",
      "|    total_cost           | 2.77e+05    |\n",
      "|    total_reward         | 2.82e+06    |\n",
      "|    total_reward_pct     | 282         |\n",
      "|    total_trades         | 74934       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027255777 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0548      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.47        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.92e+06    |\n",
      "|    total_cost           | 2.74e+05    |\n",
      "|    total_reward         | 1.92e+06    |\n",
      "|    total_reward_pct     | 192         |\n",
      "|    total_trades         | 74894       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026589785 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0227      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.19e+06    |\n",
      "|    total_cost           | 2.7e+05     |\n",
      "|    total_reward         | 2.19e+06    |\n",
      "|    total_reward_pct     | 219         |\n",
      "|    total_trades         | 73960       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018622652 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.000969   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.99        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 235        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00795814 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.0351     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.81       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 19.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3e+06       |\n",
      "|    total_cost           | 2.63e+05    |\n",
      "|    total_reward         | 2e+06       |\n",
      "|    total_reward_pct     | 200         |\n",
      "|    total_trades         | 72962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019656507 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.012       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.56        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.3e+06    |\n",
      "|    total_cost           | 2.66e+05   |\n",
      "|    total_reward         | 2.3e+06    |\n",
      "|    total_reward_pct     | 230        |\n",
      "|    total_trades         | 73108      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 268        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02215967 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0512     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.28       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0197    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 15.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2643, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3329157.80\n",
      "total_reward: 2329157.80\n",
      "total_cost: 254203.08\n",
      "total_trades: 72590\n",
      "Sharpe: 0.836\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.33e+06   |\n",
      "|    total_cost           | 2.54e+05   |\n",
      "|    total_reward         | 2.33e+06   |\n",
      "|    total_reward_pct     | 233        |\n",
      "|    total_trades         | 72590      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 285        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02306538 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | -0.0152    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.3       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0198    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 21.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021855803 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0343      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.14e+06   |\n",
      "|    total_cost           | 2.6e+05    |\n",
      "|    total_reward         | 2.14e+06   |\n",
      "|    total_reward_pct     | 214        |\n",
      "|    total_trades         | 72601      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 318        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02819509 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | -0.00418   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.25       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 14.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.28e+06    |\n",
      "|    total_cost           | 2.59e+05    |\n",
      "|    total_reward         | 2.28e+06    |\n",
      "|    total_reward_pct     | 228         |\n",
      "|    total_trades         | 72892       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036508605 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0237      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.29        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.25e+06    |\n",
      "|    total_cost           | 2.49e+05    |\n",
      "|    total_reward         | 2.25e+06    |\n",
      "|    total_reward_pct     | 225         |\n",
      "|    total_trades         | 71882       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032058164 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.00559    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.4e+06     |\n",
      "|    total_cost           | 2.34e+05    |\n",
      "|    total_reward         | 2.4e+06     |\n",
      "|    total_reward_pct     | 240         |\n",
      "|    total_trades         | 70821       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036639042 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.0291     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029829338 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.0307     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "day: 2643, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3012966.76\n",
      "total_reward: 2012966.76\n",
      "total_cost: 234305.54\n",
      "total_trades: 70384\n",
      "Sharpe: 0.785\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.01e+06    |\n",
      "|    total_cost           | 2.34e+05    |\n",
      "|    total_reward         | 2.01e+06    |\n",
      "|    total_reward_pct     | 201         |\n",
      "|    total_trades         | 70384       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 401         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028547646 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.00563     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.88        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.88e+06   |\n",
      "|    total_cost           | 2.42e+05   |\n",
      "|    total_reward         | 2.88e+06   |\n",
      "|    total_reward_pct     | 288        |\n",
      "|    total_trades         | 71280      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 418        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02856336 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.000771   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.9       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 25         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.41e+06    |\n",
      "|    total_cost           | 2.57e+05    |\n",
      "|    total_reward         | 2.41e+06    |\n",
      "|    total_reward_pct     | 241         |\n",
      "|    total_trades         | 72278       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 434         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032688368 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | -0.00825    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 451        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03915336 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.00861    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.9       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.00527   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 30.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.49e+06    |\n",
      "|    total_cost           | 2.48e+05    |\n",
      "|    total_reward         | 2.49e+06    |\n",
      "|    total_reward_pct     | 249         |\n",
      "|    total_trades         | 71645       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 469         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023451013 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0102      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.67e+06    |\n",
      "|    total_cost           | 2.65e+05    |\n",
      "|    total_reward         | 3.67e+06    |\n",
      "|    total_reward_pct     | 367         |\n",
      "|    total_trades         | 72991       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 485         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032279253 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.02        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.15        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "day: 2643, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4071418.25\n",
      "total_reward: 3071418.25\n",
      "total_cost: 259693.41\n",
      "total_trades: 72683\n",
      "Sharpe: 1.001\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.07e+06    |\n",
      "|    total_cost           | 2.6e+05     |\n",
      "|    total_reward         | 3.07e+06    |\n",
      "|    total_reward_pct     | 307         |\n",
      "|    total_trades         | 72683       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 502         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030711694 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.000177    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.86e+06   |\n",
      "|    total_cost           | 2.49e+05   |\n",
      "|    total_reward         | 2.86e+06   |\n",
      "|    total_reward_pct     | 286        |\n",
      "|    total_trades         | 71819      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 518        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02761052 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | -0.0213    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.3       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0065    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 35.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 535        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02263309 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.0038     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.5       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 39         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.92e+06    |\n",
      "|    total_cost           | 2.63e+05    |\n",
      "|    total_reward         | 3.92e+06    |\n",
      "|    total_reward_pct     | 392         |\n",
      "|    total_trades         | 71970       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 551         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051338058 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0405      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.33        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.17e+06    |\n",
      "|    total_cost           | 2.36e+05    |\n",
      "|    total_reward         | 5.17e+06    |\n",
      "|    total_reward_pct     | 517         |\n",
      "|    total_trades         | 70568       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038589075 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0196      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.61e+06    |\n",
      "|    total_cost           | 2.33e+05    |\n",
      "|    total_reward         | 4.61e+06    |\n",
      "|    total_reward_pct     | 461         |\n",
      "|    total_trades         | 70500       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026450785 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | -0.0504     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.3        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 602         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013763314 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.7        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "day: 2643, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5190742.54\n",
      "total_reward: 4190742.54\n",
      "total_cost: 225304.10\n",
      "total_trades: 69883\n",
      "Sharpe: 1.066\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.19e+06    |\n",
      "|    total_cost           | 2.25e+05    |\n",
      "|    total_reward         | 4.19e+06    |\n",
      "|    total_reward_pct     | 419         |\n",
      "|    total_trades         | 69883       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 618         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026663324 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | -0.0326     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.81e+06    |\n",
      "|    total_cost           | 2.6e+05     |\n",
      "|    total_reward         | 3.81e+06    |\n",
      "|    total_reward_pct     | 381         |\n",
      "|    total_trades         | 72574       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 635         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028873693 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0141      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 58.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.17e+06   |\n",
      "|    total_cost           | 2.73e+05   |\n",
      "|    total_reward         | 3.17e+06   |\n",
      "|    total_reward_pct     | 317        |\n",
      "|    total_trades         | 73364      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 651        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03604263 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.064      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.6       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0069    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 50.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032393314 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | -0.0096     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.92e+06   |\n",
      "|    total_cost           | 2.66e+05   |\n",
      "|    total_reward         | 2.92e+06   |\n",
      "|    total_reward_pct     | 292        |\n",
      "|    total_trades         | 73395      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 683        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03847175 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | -0.00242   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.8       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.00744   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 40.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.71e+06   |\n",
      "|    total_cost           | 2.64e+05   |\n",
      "|    total_reward         | 2.71e+06   |\n",
      "|    total_reward_pct     | 271        |\n",
      "|    total_trades         | 72935      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 699        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02658765 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.00217    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.68       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 14.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2643, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4491721.68\n",
      "total_reward: 3491721.68\n",
      "total_cost: 271654.57\n",
      "total_trades: 73135\n",
      "Sharpe: 1.022\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 4.49e+06  |\n",
      "|    total_cost           | 2.72e+05  |\n",
      "|    total_reward         | 3.49e+06  |\n",
      "|    total_reward_pct     | 349       |\n",
      "|    total_trades         | 73135     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 122       |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 717       |\n",
      "|    total_timesteps      | 88064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0230428 |\n",
      "|    clip_fraction        | 0.216     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.6     |\n",
      "|    explained_variance   | 0.0409    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 17.6      |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | -0.0144   |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 27.7      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.68e+06    |\n",
      "|    total_cost           | 2.61e+05    |\n",
      "|    total_reward         | 2.68e+06    |\n",
      "|    total_reward_pct     | 268         |\n",
      "|    total_trades         | 72799       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 734         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041110575 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0218      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 49.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 751         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031905968 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0452      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.15e+06   |\n",
      "|    total_cost           | 2.68e+05   |\n",
      "|    total_reward         | 4.15e+06   |\n",
      "|    total_reward_pct     | 415        |\n",
      "|    total_trades         | 72786      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 767        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05015435 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.79       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.00648   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 21.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.66e+06   |\n",
      "|    total_cost           | 2.65e+05   |\n",
      "|    total_reward         | 3.66e+06   |\n",
      "|    total_reward_pct     | 366        |\n",
      "|    total_trades         | 72457      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 783        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04279655 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.0727     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.61       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 37.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.43e+06   |\n",
      "|    total_cost           | 2.71e+05   |\n",
      "|    total_reward         | 4.43e+06   |\n",
      "|    total_reward_pct     | 443        |\n",
      "|    total_trades         | 73177      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 799        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03640937 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.0414     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.1       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00944   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 42.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 816         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042493388 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.095       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 58.5        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-07-08 to  2019-10-04\n",
      "PPO Sharpe Ratio:  -0.17972000716632658\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1071_3\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.14e+06 |\n",
      "|    total_cost       | 1.68e+03 |\n",
      "|    total_reward     | 4.14e+06 |\n",
      "|    total_reward_pct | 414      |\n",
      "|    total_trades     | 39264    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total timesteps  | 10576    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 10.8     |\n",
      "|    critic_loss      | 64.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7932     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2019-07-08 to  2019-10-04\n",
      "======Best Model Retraining from:  2009-01-01 to  2019-10-04\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_1071_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3e+06    |\n",
      "|    total_cost       | 1.81e+03 |\n",
      "|    total_reward     | 2e+06    |\n",
      "|    total_reward_pct | 200      |\n",
      "|    total_trades     | 34627    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total timesteps  | 10828    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -25.2    |\n",
      "|    critic_loss      | 172      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8121     |\n",
      "----------------------------------\n",
      "======Trading from:  2019-10-04 to  2020-01-06\n",
      "============================================\n",
      "25.91719135748758\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2019-10-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_1134_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 90       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.606   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 3.38     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.147    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0409  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -32.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.198   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -166     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 15.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -36.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 20.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 349       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 161       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.73e+06 |\n",
      "|    total_cost         | 1.61e+05 |\n",
      "|    total_reward       | 5.73e+06 |\n",
      "|    total_reward_pct   | 573      |\n",
      "|    total_trades       | 66783    |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -47.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 74.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 129      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 11.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -195     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 97       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 115       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | 0.00595   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -1.53e+03 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.3e+03   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.66e+06 |\n",
      "|    total_cost         | 6.42e+04 |\n",
      "|    total_reward       | 6.66e+06 |\n",
      "|    total_reward_pct   | 666      |\n",
      "|    total_trades       | 54391    |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.511   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 129      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 107      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 158      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 15.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 42.4     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -119     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -107     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.76e+06 |\n",
      "|    total_cost         | 3.65e+04 |\n",
      "|    total_reward       | 5.76e+06 |\n",
      "|    total_reward_pct   | 576      |\n",
      "|    total_trades       | 54078    |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -229     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 29.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -66.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 40.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0126  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -158     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 19.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 77.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 14.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.01e+06 |\n",
      "|    total_cost         | 3.87e+04 |\n",
      "|    total_reward       | 5.01e+06 |\n",
      "|    total_reward_pct   | 501      |\n",
      "|    total_trades       | 53888    |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.216    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -115     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 52.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.04     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 116       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 27.4      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.616     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 116       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 30.9      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -108     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.012    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 204      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 68.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2706, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4764044.59\n",
      "total_reward: 3764044.59\n",
      "total_cost: 105215.61\n",
      "total_trades: 57437\n",
      "Sharpe: 1.025\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.76e+06 |\n",
      "|    total_cost         | 1.05e+05 |\n",
      "|    total_reward       | 3.76e+06 |\n",
      "|    total_reward_pct   | 376      |\n",
      "|    total_trades       | 57437    |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -20.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.538    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.14     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -236     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 28.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 234      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 32.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.726    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.397    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -542     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 159      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.04e+06 |\n",
      "|    total_cost         | 6.95e+04 |\n",
      "|    total_reward       | 2.04e+06 |\n",
      "|    total_reward_pct   | 204      |\n",
      "|    total_trades       | 56183    |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 39.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 10.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 139      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 17.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -338     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 65.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 22.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.6e+06  |\n",
      "|    total_cost         | 2.65e+04 |\n",
      "|    total_reward       | 3.6e+06  |\n",
      "|    total_reward_pct   | 360      |\n",
      "|    total_trades       | 48202    |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 49.4     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 55       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.9      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 117       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 58.2      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 4.45      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 7.86     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.251    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 125      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -556     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 169      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.79e+06 |\n",
      "|    total_cost         | 2.1e+04  |\n",
      "|    total_reward       | 2.79e+06 |\n",
      "|    total_reward_pct   | 279      |\n",
      "|    total_trades       | 44884    |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0141   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -33.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 16.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0908   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -34.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 64.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -77.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 27.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -87.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.48e+06 |\n",
      "|    total_cost         | 1.25e+04 |\n",
      "|    total_reward       | 2.48e+06 |\n",
      "|    total_reward_pct   | 248      |\n",
      "|    total_trades       | 44292    |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.167    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 59.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.000246 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0611  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -10.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.521    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -315     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 54.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -87.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -32.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "day: 2706, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3570894.68\n",
      "total_reward: 2570894.68\n",
      "total_cost: 10900.66\n",
      "total_trades: 45197\n",
      "Sharpe: 0.848\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.57e+06 |\n",
      "|    total_cost         | 1.09e+04 |\n",
      "|    total_reward       | 2.57e+06 |\n",
      "|    total_reward_pct   | 257      |\n",
      "|    total_trades       | 45197    |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 37.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.26     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -75      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -7.63    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.258    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -26.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.669    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 118      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.69e+06 |\n",
      "|    total_cost         | 1.29e+04 |\n",
      "|    total_reward       | 2.69e+06 |\n",
      "|    total_reward_pct   | 269      |\n",
      "|    total_trades       | 49126    |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 84.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.03     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-10-04 to  2020-01-06\n",
      "A2C Sharpe Ratio:  0.4738888339370242\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_1134_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 117  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 17   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.15e+06    |\n",
      "|    total_cost           | 3.13e+05    |\n",
      "|    total_reward         | 2.15e+06    |\n",
      "|    total_reward_pct     | 215         |\n",
      "|    total_trades         | 78514       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013101969 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.012      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.9         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.36e+06    |\n",
      "|    total_cost           | 3.08e+05    |\n",
      "|    total_reward         | 2.36e+06    |\n",
      "|    total_reward_pct     | 236         |\n",
      "|    total_trades         | 78569       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021738268 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0131      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.33        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "day: 2706, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3172360.89\n",
      "total_reward: 2172360.89\n",
      "total_cost: 292110.65\n",
      "total_trades: 76983\n",
      "Sharpe: 0.890\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.17e+06    |\n",
      "|    total_cost           | 2.92e+05    |\n",
      "|    total_reward         | 2.17e+06    |\n",
      "|    total_reward_pct     | 217         |\n",
      "|    total_trades         | 76983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014394192 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00711     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.26        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016560307 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0186     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.67        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.36e+06    |\n",
      "|    total_cost           | 3.08e+05    |\n",
      "|    total_reward         | 2.36e+06    |\n",
      "|    total_reward_pct     | 236         |\n",
      "|    total_trades         | 78121       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023797847 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0218     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.11        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.69        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.76e+06    |\n",
      "|    total_cost           | 3.01e+05    |\n",
      "|    total_reward         | 2.76e+06    |\n",
      "|    total_reward_pct     | 276         |\n",
      "|    total_trades         | 77605       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018402796 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0046     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.02        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.42e+06   |\n",
      "|    total_cost           | 2.86e+05   |\n",
      "|    total_reward         | 4.42e+06   |\n",
      "|    total_reward_pct     | 442        |\n",
      "|    total_trades         | 76780      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 135        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02713592 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | -0.0019    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.8       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0171    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 28.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020791892 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.00434    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 82.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.49e+06    |\n",
      "|    total_cost           | 2.77e+05    |\n",
      "|    total_reward         | 3.49e+06    |\n",
      "|    total_reward_pct     | 349         |\n",
      "|    total_trades         | 75864       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018074624 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.00424     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.29        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "day: 2706, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5276375.07\n",
      "total_reward: 4276375.07\n",
      "total_cost: 277748.71\n",
      "total_trades: 76025\n",
      "Sharpe: 1.099\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.28e+06    |\n",
      "|    total_cost           | 2.78e+05    |\n",
      "|    total_reward         | 4.28e+06    |\n",
      "|    total_reward_pct     | 428         |\n",
      "|    total_trades         | 76025       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021370849 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.000233    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.02e+06    |\n",
      "|    total_cost           | 2.9e+05     |\n",
      "|    total_reward         | 4.02e+06    |\n",
      "|    total_reward_pct     | 402         |\n",
      "|    total_trades         | 76702       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020418247 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.00629     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 62.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025874421 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.00589     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 58.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.8e+06     |\n",
      "|    total_cost           | 2.69e+05    |\n",
      "|    total_reward         | 3.8e+06     |\n",
      "|    total_reward_pct     | 380         |\n",
      "|    total_trades         | 75389       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024691919 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.00244    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.17e+06   |\n",
      "|    total_cost           | 2.97e+05   |\n",
      "|    total_reward         | 4.17e+06   |\n",
      "|    total_reward_pct     | 417        |\n",
      "|    total_trades         | 76866      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 252        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01953217 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | -0.00852   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.4       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 53.1       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.81e+06   |\n",
      "|    total_cost           | 2.92e+05   |\n",
      "|    total_reward         | 2.81e+06   |\n",
      "|    total_reward_pct     | 281        |\n",
      "|    total_trades         | 76803      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 269        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01638533 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | -0.0189    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31         |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 53.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022182068 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00397     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "day: 2706, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3620348.70\n",
      "total_reward: 2620348.70\n",
      "total_cost: 290746.21\n",
      "total_trades: 76815\n",
      "Sharpe: 0.932\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.62e+06    |\n",
      "|    total_cost           | 2.91e+05    |\n",
      "|    total_reward         | 2.62e+06    |\n",
      "|    total_reward_pct     | 262         |\n",
      "|    total_trades         | 76815       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019270228 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.000997    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.92        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.16e+06   |\n",
      "|    total_cost           | 2.84e+05   |\n",
      "|    total_reward         | 2.16e+06   |\n",
      "|    total_reward_pct     | 216        |\n",
      "|    total_trades         | 76346      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 320        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02569159 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0368     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.61       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0205    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 18.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+06    |\n",
      "|    total_cost           | 2.75e+05    |\n",
      "|    total_reward         | 1.78e+06    |\n",
      "|    total_reward_pct     | 178         |\n",
      "|    total_trades         | 75633       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027708692 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0427     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.12        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024223682 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0195     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.58        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.14e+06   |\n",
      "|    total_cost           | 2.76e+05   |\n",
      "|    total_reward         | 3.14e+06   |\n",
      "|    total_reward_pct     | 314        |\n",
      "|    total_trades         | 75772      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 371        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03012479 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | -0.0265    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.49       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 17.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.3e+06     |\n",
      "|    total_cost           | 2.87e+05    |\n",
      "|    total_reward         | 2.3e+06     |\n",
      "|    total_reward_pct     | 230         |\n",
      "|    total_trades         | 76631       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028831568 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | -0.0227     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "day: 2706, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3880607.02\n",
      "total_reward: 2880607.02\n",
      "total_cost: 276048.83\n",
      "total_trades: 75418\n",
      "Sharpe: 0.931\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.88e+06   |\n",
      "|    total_cost           | 2.76e+05   |\n",
      "|    total_reward         | 2.88e+06   |\n",
      "|    total_reward_pct     | 288        |\n",
      "|    total_trades         | 75418      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 404        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02353616 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0483     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.53       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 19.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021599386 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0158      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.17e+06    |\n",
      "|    total_cost           | 2.64e+05    |\n",
      "|    total_reward         | 3.17e+06    |\n",
      "|    total_reward_pct     | 317         |\n",
      "|    total_trades         | 74527       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 438         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029046843 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0292      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.42e+06    |\n",
      "|    total_cost           | 2.76e+05    |\n",
      "|    total_reward         | 2.42e+06    |\n",
      "|    total_reward_pct     | 242         |\n",
      "|    total_trades         | 75490       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022470789 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0949      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.77        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.28e+06    |\n",
      "|    total_cost           | 2.7e+05     |\n",
      "|    total_reward         | 3.28e+06    |\n",
      "|    total_reward_pct     | 328         |\n",
      "|    total_trades         | 75076       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 472         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023573132 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0036      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.32        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 488        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02417433 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0372     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.4       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 35.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.16e+06    |\n",
      "|    total_cost           | 2.82e+05    |\n",
      "|    total_reward         | 4.16e+06    |\n",
      "|    total_reward_pct     | 416         |\n",
      "|    total_trades         | 75971       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 505         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028335843 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.00507    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "day: 2706, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5637097.59\n",
      "total_reward: 4637097.59\n",
      "total_cost: 267283.92\n",
      "total_trades: 75230\n",
      "Sharpe: 1.115\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.64e+06   |\n",
      "|    total_cost           | 2.67e+05   |\n",
      "|    total_reward         | 4.64e+06   |\n",
      "|    total_reward_pct     | 464        |\n",
      "|    total_trades         | 75230      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 521        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03242888 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.0833     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.7       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.00712   |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 34.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.46e+06    |\n",
      "|    total_cost           | 2.63e+05    |\n",
      "|    total_reward         | 3.46e+06    |\n",
      "|    total_reward_pct     | 346         |\n",
      "|    total_trades         | 74912       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 538         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029191943 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0823      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 68.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 556         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032231085 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0907      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 50.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.93e+06    |\n",
      "|    total_cost           | 2.63e+05    |\n",
      "|    total_reward         | 3.93e+06    |\n",
      "|    total_reward_pct     | 393         |\n",
      "|    total_trades         | 74529       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 573         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025952253 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0223      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.89e+06    |\n",
      "|    total_cost           | 2.71e+05    |\n",
      "|    total_reward         | 3.89e+06    |\n",
      "|    total_reward_pct     | 389         |\n",
      "|    total_trades         | 75283       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030654907 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.35e+06    |\n",
      "|    total_cost           | 2.75e+05    |\n",
      "|    total_reward         | 4.35e+06    |\n",
      "|    total_reward_pct     | 435         |\n",
      "|    total_trades         | 75152       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 606         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016911639 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0823      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 61.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032257397 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0976      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 67.4        |\n",
      "-----------------------------------------\n",
      "day: 2706, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4908413.17\n",
      "total_reward: 3908413.17\n",
      "total_cost: 277316.71\n",
      "total_trades: 75594\n",
      "Sharpe: 1.035\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.91e+06    |\n",
      "|    total_cost           | 2.77e+05    |\n",
      "|    total_reward         | 3.91e+06    |\n",
      "|    total_reward_pct     | 391         |\n",
      "|    total_trades         | 75594       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 640         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007934084 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0647      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.75e+06   |\n",
      "|    total_cost           | 2.62e+05   |\n",
      "|    total_reward         | 4.75e+06   |\n",
      "|    total_reward_pct     | 475        |\n",
      "|    total_trades         | 74470      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 657        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03698527 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.101      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.99       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 20.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.33e+06    |\n",
      "|    total_cost           | 2.67e+05    |\n",
      "|    total_reward         | 3.33e+06    |\n",
      "|    total_reward_pct     | 333         |\n",
      "|    total_trades         | 75063       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 675         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024083165 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0104      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 75.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.47e+06    |\n",
      "|    total_cost           | 2.65e+05    |\n",
      "|    total_reward         | 3.47e+06    |\n",
      "|    total_reward_pct     | 347         |\n",
      "|    total_trades         | 74574       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 691         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027549077 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0866      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 708         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039403275 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0484      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.26e+06    |\n",
      "|    total_cost           | 2.28e+05    |\n",
      "|    total_reward         | 3.26e+06    |\n",
      "|    total_reward_pct     | 326         |\n",
      "|    total_trades         | 71998       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 724         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022270873 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0307      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.76        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "day: 2706, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4111773.11\n",
      "total_reward: 3111773.11\n",
      "total_cost: 249556.78\n",
      "total_trades: 73338\n",
      "Sharpe: 0.876\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.11e+06    |\n",
      "|    total_cost           | 2.5e+05     |\n",
      "|    total_reward         | 3.11e+06    |\n",
      "|    total_reward_pct     | 311         |\n",
      "|    total_trades         | 73338       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026115209 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0392      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.7e+06    |\n",
      "|    total_cost           | 2.29e+05   |\n",
      "|    total_reward         | 5.7e+06    |\n",
      "|    total_reward_pct     | 570        |\n",
      "|    total_trades         | 71274      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 757        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05127254 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.0915     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.5       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.00346   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 41.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 774         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023872456 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0681      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.8        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.24e+06    |\n",
      "|    total_cost           | 2.59e+05    |\n",
      "|    total_reward         | 4.24e+06    |\n",
      "|    total_reward_pct     | 424         |\n",
      "|    total_trades         | 73588       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 792         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019233331 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.9e+06     |\n",
      "|    total_cost           | 2.47e+05    |\n",
      "|    total_reward         | 5.9e+06     |\n",
      "|    total_reward_pct     | 590         |\n",
      "|    total_trades         | 72451       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 809         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035649635 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.81e+06    |\n",
      "|    total_cost           | 2.37e+05    |\n",
      "|    total_reward         | 4.81e+06    |\n",
      "|    total_reward_pct     | 481         |\n",
      "|    total_trades         | 71559       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 825         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027774788 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0957      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.4        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-10-04 to  2020-01-06\n",
      "PPO Sharpe Ratio:  0.22429974469348996\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1134_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.19e+06 |\n",
      "|    total_cost       | 1.85e+03 |\n",
      "|    total_reward     | 2.19e+06 |\n",
      "|    total_reward_pct | 219      |\n",
      "|    total_trades     | 43399    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total timesteps  | 10828    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 15.5     |\n",
      "|    critic_loss      | 13.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8121     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2019-10-04 to  2020-01-06\n",
      "======Best Model Retraining from:  2009-01-01 to  2020-01-06\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_1134_2\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.58e+06 |\n",
      "|    total_cost       | 2.37e+03 |\n",
      "|    total_reward     | 4.58e+06 |\n",
      "|    total_reward_pct | 458      |\n",
      "|    total_trades     | 45350    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total timesteps  | 11080    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -17.3    |\n",
      "|    critic_loss      | 81.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8310     |\n",
      "----------------------------------\n",
      "======Trading from:  2020-01-06 to  2020-04-06\n",
      "============================================\n",
      "14.976886630566314\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2020-01-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_1197_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.25    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -31.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.298   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -24.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -291     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 60.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0371  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 6.73     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0261   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 801      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 410      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.02e+06 |\n",
      "|    total_cost         | 2.34e+05 |\n",
      "|    total_reward       | 5.02e+06 |\n",
      "|    total_reward_pct   | 502      |\n",
      "|    total_trades       | 72220    |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.159   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -8.42    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0239   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -79.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 97.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -19.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.7      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -1.9      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 4.49      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 53       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.31e+06 |\n",
      "|    total_cost         | 1.05e+05 |\n",
      "|    total_reward       | 3.31e+06 |\n",
      "|    total_reward_pct   | 331      |\n",
      "|    total_trades       | 62744    |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 28.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.28    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 88.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.00167  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -270     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 67.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0303   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -86.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 189      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 30       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.52e+06 |\n",
      "|    total_cost         | 6.35e+04 |\n",
      "|    total_reward       | 4.52e+06 |\n",
      "|    total_reward_pct   | 452      |\n",
      "|    total_trades       | 55302    |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.308    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -3.97    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.743    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.34    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -213     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 25.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.153    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 152      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0184  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -1.33    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -53.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 204      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 33.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.21e+06 |\n",
      "|    total_cost         | 1.54e+05 |\n",
      "|    total_reward       | 2.21e+06 |\n",
      "|    total_reward_pct   | 221      |\n",
      "|    total_trades       | 65655    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0205   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -123     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 61.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.13      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.089    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 110      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.47     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.102    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 67.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.152    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 203      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 24       |\n",
      "------------------------------------\n",
      "day: 2769, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3500206.82\n",
      "total_reward: 2500206.82\n",
      "total_cost: 162293.17\n",
      "total_trades: 64498\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.5e+06  |\n",
      "|    total_cost         | 1.62e+05 |\n",
      "|    total_reward       | 2.5e+06  |\n",
      "|    total_reward_pct   | 250      |\n",
      "|    total_trades       | 64498    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 7.04     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.342    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -99.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 11.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 150      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 15.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.695   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.826    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 142      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.22e+06 |\n",
      "|    total_cost         | 8.91e+04 |\n",
      "|    total_reward       | 2.22e+06 |\n",
      "|    total_reward_pct   | 222      |\n",
      "|    total_trades       | 57199    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -184     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 23.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0167   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -110     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 43.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -160     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 19.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0318  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 138      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 18.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.72e+06 |\n",
      "|    total_cost         | 7.87e+04 |\n",
      "|    total_reward       | 4.72e+06 |\n",
      "|    total_reward_pct   | 472      |\n",
      "|    total_trades       | 56259    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.316    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 63.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.8      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 19.2      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.52      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -132     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 15.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -45.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -205     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 76.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.85e+06 |\n",
      "|    total_cost         | 7.23e+04 |\n",
      "|    total_reward       | 3.85e+06 |\n",
      "|    total_reward_pct   | 385      |\n",
      "|    total_trades       | 57026    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0224   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -82.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.108    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 265      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 38.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0241  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -91.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0374   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 120      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 20.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.73     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.47e+06  |\n",
      "|    total_cost         | 1.14e+05  |\n",
      "|    total_reward       | 2.47e+06  |\n",
      "|    total_reward_pct   | 247       |\n",
      "|    total_trades       | 62455     |\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 218       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 6.38      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.26      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 41.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 39.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0411   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -23.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 81.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.63     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 242       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 266       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 56.1      |\n",
      "-------------------------------------\n",
      "day: 2769, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4208103.19\n",
      "total_reward: 3208103.19\n",
      "total_cost: 59621.09\n",
      "total_trades: 57489\n",
      "Sharpe: 0.881\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.21e+06  |\n",
      "|    total_cost         | 5.96e+04  |\n",
      "|    total_reward       | 3.21e+06  |\n",
      "|    total_reward_pct   | 321       |\n",
      "|    total_trades       | 57489     |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 250       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -0.000102 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 11.7      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.56      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -23.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.401    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 267       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 44.2      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.98      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0857  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 380      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 97.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 277       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 142       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 32.9      |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2020-01-06 to  2020-04-06\n",
      "A2C Sharpe Ratio:  -0.3296586176371663\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_1197_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 83   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 24   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.88e+06    |\n",
      "|    total_cost           | 3.21e+05    |\n",
      "|    total_reward         | 1.88e+06    |\n",
      "|    total_reward_pct     | 188         |\n",
      "|    total_trades         | 80123       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012913546 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0149     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.94        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.39        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4e+06       |\n",
      "|    total_cost           | 3.13e+05    |\n",
      "|    total_reward         | 3e+06       |\n",
      "|    total_reward_pct     | 300         |\n",
      "|    total_trades         | 79296       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017084533 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00899    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.75        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 97         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 83         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01769194 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.0125    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.3       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 31.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.87e+06    |\n",
      "|    total_cost           | 3.05e+05    |\n",
      "|    total_reward         | 2.87e+06    |\n",
      "|    total_reward_pct     | 287         |\n",
      "|    total_trades         | 78943       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017609783 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0163     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2769, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2914783.06\n",
      "total_reward: 1914783.06\n",
      "total_cost: 305651.59\n",
      "total_trades: 78307\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.91e+06    |\n",
      "|    total_cost           | 3.06e+05    |\n",
      "|    total_reward         | 1.91e+06    |\n",
      "|    total_reward_pct     | 191         |\n",
      "|    total_trades         | 78307       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014661385 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.043      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.88        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.48e+06    |\n",
      "|    total_cost           | 3.1e+05     |\n",
      "|    total_reward         | 2.48e+06    |\n",
      "|    total_reward_pct     | 248         |\n",
      "|    total_trades         | 79013       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018297506 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0052      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.02        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 95         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 171        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01781161 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | 0.0104     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.2       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0237    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 32.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.85e+06    |\n",
      "|    total_cost           | 2.99e+05    |\n",
      "|    total_reward         | 2.85e+06    |\n",
      "|    total_reward_pct     | 285         |\n",
      "|    total_trades         | 78233       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008215891 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.023       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.38e+06    |\n",
      "|    total_cost           | 3.05e+05    |\n",
      "|    total_reward         | 3.38e+06    |\n",
      "|    total_reward_pct     | 338         |\n",
      "|    total_trades         | 78329       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030495077 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.00208    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.1e+06     |\n",
      "|    total_cost           | 2.87e+05    |\n",
      "|    total_reward         | 2.1e+06     |\n",
      "|    total_reward_pct     | 210         |\n",
      "|    total_trades         | 77417       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025575582 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0194     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020671671 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0342     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.51        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "day: 2769, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3887793.94\n",
      "total_reward: 2887793.94\n",
      "total_cost: 290348.58\n",
      "total_trades: 77829\n",
      "Sharpe: 0.834\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.89e+06    |\n",
      "|    total_cost           | 2.9e+05     |\n",
      "|    total_reward         | 2.89e+06    |\n",
      "|    total_reward_pct     | 289         |\n",
      "|    total_trades         | 77829       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025510918 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.00148     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.13e+06    |\n",
      "|    total_cost           | 2.99e+05    |\n",
      "|    total_reward         | 3.13e+06    |\n",
      "|    total_reward_pct     | 313         |\n",
      "|    total_trades         | 78017       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030286599 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0161      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.99e+06   |\n",
      "|    total_cost           | 2.91e+05   |\n",
      "|    total_reward         | 1.99e+06   |\n",
      "|    total_reward_pct     | 199        |\n",
      "|    total_trades         | 77605      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 295        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03656306 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.065      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.3       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.021     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 31         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028913224 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0259      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.36e+06    |\n",
      "|    total_cost           | 2.96e+05    |\n",
      "|    total_reward         | 2.36e+06    |\n",
      "|    total_reward_pct     | 236         |\n",
      "|    total_trades         | 77601       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025651539 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0221     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.56e+06    |\n",
      "|    total_cost           | 2.84e+05    |\n",
      "|    total_reward         | 1.56e+06    |\n",
      "|    total_reward_pct     | 156         |\n",
      "|    total_trades         | 76570       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019086061 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0262      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "day: 2769, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2900687.95\n",
      "total_reward: 1900687.95\n",
      "total_cost: 290404.22\n",
      "total_trades: 76546\n",
      "Sharpe: 0.616\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.9e+06     |\n",
      "|    total_cost           | 2.9e+05     |\n",
      "|    total_reward         | 1.9e+06     |\n",
      "|    total_reward_pct     | 190         |\n",
      "|    total_trades         | 76546       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019888477 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0139      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019172378 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.00378     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.58        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.86e+06  |\n",
      "|    total_cost           | 2.99e+05  |\n",
      "|    total_reward         | 1.86e+06  |\n",
      "|    total_reward_pct     | 186       |\n",
      "|    total_trades         | 77545     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 107       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 400       |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0329438 |\n",
      "|    clip_fraction        | 0.259     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.3     |\n",
      "|    explained_variance   | 0.0136    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 6.72      |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -0.0103   |\n",
      "|    std                  | 1.03      |\n",
      "|    value_loss           | 14.7      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.52e+06  |\n",
      "|    total_cost           | 2.9e+05   |\n",
      "|    total_reward         | 1.52e+06  |\n",
      "|    total_reward_pct     | 152       |\n",
      "|    total_trades         | 77012     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 107       |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 417       |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0390212 |\n",
      "|    clip_fraction        | 0.283     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.3     |\n",
      "|    explained_variance   | -0.0226   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 9.46      |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -0.0172   |\n",
      "|    std                  | 1.03      |\n",
      "|    value_loss           | 21.8      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.67e+06    |\n",
      "|    total_cost           | 2.85e+05    |\n",
      "|    total_reward         | 1.67e+06    |\n",
      "|    total_reward_pct     | 167         |\n",
      "|    total_trades         | 76724       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 435         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030422635 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0038     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 452         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027675286 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.00596    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.74        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.11e+06    |\n",
      "|    total_cost           | 2.85e+05    |\n",
      "|    total_reward         | 2.11e+06    |\n",
      "|    total_reward_pct     | 211         |\n",
      "|    total_trades         | 76438       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 486         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034712493 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | -0.0113     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "day: 2769, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4405887.58\n",
      "total_reward: 3405887.58\n",
      "total_cost: 292269.56\n",
      "total_trades: 77182\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.41e+06    |\n",
      "|    total_cost           | 2.92e+05    |\n",
      "|    total_reward         | 3.41e+06    |\n",
      "|    total_reward_pct     | 341         |\n",
      "|    total_trades         | 77182       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046270844 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0275      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.53        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 540         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030836085 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.052       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.23e+06    |\n",
      "|    total_cost           | 2.98e+05    |\n",
      "|    total_reward         | 2.23e+06    |\n",
      "|    total_reward_pct     | 223         |\n",
      "|    total_trades         | 76947       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 561         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026698021 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0353      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.43e+06   |\n",
      "|    total_cost           | 2.98e+05   |\n",
      "|    total_reward         | 2.43e+06   |\n",
      "|    total_reward_pct     | 243        |\n",
      "|    total_trades         | 76751      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 581        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04751148 |\n",
      "|    clip_fraction        | 0.368      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0083     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.08       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.00947   |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 14.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.24e+06    |\n",
      "|    total_cost           | 3.03e+05    |\n",
      "|    total_reward         | 3.24e+06    |\n",
      "|    total_reward_pct     | 324         |\n",
      "|    total_trades         | 77089       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032126978 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.021       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.3         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017464083 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0276      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.38e+06   |\n",
      "|    total_cost           | 2.97e+05   |\n",
      "|    total_reward         | 3.38e+06   |\n",
      "|    total_reward_pct     | 338        |\n",
      "|    total_trades         | 76110      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 633        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03239011 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.0526     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.7       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.00414   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 28.7       |\n",
      "----------------------------------------\n",
      "day: 2769, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3822068.13\n",
      "total_reward: 2822068.13\n",
      "total_cost: 292825.65\n",
      "total_trades: 76229\n",
      "Sharpe: 0.877\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.82e+06    |\n",
      "|    total_cost           | 2.93e+05    |\n",
      "|    total_reward         | 2.82e+06    |\n",
      "|    total_reward_pct     | 282         |\n",
      "|    total_trades         | 76229       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 650         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028630516 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.049       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.56e+06    |\n",
      "|    total_cost           | 2.94e+05    |\n",
      "|    total_reward         | 3.56e+06    |\n",
      "|    total_reward_pct     | 356         |\n",
      "|    total_trades         | 75957       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039165184 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0469      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 685         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020873848 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.00537     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 4.96e+06  |\n",
      "|    total_cost           | 3.04e+05  |\n",
      "|    total_reward         | 3.96e+06  |\n",
      "|    total_reward_pct     | 396       |\n",
      "|    total_trades         | 76663     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 104       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 704       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0362905 |\n",
      "|    clip_fraction        | 0.26      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44       |\n",
      "|    explained_variance   | 0.0886    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 11.2      |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -0.0152   |\n",
      "|    std                  | 1.05      |\n",
      "|    value_loss           | 28.7      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.62e+06   |\n",
      "|    total_cost           | 2.92e+05   |\n",
      "|    total_reward         | 2.62e+06   |\n",
      "|    total_reward_pct     | 262        |\n",
      "|    total_trades         | 76587      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 721        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03946323 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | -0.00197   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19         |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 33.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.58e+06    |\n",
      "|    total_cost           | 2.87e+05    |\n",
      "|    total_reward         | 2.58e+06    |\n",
      "|    total_reward_pct     | 258         |\n",
      "|    total_trades         | 76334       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 738         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054966487 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.00233     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 756        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03902085 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.093      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15         |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0044    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 25.4       |\n",
      "----------------------------------------\n",
      "day: 2769, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2789719.18\n",
      "total_reward: 1789719.18\n",
      "total_cost: 289088.84\n",
      "total_trades: 76076\n",
      "Sharpe: 0.693\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.79e+06    |\n",
      "|    total_cost           | 2.89e+05    |\n",
      "|    total_reward         | 1.79e+06    |\n",
      "|    total_reward_pct     | 179         |\n",
      "|    total_trades         | 76076       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 774         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036784068 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.00195     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.09        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.37e+06    |\n",
      "|    total_cost           | 2.73e+05    |\n",
      "|    total_reward         | 5.37e+06    |\n",
      "|    total_reward_pct     | 537         |\n",
      "|    total_trades         | 74991       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 791         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029832166 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0552      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.97        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.18e+06    |\n",
      "|    total_cost           | 2.79e+05    |\n",
      "|    total_reward         | 5.18e+06    |\n",
      "|    total_reward_pct     | 518         |\n",
      "|    total_trades         | 75520       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 809         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031180022 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0889      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0085     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 65.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 828        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03425876 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.0326     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.9       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00655   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 59.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.08e+06    |\n",
      "|    total_cost           | 2.89e+05    |\n",
      "|    total_reward         | 2.08e+06    |\n",
      "|    total_reward_pct     | 208         |\n",
      "|    total_trades         | 75669       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 845         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021262143 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0882      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.55        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.71e+06    |\n",
      "|    total_cost           | 2.92e+05    |\n",
      "|    total_reward         | 3.71e+06    |\n",
      "|    total_reward_pct     | 371         |\n",
      "|    total_trades         | 75936       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 862         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023602465 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0705      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "day: 2769, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3076498.64\n",
      "total_reward: 2076498.64\n",
      "total_cost: 288083.60\n",
      "total_trades: 75923\n",
      "Sharpe: 0.752\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.08e+06   |\n",
      "|    total_cost           | 2.88e+05   |\n",
      "|    total_reward         | 2.08e+06   |\n",
      "|    total_reward_pct     | 208        |\n",
      "|    total_trades         | 75923      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 880        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03802585 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.0403     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.1       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 39.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 897         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045412578 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0963      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.9e+06     |\n",
      "|    total_cost           | 2.89e+05    |\n",
      "|    total_reward         | 2.9e+06     |\n",
      "|    total_reward_pct     | 290         |\n",
      "|    total_trades         | 76219       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 914         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028060306 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0727      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.35        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.09e+06   |\n",
      "|    total_cost           | 2.85e+05   |\n",
      "|    total_reward         | 3.09e+06   |\n",
      "|    total_reward_pct     | 309        |\n",
      "|    total_trades         | 75801      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 932        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03859178 |\n",
      "|    clip_fraction        | 0.351      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.055      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.8       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 25.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-01-06 to  2020-04-06\n",
      "PPO Sharpe Ratio:  -0.48320775789262393\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1197_2\n",
      "day: 2769, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3530789.29\n",
      "total_reward: 2530789.29\n",
      "total_cost: 1440.16\n",
      "total_trades: 44764\n",
      "Sharpe: 0.706\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.58e+06 |\n",
      "|    total_cost       | 2.02e+03 |\n",
      "|    total_reward     | 2.58e+06 |\n",
      "|    total_reward_pct | 258      |\n",
      "|    total_trades     | 39524    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total timesteps  | 11080    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -43.2    |\n",
      "|    critic_loss      | 159      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8310     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-01-06 to  2020-04-06\n",
      "======Best Model Retraining from:  2009-01-01 to  2020-04-06\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_1197_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.782   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -13.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.471    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 95       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -74.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -183     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 19.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0507   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 17.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0343   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 415      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 150      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.67e+06 |\n",
      "|    total_cost         | 1.52e+05 |\n",
      "|    total_reward       | 3.67e+06 |\n",
      "|    total_reward_pct   | 367      |\n",
      "|    total_trades       | 66302    |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0242  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 94.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -238     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 38.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -242      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 31.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -156     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 18.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0197  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 206      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 35.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -407     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 118      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.57e+06 |\n",
      "|    total_cost         | 1.01e+05 |\n",
      "|    total_reward       | 3.57e+06 |\n",
      "|    total_reward_pct   | 357      |\n",
      "|    total_trades       | 60902    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00044  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 35.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 44.9      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.65      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 21.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -26.2    |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 1.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 325      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 78       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.87e+06 |\n",
      "|    total_cost         | 1.16e+05 |\n",
      "|    total_reward       | 2.87e+06 |\n",
      "|    total_reward_pct   | 287      |\n",
      "|    total_trades       | 57107    |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.011   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 351      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 220      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 13.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.497    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0261  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -9.24    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.46     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -152      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 18.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -49      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 738      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 443      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.01e+06  |\n",
      "|    total_cost         | 8.09e+04  |\n",
      "|    total_reward       | 4.01e+06  |\n",
      "|    total_reward_pct   | 401       |\n",
      "|    total_trades       | 54502     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 4.91      |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 1.19      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0464   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -296     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 52.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.144   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -168     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 19.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -94      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.41     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 12.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.887    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -289     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 69.3     |\n",
      "------------------------------------\n",
      "day: 2832, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5954327.10\n",
      "total_reward: 4954327.10\n",
      "total_cost: 51120.70\n",
      "total_trades: 52608\n",
      "Sharpe: 0.921\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.95e+06 |\n",
      "|    total_cost         | 5.11e+04 |\n",
      "|    total_reward       | 4.95e+06 |\n",
      "|    total_reward_pct   | 495      |\n",
      "|    total_trades       | 52608    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -96.8    |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 5.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 1.69     |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 1.56     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -90       |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 21.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 22.7      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 8.29      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -99      |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 26.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.06e+06 |\n",
      "|    total_cost         | 2.91e+04 |\n",
      "|    total_reward       | 3.06e+06 |\n",
      "|    total_reward_pct   | 306      |\n",
      "|    total_trades       | 49242    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -889     |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 495      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 6.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 74.2     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 3.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -296     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 59.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 300      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 56.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 281      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 58.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.9e+06  |\n",
      "|    total_cost         | 3.83e+04 |\n",
      "|    total_reward       | 2.9e+06  |\n",
      "|    total_reward_pct   | 290      |\n",
      "|    total_trades       | 48692    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.114   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -19.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.735    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -323     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 74.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -290     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 47.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -63.9     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.5       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 14.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.36     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | 0.000601  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -1.03e+03 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 589       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.71e+06 |\n",
      "|    total_cost         | 5.88e+04 |\n",
      "|    total_reward       | 2.71e+06 |\n",
      "|    total_reward_pct   | 271      |\n",
      "|    total_trades       | 54384    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0194   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -39.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -36.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 84       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 370      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 85.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -56.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 36.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.52e+06 |\n",
      "|    total_cost         | 2.95e+04 |\n",
      "|    total_reward       | 3.52e+06 |\n",
      "|    total_reward_pct   | 352      |\n",
      "|    total_trades       | 52446    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -562     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 450      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 241       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 31.2      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.754     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -12.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.736    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0129   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -138     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 13.8     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -1.47    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 135      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0551   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -300     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 62.9     |\n",
      "------------------------------------\n",
      "day: 2832, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2809423.81\n",
      "total_reward: 1809423.81\n",
      "total_cost: 133808.41\n",
      "total_trades: 60832\n",
      "Sharpe: 0.584\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.81e+06 |\n",
      "|    total_cost         | 1.34e+05 |\n",
      "|    total_reward       | 1.81e+06 |\n",
      "|    total_reward_pct   | 181      |\n",
      "|    total_trades       | 60832    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 4.83e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -29.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.522    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.00598 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 37.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -142     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 19       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -18.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.67     |\n",
      "------------------------------------\n",
      "======Trading from:  2020-04-06 to  2020-07-07\n",
      "============================================\n",
      "169.48991065644063\n",
      "turbulence_threshold:  52.314193250419386\n",
      "======Model training from:  2009-01-01 to  2020-04-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_1260_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 87       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.0586   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -25.1    |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 0.597    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.35     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -67.6    |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 3.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.00915  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -127     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 8.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 78.9     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 4.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.127   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 230      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 45.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.53e+06 |\n",
      "|    total_cost         | 1.74e+05 |\n",
      "|    total_reward       | 2.53e+06 |\n",
      "|    total_reward_pct   | 253      |\n",
      "|    total_trades       | 69181    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 92.4     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 6.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0165   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -212     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 25       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -72.3     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 4.43      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -114     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 249      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 47       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -299     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 72.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.22e+06 |\n",
      "|    total_cost         | 7.74e+04 |\n",
      "|    total_reward       | 5.22e+06 |\n",
      "|    total_reward_pct   | 522      |\n",
      "|    total_trades       | 58825    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 39.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.116    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.184   |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 3.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -31.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -240     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 47.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 247      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 39.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.77e+06  |\n",
      "|    total_cost         | 1.03e+05  |\n",
      "|    total_reward       | 2.77e+06  |\n",
      "|    total_reward_pct   | 277       |\n",
      "|    total_trades       | 60782     |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 329       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 184       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 16.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.667    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -27.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -320     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 77.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.33     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -40.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.72     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00191  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 1.31e+03 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.19e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.85e+06 |\n",
      "|    total_cost         | 1.58e+05 |\n",
      "|    total_reward       | 5.85e+06 |\n",
      "|    total_reward_pct   | 585      |\n",
      "|    total_trades       | 64776    |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0025  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 49.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -409     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 99.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -133     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 15.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -79.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 234      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 33.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -544     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 216      |\n",
      "------------------------------------\n",
      "day: 2832, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5713566.31\n",
      "total_reward: 4713566.31\n",
      "total_cost: 77839.59\n",
      "total_trades: 57792\n",
      "Sharpe: 0.840\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.71e+06 |\n",
      "|    total_cost         | 7.78e+04 |\n",
      "|    total_reward       | 4.71e+06 |\n",
      "|    total_reward_pct   | 471      |\n",
      "|    total_trades       | 57792    |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -119     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0548   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -25.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 134      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 19.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 35.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -269     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 95.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.81e+06  |\n",
      "|    total_cost         | 3.25e+04  |\n",
      "|    total_reward       | 3.81e+06  |\n",
      "|    total_reward_pct   | 381       |\n",
      "|    total_trades       | 53422     |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -1.83e+03 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.2e+03   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 69.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.28     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 160       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 54        |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.01      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 166       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -264      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 72        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 244      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 35.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 2.43e+03 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.93e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.38e+06 |\n",
      "|    total_cost         | 2.88e+04 |\n",
      "|    total_reward       | 3.38e+06 |\n",
      "|    total_reward_pct   | 338      |\n",
      "|    total_trades       | 52171    |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 121      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -203     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 35.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.184    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -37.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0671   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 24.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 32.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.34     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -0.0114   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -1.29e+03 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 869       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.27e+06 |\n",
      "|    total_cost         | 6.98e+04 |\n",
      "|    total_reward       | 3.27e+06 |\n",
      "|    total_reward_pct   | 327      |\n",
      "|    total_trades       | 55844    |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -125     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 81.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.87      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.083   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 258      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 46.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 56.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.98     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 223       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -8.52e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -259      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 69.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.29e+06  |\n",
      "|    total_cost         | 4.57e+04  |\n",
      "|    total_reward       | 2.29e+06  |\n",
      "|    total_reward_pct   | 229       |\n",
      "|    total_trades       | 55404     |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -0.0013   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -1.38e+03 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.26e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 72.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 13.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -42.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 147      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 13.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 11.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 429      |\n",
      "------------------------------------\n",
      "day: 2832, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3803569.51\n",
      "total_reward: 2803569.51\n",
      "total_cost: 35514.77\n",
      "total_trades: 51257\n",
      "Sharpe: 0.650\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.8e+06  |\n",
      "|    total_cost         | 3.55e+04 |\n",
      "|    total_reward       | 2.8e+06  |\n",
      "|    total_reward_pct   | 280      |\n",
      "|    total_trades       | 51257    |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 51.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -40      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -69.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -39.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.31     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-04-06 to  2020-07-07\n",
      "A2C Sharpe Ratio:  -0.2581379212705443\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_1260_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 102  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 20   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.56e+06     |\n",
      "|    total_cost           | 3.39e+05     |\n",
      "|    total_reward         | 1.56e+06     |\n",
      "|    total_reward_pct     | 156          |\n",
      "|    total_trades         | 82313        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153777115 |\n",
      "|    clip_fraction        | 0.224        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | 0.00371      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.66         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0281      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 11.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.38e+06    |\n",
      "|    total_cost           | 3.2e+05     |\n",
      "|    total_reward         | 1.38e+06    |\n",
      "|    total_reward_pct     | 138         |\n",
      "|    total_trades         | 81290       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012035135 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0254     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 72         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01848105 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | -0.015     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.6       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0178    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 37.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.3e+06     |\n",
      "|    total_cost           | 3.12e+05    |\n",
      "|    total_reward         | 2.3e+06     |\n",
      "|    total_reward_pct     | 230         |\n",
      "|    total_trades         | 80475       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016917855 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00264     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.38        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "day: 2832, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3503411.89\n",
      "total_reward: 2503411.89\n",
      "total_cost: 319641.20\n",
      "total_trades: 81137\n",
      "Sharpe: 0.798\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.5e+06     |\n",
      "|    total_cost           | 3.2e+05     |\n",
      "|    total_reward         | 2.5e+06     |\n",
      "|    total_reward_pct     | 250         |\n",
      "|    total_trades         | 81137       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014116287 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0204     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.56e+06    |\n",
      "|    total_cost           | 3.16e+05    |\n",
      "|    total_reward         | 1.56e+06    |\n",
      "|    total_reward_pct     | 156         |\n",
      "|    total_trades         | 80661       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021657284 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00699    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024369402 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.00423     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.48e+06   |\n",
      "|    total_cost           | 3.09e+05   |\n",
      "|    total_reward         | 2.48e+06   |\n",
      "|    total_reward_pct     | 248        |\n",
      "|    total_trades         | 79693      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 161        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03288115 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | -0.0584    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.29       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.022     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 13.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.83e+06    |\n",
      "|    total_cost           | 2.97e+05    |\n",
      "|    total_reward         | 1.83e+06    |\n",
      "|    total_reward_pct     | 183         |\n",
      "|    total_trades         | 78838       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020292455 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.00516     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.13        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 196        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02084276 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | -0.00565   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.6       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 35.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.78e+06   |\n",
      "|    total_cost           | 3.04e+05   |\n",
      "|    total_reward         | 1.78e+06   |\n",
      "|    total_reward_pct     | 178        |\n",
      "|    total_trades         | 79466      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 214        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02457497 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | -0.00389   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.45       |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 15.2       |\n",
      "----------------------------------------\n",
      "day: 2832, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2854675.41\n",
      "total_reward: 1854675.41\n",
      "total_cost: 308379.25\n",
      "total_trades: 79257\n",
      "Sharpe: 0.670\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.85e+06    |\n",
      "|    total_cost           | 3.08e+05    |\n",
      "|    total_reward         | 1.85e+06    |\n",
      "|    total_reward_pct     | 185         |\n",
      "|    total_trades         | 79257       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023858935 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0174     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.51        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.48e+06    |\n",
      "|    total_cost           | 2.89e+05    |\n",
      "|    total_reward         | 1.48e+06    |\n",
      "|    total_reward_pct     | 148         |\n",
      "|    total_trades         | 77958       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020275587 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0199      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 39.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018104693 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0609      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.02e+06    |\n",
      "|    total_cost           | 2.94e+05    |\n",
      "|    total_reward         | 2.02e+06    |\n",
      "|    total_reward_pct     | 202         |\n",
      "|    total_trades         | 78239       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022344263 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0125     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.39        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.96e+06    |\n",
      "|    total_cost           | 3.11e+05    |\n",
      "|    total_reward         | 2.96e+06    |\n",
      "|    total_reward_pct     | 296         |\n",
      "|    total_trades         | 79124       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 303         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012976399 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.00214    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.34e+06   |\n",
      "|    total_cost           | 3.06e+05   |\n",
      "|    total_reward         | 2.34e+06   |\n",
      "|    total_reward_pct     | 234        |\n",
      "|    total_trades         | 79439      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 320        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03795524 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | -0.00883   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 43.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041596137 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.00102     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "day: 2832, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2864945.86\n",
      "total_reward: 1864945.86\n",
      "total_cost: 316268.98\n",
      "total_trades: 79678\n",
      "Sharpe: 0.663\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.86e+06    |\n",
      "|    total_cost           | 3.16e+05    |\n",
      "|    total_reward         | 1.86e+06    |\n",
      "|    total_reward_pct     | 186         |\n",
      "|    total_trades         | 79678       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024248574 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.0018     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.33        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.2e+06     |\n",
      "|    total_cost           | 3.1e+05     |\n",
      "|    total_reward         | 2.2e+06     |\n",
      "|    total_reward_pct     | 220         |\n",
      "|    total_trades         | 79507       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 373         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019313503 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0149      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024729012 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.000749    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.55e+06    |\n",
      "|    total_cost           | 3.07e+05    |\n",
      "|    total_reward         | 1.55e+06    |\n",
      "|    total_reward_pct     | 155         |\n",
      "|    total_trades         | 79315       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029573187 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.0319     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6           |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.28e+06    |\n",
      "|    total_cost           | 3.11e+05    |\n",
      "|    total_reward         | 2.28e+06    |\n",
      "|    total_reward_pct     | 228         |\n",
      "|    total_trades         | 79391       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 427         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029051807 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.00354     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.01        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.95e+06    |\n",
      "|    total_cost           | 2.83e+05    |\n",
      "|    total_reward         | 1.95e+06    |\n",
      "|    total_reward_pct     | 195         |\n",
      "|    total_trades         | 77692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035839386 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0017      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013781153 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0357      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "day: 2832, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3395259.72\n",
      "total_reward: 2395259.72\n",
      "total_cost: 278994.46\n",
      "total_trades: 77579\n",
      "Sharpe: 0.781\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.4e+06     |\n",
      "|    total_cost           | 2.79e+05    |\n",
      "|    total_reward         | 2.4e+06     |\n",
      "|    total_reward_pct     | 240         |\n",
      "|    total_trades         | 77579       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041962907 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.00531     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.72        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.27e+06    |\n",
      "|    total_cost           | 2.55e+05    |\n",
      "|    total_reward         | 2.27e+06    |\n",
      "|    total_reward_pct     | 227         |\n",
      "|    total_trades         | 75972       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 498         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027150573 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | -0.00167    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.85        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027979732 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | -0.00447    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.63e+06    |\n",
      "|    total_cost           | 2.53e+05    |\n",
      "|    total_reward         | 2.63e+06    |\n",
      "|    total_reward_pct     | 263         |\n",
      "|    total_trades         | 76034       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 534         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029010084 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | -0.0409     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.19e+06    |\n",
      "|    total_cost           | 2.39e+05    |\n",
      "|    total_reward         | 2.19e+06    |\n",
      "|    total_reward_pct     | 219         |\n",
      "|    total_trades         | 75201       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 551         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024523677 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | -0.0016     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.69        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.11e+06    |\n",
      "|    total_cost           | 2.71e+05    |\n",
      "|    total_reward         | 2.11e+06    |\n",
      "|    total_reward_pct     | 211         |\n",
      "|    total_trades         | 77399       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 569         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017739793 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0112      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 586        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04244773 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | -0.00189   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.9       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 39.6       |\n",
      "----------------------------------------\n",
      "day: 2832, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3829490.71\n",
      "total_reward: 2829490.71\n",
      "total_cost: 230635.59\n",
      "total_trades: 74538\n",
      "Sharpe: 0.846\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.83e+06  |\n",
      "|    total_cost           | 2.31e+05  |\n",
      "|    total_reward         | 2.83e+06  |\n",
      "|    total_reward_pct     | 283       |\n",
      "|    total_trades         | 74538     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 115       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 603       |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0317543 |\n",
      "|    clip_fraction        | 0.285     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.4     |\n",
      "|    explained_variance   | -0.0365   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 8.62      |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | -0.00928  |\n",
      "|    std                  | 1.06      |\n",
      "|    value_loss           | 18.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.5e+06     |\n",
      "|    total_cost           | 2.76e+05    |\n",
      "|    total_reward         | 2.5e+06     |\n",
      "|    total_reward_pct     | 250         |\n",
      "|    total_trades         | 77521       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 622         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035462826 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0076      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.3e+06     |\n",
      "|    total_cost           | 2.49e+05    |\n",
      "|    total_reward         | 2.3e+06     |\n",
      "|    total_reward_pct     | 230         |\n",
      "|    total_trades         | 76123       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 640         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022579905 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0383      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 51.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 658         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028351214 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.051       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.49e+06    |\n",
      "|    total_cost           | 2.7e+05     |\n",
      "|    total_reward         | 2.49e+06    |\n",
      "|    total_reward_pct     | 249         |\n",
      "|    total_trades         | 77386       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 675         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033512384 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | -0.0263     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.99        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.03e+06    |\n",
      "|    total_cost           | 2.79e+05    |\n",
      "|    total_reward         | 2.03e+06    |\n",
      "|    total_reward_pct     | 203         |\n",
      "|    total_trades         | 77472       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 693         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022800047 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | -0.0169     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 710         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028472714 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 4.09e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.83        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "day: 2832, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3553725.10\n",
      "total_reward: 2553725.10\n",
      "total_cost: 260758.72\n",
      "total_trades: 76138\n",
      "Sharpe: 0.809\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.55e+06   |\n",
      "|    total_cost           | 2.61e+05   |\n",
      "|    total_reward         | 2.55e+06   |\n",
      "|    total_reward_pct     | 255        |\n",
      "|    total_trades         | 76138      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 728        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03435394 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.0291     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11         |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.007     |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 20.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.55e+06    |\n",
      "|    total_cost           | 2.98e+05    |\n",
      "|    total_reward         | 2.55e+06    |\n",
      "|    total_reward_pct     | 255         |\n",
      "|    total_trades         | 78261       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 747         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030453112 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | -0.015      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.16e+06   |\n",
      "|    total_cost           | 2.9e+05    |\n",
      "|    total_reward         | 2.16e+06   |\n",
      "|    total_reward_pct     | 216        |\n",
      "|    total_trades         | 77825      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 765        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03590348 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.00568    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.3       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 72.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041075815 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.00878     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0095     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.86e+06   |\n",
      "|    total_cost           | 2.6e+05    |\n",
      "|    total_reward         | 1.86e+06   |\n",
      "|    total_reward_pct     | 186        |\n",
      "|    total_trades         | 76032      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 800        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04611015 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | -0.107     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.6        |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0088    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 11.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.21e+06    |\n",
      "|    total_cost           | 2.54e+05    |\n",
      "|    total_reward         | 2.21e+06    |\n",
      "|    total_reward_pct     | 221         |\n",
      "|    total_trades         | 75282       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 817         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045914963 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0478      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.4         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 835        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05181381 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | 0.00528    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 36.4       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.00658   |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 48.4       |\n",
      "----------------------------------------\n",
      "day: 2832, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3048281.40\n",
      "total_reward: 2048281.40\n",
      "total_cost: 250077.49\n",
      "total_trades: 75027\n",
      "Sharpe: 0.735\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.05e+06    |\n",
      "|    total_cost           | 2.5e+05     |\n",
      "|    total_reward         | 2.05e+06    |\n",
      "|    total_reward_pct     | 205         |\n",
      "|    total_trades         | 75027       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062250536 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | -0.0714     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.36        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.00107     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.87e+06    |\n",
      "|    total_cost           | 2.7e+05     |\n",
      "|    total_reward         | 8.7e+05     |\n",
      "|    total_reward_pct     | 87          |\n",
      "|    total_trades         | 76075       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 872         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040438768 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0187      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.83        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-04-06 to  2020-07-07\n",
      "PPO Sharpe Ratio:  -0.22357879576233786\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1260_2\n",
      "day: 2832, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3765383.17\n",
      "total_reward: 2765383.17\n",
      "total_cost: 1591.60\n",
      "total_trades: 34416\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.21e+06 |\n",
      "|    total_cost       | 2.1e+03  |\n",
      "|    total_reward     | 2.21e+06 |\n",
      "|    total_reward_pct | 221      |\n",
      "|    total_trades     | 38070    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total timesteps  | 11332    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -0.0279  |\n",
      "|    critic_loss      | 95       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8499     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-04-06 to  2020-07-07\n",
      "======Best Model Retraining from:  2009-01-01 to  2020-07-07\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_1260_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.79e+06 |\n",
      "|    total_cost       | 1.52e+03 |\n",
      "|    total_reward     | 3.79e+06 |\n",
      "|    total_reward_pct | 379      |\n",
      "|    total_trades     | 47324    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total timesteps  | 11584    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 13.7     |\n",
      "|    critic_loss      | 145      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8688     |\n",
      "----------------------------------\n",
      "======Trading from:  2020-07-07 to  2020-10-05\n",
      "============================================\n",
      "28.36177978445478\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2020-07-07\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_1323_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.256    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 57.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.368   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -46.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 88        |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 47.9      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 325      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 91.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.64e+06 |\n",
      "|    total_cost         | 1.46e+05 |\n",
      "|    total_reward       | 2.64e+06 |\n",
      "|    total_reward_pct   | 264      |\n",
      "|    total_trades       | 65106    |\n",
      "| time/                 |          |\n",
      "|    fps                | 93       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -46.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 94       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0568   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 32.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 95       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0571  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 129      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0532   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 42.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 93       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -93.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 94       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -4.36    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.04e+06 |\n",
      "|    total_cost         | 7.41e+04 |\n",
      "|    total_reward       | 3.04e+06 |\n",
      "|    total_reward_pct   | 304      |\n",
      "|    total_trades       | 51539    |\n",
      "| time/                 |          |\n",
      "|    fps                | 94       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 102      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.39     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 95        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -122      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 95        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 300       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 54.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 197      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 41.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 152      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 97        |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 22.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.37      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.36e+06 |\n",
      "|    total_cost         | 5.96e+04 |\n",
      "|    total_reward       | 2.36e+06 |\n",
      "|    total_reward_pct   | 236      |\n",
      "|    total_trades       | 48483    |\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -16.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.487    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 164      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 24.4     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -259     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 49.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 132      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -169     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 82       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -1.9e+03 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.13e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.42e+06  |\n",
      "|    total_cost         | 4.41e+04  |\n",
      "|    total_reward       | 4.42e+06  |\n",
      "|    total_reward_pct   | 442       |\n",
      "|    total_trades       | 43492     |\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -128      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.103   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -44.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 57.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 113      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -175     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 21.5     |\n",
      "------------------------------------\n",
      "day: 2895, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4055589.78\n",
      "total_reward: 3055589.78\n",
      "total_cost: 55716.41\n",
      "total_trades: 44726\n",
      "Sharpe: 0.675\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.06e+06 |\n",
      "|    total_cost         | 5.57e+04 |\n",
      "|    total_reward       | 3.06e+06 |\n",
      "|    total_reward_pct   | 306      |\n",
      "|    total_trades       | 44726    |\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -2.11    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0449   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 18.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.756    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -30.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.744    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.106    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 98.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -2.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 226      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 31.4     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.163   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 358      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 98.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.05e+06 |\n",
      "|    total_cost         | 1.47e+05 |\n",
      "|    total_reward       | 2.05e+06 |\n",
      "|    total_reward_pct   | 205      |\n",
      "|    total_trades       | 59148    |\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0839  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -86.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.016   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 2.95     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.838    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -55.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.086   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 61       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 174      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 24.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -287     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 65.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.73e+06 |\n",
      "|    total_cost         | 8.95e+04 |\n",
      "|    total_reward       | 2.73e+06 |\n",
      "|    total_reward_pct   | 273      |\n",
      "|    total_trades       | 51481    |\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.115   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -45.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 59.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 49.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -5.66    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -269     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 51.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 77.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.77e+06 |\n",
      "|    total_cost         | 3.33e+04 |\n",
      "|    total_reward       | 2.77e+06 |\n",
      "|    total_reward_pct   | 277      |\n",
      "|    total_trades       | 46078    |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 33.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.981    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 8.27     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.58     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 240       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -187      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 22.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -133     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 24.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 670      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 737      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.97e+06 |\n",
      "|    total_cost         | 1.3e+04  |\n",
      "|    total_reward       | 2.97e+06 |\n",
      "|    total_reward_pct   | 297      |\n",
      "|    total_trades       | 39065    |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 73.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -29.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 33.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.922    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 28.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.957    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 53.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.03     |\n",
      "------------------------------------\n",
      "day: 2895, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4518086.22\n",
      "total_reward: 3518086.22\n",
      "total_cost: 12930.06\n",
      "total_trades: 41289\n",
      "Sharpe: 0.864\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.52e+06  |\n",
      "|    total_cost         | 1.29e+04  |\n",
      "|    total_reward       | 3.52e+06  |\n",
      "|    total_reward_pct   | 352       |\n",
      "|    total_trades       | 41289     |\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 281       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -10.1     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.385     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 19.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.327    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 289      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -108     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.59     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-07-07 to  2020-10-05\n",
      "A2C Sharpe Ratio:  0.060037845401570776\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_1323_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 108  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 18   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.41e+06    |\n",
      "|    total_cost           | 3.51e+05    |\n",
      "|    total_reward         | 2.41e+06    |\n",
      "|    total_reward_pct     | 241         |\n",
      "|    total_trades         | 83920       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017877497 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -9.42e-06   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.3         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 3.08e+06     |\n",
      "|    total_cost           | 3.41e+05     |\n",
      "|    total_reward         | 2.08e+06     |\n",
      "|    total_reward_pct     | 208          |\n",
      "|    total_trades         | 83091        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064492263 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.00667     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.8         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 52.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015744278 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.000434    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.33e+06    |\n",
      "|    total_cost           | 3.36e+05    |\n",
      "|    total_reward         | 2.33e+06    |\n",
      "|    total_reward_pct     | 233         |\n",
      "|    total_trades         | 83116       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009514619 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0245     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "day: 2895, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4818406.10\n",
      "total_reward: 3818406.10\n",
      "total_cost: 336943.93\n",
      "total_trades: 82842\n",
      "Sharpe: 0.893\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.82e+06   |\n",
      "|    total_cost           | 3.37e+05   |\n",
      "|    total_reward         | 3.82e+06   |\n",
      "|    total_reward_pct     | 382        |\n",
      "|    total_trades         | 82842      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 116        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01260197 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.0112    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.025     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 39.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021598322 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.039      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 73.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.64e+06    |\n",
      "|    total_cost           | 3.39e+05    |\n",
      "|    total_reward         | 1.64e+06    |\n",
      "|    total_reward_pct     | 164         |\n",
      "|    total_trades         | 82836       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029354708 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0247     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.75        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.25e+06    |\n",
      "|    total_cost           | 3.29e+05    |\n",
      "|    total_reward         | 2.25e+06    |\n",
      "|    total_reward_pct     | 225         |\n",
      "|    total_trades         | 81951       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014727084 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00927     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.32e+06    |\n",
      "|    total_cost           | 3.17e+05    |\n",
      "|    total_reward         | 3.32e+06    |\n",
      "|    total_reward_pct     | 332         |\n",
      "|    total_trades         | 81309       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023687886 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00951     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019857794 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0125     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 70.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.68e+06    |\n",
      "|    total_cost           | 3.14e+05    |\n",
      "|    total_reward         | 3.68e+06    |\n",
      "|    total_reward_pct     | 368         |\n",
      "|    total_trades         | 80713       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022118023 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.83        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "day: 2895, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4773942.30\n",
      "total_reward: 3773942.30\n",
      "total_cost: 319934.50\n",
      "total_trades: 81183\n",
      "Sharpe: 0.806\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.77e+06    |\n",
      "|    total_cost           | 3.2e+05     |\n",
      "|    total_reward         | 3.77e+06    |\n",
      "|    total_reward_pct     | 377         |\n",
      "|    total_trades         | 81183       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014552973 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00993     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 73.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021814302 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00161    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 70.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.92e+06   |\n",
      "|    total_cost           | 3e+05      |\n",
      "|    total_reward         | 3.92e+06   |\n",
      "|    total_reward_pct     | 392        |\n",
      "|    total_trades         | 80367      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 295        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02049081 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | -0.0192    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15         |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 37.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.75e+06   |\n",
      "|    total_cost           | 3.08e+05   |\n",
      "|    total_reward         | 4.75e+06   |\n",
      "|    total_reward_pct     | 475        |\n",
      "|    total_trades         | 81209      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 315        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03481839 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | -0.00584   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.2       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0168    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 72         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.48e+06    |\n",
      "|    total_cost           | 3.06e+05    |\n",
      "|    total_reward         | 4.48e+06    |\n",
      "|    total_reward_pct     | 448         |\n",
      "|    total_trades         | 80326       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029682029 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0207      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.3        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 104       |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 353       |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0364718 |\n",
      "|    clip_fraction        | 0.204     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.2     |\n",
      "|    explained_variance   | 0.0229    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 46.7      |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -0.0166   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 101       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.57e+06   |\n",
      "|    total_cost           | 3e+05      |\n",
      "|    total_reward         | 4.57e+06   |\n",
      "|    total_reward_pct     | 457        |\n",
      "|    total_trades         | 80393      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 375        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02160195 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.19       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.59       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 16.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2895, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5749551.69\n",
      "total_reward: 4749551.69\n",
      "total_cost: 317738.45\n",
      "total_trades: 81614\n",
      "Sharpe: 0.931\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.75e+06   |\n",
      "|    total_cost           | 3.18e+05   |\n",
      "|    total_reward         | 4.75e+06   |\n",
      "|    total_reward_pct     | 475        |\n",
      "|    total_trades         | 81614      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 394        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02991876 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0576     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37.3       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 104        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 414         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028360082 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0826      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.2        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.07e+06    |\n",
      "|    total_cost           | 2.89e+05    |\n",
      "|    total_reward         | 5.07e+06    |\n",
      "|    total_reward_pct     | 507         |\n",
      "|    total_trades         | 78664       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016803721 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0342      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.4e+06    |\n",
      "|    total_cost           | 2.86e+05   |\n",
      "|    total_reward         | 2.4e+06    |\n",
      "|    total_reward_pct     | 240        |\n",
      "|    total_trades         | 78993      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 452        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02399713 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0234     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 123        |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 138        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 472         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018529424 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0143      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 62.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.43e+06    |\n",
      "|    total_cost           | 2.82e+05    |\n",
      "|    total_reward         | 2.43e+06    |\n",
      "|    total_reward_pct     | 243         |\n",
      "|    total_trades         | 77749       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 493         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014455082 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0306     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.57e+06   |\n",
      "|    total_cost           | 2.94e+05   |\n",
      "|    total_reward         | 3.57e+06   |\n",
      "|    total_reward_pct     | 357        |\n",
      "|    total_trades         | 78840      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 513        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02291744 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0373     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.7       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0207    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 24.3       |\n",
      "----------------------------------------\n",
      "day: 2895, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5720475.46\n",
      "total_reward: 4720475.46\n",
      "total_cost: 307940.46\n",
      "total_trades: 79805\n",
      "Sharpe: 0.867\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.72e+06    |\n",
      "|    total_cost           | 3.08e+05    |\n",
      "|    total_reward         | 4.72e+06    |\n",
      "|    total_reward_pct     | 472         |\n",
      "|    total_trades         | 79805       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 533         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018928638 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0966      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 75.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 552         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026751107 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0182      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 95.2        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 6.79e+06  |\n",
      "|    total_cost           | 2.85e+05  |\n",
      "|    total_reward         | 5.79e+06  |\n",
      "|    total_reward_pct     | 579       |\n",
      "|    total_trades         | 78556     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 103       |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 571       |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0351991 |\n",
      "|    clip_fraction        | 0.336     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.6     |\n",
      "|    explained_variance   | 0.178     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 13.4      |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -0.00229  |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 30.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.4e+06     |\n",
      "|    total_cost           | 2.76e+05    |\n",
      "|    total_reward         | 5.4e+06     |\n",
      "|    total_reward_pct     | 540         |\n",
      "|    total_trades         | 77640       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 591         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026436351 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0991      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.4        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 612         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036903404 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.1        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.13e+06    |\n",
      "|    total_cost           | 2.97e+05    |\n",
      "|    total_reward         | 6.13e+06    |\n",
      "|    total_reward_pct     | 613         |\n",
      "|    total_trades         | 78398       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 632         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026926542 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.3        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 92.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.21e+06    |\n",
      "|    total_cost           | 2.95e+05    |\n",
      "|    total_reward         | 4.21e+06    |\n",
      "|    total_reward_pct     | 421         |\n",
      "|    total_trades         | 78721       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 651         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024189563 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.082       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.1        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "day: 2895, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6233327.10\n",
      "total_reward: 5233327.10\n",
      "total_cost: 271247.37\n",
      "total_trades: 76849\n",
      "Sharpe: 0.877\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.23e+06    |\n",
      "|    total_cost           | 2.71e+05    |\n",
      "|    total_reward         | 5.23e+06    |\n",
      "|    total_reward_pct     | 523         |\n",
      "|    total_trades         | 76849       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 671         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022240551 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0085     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 82.3        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 103       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 690       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0263412 |\n",
      "|    clip_fraction        | 0.23      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.9     |\n",
      "|    explained_variance   | 0.0728    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 42.6      |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -0.00973  |\n",
      "|    std                  | 1.05      |\n",
      "|    value_loss           | 152       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.25e+06   |\n",
      "|    total_cost           | 2.94e+05   |\n",
      "|    total_reward         | 5.25e+06   |\n",
      "|    total_reward_pct     | 525        |\n",
      "|    total_trades         | 78336      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 710        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02248248 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.24       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.9       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 24.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6e+06       |\n",
      "|    total_cost           | 2.94e+05    |\n",
      "|    total_reward         | 5e+06       |\n",
      "|    total_reward_pct     | 500         |\n",
      "|    total_trades         | 78287       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021162668 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.2        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 750         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023634817 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.9        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.63e+06    |\n",
      "|    total_cost           | 2.73e+05    |\n",
      "|    total_reward         | 3.63e+06    |\n",
      "|    total_reward_pct     | 363         |\n",
      "|    total_trades         | 76757       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 770         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033815607 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.15e+06    |\n",
      "|    total_cost           | 2.99e+05    |\n",
      "|    total_reward         | 3.15e+06    |\n",
      "|    total_reward_pct     | 315         |\n",
      "|    total_trades         | 78510       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 790         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032653518 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.07        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 810         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022246143 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.3        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 63.8        |\n",
      "-----------------------------------------\n",
      "day: 2895, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6562668.58\n",
      "total_reward: 5562668.58\n",
      "total_cost: 294840.25\n",
      "total_trades: 78797\n",
      "Sharpe: 0.933\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.56e+06    |\n",
      "|    total_cost           | 2.95e+05    |\n",
      "|    total_reward         | 5.56e+06    |\n",
      "|    total_reward_pct     | 556         |\n",
      "|    total_trades         | 78797       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 829         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053112615 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0525      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.65e+06    |\n",
      "|    total_cost           | 2.75e+05    |\n",
      "|    total_reward         | 3.65e+06    |\n",
      "|    total_reward_pct     | 365         |\n",
      "|    total_trades         | 77523       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 850         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032469682 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.3         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.23e+06    |\n",
      "|    total_cost           | 2.99e+05    |\n",
      "|    total_reward         | 5.23e+06    |\n",
      "|    total_reward_pct     | 523         |\n",
      "|    total_trades         | 78641       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 870         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033574313 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 62.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 889         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044532634 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.74e+06   |\n",
      "|    total_cost           | 2.83e+05   |\n",
      "|    total_reward         | 5.74e+06   |\n",
      "|    total_reward_pct     | 574        |\n",
      "|    total_trades         | 77807      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 908        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02941492 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.214      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.05       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.00711   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 23.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.96e+06   |\n",
      "|    total_cost           | 3.04e+05   |\n",
      "|    total_reward         | 3.96e+06   |\n",
      "|    total_reward_pct     | 396        |\n",
      "|    total_trades         | 78978      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 927        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04159013 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.315      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 50.9       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.00805   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 114        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 946        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01913132 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.109      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35.6       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00847   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 83.7       |\n",
      "----------------------------------------\n",
      "day: 2895, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6127169.10\n",
      "total_reward: 5127169.10\n",
      "total_cost: 279167.66\n",
      "total_trades: 77445\n",
      "Sharpe: 0.887\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.13e+06    |\n",
      "|    total_cost           | 2.79e+05    |\n",
      "|    total_reward         | 5.13e+06    |\n",
      "|    total_reward_pct     | 513         |\n",
      "|    total_trades         | 77445       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 966         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053773966 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0375      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.00231     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 66.2        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-07-07 to  2020-10-05\n",
      "PPO Sharpe Ratio:  0.10164700650252316\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1323_2\n",
      "day: 2895, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3440493.32\n",
      "total_reward: 2440493.32\n",
      "total_cost: 2503.22\n",
      "total_trades: 32717\n",
      "Sharpe: 0.615\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.44e+06 |\n",
      "|    total_cost       | 2.5e+03  |\n",
      "|    total_reward     | 2.44e+06 |\n",
      "|    total_reward_pct | 244      |\n",
      "|    total_trades     | 32717    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total timesteps  | 11584    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -13.1    |\n",
      "|    critic_loss      | 83.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8688     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-07-07 to  2020-10-05\n",
      "======Best Model Retraining from:  2009-01-01 to  2020-10-05\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_1323_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 95   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 21   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.48e+06    |\n",
      "|    total_cost           | 3.65e+05    |\n",
      "|    total_reward         | 2.48e+06    |\n",
      "|    total_reward_pct     | 248         |\n",
      "|    total_trades         | 85867       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010808632 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.00923     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.99        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.34e+06    |\n",
      "|    total_cost           | 3.58e+05    |\n",
      "|    total_reward         | 2.34e+06    |\n",
      "|    total_reward_pct     | 234         |\n",
      "|    total_trades         | 85383       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020618167 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00798    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 77.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 80         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01385612 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | 0.00104    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32         |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 70.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.57e+06    |\n",
      "|    total_cost           | 3.5e+05     |\n",
      "|    total_reward         | 1.57e+06    |\n",
      "|    total_reward_pct     | 157         |\n",
      "|    total_trades         | 84627       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012658894 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.236      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.44        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.68e+06    |\n",
      "|    total_cost           | 3.57e+05    |\n",
      "|    total_reward         | 3.68e+06    |\n",
      "|    total_reward_pct     | 368         |\n",
      "|    total_trades         | 85187       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037788823 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00396     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018924696 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00309    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.6        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "day: 2958, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3618248.55\n",
      "total_reward: 2618248.55\n",
      "total_cost: 343273.31\n",
      "total_trades: 83900\n",
      "Sharpe: 0.635\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.62e+06    |\n",
      "|    total_cost           | 3.43e+05    |\n",
      "|    total_reward         | 2.62e+06    |\n",
      "|    total_reward_pct     | 262         |\n",
      "|    total_trades         | 83900       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022528702 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0198      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.97e+06    |\n",
      "|    total_cost           | 3.39e+05    |\n",
      "|    total_reward         | 2.97e+06    |\n",
      "|    total_reward_pct     | 297         |\n",
      "|    total_trades         | 83816       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020359185 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.013      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 200        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02751158 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | 0.0276     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37.2       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0226    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 67.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.51e+06    |\n",
      "|    total_cost           | 3.44e+05    |\n",
      "|    total_reward         | 2.51e+06    |\n",
      "|    total_reward_pct     | 251         |\n",
      "|    total_trades         | 84061       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022834653 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0293      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.4e+06     |\n",
      "|    total_cost           | 3.32e+05    |\n",
      "|    total_reward         | 2.4e+06     |\n",
      "|    total_reward_pct     | 240         |\n",
      "|    total_trades         | 83009       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014853498 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0126     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029968185 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00467     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.57e+06    |\n",
      "|    total_cost           | 3.36e+05    |\n",
      "|    total_reward         | 1.57e+06    |\n",
      "|    total_reward_pct     | 157         |\n",
      "|    total_trades         | 83320       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029031813 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.00289     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "day: 2958, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5279355.45\n",
      "total_reward: 4279355.45\n",
      "total_cost: 330090.19\n",
      "total_trades: 83290\n",
      "Sharpe: 0.889\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.28e+06    |\n",
      "|    total_cost           | 3.3e+05     |\n",
      "|    total_reward         | 4.28e+06    |\n",
      "|    total_reward_pct     | 428         |\n",
      "|    total_trades         | 83290       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025933767 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.00453     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.2         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.22e+06    |\n",
      "|    total_cost           | 3.16e+05    |\n",
      "|    total_reward         | 4.22e+06    |\n",
      "|    total_reward_pct     | 422         |\n",
      "|    total_trades         | 82332       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 320         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023257323 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.00273    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039002188 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.00426    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.32e+06   |\n",
      "|    total_cost           | 3.04e+05   |\n",
      "|    total_reward         | 6.32e+06   |\n",
      "|    total_reward_pct     | 632        |\n",
      "|    total_trades         | 81246      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 359        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06270802 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0357     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.3       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 28.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.98e+06    |\n",
      "|    total_cost           | 3.42e+05    |\n",
      "|    total_reward         | 2.98e+06    |\n",
      "|    total_reward_pct     | 298         |\n",
      "|    total_trades         | 83476       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027133344 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0469      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.7        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 402        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01787978 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0323     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.9       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 88.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.24e+06    |\n",
      "|    total_cost           | 3.12e+05    |\n",
      "|    total_reward         | 3.24e+06    |\n",
      "|    total_reward_pct     | 324         |\n",
      "|    total_trades         | 82317       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017857831 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "day: 2958, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4241791.32\n",
      "total_reward: 3241791.32\n",
      "total_cost: 345096.02\n",
      "total_trades: 83972\n",
      "Sharpe: 0.784\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.24e+06    |\n",
      "|    total_cost           | 3.45e+05    |\n",
      "|    total_reward         | 3.24e+06    |\n",
      "|    total_reward_pct     | 324         |\n",
      "|    total_trades         | 83972       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022108104 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0591      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 68.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 462         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022541702 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0214      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 69.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.81e+06    |\n",
      "|    total_cost           | 3.34e+05    |\n",
      "|    total_reward         | 1.81e+06    |\n",
      "|    total_reward_pct     | 181         |\n",
      "|    total_trades         | 83501       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 482         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030280035 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.39e+06    |\n",
      "|    total_cost           | 3.29e+05    |\n",
      "|    total_reward         | 4.39e+06    |\n",
      "|    total_reward_pct     | 439         |\n",
      "|    total_trades         | 83073       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022080397 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.00346    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 523         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034973815 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0416      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 93.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.84e+06    |\n",
      "|    total_cost           | 3.47e+05    |\n",
      "|    total_reward         | 3.84e+06    |\n",
      "|    total_reward_pct     | 384         |\n",
      "|    total_trades         | 84094       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 541         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023038596 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.024       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 79.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.23e+06    |\n",
      "|    total_cost           | 3.31e+05    |\n",
      "|    total_reward         | 2.23e+06    |\n",
      "|    total_reward_pct     | 223         |\n",
      "|    total_trades         | 82583       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 561         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036269356 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.000881    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.09        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "day: 2958, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3370954.00\n",
      "total_reward: 2370954.00\n",
      "total_cost: 314370.06\n",
      "total_trades: 81680\n",
      "Sharpe: 0.682\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.37e+06   |\n",
      "|    total_cost           | 3.14e+05   |\n",
      "|    total_reward         | 2.37e+06   |\n",
      "|    total_reward_pct     | 237        |\n",
      "|    total_trades         | 81680      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 581        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02251979 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.0396     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.6       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0168    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 52.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 601         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021267956 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.031       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 53.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.47e+06   |\n",
      "|    total_cost           | 2.99e+05   |\n",
      "|    total_reward         | 3.47e+06   |\n",
      "|    total_reward_pct     | 347        |\n",
      "|    total_trades         | 80972      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 623        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05343121 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.081      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.06       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 18.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4e+06      |\n",
      "|    total_cost           | 3.12e+05   |\n",
      "|    total_reward         | 3e+06      |\n",
      "|    total_reward_pct     | 300        |\n",
      "|    total_trades         | 81819      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 646        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02373391 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.0376     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.8       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 88.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 666         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034486517 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.00856     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.74e+06    |\n",
      "|    total_cost           | 3.06e+05    |\n",
      "|    total_reward         | 5.74e+06    |\n",
      "|    total_reward_pct     | 574         |\n",
      "|    total_trades         | 81299       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 686         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046010606 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | -0.0145     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.49e+06    |\n",
      "|    total_cost           | 3.13e+05    |\n",
      "|    total_reward         | 2.49e+06    |\n",
      "|    total_reward_pct     | 249         |\n",
      "|    total_trades         | 81407       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 706         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030315636 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0529      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.8        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 726         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036400765 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.00356     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "day: 2958, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5324723.08\n",
      "total_reward: 4324723.08\n",
      "total_cost: 311847.18\n",
      "total_trades: 81512\n",
      "Sharpe: 0.948\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.32e+06   |\n",
      "|    total_cost           | 3.12e+05   |\n",
      "|    total_reward         | 4.32e+06   |\n",
      "|    total_reward_pct     | 432        |\n",
      "|    total_trades         | 81512      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 748        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03260328 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | -0.00719   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.5       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.00732   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 30.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.88e+06   |\n",
      "|    total_cost           | 3.16e+05   |\n",
      "|    total_reward         | 3.88e+06   |\n",
      "|    total_reward_pct     | 388        |\n",
      "|    total_trades         | 82245      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 768        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02906955 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.011      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.2       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 72.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 788        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02905547 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.00777    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 36.6       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00563   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 78.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.68e+06    |\n",
      "|    total_cost           | 3.13e+05    |\n",
      "|    total_reward         | 3.68e+06    |\n",
      "|    total_reward_pct     | 368         |\n",
      "|    total_trades         | 81737       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 810         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024733394 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.00791     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 90.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.96e+06    |\n",
      "|    total_cost           | 3.01e+05    |\n",
      "|    total_reward         | 2.96e+06    |\n",
      "|    total_reward_pct     | 296         |\n",
      "|    total_trades         | 81500       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 828         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048385695 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.00962     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.44        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.8e+06     |\n",
      "|    total_cost           | 3.18e+05    |\n",
      "|    total_reward         | 2.8e+06     |\n",
      "|    total_reward_pct     | 280         |\n",
      "|    total_trades         | 81558       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 848         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018057775 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0328      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 56.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 866         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047423914 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0164      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 64.2        |\n",
      "-----------------------------------------\n",
      "day: 2958, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6048902.60\n",
      "total_reward: 5048902.60\n",
      "total_cost: 312198.81\n",
      "total_trades: 81640\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.05e+06    |\n",
      "|    total_cost           | 3.12e+05    |\n",
      "|    total_reward         | 5.05e+06    |\n",
      "|    total_reward_pct     | 505         |\n",
      "|    total_trades         | 81640       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 883         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039719872 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | -0.0596     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.11e+06    |\n",
      "|    total_cost           | 3.05e+05    |\n",
      "|    total_reward         | 5.11e+06    |\n",
      "|    total_reward_pct     | 511         |\n",
      "|    total_trades         | 81561       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 901         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038981453 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0149      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 919         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025212511 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.00624     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.12e+06    |\n",
      "|    total_cost           | 3.05e+05    |\n",
      "|    total_reward         | 4.12e+06    |\n",
      "|    total_reward_pct     | 412         |\n",
      "|    total_trades         | 80674       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 937         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029023811 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | -0.0392     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.003       |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.5e+06    |\n",
      "|    total_cost           | 3.19e+05   |\n",
      "|    total_reward         | 4.5e+06    |\n",
      "|    total_reward_pct     | 450        |\n",
      "|    total_trades         | 82107      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 955        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03153739 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.028      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46.2       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00994   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 103        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 975        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04021734 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.0284     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 63         |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 121        |\n",
      "----------------------------------------\n",
      "======Trading from:  2020-10-05 to  2021-01-05\n",
      "============================================\n",
      "14.697780459408165\n",
      "turbulence_threshold:  286.9563664825805\n",
      "======Model training from:  2009-01-01 to  2020-10-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_1386_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0573   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -4.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.541    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.118    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 4.27     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.549    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0385   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -355     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 84.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.124   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 25.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 403      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 125      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.31e+06 |\n",
      "|    total_cost         | 2.08e+05 |\n",
      "|    total_reward       | 2.31e+06 |\n",
      "|    total_reward_pct   | 231      |\n",
      "|    total_trades       | 73021    |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -16.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.454    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 44.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.273   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 90.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0381   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 56.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0396   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -62.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 96.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 22.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.44e+06 |\n",
      "|    total_cost         | 2.17e+05 |\n",
      "|    total_reward       | 1.44e+06 |\n",
      "|    total_reward_pct   | 144      |\n",
      "|    total_trades       | 75114    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0111  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 34.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.53     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -82.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0234   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -38.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.73     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -2.92e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 81.5      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.84      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0493  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 26.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.489    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.116   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 273      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 44.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.28e+06 |\n",
      "|    total_cost         | 1.36e+05 |\n",
      "|    total_reward       | 3.28e+06 |\n",
      "|    total_reward_pct   | 328      |\n",
      "|    total_trades       | 65460    |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.122   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -121     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -90.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0569  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 48.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -99.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 76.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -92.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.57e+06 |\n",
      "|    total_cost         | 1.64e+05 |\n",
      "|    total_reward       | 1.57e+06 |\n",
      "|    total_reward_pct   | 157      |\n",
      "|    total_trades       | 64484    |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0365   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 20.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0434   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 261      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 50.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -124     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.51     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 24        |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.98      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 189      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 144      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -938     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 617      |\n",
      "------------------------------------\n",
      "day: 2958, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3764417.45\n",
      "total_reward: 2764417.45\n",
      "total_cost: 121859.06\n",
      "total_trades: 60906\n",
      "Sharpe: 0.599\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.76e+06 |\n",
      "|    total_cost         | 1.22e+05 |\n",
      "|    total_reward       | 2.76e+06 |\n",
      "|    total_reward_pct   | 276      |\n",
      "|    total_trades       | 60906    |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0534   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 27       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0238   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 197      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 29.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -109     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 470      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 113      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -83.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.66     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.26e+06  |\n",
      "|    total_cost         | 5.38e+04  |\n",
      "|    total_reward       | 3.26e+06  |\n",
      "|    total_reward_pct   | 326       |\n",
      "|    total_trades       | 53236     |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -0.000338 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -26.8     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.688     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 92.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -60.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 58.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.29     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -7       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.92e+06 |\n",
      "|    total_cost         | 3.49e+04 |\n",
      "|    total_reward       | 4.92e+06 |\n",
      "|    total_reward_pct   | 492      |\n",
      "|    total_trades       | 49982    |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.00307  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 115      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 39.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 54.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -18.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 18.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 206       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 417       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 109       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 211       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -321      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 74.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.09e+06 |\n",
      "|    total_cost         | 2.23e+04 |\n",
      "|    total_reward       | 5.09e+06 |\n",
      "|    total_reward_pct   | 509      |\n",
      "|    total_trades       | 50981    |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -25.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -393     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 83.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -144     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 116      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -397     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 262      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 239       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -1.12e+03 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 808       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.67e+06 |\n",
      "|    total_cost         | 4.06e+04 |\n",
      "|    total_reward       | 4.67e+06 |\n",
      "|    total_reward_pct   | 467      |\n",
      "|    total_trades       | 54126    |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 175      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0104   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 186      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 256       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 100       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 7.27      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 53.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.00168 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 558      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 265      |\n",
      "------------------------------------\n",
      "day: 2958, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3766845.05\n",
      "total_reward: 2766845.05\n",
      "total_cost: 28376.80\n",
      "total_trades: 51968\n",
      "Sharpe: 0.633\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.77e+06 |\n",
      "|    total_cost         | 2.84e+04 |\n",
      "|    total_reward       | 2.77e+06 |\n",
      "|    total_reward_pct   | 277      |\n",
      "|    total_trades       | 51968    |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -175     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 19       |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-10-05 to  2021-01-05\n",
      "A2C Sharpe Ratio:  0.15210836217825655\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_1386_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 111  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 18   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.07e+06    |\n",
      "|    total_cost           | 3.65e+05    |\n",
      "|    total_reward         | 2.07e+06    |\n",
      "|    total_reward_pct     | 207         |\n",
      "|    total_trades         | 85822       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018841768 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0132     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.02        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.93e+06   |\n",
      "|    total_cost           | 3.53e+05   |\n",
      "|    total_reward         | 1.93e+06   |\n",
      "|    total_reward_pct     | 193        |\n",
      "|    total_trades         | 85031      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02523071 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | 0.0025     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.6       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0176    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 44.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 72         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02260097 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.00167   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.4       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 71.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.37e+06    |\n",
      "|    total_cost           | 3.53e+05    |\n",
      "|    total_reward         | 2.37e+06    |\n",
      "|    total_reward_pct     | 237         |\n",
      "|    total_trades         | 85223       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019145178 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.55        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "day: 2958, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2610033.22\n",
      "total_reward: 1610033.22\n",
      "total_cost: 338535.90\n",
      "total_trades: 83749\n",
      "Sharpe: 0.530\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+06    |\n",
      "|    total_cost           | 3.39e+05    |\n",
      "|    total_reward         | 1.61e+06    |\n",
      "|    total_reward_pct     | 161         |\n",
      "|    total_trades         | 83749       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021622173 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00769     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016291128 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00683     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.82e+06    |\n",
      "|    total_cost           | 3.33e+05    |\n",
      "|    total_reward         | 1.82e+06    |\n",
      "|    total_reward_pct     | 182         |\n",
      "|    total_trades         | 83717       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016563654 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0221     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.76e+06    |\n",
      "|    total_cost           | 3.29e+05    |\n",
      "|    total_reward         | 1.76e+06    |\n",
      "|    total_reward_pct     | 176         |\n",
      "|    total_trades         | 83200       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022400565 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.00611    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.3        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 56.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 180        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01383831 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | -0.00329   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.8       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 25.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.05e+06   |\n",
      "|    total_cost           | 3.1e+05    |\n",
      "|    total_reward         | 2.05e+06   |\n",
      "|    total_reward_pct     | 205        |\n",
      "|    total_trades         | 81843      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 199        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01433721 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | 0.0662     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.4       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 20.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.08e+06    |\n",
      "|    total_cost           | 3.21e+05    |\n",
      "|    total_reward         | 3.08e+06    |\n",
      "|    total_reward_pct     | 308         |\n",
      "|    total_trades         | 82218       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021991728 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00319     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034332655 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00825    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 72.6        |\n",
      "-----------------------------------------\n",
      "day: 2958, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4929526.09\n",
      "total_reward: 3929526.09\n",
      "total_cost: 314059.30\n",
      "total_trades: 81752\n",
      "Sharpe: 0.764\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.93e+06    |\n",
      "|    total_cost           | 3.14e+05    |\n",
      "|    total_reward         | 3.93e+06    |\n",
      "|    total_reward_pct     | 393         |\n",
      "|    total_trades         | 81752       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008315628 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0193      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.42e+06    |\n",
      "|    total_cost           | 3.03e+05    |\n",
      "|    total_reward         | 2.42e+06    |\n",
      "|    total_reward_pct     | 242         |\n",
      "|    total_trades         | 80737       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023124846 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0371      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.26        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.91e+06   |\n",
      "|    total_cost           | 3.04e+05   |\n",
      "|    total_reward         | 4.91e+06   |\n",
      "|    total_reward_pct     | 491        |\n",
      "|    total_trades         | 81188      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 288        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03046402 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.0198     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.2       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 36.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 306        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02179913 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | -0.00931   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 89.6       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.00721   |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 124        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.91e+06    |\n",
      "|    total_cost           | 2.93e+05    |\n",
      "|    total_reward         | 4.91e+06    |\n",
      "|    total_reward_pct     | 491         |\n",
      "|    total_trades         | 80243       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024544397 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0393      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.84e+06    |\n",
      "|    total_cost           | 2.81e+05    |\n",
      "|    total_reward         | 4.84e+06    |\n",
      "|    total_reward_pct     | 484         |\n",
      "|    total_trades         | 79448       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 342         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029883452 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00411     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.9        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 113       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 360       |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0326178 |\n",
      "|    clip_fraction        | 0.184     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.2     |\n",
      "|    explained_variance   | -0.000794 |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 137       |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -0.00908  |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 153       |\n",
      "---------------------------------------\n",
      "day: 2958, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4088148.44\n",
      "total_reward: 3088148.44\n",
      "total_cost: 287586.93\n",
      "total_trades: 79980\n",
      "Sharpe: 0.789\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.09e+06    |\n",
      "|    total_cost           | 2.88e+05    |\n",
      "|    total_reward         | 3.09e+06    |\n",
      "|    total_reward_pct     | 309         |\n",
      "|    total_trades         | 79980       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019718785 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.068       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.2         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.2e+06     |\n",
      "|    total_cost           | 3.12e+05    |\n",
      "|    total_reward         | 4.2e+06     |\n",
      "|    total_reward_pct     | 420         |\n",
      "|    total_trades         | 81242       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019134168 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0295      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 413        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03311757 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.00854    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.9       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.00749   |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 109        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.1e+06     |\n",
      "|    total_cost           | 2.93e+05    |\n",
      "|    total_reward         | 4.1e+06     |\n",
      "|    total_reward_pct     | 410         |\n",
      "|    total_trades         | 80091       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 431         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030365752 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.00169     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.36e+06    |\n",
      "|    total_cost           | 2.88e+05    |\n",
      "|    total_reward         | 3.36e+06    |\n",
      "|    total_reward_pct     | 336         |\n",
      "|    total_trades         | 79966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021316608 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0159      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 89.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 467        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02247293 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0709     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 66.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.78e+06    |\n",
      "|    total_cost           | 2.78e+05    |\n",
      "|    total_reward         | 3.78e+06    |\n",
      "|    total_reward_pct     | 378         |\n",
      "|    total_trades         | 79028       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 485         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027857613 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.00872     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.8        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 83.3        |\n",
      "-----------------------------------------\n",
      "day: 2958, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5068394.68\n",
      "total_reward: 4068394.68\n",
      "total_cost: 284357.69\n",
      "total_trades: 79647\n",
      "Sharpe: 0.849\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.07e+06    |\n",
      "|    total_cost           | 2.84e+05    |\n",
      "|    total_reward         | 4.07e+06    |\n",
      "|    total_reward_pct     | 407         |\n",
      "|    total_trades         | 79647       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028489094 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.71        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.58e+06    |\n",
      "|    total_cost           | 2.77e+05    |\n",
      "|    total_reward         | 4.58e+06    |\n",
      "|    total_reward_pct     | 458         |\n",
      "|    total_trades         | 79406       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 520         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040060744 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0285      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.1        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 538         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040135078 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.00322     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78          |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.81e+06   |\n",
      "|    total_cost           | 2.66e+05   |\n",
      "|    total_reward         | 4.81e+06   |\n",
      "|    total_reward_pct     | 481        |\n",
      "|    total_trades         | 77848      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 557        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06459684 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.112      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.94       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.00447   |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 18.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.43e+06    |\n",
      "|    total_cost           | 2.89e+05    |\n",
      "|    total_reward         | 4.43e+06    |\n",
      "|    total_reward_pct     | 443         |\n",
      "|    total_trades         | 80134       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030398866 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0178      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.5        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 593        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01961893 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.00746    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 66.3       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00562   |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 137        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.83e+06   |\n",
      "|    total_cost           | 2.81e+05   |\n",
      "|    total_reward         | 4.83e+06   |\n",
      "|    total_reward_pct     | 483        |\n",
      "|    total_trades         | 79056      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 611        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03595911 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.4       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 31.4       |\n",
      "----------------------------------------\n",
      "day: 2958, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4658082.18\n",
      "total_reward: 3658082.18\n",
      "total_cost: 282036.39\n",
      "total_trades: 79192\n",
      "Sharpe: 0.767\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.66e+06    |\n",
      "|    total_cost           | 2.82e+05    |\n",
      "|    total_reward         | 3.66e+06    |\n",
      "|    total_reward_pct     | 366         |\n",
      "|    total_trades         | 79192       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 629         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030035831 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0178      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.7        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 647        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01718508 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0724     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48.3       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 93.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.83e+06    |\n",
      "|    total_cost           | 2.83e+05    |\n",
      "|    total_reward         | 4.83e+06    |\n",
      "|    total_reward_pct     | 483         |\n",
      "|    total_trades         | 79076       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 665         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014961295 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | -0.0235     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 56.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.63e+06    |\n",
      "|    total_cost           | 2.72e+05    |\n",
      "|    total_reward         | 5.63e+06    |\n",
      "|    total_reward_pct     | 563         |\n",
      "|    total_trades         | 77537       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 685         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034953035 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 703         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037750978 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0402      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.35e+06    |\n",
      "|    total_cost           | 3.09e+05    |\n",
      "|    total_reward         | 3.35e+06    |\n",
      "|    total_reward_pct     | 335         |\n",
      "|    total_trades         | 81430       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 720         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022197936 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0505      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 91.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.94e+06    |\n",
      "|    total_cost           | 2.93e+05    |\n",
      "|    total_reward         | 3.94e+06    |\n",
      "|    total_reward_pct     | 394         |\n",
      "|    total_trades         | 79745       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 738         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041745678 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2958, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5686663.58\n",
      "total_reward: 4686663.58\n",
      "total_cost: 324839.04\n",
      "total_trades: 82218\n",
      "Sharpe: 0.851\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.69e+06    |\n",
      "|    total_cost           | 3.25e+05    |\n",
      "|    total_reward         | 4.69e+06    |\n",
      "|    total_reward_pct     | 469         |\n",
      "|    total_trades         | 82218       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 756         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028988745 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.025       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.8        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 774        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03472601 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0395     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 54.4       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00839   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 146        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.76e+06    |\n",
      "|    total_cost           | 2.91e+05    |\n",
      "|    total_reward         | 3.76e+06    |\n",
      "|    total_reward_pct     | 376         |\n",
      "|    total_trades         | 79501       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 792         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051380627 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.02e+06    |\n",
      "|    total_cost           | 2.93e+05    |\n",
      "|    total_reward         | 5.02e+06    |\n",
      "|    total_reward_pct     | 502         |\n",
      "|    total_trades         | 79680       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 810         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017898183 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0404      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 827         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011026343 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0547      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.9        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.97e+06    |\n",
      "|    total_cost           | 3e+05       |\n",
      "|    total_reward         | 4.97e+06    |\n",
      "|    total_reward_pct     | 497         |\n",
      "|    total_trades         | 80735       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 845         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022071159 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.56e+06    |\n",
      "|    total_cost           | 3.07e+05    |\n",
      "|    total_reward         | 5.56e+06    |\n",
      "|    total_reward_pct     | 556         |\n",
      "|    total_trades         | 81374       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 863         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039125204 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0559      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46          |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 881         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022960458 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0948      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.2        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-10-05 to  2021-01-05\n",
      "PPO Sharpe Ratio:  0.17827394772203287\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1386_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.68e+06 |\n",
      "|    total_cost       | 1.3e+03  |\n",
      "|    total_reward     | 1.68e+06 |\n",
      "|    total_reward_pct | 168      |\n",
      "|    total_trades     | 45765    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total timesteps  | 11836    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -10.6    |\n",
      "|    critic_loss      | 11       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8877     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-10-05 to  2021-01-05\n",
      "======Best Model Retraining from:  2009-01-01 to  2021-01-05\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_1386_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 108  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 18   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.12e+06    |\n",
      "|    total_cost           | 3.79e+05    |\n",
      "|    total_reward         | 4.12e+06    |\n",
      "|    total_reward_pct     | 412         |\n",
      "|    total_trades         | 87900       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018165499 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0285     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.45        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.76e+06   |\n",
      "|    total_cost           | 3.74e+05   |\n",
      "|    total_reward         | 3.76e+06   |\n",
      "|    total_reward_pct     | 376        |\n",
      "|    total_trades         | 87342      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01152222 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | -0.00304   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.3       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 86.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024836373 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00929     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 78.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.19e+06    |\n",
      "|    total_cost           | 3.66e+05    |\n",
      "|    total_reward         | 3.19e+06    |\n",
      "|    total_reward_pct     | 319         |\n",
      "|    total_trades         | 86546       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025524637 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.142      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.28        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.36e+06   |\n",
      "|    total_cost           | 3.5e+05    |\n",
      "|    total_reward         | 3.36e+06   |\n",
      "|    total_reward_pct     | 336        |\n",
      "|    total_trades         | 85581      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 111        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02360474 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | 0.0033     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.7       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0217    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 60.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032707784 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.00484    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 60.3        |\n",
      "-----------------------------------------\n",
      "day: 3021, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3629146.93\n",
      "total_reward: 2629146.93\n",
      "total_cost: 346248.48\n",
      "total_trades: 85341\n",
      "Sharpe: 0.740\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.63e+06    |\n",
      "|    total_cost           | 3.46e+05    |\n",
      "|    total_reward         | 2.63e+06    |\n",
      "|    total_reward_pct     | 263         |\n",
      "|    total_trades         | 85341       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012731379 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0836     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.65        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.66e+06   |\n",
      "|    total_cost           | 3.44e+05   |\n",
      "|    total_reward         | 3.66e+06   |\n",
      "|    total_reward_pct     | 366        |\n",
      "|    total_trades         | 84870      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 165        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02210123 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | 0.00201    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.1       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 43.1       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022488747 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00576    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 73.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.91e+06    |\n",
      "|    total_cost           | 3.41e+05    |\n",
      "|    total_reward         | 2.91e+06    |\n",
      "|    total_reward_pct     | 291         |\n",
      "|    total_trades         | 85027       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021141857 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0306      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.77        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.48e+06    |\n",
      "|    total_cost           | 3.47e+05    |\n",
      "|    total_reward         | 3.48e+06    |\n",
      "|    total_reward_pct     | 348         |\n",
      "|    total_trades         | 84845       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011457488 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -8.88e-05   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033978052 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.00287     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 64.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.61e+06    |\n",
      "|    total_cost           | 3.44e+05    |\n",
      "|    total_reward         | 2.61e+06    |\n",
      "|    total_reward_pct     | 261         |\n",
      "|    total_trades         | 84256       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 258         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022923522 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0311     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.54        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "day: 3021, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4461223.73\n",
      "total_reward: 3461223.73\n",
      "total_cost: 318614.02\n",
      "total_trades: 82899\n",
      "Sharpe: 0.818\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.46e+06    |\n",
      "|    total_cost           | 3.19e+05    |\n",
      "|    total_reward         | 3.46e+06    |\n",
      "|    total_reward_pct     | 346         |\n",
      "|    total_trades         | 82899       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038397938 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0323      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033758245 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0304      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 71.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.61e+06    |\n",
      "|    total_cost           | 3.09e+05    |\n",
      "|    total_reward         | 3.61e+06    |\n",
      "|    total_reward_pct     | 361         |\n",
      "|    total_trades         | 82113       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018219639 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.03e+06    |\n",
      "|    total_cost           | 2.87e+05    |\n",
      "|    total_reward         | 3.03e+06    |\n",
      "|    total_reward_pct     | 303         |\n",
      "|    total_trades         | 80334       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024901332 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.00514     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 73.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023680104 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0017      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 89.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.93e+06    |\n",
      "|    total_cost           | 2.64e+05    |\n",
      "|    total_reward         | 1.93e+06    |\n",
      "|    total_reward_pct     | 193         |\n",
      "|    total_trades         | 78737       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 366         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016440915 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.011       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.82e+06    |\n",
      "|    total_cost           | 3e+05       |\n",
      "|    total_reward         | 2.82e+06    |\n",
      "|    total_reward_pct     | 282         |\n",
      "|    total_trades         | 81520       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 384         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016018378 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 402        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02190782 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.00681    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.3       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 91.9       |\n",
      "----------------------------------------\n",
      "day: 3021, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3954647.74\n",
      "total_reward: 2954647.74\n",
      "total_cost: 301941.72\n",
      "total_trades: 81648\n",
      "Sharpe: 0.682\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.95e+06    |\n",
      "|    total_cost           | 3.02e+05    |\n",
      "|    total_reward         | 2.95e+06    |\n",
      "|    total_reward_pct     | 295         |\n",
      "|    total_trades         | 81648       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 420         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011663387 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.00165     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.35e+06    |\n",
      "|    total_cost           | 2.85e+05    |\n",
      "|    total_reward         | 2.35e+06    |\n",
      "|    total_reward_pct     | 235         |\n",
      "|    total_trades         | 80485       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 438         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014062293 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0187      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 78.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 456         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009456124 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.00474     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 79.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.03e+06   |\n",
      "|    total_cost           | 2.72e+05   |\n",
      "|    total_reward         | 2.03e+06   |\n",
      "|    total_reward_pct     | 203        |\n",
      "|    total_trades         | 79657      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 475        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01739474 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0497     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.9       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 59.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.92e+06    |\n",
      "|    total_cost           | 2.74e+05    |\n",
      "|    total_reward         | 1.92e+06    |\n",
      "|    total_reward_pct     | 192         |\n",
      "|    total_trades         | 78980       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033414464 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.0516     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.06        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 512         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014971448 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0401      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.89e+06    |\n",
      "|    total_cost           | 2.41e+05    |\n",
      "|    total_reward         | 1.89e+06    |\n",
      "|    total_reward_pct     | 189         |\n",
      "|    total_trades         | 76659       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 529         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014045825 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.00519    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n",
      "day: 3021, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2817668.60\n",
      "total_reward: 1817668.60\n",
      "total_cost: 251449.10\n",
      "total_trades: 77352\n",
      "Sharpe: 0.495\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.82e+06    |\n",
      "|    total_cost           | 2.51e+05    |\n",
      "|    total_reward         | 1.82e+06    |\n",
      "|    total_reward_pct     | 182         |\n",
      "|    total_trades         | 77352       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 547         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020116452 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.0239     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.85        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.83e+06    |\n",
      "|    total_cost           | 2.66e+05    |\n",
      "|    total_reward         | 1.83e+06    |\n",
      "|    total_reward_pct     | 183         |\n",
      "|    total_trades         | 78936       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016468829 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.053       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 57.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 583         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015662756 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0231      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00944    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 69.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.59e+06   |\n",
      "|    total_cost           | 2.41e+05   |\n",
      "|    total_reward         | 1.59e+06   |\n",
      "|    total_reward_pct     | 159        |\n",
      "|    total_trades         | 75263      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 603        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03779549 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.0374     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.12       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0216    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 19.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.12e+06    |\n",
      "|    total_cost           | 2.34e+05    |\n",
      "|    total_reward         | 2.12e+06    |\n",
      "|    total_reward_pct     | 212         |\n",
      "|    total_trades         | 75830       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 621         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010865979 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0933      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 639        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01182968 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.082      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.3       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.00989   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 88.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.37e+06    |\n",
      "|    total_cost           | 2.11e+05    |\n",
      "|    total_reward         | 1.37e+06    |\n",
      "|    total_reward_pct     | 137         |\n",
      "|    total_trades         | 73984       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 657         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020648167 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.94        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 3021, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2952664.37\n",
      "total_reward: 1952664.37\n",
      "total_cost: 226093.93\n",
      "total_trades: 75138\n",
      "Sharpe: 0.515\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.95e+06    |\n",
      "|    total_cost           | 2.26e+05    |\n",
      "|    total_reward         | 1.95e+06    |\n",
      "|    total_reward_pct     | 195         |\n",
      "|    total_trades         | 75138       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 675         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014383847 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 693          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050158203 |\n",
      "|    clip_fraction        | 0.0872       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44          |\n",
      "|    explained_variance   | 0.111        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.4         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00823     |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 70.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.4e+06     |\n",
      "|    total_cost           | 2.45e+05    |\n",
      "|    total_reward         | 2.4e+06     |\n",
      "|    total_reward_pct     | 240         |\n",
      "|    total_trades         | 76769       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 713         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010715859 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.48e+06     |\n",
      "|    total_cost           | 1.95e+05     |\n",
      "|    total_reward         | 1.48e+06     |\n",
      "|    total_reward_pct     | 148          |\n",
      "|    total_trades         | 71403        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 731          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027594883 |\n",
      "|    clip_fraction        | 0.0867       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44          |\n",
      "|    explained_variance   | 0.102        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.4         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00947     |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 73.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 749         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011555186 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.73e+06   |\n",
      "|    total_cost           | 2.02e+05   |\n",
      "|    total_reward         | 1.73e+06   |\n",
      "|    total_reward_pct     | 173        |\n",
      "|    total_trades         | 72504      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 767        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00867185 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13         |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 29.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.59e+06    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 1.59e+06    |\n",
      "|    total_reward_pct     | 159         |\n",
      "|    total_trades         | 74500       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 785         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017260915 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 803         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004436452 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 43.5        |\n",
      "-----------------------------------------\n",
      "day: 3021, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2514910.57\n",
      "total_reward: 1514910.57\n",
      "total_cost: 217424.06\n",
      "total_trades: 72989\n",
      "Sharpe: 0.450\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.51e+06    |\n",
      "|    total_cost           | 2.17e+05    |\n",
      "|    total_reward         | 1.51e+06    |\n",
      "|    total_reward_pct     | 151         |\n",
      "|    total_trades         | 72989       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 821         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012157908 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.01e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 2.01e+06    |\n",
      "|    total_reward_pct     | 201         |\n",
      "|    total_trades         | 73779       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 841         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026800249 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 859         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018138554 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.94e+06    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 1.94e+06    |\n",
      "|    total_reward_pct     | 194         |\n",
      "|    total_trades         | 75007       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 876         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007827761 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.87e+06    |\n",
      "|    total_cost           | 1.96e+05    |\n",
      "|    total_reward         | 1.87e+06    |\n",
      "|    total_reward_pct     | 187         |\n",
      "|    total_trades         | 72562       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 895         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024518384 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "======Trading from:  2021-01-05 to  2021-04-07\n",
      "Ensemble Strategy took:  587.6972678144773  minutes\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 PPO_model_kwargs,\n",
    "                                                 DDPG_model_kwargs,\n",
    "                                                 timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "-0qd8acMtj1f",
    "outputId": "34e407ec-0b6e-42fb-e707-0c577a79dc74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2015-10-02</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.065917</td>\n",
       "      <td>0.018347</td>\n",
       "      <td>0.24591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.27151</td>\n",
       "      <td>0.411378</td>\n",
       "      <td>0.232992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.019543</td>\n",
       "      <td>0.078859</td>\n",
       "      <td>0.15714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>-0.0599</td>\n",
       "      <td>-0.060643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.70411</td>\n",
       "      <td>0.52179</td>\n",
       "      <td>0.577368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.413728</td>\n",
       "      <td>0.348593</td>\n",
       "      <td>0.526571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.478532</td>\n",
       "      <td>0.379818</td>\n",
       "      <td>0.172271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.009192</td>\n",
       "      <td>-0.077251</td>\n",
       "      <td>0.13792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.648525</td>\n",
       "      <td>0.714891</td>\n",
       "      <td>0.698466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>693</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.091284</td>\n",
       "      <td>-0.16485</td>\n",
       "      <td>-0.132641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>756</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.047054</td>\n",
       "      <td>-0.008816</td>\n",
       "      <td>-0.005142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>819</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.448246</td>\n",
       "      <td>0.579053</td>\n",
       "      <td>0.454972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>882</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.178722</td>\n",
       "      <td>-0.288287</td>\n",
       "      <td>-0.275889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>945</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.345802</td>\n",
       "      <td>0.212053</td>\n",
       "      <td>0.572792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1008</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.126194</td>\n",
       "      <td>0.182138</td>\n",
       "      <td>0.229295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1071</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.096805</td>\n",
       "      <td>-0.17972</td>\n",
       "      <td>-0.077561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1134</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.473889</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>0.522123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1197</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.329659</td>\n",
       "      <td>-0.483208</td>\n",
       "      <td>-0.361307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1260</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.258138</td>\n",
       "      <td>-0.223579</td>\n",
       "      <td>-0.185427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1323</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.060038</td>\n",
       "      <td>0.101647</td>\n",
       "      <td>0.095316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1386</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.152108</td>\n",
       "      <td>0.178274</td>\n",
       "      <td>0.156717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0    126  2015-10-02  2016-01-04       DDPG   0.065917   0.018347     0.24591\n",
       "1    189  2016-01-04  2016-04-05        PPO    0.27151   0.411378    0.232992\n",
       "2    252  2016-04-05  2016-07-05       DDPG  -0.019543   0.078859     0.15714\n",
       "3    315  2016-07-05  2016-10-03        A2C   0.010097    -0.0599   -0.060643\n",
       "4    378  2016-10-03  2017-01-03        A2C    0.70411    0.52179    0.577368\n",
       "5    441  2017-01-03  2017-04-04       DDPG   0.413728   0.348593    0.526571\n",
       "6    504  2017-04-04  2017-07-05        A2C   0.478532   0.379818    0.172271\n",
       "7    567  2017-07-05  2017-10-03       DDPG   0.009192  -0.077251     0.13792\n",
       "8    630  2017-10-03  2018-01-03        PPO   0.648525   0.714891    0.698466\n",
       "9    693  2018-01-03  2018-04-05        A2C  -0.091284   -0.16485   -0.132641\n",
       "10   756  2018-04-05  2018-07-05       DDPG  -0.047054  -0.008816   -0.005142\n",
       "11   819  2018-07-05  2018-10-03        PPO   0.448246   0.579053    0.454972\n",
       "12   882  2018-10-03  2019-01-04        A2C  -0.178722  -0.288287   -0.275889\n",
       "13   945  2019-01-04  2019-04-05       DDPG   0.345802   0.212053    0.572792\n",
       "14  1008  2019-04-05  2019-07-08       DDPG   0.126194   0.182138    0.229295\n",
       "15  1071  2019-07-08  2019-10-04       DDPG  -0.096805   -0.17972   -0.077561\n",
       "16  1134  2019-10-04  2020-01-06       DDPG   0.473889     0.2243    0.522123\n",
       "17  1197  2020-01-06  2020-04-06        A2C  -0.329659  -0.483208   -0.361307\n",
       "18  1260  2020-04-06  2020-07-07       DDPG  -0.258138  -0.223579   -0.185427\n",
       "19  1323  2020-07-07  2020-10-05        PPO   0.060038   0.101647    0.095316\n",
       "20  1386  2020-10-05  2021-01-05        PPO   0.152108   0.178274    0.156717"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "X4JKB--8tj1g"
   },
   "outputs": [],
   "source": [
    "unique_trade_date = processed_full[(processed_full.date > val_test_start)&(processed_full.date <= val_test_end)].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "q9mKF7GGtj1g",
    "outputId": "5de4e5e6-d74b-4d12-b786-7e299dabd6a5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  0.7099604233615532\n"
     ]
    }
   ],
   "source": [
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "oyosyW7_tj1g",
    "outputId": "29307dfb-1d27-4fb7-dc7a-7a34a4902d59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>1.673370e+06</td>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>2021-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>1.662705e+06</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>-0.006373</td>\n",
       "      <td>2021-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>1.667396e+06</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>2021-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>1.676920e+06</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>2021-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>1.673579e+06</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>-0.001992</td>\n",
       "      <td>2021-04-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      account_value        date  daily_return    datadate\n",
       "1318   1.673370e+06  2021-03-30      0.001876  2021-03-30\n",
       "1319   1.662705e+06  2021-03-31     -0.006373  2021-03-31\n",
       "1320   1.667396e+06  2021-04-01      0.002821  2021-04-01\n",
       "1321   1.676920e+06  2021-04-05      0.005712  2021-04-05\n",
       "1322   1.673579e+06  2021-04-06     -0.001992  2021-04-06"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_account_value.set_index('date').account_value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "1053083a-d74c-48b0-a623-de33282e2fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.103060\n",
      "Cumulative returns     0.673579\n",
      "Annual volatility      0.155378\n",
      "Sharpe ratio           0.709960\n",
      "Calmar ratio           0.412739\n",
      "Stability              0.694572\n",
      "Max drawdown          -0.249698\n",
      "Omega ratio            1.146873\n",
      "Sortino ratio          0.965346\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.890930\n",
      "Daily value at risk   -0.019138\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lKRGftSS7pNM",
    "outputId": "4f77cef2-3934-444a-cacc-4ed8f94514ae",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (1322, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2016-01-04</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2021-04-05</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>62</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>10.356%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>67.692%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>15.543%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-24.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-1.914%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.97</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.58</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.13</td>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>2018-03-23</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.94</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>2016-02-11</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.72</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>2016-07-14</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.04%</td>\n",
       "      <td>-7.49%</td>\n",
       "      <td>4.64%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlLT9_5WN478"
   },
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YktexHcqh1jc",
    "outputId": "38566531-a3a0-4705-db30-d437e8f8fc73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_baseline() got an unexpected keyword argument 'baseline_start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a5951a96496e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==============Get Baseline Stats===========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m baseline_perf_stats=get_baseline('^DJI',\n\u001b[0m\u001b[1;32m      3\u001b[0m                                   \u001b[0mbaseline_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
      "\u001b[0;31mTypeError\u001b[0m: get_baseline() got an unexpected keyword argument 'baseline_start'"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_perf_stats=get_baseline('^DJI',\n",
    "                                  baseline_start = df_account_value.loc[0,'date'],\n",
    "                                  baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "FinRL_ensemble_stock_trading_ICAIF_2020.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
