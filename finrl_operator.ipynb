{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install alpaca_trade_api schedule holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb039e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import alpaca_trade_api as api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.trade.backtest import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import (\n",
    "    NormalActionNoise,\n",
    "    OrnsteinUhlenbeckActionNoise,)\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.td3.policies import MlpPolicy\n",
    "from stable_baselines3.common.noise import (\n",
    "    NormalActionNoise,\n",
    "    OrnsteinUhlenbeckActionNoise,\n",
    ")\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "\n",
    "import itertools\n",
    "from datetime import datetime, time\n",
    "import schedule\n",
    "import holidays\n",
    "\n",
    "holiday_check = holidays.US()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03842e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload # python 2.7 does not require this\n",
    "import finrl.model.models\n",
    "reload(finrl.model.models)\n",
    "from finrl.model.models import DRLEnsembleAgent\n",
    "\n",
    "import finrl.env.env_stocktrading \n",
    "reload(finrl.env.env_stocktrading)\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "\n",
    "import finrl.preprocessing.data\n",
    "reload(finrl.preprocessing.data)\n",
    "from finrl.preprocessing.data import data_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = api.REST('PK16U0CS4BSI2T7LLNJ7',\n",
    "        'Yh0OAxgUzUUhhiSzxQBgvpEUa7nc8lVhhzFVKK0B',\n",
    "        'https://paper-api.alpaca.markets', api_version='v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29073a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0454f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(agent, model_name, env):\n",
    "    \n",
    "    MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\n",
    "    \n",
    "#     model = get_latest_file(config.TRAINED_MODEL_DIR, model_name)\n",
    "    model = get_latest_file('./old_trained_models/', model_name)\n",
    "    model = MODELS[agent].load(model, env=env)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_daily(model, model_name, tb_log_name, total_timesteps=5000):\n",
    "    \n",
    "    model = model.learn(total_timesteps=total_timesteps, tb_log_name=tb_log_name)\n",
    "    model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name.upper()}_{total_timesteps//1000}k\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de286f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_trade(actions_trade):\n",
    "    \n",
    "    for ticker in actions_trade.columns[1:]:\n",
    "        if actions_trade.iloc[-1][ticker] > 0:\n",
    "            api.submit_order(\n",
    "                symbol=ticker,\n",
    "                qty=int(actions_trade.iloc[-1][ticker]),\n",
    "                side='buy',\n",
    "                type='market',\n",
    "                time_in_force='gtc'\n",
    "            )\n",
    "        elif actions_trade.iloc[-1][ticker] < 0:\n",
    "            api.submit_order(\n",
    "                symbol=ticker,\n",
    "                qty= abs(int(actions_trade.iloc[-1][ticker])),\n",
    "                side='sell',\n",
    "                type='market',\n",
    "                time_in_force='gtc'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c54ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_file(directory, file_name):\n",
    "    files = glob.glob(os.path.join(os.getcwd(), directory, file_name))\n",
    "#     files = glob.glob(os.path.join('/Users/evienguyen/Documents/FinRL/Modified FinRL', 'results', 'actions_trade_ensemble*'))\n",
    "\n",
    "    files.sort(key=os.path.getmtime)\n",
    "    print(files)\n",
    "    actions_trade =  sorted(files,key=os.path.getmtime)[-1]\n",
    "    \n",
    "    return actions_trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5cbc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_turb_thresh(data):\n",
    "    '''\n",
    "        Input: raw full data df\n",
    "        Return initial turbulence from full data until trading day\n",
    "    '''\n",
    "    \n",
    "    df_price_pivot = data.pivot(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "    # use returns to calculate turbulence\n",
    "    df_price_pivot = df_price_pivot.pct_change()\n",
    "    \n",
    "    print(df_price_pivot.shape)\n",
    "    print(df_price_pivot)\n",
    "    \n",
    "    unique_date = data.date.unique()\n",
    "    # start after a year\n",
    "    start = 252\n",
    "    turbulence_index = [0] * start\n",
    "    # turbulence_index = [0]\n",
    "    count = 0\n",
    "    for i in range(start, len(unique_date)):\n",
    "        current_price = df_price_pivot[df_price_pivot.index == unique_date[i]]\n",
    "        # use one year rolling window to calcualte covariance\n",
    "        hist_price = df_price_pivot[\n",
    "            (df_price_pivot.index < unique_date[i])\n",
    "            & (df_price_pivot.index >= unique_date[i - 252])\n",
    "        ]\n",
    "        # Drop tickers which has number missing values more than the \"oldest\" ticker\n",
    "        filtered_hist_price = hist_price.iloc[hist_price.isna().sum().min():].dropna(axis=1)\n",
    "\n",
    "        cov_temp = filtered_hist_price.cov()\n",
    "        current_temp = current_price[[x for x in filtered_hist_price]] - np.mean(filtered_hist_price, axis=0)\n",
    "        temp = current_temp.values.dot(np.linalg.pinv(cov_temp)).dot(\n",
    "            current_temp.values.T\n",
    "        )\n",
    "        if temp > 0:\n",
    "            count += 1\n",
    "            if count > 2:\n",
    "                turbulence_temp = temp[0][0]\n",
    "            else:\n",
    "                # avoid large outlier because of the calculation just begins\n",
    "                turbulence_temp = 0\n",
    "        else:\n",
    "            turbulence_temp = 0\n",
    "        turbulence_index.append(turbulence_temp)\n",
    "\n",
    "    turbulence_index = pd.DataFrame(\n",
    "        {\"date\": df_price_pivot.index, \"turbulence\": turbulence_index}\n",
    "    )\n",
    "    \n",
    "    data = data.merge(turbulence_index, on=\"date\")\n",
    "    data = data.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n",
    "    \n",
    "    insample_turbulence_threshold = np.quantile(data.turbulence.values, 0.85)\n",
    "    \n",
    "    return insample_turbulence_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_thresh = calc_turb_thresh(raw_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f14066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "validation_window = 63\n",
    "rebalance_window = 63\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "beginning = '2000-01-01'\n",
    "train_start = datetime.today() - timedelta(days=validation_window + rebalance_window)\n",
    "\n",
    "val_start = datetime.today() - timedelta(days=validation_window)\n",
    "val_start = val_start.strftime('%Y-%m-%d')\n",
    "\n",
    "val_end = datetime.today()\n",
    "val_end = val_end.strftime('%Y-%m-%d')\n",
    "\n",
    "raw_full_path = os.path.join(os.getcwd(), 'data', 'raw_full.csv')\n",
    "\n",
    "if not os.path.exists(raw_full_path):\n",
    "    print(\"Not found existing data\")\n",
    "    \n",
    "    raw_full = YahooDownloader(start_date = beginning,\n",
    "                         end_date = '2021-06-23',\n",
    "                         ticker_list = config.SP_500_TICKER).fetch_data()\n",
    "\n",
    "    raw_full.to_csv(raw_full_path)\n",
    "else:\n",
    "    print(\"Found existing data\")\n",
    "    raw_full = pd.read_csv(raw_full_path)\n",
    "    raw_full = raw_full.drop(columns = 'Unnamed: 0')\n",
    "    latest_date = raw_full.iloc[-1, :].date\n",
    "    print(today, latest_date)\n",
    "    if today != latest_date:\n",
    "        raw_full.append(\n",
    "            YahooDownloader(start_date = latest_date,\n",
    "                             end_date = today,\n",
    "                             ticker_list = config.SP_500_TICKER).fetch_data()\n",
    "        )\n",
    "\n",
    "init_thresh = calc_turb_thresh(raw_full)\n",
    "last_state_ensemble = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb4430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_daily_data(train_start, today):\n",
    "    '''\n",
    "        Return full processed 126 days data with turbulence + tech_indicators\n",
    "    '''\n",
    "    \n",
    "    raw_recent_path = os.path.join('data', 'raw_recent')\n",
    "    \n",
    "    if not os.path.exists(raw_recent_path):\n",
    "        \n",
    "        raw_recent = YahooDownloader(start_date = train_start - timedelta(days=365),\n",
    "                         end_date = today,\n",
    "                         ticker_list = config.SP_500_TICKER).fetch_data()\n",
    "    else:\n",
    "        raw_recent = pd.read_csv(raw_recent_path)\n",
    "        \n",
    "        latest_date = raw_recent.iloc[-1, :].date\n",
    "        \n",
    "        if today != latest_date:\n",
    "            raw_recent.append(\n",
    "                YahooDownloader(start_date = latest_date,\n",
    "                                 end_date = today,\n",
    "                                 ticker_list = config.SP_500_TICKER).fetch_data()\n",
    "            )\n",
    "        else:\n",
    "            raw_recent.iloc[-1, :] = YahooDownloader(start_date = today,\n",
    "                                 end_date = today,\n",
    "                                 ticker_list = config.SP_500_TICKER).fetch_data()\n",
    "    \n",
    "    fe = FeatureEngineer(\n",
    "                        use_technical_indicator=True,\n",
    "                        tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                        use_turbulence=True,\n",
    "                        user_defined_feature = False)\n",
    "\n",
    "    processed = fe.preprocess_data(raw_recent)\n",
    "    \n",
    "    list_ticker = processed[\"tic\"].unique().tolist()\n",
    "    list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "    combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "    processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "    processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "    processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "    processed_full = processed_full.fillna(0)\n",
    "    \n",
    "    return processed_full, raw_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_predict(df, raw_recent, last_state_ensemble, initial_turbulence):\n",
    "\n",
    "    timesteps_dict = {'a2c' : 30_000, \n",
    "                 'ppo' : 100_000, \n",
    "                 'ddpg' : 10_000\n",
    "                 }\n",
    "    \n",
    "    insample_turbulence_threshold = initial_turbulence\n",
    "\n",
    "    ppo_sharpe_list = []\n",
    "    ddpg_sharpe_list = []\n",
    "    a2c_sharpe_list = []\n",
    "\n",
    "    model_use = ''\n",
    "    # start = time.time()\n",
    "    stock_dimension = len(df.tic.unique())\n",
    "    state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "    print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "\n",
    "    env_kwargs = {\n",
    "        \"hmax\": 100, \n",
    "        \"initial_amount\": 100000, #TODO: dynamic change amount\n",
    "        \"buy_cost_pct\": 0.001, \n",
    "        \"sell_cost_pct\": 0.001, \n",
    "        \"state_space\": state_space, \n",
    "        \"stock_dim\": stock_dimension, \n",
    "        \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "        \"action_space\": stock_dimension, \n",
    "        \"reward_scaling\": 1e-4,\n",
    "        \"print_verbosity\":5\n",
    "\n",
    "    }\n",
    "    ensemble_agent = DRLEnsembleAgent(df=df,\n",
    "                     rebalance_window=rebalance_window, \n",
    "                     validation_window=validation_window, \n",
    "                     **env_kwargs)\n",
    "\n",
    "#     validation_start_date_list.append(val_start)\n",
    "#     validation_end_date_list.append(val_end)\n",
    "    # iteration_list.append(i)\n",
    "\n",
    "    print(\"============================================\")\n",
    "    ## initial state is empty\n",
    "    # if i - self.rebalance_window - self.validation_window == 0:\n",
    "    #     # inital state\n",
    "    #     initial = True\n",
    "    # else:\n",
    "    #     # previous state\n",
    "    #     initial = False\n",
    "\n",
    "    # Tuning trubulence index based on historical data\n",
    "    # Turbulence lookback window is one quarter (63 days)\n",
    "#     end_date_index = df.index[df[\"date\"] == ensemble_agent.unique_trade_date[train_start]].to_list()[-1]\n",
    "#     start_date_index = end_date_index - 63 + 1\n",
    "\n",
    "#     historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n",
    "\n",
    "#     historical_turbulence = historical_turbulence.drop_duplicates(subset=['date'])\n",
    "\n",
    "    historical_turbulence_mean = np.mean(df.iloc[64:, :].turbulence.values)\n",
    "\n",
    "    \n",
    "       \n",
    "    turbulence_index = calc_turb_thresh(raw_recent)\n",
    "    print(historical_turbulence_mean)\n",
    "    print(turbulence_index)\n",
    "    \n",
    "    if historical_turbulence_mean > insample_turbulence_threshold:\n",
    "        # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
    "        # then we assume that the current market is volatile,\n",
    "        # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
    "        # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
    "        turbulence_threshold = insample_turbulence_threshold\n",
    "    else:\n",
    "        # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
    "        # then we tune up the turbulence_threshold, meaning we lower the risk\n",
    "        turbulence_threshold = np.quantile(turbulence_index, 1)\n",
    "    print(\"turbulence_threshold: \", turbulence_threshold)\n",
    "\n",
    "    ############## Environment Setup starts ##############\n",
    "    ## training env\n",
    "#     train = data_split(ensemble_agent.df, start=train_start, end=val_start)\n",
    "#     ensemble_agent.train_env = DummyVecEnv([lambda: StockTradingEnv(train,\n",
    "#                                                         ensemble_agent.stock_dim,\n",
    "#                                                         ensemble_agent.hmax,\n",
    "#                                                         ensemble_agent.initial_amount,\n",
    "#                                                         ensemble_agent.buy_cost_pct,\n",
    "#                                                         ensemble_agent.sell_cost_pct,\n",
    "#                                                         ensemble_agent.reward_scaling,\n",
    "#                                                         ensemble_agent.state_space,\n",
    "#                                                         ensemble_agent.action_space,\n",
    "#                                                         ensemble_agent.tech_indicator_list,\n",
    "#                                                         print_verbosity=ensemble_agent.print_verbosity)])\n",
    "\n",
    "    validation = data_split(ensemble_agent.df, start = df.date.unique()[-63], end = df.date.unique()[-1])\n",
    "    ############## Environment Setup ends ##############\n",
    "\n",
    "    ############## Validation starts ##############\n",
    "\n",
    "    print(\"======A2C Validation from: \", val_start, \"to \",val_end)\n",
    "    val_env_a2c = DummyVecEnv([lambda: StockTradingEnv(validation,\n",
    "                                                        ensemble_agent.stock_dim,\n",
    "                                                        ensemble_agent.hmax,\n",
    "                                                        ensemble_agent.initial_amount,\n",
    "                                                        ensemble_agent.buy_cost_pct,\n",
    "                                                        ensemble_agent.sell_cost_pct,\n",
    "                                                        ensemble_agent.reward_scaling,\n",
    "                                                        ensemble_agent.state_space,\n",
    "                                                        ensemble_agent.action_space,\n",
    "                                                        ensemble_agent.tech_indicator_list,\n",
    "                                                        turbulence_threshold=turbulence_threshold,\n",
    "#                                                         iteration=i,\n",
    "                                                        model_name='A2C',\n",
    "                                                        mode='validation',\n",
    "                                                        print_verbosity=ensemble_agent.print_verbosity)])\n",
    "    val_obs_a2c = val_env_a2c.reset()\n",
    "\n",
    "    model_a2c = load_model('a2c', 'A2C_30k*', env=val_env_a2c)\n",
    "    \n",
    "    val_a2c_model =  ensemble_agent.DRL_validation(model=model_a2c,test_data=validation,test_env=val_env_a2c,test_obs=val_obs_a2c)\n",
    "    sharpe_a2c = ensemble_agent.get_validation_sharpe(model_name=\"A2C\")\n",
    "    print(\"A2C Sharpe Ratio: \", sharpe_a2c)\n",
    "\n",
    "    print(\"======PPO Validation from: \", val_start, \"to \",val_end)\n",
    "    val_env_ppo = DummyVecEnv([lambda: StockTradingEnv(validation,\n",
    "                                                        ensemble_agent.stock_dim,\n",
    "                                                        ensemble_agent.hmax,\n",
    "                                                        ensemble_agent.initial_amount,\n",
    "                                                        ensemble_agent.buy_cost_pct,\n",
    "                                                        ensemble_agent.sell_cost_pct,\n",
    "                                                        ensemble_agent.reward_scaling,\n",
    "                                                        ensemble_agent.state_space,\n",
    "                                                        ensemble_agent.action_space,\n",
    "                                                        ensemble_agent.tech_indicator_list,\n",
    "                                                        turbulence_threshold=turbulence_threshold,\n",
    "#                                                         iteration=i,\n",
    "                                                        model_name='PPO',\n",
    "                                                        mode='validation',\n",
    "                                                        print_verbosity=ensemble_agent.print_verbosity)])\n",
    "    val_obs_ppo = val_env_ppo.reset()\n",
    "    \n",
    "    model_ppo = load_model('ppo', 'PPO_100k*', env=val_env_ppo)\n",
    "    \n",
    "    val_ppo_model = ensemble_agent.DRL_validation(model=model_ppo,test_data=validation,test_env=val_env_ppo,test_obs=val_obs_ppo)\n",
    "    sharpe_ppo = ensemble_agent.get_validation_sharpe(model_name=\"PPO\")\n",
    "    print(\"PPO Sharpe Ratio: \", sharpe_ppo)\n",
    "\n",
    "    print(\"======DDPG Validation from: \", val_start, \"to \",val_end)\n",
    "    val_env_ddpg = DummyVecEnv([lambda: StockTradingEnv(validation,\n",
    "                                                        ensemble_agent.stock_dim,\n",
    "                                                        ensemble_agent.hmax,\n",
    "                                                        ensemble_agent.initial_amount,\n",
    "                                                        ensemble_agent.buy_cost_pct,\n",
    "                                                        ensemble_agent.sell_cost_pct,\n",
    "                                                        ensemble_agent.reward_scaling,\n",
    "                                                        ensemble_agent.state_space,\n",
    "                                                        ensemble_agent.action_space,\n",
    "                                                        ensemble_agent.tech_indicator_list,\n",
    "                                                        turbulence_threshold=turbulence_threshold,\n",
    "#                                                         iteration=i,\n",
    "                                                        model_name='DDPG',\n",
    "                                                        mode='validation',\n",
    "                                                        print_verbosity=ensemble_agent.print_verbosity)])\n",
    "    val_obs_ddpg = val_env_ddpg.reset()\n",
    "    \n",
    "    model_ddpg = load_model('ddpg', 'DDPG_10k*', env=val_env_ddpg)\n",
    "    \n",
    "    val_ddpg_model = ensemble_agent.DRL_validation(model=model_ddpg,test_data=validation,test_env=val_env_ddpg,test_obs=val_obs_ddpg)\n",
    "    sharpe_ddpg = ensemble_agent.get_validation_sharpe(model_name=\"DDPG\")\n",
    "    print(\"DDPG Sharpe Ratio: \", sharpe_ddpg)\n",
    "\n",
    "    ppo_sharpe_list.append(sharpe_ppo)\n",
    "    a2c_sharpe_list.append(sharpe_a2c)\n",
    "    ddpg_sharpe_list.append(sharpe_ddpg)\n",
    "\n",
    "    print(\"======Best Model Retraining from: \", val_start, \"to \",\n",
    "          val_end)\n",
    "    # Environment setup for model retraining up to first trade date\n",
    "    train_full = data_split(ensemble_agent.df, start = df.date.unique()[-63], end = df.date.unique()[-1])\n",
    "    train_full_env = DummyVecEnv([lambda: StockTradingEnv(train_full,\n",
    "                                                        ensemble_agent.stock_dim,\n",
    "                                                        ensemble_agent.hmax,\n",
    "                                                        ensemble_agent.initial_amount,\n",
    "                                                        ensemble_agent.buy_cost_pct,\n",
    "                                                        ensemble_agent.sell_cost_pct,\n",
    "                                                        ensemble_agent.reward_scaling,\n",
    "                                                        ensemble_agent.state_space,\n",
    "                                                        ensemble_agent.action_space,\n",
    "                                                        ensemble_agent.tech_indicator_list,\n",
    "                                                        print_verbosity=ensemble_agent.print_verbosity)])\n",
    "    # Model Selection based on sharpe ratio\n",
    "    if (sharpe_ppo >= sharpe_a2c) & (sharpe_ppo >= sharpe_ddpg):\n",
    "        model_use = 'ppo'\n",
    "        model_ensemble = load_model('ppo', 'PPO_100k*', env=train_full_env)\n",
    "\n",
    "    elif (sharpe_a2c > sharpe_ppo) & (sharpe_a2c > sharpe_ddpg):\n",
    "        model_use = 'a2c'\n",
    "        model_ensemble = load_model('a2c', 'A2C_30k*', env=train_full_env)\n",
    "    else:\n",
    "        model_use = 'ddpg'\n",
    "        model_ensemble = load_model('ddpg', 'DDPG_10k*', env=train_full_env)\n",
    "        \n",
    "    model_ensemble = train_model_daily(model_ensemble, \"ensemble\", tb_log_name=\"ensemble_{}\".format(model_use), total_timesteps=timesteps_dict[model_use]) #50_000\n",
    "    ############## Training and Validation ends ##############\n",
    "\n",
    "    ############## Trading starts ##############\n",
    "    # TODO: Update last state from correct environment\n",
    "    print(\"======Trading from: \", val_start, \"to \", val_end)\n",
    "\n",
    "    last_state_ensemble = ensemble_agent.DRL_prediction(model=model_ensemble, name=\"ensemble\",\n",
    "                                             last_state=last_state_ensemble,\n",
    "                                             turbulence_threshold = turbulence_threshold,\n",
    "                                             initial=(len(last_state_ensemble) == 0),\n",
    "                                             trade_data=train_full)\n",
    "    \n",
    "    return last_state_ensemble\n",
    "    ############## Trading ends #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    in_trading_time = (\n",
    "        time(hour=9,minute=30) <= datetime.now().time() < time(hour=16, minute=0) and\n",
    "        (datetime.now().date() not in holiday_check)\n",
    "    )\n",
    "    print(\"DATE: {} HOUR: {} \\nHOLIDAY: {}\".format(datetime.now().date(), datetime.now().time(), (datetime.now().date() in holiday_check)))\n",
    "    \n",
    "    if in_trading_time:\n",
    "        \n",
    "        daily_processed_df, raw_recent = refresh_daily_data(train_start, today)\n",
    "        \n",
    "        last_state_path = os.path.join(os.getcwd(), 'results', 'last_state_ensemble_61.csv')\n",
    "        if len(last_state_ensemble) == 0:\n",
    "            if not os.path.exists(last_state_path):\n",
    "                print(\"Not found existing data\")\n",
    "                last_state_ensemble = []\n",
    "        else:\n",
    "            print(\"Found existing data\")\n",
    "\n",
    "            last_state_ensemble = pd.read_csv(last_state_path)\n",
    "\n",
    "            last_state_ensemble = last_state_ensemble.last_state.tolist()\n",
    "\n",
    "\n",
    "                \n",
    "        last_state_ensemble = daily_predict(daily_processed_df, last_state_ensemble, raw_recent, init_thresh)\n",
    "\n",
    "        actions_trade = pd.read_csv(get_latest_file('results','actions_trade_ensemble*'))\n",
    "        perform_trade(actions_trade=actions_trade)\n",
    "        \n",
    "    else:\n",
    "        print(\"Trading close\")\n",
    "      \n",
    "schedule.clear()\n",
    "schedule.every(15).minutes.do(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.get_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f77e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    schedule.run_pending()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fda597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
