{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL/blob/master/FinRL_ensemble_stock_trading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "dcf73e63-fece-409e-e887-2d33774cdf94"
   },
   "outputs": [],
   "source": [
    "## install finrl library\n",
    "# !pip3 install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/evienguyen/Documents/FinRL/FinRL',\n",
       " '/usr/local/Cellar/python@3.9/3.9.1_6/Frameworks/Python.framework/Versions/3.9/lib/python39.zip',\n",
       " '/usr/local/Cellar/python@3.9/3.9.1_6/Frameworks/Python.framework/Versions/3.9/lib/python3.9',\n",
       " '/usr/local/Cellar/python@3.9/3.9.1_6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/Users/evienguyen/Library/Python/3.9/lib/python/site-packages',\n",
       " '/usr/local/lib/python3.9/site-packages',\n",
       " '/Users/evienguyen/Library/Python/3.9/lib/python/site-packages/IPython/extensions',\n",
       " '/Users/evienguyen/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/evienguyen/Documents/FinRL/FinRL/finrl'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble_agent.print_test()\n",
    "import os\n",
    "os.chdir('/Users/evienguyen/Documents/FinRL/FinRL/finrl')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.trade.backtest import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DRL_prediction', 'DRL_validation', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'get_model', 'get_validation_sharpe', 'print_test', 'run_ensemble_strategy', 'train_model']\n"
     ]
    }
   ],
   "source": [
    " print (dir(DRLEnsembleAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Users/evienguyen/Documents/FinRL/FinRL/finrl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "fe5cd33c-9434-4372-b836-622a50f0d3d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000-01-01'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "a42433a2-c7c9-4c06-b53f-28723b4957af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'MSFT', 'JPM', 'V', 'RTX', 'PG', 'GS', 'NKE', 'DIS', 'AXP', 'HD', 'INTC', 'WMT', 'IBM', 'MRK', 'UNH', 'KO', 'CAT', 'TRV', 'JNJ', 'CVX', 'MCD', 'VZ', 'CSCO', 'XOM', 'BA', 'MMM', 'PFE', 'WBA', 'DD']\n"
     ]
    }
   ],
   "source": [
    "print(config.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "b9293979-3d5b-48f6-9b99-6facf5bc5f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (86400, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = '2010-01-01',\n",
    "                     end_date = '2021-06-14',\n",
    "                     ticker_list = config.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "GiRuFOTOtj1Y",
    "outputId": "015897f3-d0d9-49d6-a28d-d2888e3c7a1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>7.622500</td>\n",
       "      <td>7.660714</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>6.572422</td>\n",
       "      <td>493729600.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>40.810001</td>\n",
       "      <td>41.099998</td>\n",
       "      <td>40.389999</td>\n",
       "      <td>34.405621</td>\n",
       "      <td>6894300.0</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>55.720001</td>\n",
       "      <td>56.389999</td>\n",
       "      <td>54.799999</td>\n",
       "      <td>43.777542</td>\n",
       "      <td>6186700.0</td>\n",
       "      <td>BA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>57.650002</td>\n",
       "      <td>59.189999</td>\n",
       "      <td>57.509998</td>\n",
       "      <td>42.787361</td>\n",
       "      <td>7325600.0</td>\n",
       "      <td>CAT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>24.110001</td>\n",
       "      <td>24.840000</td>\n",
       "      <td>24.010000</td>\n",
       "      <td>18.332541</td>\n",
       "      <td>59853700.0</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close       volume   tic  \\\n",
       "0  2010-01-04   7.622500   7.660714   7.585000   6.572422  493729600.0  AAPL   \n",
       "1  2010-01-04  40.810001  41.099998  40.389999  34.405621    6894300.0   AXP   \n",
       "2  2010-01-04  55.720001  56.389999  54.799999  43.777542    6186700.0    BA   \n",
       "3  2010-01-04  57.650002  59.189999  57.509998  42.787361    7325600.0   CAT   \n",
       "4  2010-01-04  24.110001  24.840000  24.010000  18.332541   59853700.0  CSCO   \n",
       "\n",
       "   day  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "DSw4ZEzVtj1Z",
    "outputId": "517b31f3-e7b4-419b-9322-517babcd5546"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86395</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>234.389999</td>\n",
       "      <td>235.440002</td>\n",
       "      <td>233.710007</td>\n",
       "      <td>234.960007</td>\n",
       "      <td>5376500.0</td>\n",
       "      <td>V</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86396</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>57.490002</td>\n",
       "      <td>57.549999</td>\n",
       "      <td>57.009998</td>\n",
       "      <td>57.330002</td>\n",
       "      <td>12924100.0</td>\n",
       "      <td>VZ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86397</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>55.820000</td>\n",
       "      <td>54.810001</td>\n",
       "      <td>55.310001</td>\n",
       "      <td>3942600.0</td>\n",
       "      <td>WBA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86398</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>140.229996</td>\n",
       "      <td>140.850006</td>\n",
       "      <td>139.860001</td>\n",
       "      <td>140.750000</td>\n",
       "      <td>8408800.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86399</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>63.009998</td>\n",
       "      <td>63.189999</td>\n",
       "      <td>62.139999</td>\n",
       "      <td>62.169998</td>\n",
       "      <td>17618900.0</td>\n",
       "      <td>XOM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date        open        high         low       close      volume  \\\n",
       "86395  2021-06-11  234.389999  235.440002  233.710007  234.960007   5376500.0   \n",
       "86396  2021-06-11   57.490002   57.549999   57.009998   57.330002  12924100.0   \n",
       "86397  2021-06-11   55.580002   55.820000   54.810001   55.310001   3942600.0   \n",
       "86398  2021-06-11  140.229996  140.850006  139.860001  140.750000   8408800.0   \n",
       "86399  2021-06-11   63.009998   63.189999   62.139999   62.169998  17618900.0   \n",
       "\n",
       "       tic  day  \n",
       "86395    V    4  \n",
       "86396   VZ    4  \n",
       "86397  WBA    4  \n",
       "86398  WMT    4  \n",
       "86399  XOM    4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "45525740-8ce0-4031-c2c5-bfd6a7a1cd7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86400, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "4hYkeaPiICHS",
    "outputId": "26d3122c-f143-4671-8891-4ac5ce27d2e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>7.622500</td>\n",
       "      <td>7.660714</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>6.572422</td>\n",
       "      <td>493729600.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>40.810001</td>\n",
       "      <td>41.099998</td>\n",
       "      <td>40.389999</td>\n",
       "      <td>34.405621</td>\n",
       "      <td>6894300.0</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>55.720001</td>\n",
       "      <td>56.389999</td>\n",
       "      <td>54.799999</td>\n",
       "      <td>43.777542</td>\n",
       "      <td>6186700.0</td>\n",
       "      <td>BA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>57.650002</td>\n",
       "      <td>59.189999</td>\n",
       "      <td>57.509998</td>\n",
       "      <td>42.787361</td>\n",
       "      <td>7325600.0</td>\n",
       "      <td>CAT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>24.110001</td>\n",
       "      <td>24.840000</td>\n",
       "      <td>24.010000</td>\n",
       "      <td>18.332541</td>\n",
       "      <td>59853700.0</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close       volume   tic  \\\n",
       "0  2010-01-04   7.622500   7.660714   7.585000   6.572422  493729600.0  AAPL   \n",
       "1  2010-01-04  40.810001  41.099998  40.389999  34.405621    6894300.0   AXP   \n",
       "2  2010-01-04  55.720001  56.389999  54.799999  43.777542    6186700.0    BA   \n",
       "3  2010-01-04  57.650002  59.189999  57.509998  42.787361    7325600.0   CAT   \n",
       "4  2010-01-04  24.110001  24.840000  24.010000  18.332541   59853700.0  CSCO   \n",
       "\n",
       "   day  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgXfBcjxtj1a",
    "outputId": "1a887a88-8cb0-4d02-c518-374278251850",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "R_3v-ycktj1b"
   },
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "grvhGJJII3Xn",
    "outputId": "eded8f63-ac44-4a51-f2bb-4a54a07cbd11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72724</th>\n",
       "      <td>2016-08-24</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>30.980000</td>\n",
       "      <td>31.200001</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>26.729086</td>\n",
       "      <td>24474700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.215539</td>\n",
       "      <td>26.894651</td>\n",
       "      <td>26.140128</td>\n",
       "      <td>61.509439</td>\n",
       "      <td>100.043110</td>\n",
       "      <td>16.482140</td>\n",
       "      <td>26.391747</td>\n",
       "      <td>25.514014</td>\n",
       "      <td>9.208442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15567</th>\n",
       "      <td>2011-06-06</td>\n",
       "      <td>WBA</td>\n",
       "      <td>43.009998</td>\n",
       "      <td>43.470001</td>\n",
       "      <td>42.939999</td>\n",
       "      <td>33.225731</td>\n",
       "      <td>5803800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>34.937304</td>\n",
       "      <td>33.013365</td>\n",
       "      <td>52.158286</td>\n",
       "      <td>-35.764926</td>\n",
       "      <td>25.048593</td>\n",
       "      <td>33.623655</td>\n",
       "      <td>32.613913</td>\n",
       "      <td>18.143360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50119</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>NKE</td>\n",
       "      <td>38.270000</td>\n",
       "      <td>38.625000</td>\n",
       "      <td>38.195000</td>\n",
       "      <td>35.548630</td>\n",
       "      <td>5825800.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.146177</td>\n",
       "      <td>36.713782</td>\n",
       "      <td>35.250203</td>\n",
       "      <td>50.603858</td>\n",
       "      <td>-52.915138</td>\n",
       "      <td>0.714373</td>\n",
       "      <td>35.845718</td>\n",
       "      <td>35.294847</td>\n",
       "      <td>58.146455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80902</th>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>RTX</td>\n",
       "      <td>76.563873</td>\n",
       "      <td>77.079926</td>\n",
       "      <td>76.544998</td>\n",
       "      <td>69.725555</td>\n",
       "      <td>5409433.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984325</td>\n",
       "      <td>69.911118</td>\n",
       "      <td>67.111163</td>\n",
       "      <td>68.935131</td>\n",
       "      <td>93.177054</td>\n",
       "      <td>23.993901</td>\n",
       "      <td>67.248936</td>\n",
       "      <td>65.553472</td>\n",
       "      <td>13.999506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99215</th>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>CVX</td>\n",
       "      <td>111.029999</td>\n",
       "      <td>113.820000</td>\n",
       "      <td>110.910004</td>\n",
       "      <td>100.559296</td>\n",
       "      <td>8470700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.149488</td>\n",
       "      <td>101.979245</td>\n",
       "      <td>95.252855</td>\n",
       "      <td>50.299419</td>\n",
       "      <td>46.490710</td>\n",
       "      <td>2.568560</td>\n",
       "      <td>98.258585</td>\n",
       "      <td>100.398791</td>\n",
       "      <td>40.398194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date   tic        open        high         low       close  \\\n",
       "72724  2016-08-24  CSCO   30.980000   31.200001   30.950001   26.729086   \n",
       "15567  2011-06-06   WBA   43.009998   43.470001   42.939999   33.225731   \n",
       "50119  2014-08-01   NKE   38.270000   38.625000   38.195000   35.548630   \n",
       "80902  2017-05-23   RTX   76.563873   77.079926   76.544998   69.725555   \n",
       "99215  2019-01-24   CVX  111.029999  113.820000  110.910004  100.559296   \n",
       "\n",
       "           volume  day      macd     boll_ub    boll_lb     rsi_30  \\\n",
       "72724  24474700.0  2.0  0.215539   26.894651  26.140128  61.509439   \n",
       "15567   5803800.0  0.0  0.120316   34.937304  33.013365  52.158286   \n",
       "50119   5825800.0  4.0  0.146177   36.713782  35.250203  50.603858   \n",
       "80902   5409433.0  1.0  0.984325   69.911118  67.111163  68.935131   \n",
       "99215   8470700.0  3.0  0.149488  101.979245  95.252855  50.299419   \n",
       "\n",
       "           cci_30      dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "72724  100.043110  16.482140     26.391747     25.514014    9.208442  \n",
       "15567  -35.764926  25.048593     33.623655     32.613913   18.143360  \n",
       "50119  -52.915138   0.714373     35.845718     35.294847   58.146455  \n",
       "80902   93.177054  23.993901     67.248936     65.553472   13.999506  \n",
       "99215   46.490710   2.568560     98.258585    100.398791   40.398194  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_full_copy = processed_full\n",
    "processed_full_copy.set_index('date',inplace=True)\n",
    "%matplotlib inline\n",
    "processed_full_copy.turbulence.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "80acc632-dbc2-4de7-b9cd-0685b130fe42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "85af7d0d-3cf3-4473-a62d-e9712c92fe44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, State Space: 301\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001, \n",
    "    \"sell_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_full.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "v-gthCxMtj1d"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "train_start = '2010-01-01'\n",
    "train_end = '2016-10-01'\n",
    "val_test_start = '2016-10-01'\n",
    "val_test_end = '2021-06-14'\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed_full,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KsfEHa_Etj1d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.0005\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      \"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 50_000,\n",
    "                      \"learning_rate\": 0.000005,\n",
    "                      \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 30_000, \n",
    "                 'ppo' : 100_000, \n",
    "                 'ddpg' : 10_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1lyCECstj1e",
    "outputId": "940e556d-8fbd-4112-c463-b155f6a0f581",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "16.887756699950526\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2016-10-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_7\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.302    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -95.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0139  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 11.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0478   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 54.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.01e+06 |\n",
      "|    total_cost         | 1.06e+05 |\n",
      "|    total_reward       | 1.01e+06 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 42256    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 51.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 58.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.156   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -64.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.2e+06  |\n",
      "|    total_cost         | 8.43e+04 |\n",
      "|    total_reward       | 1.2e+06  |\n",
      "|    total_reward_pct   | 120      |\n",
      "|    total_trades       | 38602    |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0489  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -116     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0252  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -120     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 11.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.398    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 13.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.416    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.81e+06 |\n",
      "|    total_cost         | 6.57e+04 |\n",
      "|    total_reward       | 8.08e+05 |\n",
      "|    total_reward_pct   | 80.8     |\n",
      "|    total_trades       | 38140    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0924   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -199     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 30.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -50.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -143     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.69e+06  |\n",
      "|    total_cost         | 4.07e+04  |\n",
      "|    total_reward       | 6.86e+05  |\n",
      "|    total_reward_pct   | 68.6      |\n",
      "|    total_trades       | 34375     |\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -8.34e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 36.3      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.744     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.404   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -74.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.162    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 83.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.52     |\n",
      "------------------------------------\n",
      "day: 1698, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1637265.29\n",
      "total_reward: 637265.29\n",
      "total_cost: 38321.21\n",
      "total_trades: 33598\n",
      "Sharpe: 0.529\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.64e+06 |\n",
      "|    total_cost         | 3.83e+04 |\n",
      "|    total_reward       | 6.37e+05 |\n",
      "|    total_reward_pct   | 63.7     |\n",
      "|    total_trades       | 33598    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -78.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0419   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 137      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0478  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -70.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.02e+06 |\n",
      "|    total_cost         | 2.65e+04 |\n",
      "|    total_reward       | 1.02e+06 |\n",
      "|    total_reward_pct   | 102      |\n",
      "|    total_trades       | 32499    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.215   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -130     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -8.99    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.176    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.16     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -185     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 21.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.94e+06  |\n",
      "|    total_cost         | 1.94e+04  |\n",
      "|    total_reward       | 9.43e+05  |\n",
      "|    total_reward_pct   | 94.3      |\n",
      "|    total_trades       | 31373     |\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -0.000701 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -48.2     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.19      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -2.25     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.449     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 23        |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.703     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 26.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.52e+06 |\n",
      "|    total_cost         | 2.71e+04 |\n",
      "|    total_reward       | 5.18e+05 |\n",
      "|    total_reward_pct   | 51.8     |\n",
      "|    total_trades       | 33136    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.024    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -90.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -54.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -53.7     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 3.32      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.57e+06 |\n",
      "|    total_cost         | 2.74e+04 |\n",
      "|    total_reward       | 5.65e+05 |\n",
      "|    total_reward_pct   | 56.5     |\n",
      "|    total_trades       | 32815    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.0516  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -1.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.356    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.186    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 92.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.0246   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -121     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 11.3     |\n",
      "------------------------------------\n",
      "day: 1698, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1597284.23\n",
      "total_reward: 597284.23\n",
      "total_cost: 21451.69\n",
      "total_trades: 31458\n",
      "Sharpe: 0.524\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.6e+06  |\n",
      "|    total_cost         | 2.15e+04 |\n",
      "|    total_reward       | 5.97e+05 |\n",
      "|    total_reward_pct   | 59.7     |\n",
      "|    total_trades       | 31458    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -61      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.00163 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 22.1     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.524    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 43       |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.0809  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 61.5     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 4.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.7e+06  |\n",
      "|    total_cost         | 2.46e+04 |\n",
      "|    total_reward       | 7.01e+05 |\n",
      "|    total_reward_pct   | 70.1     |\n",
      "|    total_trades       | 30949    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -1.28    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 52.8     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 3.13     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.129    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -64.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.53e+06 |\n",
      "|    total_cost         | 1.82e+04 |\n",
      "|    total_reward       | 5.31e+05 |\n",
      "|    total_reward_pct   | 53.1     |\n",
      "|    total_trades       | 30300    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.0728   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -27      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -59.7    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 36.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.788    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -38.4    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.75e+06 |\n",
      "|    total_cost         | 1.46e+04 |\n",
      "|    total_reward       | 7.51e+05 |\n",
      "|    total_reward_pct   | 75.1     |\n",
      "|    total_trades       | 29675    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0.00426  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 40.1     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 6.46     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -9.54e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -28.3     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.518     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -65.4    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.73e+06 |\n",
      "|    total_cost         | 1.1e+04  |\n",
      "|    total_reward       | 7.28e+05 |\n",
      "|    total_reward_pct   | 72.8     |\n",
      "|    total_trades       | 29491    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0.242    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 9.75     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0724   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.162   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -75.7    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 5.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -19.5    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.44     |\n",
      "------------------------------------\n",
      "day: 1698, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1822674.89\n",
      "total_reward: 822674.89\n",
      "total_cost: 9002.59\n",
      "total_trades: 28485\n",
      "Sharpe: 0.676\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.82e+06 |\n",
      "|    total_cost         | 9e+03    |\n",
      "|    total_reward       | 8.23e+05 |\n",
      "|    total_reward_pct   | 82.3     |\n",
      "|    total_trades       | 28485    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 4.24     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0229   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 26.2     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.735    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -50.1    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -169     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 18.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.52e+06 |\n",
      "|    total_cost         | 6.88e+03 |\n",
      "|    total_reward       | 5.19e+05 |\n",
      "|    total_reward_pct   | 51.9     |\n",
      "|    total_trades       | 27936    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 17.4     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.209    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | -0.0554  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 26.9     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 50.8     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.53e+06 |\n",
      "|    total_cost         | 6.77e+03 |\n",
      "|    total_reward       | 5.33e+05 |\n",
      "|    total_reward_pct   | 53.3     |\n",
      "|    total_trades       | 27206    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 66.9     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 56       |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | -0.578   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 12.9     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.139    |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2016-10-03 to  2017-01-03\n",
      "A2C Sharpe Ratio:  0.7357610746881126\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_6\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.84e+06 |\n",
      "|    total_cost       | 1.59e+05 |\n",
      "|    total_reward     | 8.39e+05 |\n",
      "|    total_reward_pct | 83.9     |\n",
      "|    total_trades     | 48688    |\n",
      "| time/               |          |\n",
      "|    fps              | 164      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "day: 1698, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1789942.56\n",
      "total_reward: 789942.56\n",
      "total_cost: 159962.04\n",
      "total_trades: 48804\n",
      "Sharpe: 0.726\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.79e+06    |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | 7.9e+05     |\n",
      "|    total_reward_pct     | 79          |\n",
      "|    total_trades         | 48804       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014702624 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00178    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.57        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 7.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.55e+06    |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 5.55e+05    |\n",
      "|    total_reward_pct     | 55.5        |\n",
      "|    total_trades         | 48569       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013905538 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.032      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.83        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 8.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.81e+06    |\n",
      "|    total_cost           | 1.62e+05    |\n",
      "|    total_reward         | 8.05e+05    |\n",
      "|    total_reward_pct     | 80.5        |\n",
      "|    total_trades         | 48966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020712512 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00685    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.15        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.77        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.81e+06   |\n",
      "|    total_cost           | 1.62e+05   |\n",
      "|    total_reward         | 8.11e+05   |\n",
      "|    total_reward_pct     | 81.1       |\n",
      "|    total_trades         | 48795      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 63         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01957041 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | -0.00989   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.29       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0272    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 8.45       |\n",
      "----------------------------------------\n",
      "day: 1698, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1942318.17\n",
      "total_reward: 942318.17\n",
      "total_cost: 160646.37\n",
      "total_trades: 48747\n",
      "Sharpe: 0.765\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.94e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 9.42e+05    |\n",
      "|    total_reward_pct     | 94.2        |\n",
      "|    total_trades         | 48747       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017575601 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0348     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.59        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.12e+06    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | 1.12e+06    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 48456       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018077906 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0306      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.47        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.9         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.06e+06    |\n",
      "|    total_cost           | 1.59e+05    |\n",
      "|    total_reward         | 1.06e+06    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 48585       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021956645 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0251      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.85        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.01        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.94e+06  |\n",
      "|    total_cost           | 1.54e+05  |\n",
      "|    total_reward         | 9.42e+05  |\n",
      "|    total_reward_pct     | 94.2      |\n",
      "|    total_trades         | 47940     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 159       |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0220487 |\n",
      "|    clip_fraction        | 0.219     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43       |\n",
      "|    explained_variance   | 0.0385    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 3.98      |\n",
      "|    n_updates            | 80        |\n",
      "|    policy_gradient_loss | -0.0233   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 9.85      |\n",
      "---------------------------------------\n",
      "day: 1698, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2103599.74\n",
      "total_reward: 1103599.74\n",
      "total_cost: 157910.27\n",
      "total_trades: 48471\n",
      "Sharpe: 0.844\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 48471       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030122241 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0263      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.85        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.09e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 1.09e+06    |\n",
      "|    total_reward_pct     | 109         |\n",
      "|    total_trades         | 48904       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020384774 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.009       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.13        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.06e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 1.06e+06    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 47829       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027547305 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0547      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.49        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.6         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.96e+06   |\n",
      "|    total_cost           | 1.5e+05    |\n",
      "|    total_reward         | 9.64e+05   |\n",
      "|    total_reward_pct     | 96.4       |\n",
      "|    total_trades         | 47539      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 167        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01741739 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0275     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.3        |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0201    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 8.53       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.92e+06    |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 9.2e+05     |\n",
      "|    total_reward_pct     | 92          |\n",
      "|    total_trades         | 47629       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018625122 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.042       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.07        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.25        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1926104.01\n",
      "total_reward: 926104.01\n",
      "total_cost: 149714.17\n",
      "total_trades: 47206\n",
      "Sharpe: 0.723\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.97e+06   |\n",
      "|    total_cost           | 1.5e+05    |\n",
      "|    total_reward         | 9.73e+05   |\n",
      "|    total_reward_pct     | 97.3       |\n",
      "|    total_trades         | 47867      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01842745 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0624     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.53       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 10.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.67e+06    |\n",
      "|    total_cost           | 1.38e+05    |\n",
      "|    total_reward         | 6.73e+05    |\n",
      "|    total_reward_pct     | 67.3        |\n",
      "|    total_trades         | 46097       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029582486 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.076       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.31        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.83e+06    |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | 8.34e+05    |\n",
      "|    total_reward_pct     | 83.4        |\n",
      "|    total_trades         | 46823       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024648977 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0815      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.2         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 7.65        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.96e+06   |\n",
      "|    total_cost           | 1.45e+05   |\n",
      "|    total_reward         | 9.56e+05   |\n",
      "|    total_reward_pct     | 95.6       |\n",
      "|    total_trades         | 46790      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 231        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02599917 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0804     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4          |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 8.08       |\n",
      "----------------------------------------\n",
      "day: 1698, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1866741.64\n",
      "total_reward: 866741.64\n",
      "total_cost: 141666.62\n",
      "total_trades: 46452\n",
      "Sharpe: 0.671\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.87e+06    |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | 8.67e+05    |\n",
      "|    total_reward_pct     | 86.7        |\n",
      "|    total_trades         | 46452       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018782508 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.73        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.2e+06     |\n",
      "|    total_cost           | 1.46e+05    |\n",
      "|    total_reward         | 1.2e+06     |\n",
      "|    total_reward_pct     | 120         |\n",
      "|    total_trades         | 47162       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018170908 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.9         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.76e+06    |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 7.55e+05    |\n",
      "|    total_reward_pct     | 75.5        |\n",
      "|    total_trades         | 47744       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022178732 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.5         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.92e+06    |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | 9.18e+05    |\n",
      "|    total_reward_pct     | 91.8        |\n",
      "|    total_trades         | 46926       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025339909 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.53        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.18        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1719543.49\n",
      "total_reward: 719543.49\n",
      "total_cost: 144482.16\n",
      "total_trades: 47022\n",
      "Sharpe: 0.608\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.72e+06    |\n",
      "|    total_cost           | 1.44e+05    |\n",
      "|    total_reward         | 7.2e+05     |\n",
      "|    total_reward_pct     | 72          |\n",
      "|    total_trades         | 47022       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024322582 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.75        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.49        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.75e+06   |\n",
      "|    total_cost           | 1.44e+05   |\n",
      "|    total_reward         | 7.47e+05   |\n",
      "|    total_reward_pct     | 74.7       |\n",
      "|    total_trades         | 46823      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 308        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03222155 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.95       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0291    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 7.64       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2e+06       |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 1e+06       |\n",
      "|    total_reward_pct     | 100         |\n",
      "|    total_trades         | 45947       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021754328 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.096       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.88        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 8.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.94e+06    |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | 9.39e+05    |\n",
      "|    total_reward_pct     | 93.9        |\n",
      "|    total_trades         | 47064       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027043508 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.61        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 8.5         |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2127299.94\n",
      "total_reward: 1127299.94\n",
      "total_cost: 134340.31\n",
      "total_trades: 46703\n",
      "Sharpe: 0.807\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.13e+06   |\n",
      "|    total_cost           | 1.34e+05   |\n",
      "|    total_reward         | 1.13e+06   |\n",
      "|    total_reward_pct     | 113        |\n",
      "|    total_trades         | 46703      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 347        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03677942 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0952     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.28       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 9.9        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.92e+06   |\n",
      "|    total_cost           | 1.36e+05   |\n",
      "|    total_reward         | 9.24e+05   |\n",
      "|    total_reward_pct     | 92.4       |\n",
      "|    total_trades         | 45681      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 360        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02678207 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.0721     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.37       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 11.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.84e+06  |\n",
      "|    total_cost           | 1.36e+05  |\n",
      "|    total_reward         | 8.38e+05  |\n",
      "|    total_reward_pct     | 83.8      |\n",
      "|    total_trades         | 46522     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 159       |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 372       |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0350829 |\n",
      "|    clip_fraction        | 0.268     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44       |\n",
      "|    explained_variance   | 0.13      |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 4.01      |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -0.0178   |\n",
      "|    std                  | 1.05      |\n",
      "|    value_loss           | 10.3      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.09e+06    |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | 1.09e+06    |\n",
      "|    total_reward_pct     | 109         |\n",
      "|    total_trades         | 46115       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034114458 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | -0.062      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.11        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1967061.63\n",
      "total_reward: 967061.63\n",
      "total_cost: 138330.87\n",
      "total_trades: 46272\n",
      "Sharpe: 0.744\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.97e+06    |\n",
      "|    total_cost           | 1.38e+05    |\n",
      "|    total_reward         | 9.67e+05    |\n",
      "|    total_reward_pct     | 96.7        |\n",
      "|    total_trades         | 46272       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018032588 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.19        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.97e+06    |\n",
      "|    total_cost           | 1.35e+05    |\n",
      "|    total_reward         | 9.71e+05    |\n",
      "|    total_reward_pct     | 97.1        |\n",
      "|    total_trades         | 45719       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020763123 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0803      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.9         |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.03e+06    |\n",
      "|    total_cost           | 1.25e+05    |\n",
      "|    total_reward         | 1.03e+06    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 44607       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 424         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018932177 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.22        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 9.91        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.66e+06    |\n",
      "|    total_cost           | 1.36e+05    |\n",
      "|    total_reward         | 6.61e+05    |\n",
      "|    total_reward_pct     | 66.1        |\n",
      "|    total_trades         | 46026       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028156668 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.62        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 9.18        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1754285.19\n",
      "total_reward: 754285.19\n",
      "total_cost: 132219.16\n",
      "total_trades: 45458\n",
      "Sharpe: 0.628\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.75e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 7.54e+05    |\n",
      "|    total_reward_pct     | 75.4        |\n",
      "|    total_trades         | 45458       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025229795 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0416      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.59        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 8.35        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.59e+06   |\n",
      "|    total_cost           | 1.25e+05   |\n",
      "|    total_reward         | 5.87e+05   |\n",
      "|    total_reward_pct     | 58.7       |\n",
      "|    total_trades         | 44876      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 463        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03678731 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.217      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.02       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 6.85       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.68e+06    |\n",
      "|    total_cost           | 1.38e+05    |\n",
      "|    total_reward         | 6.76e+05    |\n",
      "|    total_reward_pct     | 67.6        |\n",
      "|    total_trades         | 46539       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 475         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030729316 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.63        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 7.18        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.07e+06   |\n",
      "|    total_cost           | 1.41e+05   |\n",
      "|    total_reward         | 1.07e+06   |\n",
      "|    total_reward_pct     | 107        |\n",
      "|    total_trades         | 46271      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 488        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04013017 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.123      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.31       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 9.58       |\n",
      "----------------------------------------\n",
      "day: 1698, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1754343.71\n",
      "total_reward: 754343.71\n",
      "total_cost: 140388.77\n",
      "total_trades: 46807\n",
      "Sharpe: 0.608\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.75e+06    |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | 7.54e+05    |\n",
      "|    total_reward_pct     | 75.4        |\n",
      "|    total_trades         | 46807       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035921726 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0573      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.84        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 8.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.52e+06    |\n",
      "|    total_cost           | 1.46e+05    |\n",
      "|    total_reward         | 5.24e+05    |\n",
      "|    total_reward_pct     | 52.4        |\n",
      "|    total_trades         | 46925       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 514         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025601389 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0638      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.83        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.89e+06   |\n",
      "|    total_cost           | 1.27e+05   |\n",
      "|    total_reward         | 8.91e+05   |\n",
      "|    total_reward_pct     | 89.1       |\n",
      "|    total_trades         | 45621      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 527        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04618525 |\n",
      "|    clip_fraction        | 0.366      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.186      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.91       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 7.32       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 8.77e+05    |\n",
      "|    total_reward_pct     | 87.7        |\n",
      "|    total_trades         | 45962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 540         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026819747 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.82        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 8.98        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.15e+06    |\n",
      "|    total_cost           | 1.34e+05    |\n",
      "|    total_reward         | 1.15e+06    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 46337       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 553         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019908782 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.04        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 9.17        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1833901.48\n",
      "total_reward: 833901.48\n",
      "total_cost: 134725.48\n",
      "total_trades: 46316\n",
      "Sharpe: 0.655\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.14e+06   |\n",
      "|    total_cost           | 1.41e+05   |\n",
      "|    total_reward         | 1.14e+06   |\n",
      "|    total_reward_pct     | 114        |\n",
      "|    total_trades         | 46962      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 566        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03699875 |\n",
      "|    clip_fraction        | 0.28       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.34       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 10.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.99e+06    |\n",
      "|    total_cost           | 1.38e+05    |\n",
      "|    total_reward         | 9.94e+05    |\n",
      "|    total_reward_pct     | 99.4        |\n",
      "|    total_trades         | 46627       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053507574 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.56        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.79e+06    |\n",
      "|    total_cost           | 1.41e+05    |\n",
      "|    total_reward         | 7.94e+05    |\n",
      "|    total_reward_pct     | 79.4        |\n",
      "|    total_trades         | 47104       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029799517 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0644      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.16        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 9.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.89e+06    |\n",
      "|    total_cost           | 1.38e+05    |\n",
      "|    total_reward         | 8.91e+05    |\n",
      "|    total_reward_pct     | 89.1        |\n",
      "|    total_trades         | 46648       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056503408 |\n",
      "|    clip_fraction        | 0.391       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0503      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.94        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 8.32        |\n",
      "-----------------------------------------\n",
      "day: 1698, episode: 75\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2175733.56\n",
      "total_reward: 1175733.56\n",
      "total_cost: 134173.15\n",
      "total_trades: 45850\n",
      "Sharpe: 0.822\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.18e+06   |\n",
      "|    total_cost           | 1.34e+05   |\n",
      "|    total_reward         | 1.18e+06   |\n",
      "|    total_reward_pct     | 118        |\n",
      "|    total_trades         | 45850      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 617        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02945008 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | 0.1        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.62       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00761   |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 9.6        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+06    |\n",
      "|    total_cost           | 1.29e+05    |\n",
      "|    total_reward         | 1.04e+06    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 45486       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032551214 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.83        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2016-10-03 to  2017-01-03\n",
      "PPO Sharpe Ratio:  0.5948103255131427\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_6\n",
      "day: 1698, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1657543.33\n",
      "total_reward: 657543.33\n",
      "total_cost: 1743.19\n",
      "total_trades: 33782\n",
      "Sharpe: 0.546\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.98e+06 |\n",
      "|    total_cost       | 1.79e+03 |\n",
      "|    total_reward     | 9.82e+05 |\n",
      "|    total_reward_pct | 98.2     |\n",
      "|    total_trades     | 24358    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 57       |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total timesteps  | 6796     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.74     |\n",
      "|    critic_loss      | 36.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5097     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2016-10-03 to  2017-01-03\n",
      "======Best Model Retraining from:  2010-01-01 to  2017-01-03\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_126_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 14.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.617    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0219   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -90.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0312  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -5.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.47     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.47e+06 |\n",
      "|    total_cost         | 1.04e+05 |\n",
      "|    total_reward       | 1.47e+06 |\n",
      "|    total_reward_pct   | 147      |\n",
      "|    total_trades       | 43714    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.44    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 23.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 23.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.254    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -47.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.287    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 15.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.698    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.87e+06 |\n",
      "|    total_cost         | 9.63e+04 |\n",
      "|    total_reward       | 8.67e+05 |\n",
      "|    total_reward_pct   | 86.7     |\n",
      "|    total_trades       | 43295    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -3.96    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 40.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.00814 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 26.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.82e+06 |\n",
      "|    total_cost         | 6.05e+04 |\n",
      "|    total_reward       | 8.2e+05  |\n",
      "|    total_reward_pct   | 82       |\n",
      "|    total_trades       | 37928    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.061   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -55.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.027   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -189     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 25.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.166    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 108      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -58.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.73e+06 |\n",
      "|    total_cost         | 2.96e+04 |\n",
      "|    total_reward       | 7.33e+05 |\n",
      "|    total_reward_pct   | 73.3     |\n",
      "|    total_trades       | 32678    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0783   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 144      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 14.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.192   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -88.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.23     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 170       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 16.4      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1761, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1636310.95\n",
      "total_reward: 636310.95\n",
      "total_cost: 21968.73\n",
      "total_trades: 31223\n",
      "Sharpe: 0.485\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.64e+06 |\n",
      "|    total_cost         | 2.2e+04  |\n",
      "|    total_reward       | 6.36e+05 |\n",
      "|    total_reward_pct   | 63.6     |\n",
      "|    total_trades       | 31223    |\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.419    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 40.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.952    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.217    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -3.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.202    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 27.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -230     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 26.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.81e+06 |\n",
      "|    total_cost         | 1.63e+04 |\n",
      "|    total_reward       | 8.05e+05 |\n",
      "|    total_reward_pct   | 80.5     |\n",
      "|    total_trades       | 29957    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.008   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 46.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 21.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.00923  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 265      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 56.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.74e+06 |\n",
      "|    total_cost         | 1.91e+04 |\n",
      "|    total_reward       | 7.41e+05 |\n",
      "|    total_reward_pct   | 74.1     |\n",
      "|    total_trades       | 31286    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -86.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.05     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 142       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 26.7      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.416     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 17.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.01     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.18e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 46        |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.11      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.73e+06 |\n",
      "|    total_cost         | 1.31e+04 |\n",
      "|    total_reward       | 7.33e+05 |\n",
      "|    total_reward_pct   | 73.3     |\n",
      "|    total_trades       | 30656    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0613  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -164     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 17.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -47.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.71     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -143     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.74e+06  |\n",
      "|    total_cost         | 2.36e+04  |\n",
      "|    total_reward       | 7.38e+05  |\n",
      "|    total_reward_pct   | 73.8      |\n",
      "|    total_trades       | 32997     |\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -36.5     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 78.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -84.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.123    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 93.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.19     |\n",
      "------------------------------------\n",
      "day: 1761, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1750117.20\n",
      "total_reward: 750117.20\n",
      "total_cost: 9732.76\n",
      "total_trades: 30223\n",
      "Sharpe: 0.540\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.75e+06 |\n",
      "|    total_cost         | 9.73e+03 |\n",
      "|    total_reward       | 7.5e+05  |\n",
      "|    total_reward_pct   | 75       |\n",
      "|    total_trades       | 30223    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.00289 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 75.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.04     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 4.1      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 24.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.65e+06 |\n",
      "|    total_cost         | 9.62e+03 |\n",
      "|    total_reward       | 6.54e+05 |\n",
      "|    total_reward_pct   | 65.4     |\n",
      "|    total_trades       | 29166    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 73       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 126      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 97       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -22.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.565    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.71e+06 |\n",
      "|    total_cost         | 7.99e+03 |\n",
      "|    total_reward       | 7.14e+05 |\n",
      "|    total_reward_pct   | 71.4     |\n",
      "|    total_trades       | 27524    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.188    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 10.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.792    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 19       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -11.8    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.275    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.68e+06 |\n",
      "|    total_cost         | 7.4e+03  |\n",
      "|    total_reward       | 6.78e+05 |\n",
      "|    total_reward_pct   | 67.8     |\n",
      "|    total_trades       | 26559    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 59.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 1.31e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -145     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 5.63     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.584   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 78.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.65e+06 |\n",
      "|    total_cost         | 6.07e+03 |\n",
      "|    total_reward       | 6.5e+05  |\n",
      "|    total_reward_pct   | 65       |\n",
      "|    total_trades       | 25721    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.292   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 92.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -73.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 79.4     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 4.6      |\n",
      "------------------------------------\n",
      "day: 1761, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1702822.83\n",
      "total_reward: 702822.83\n",
      "total_cost: 6865.30\n",
      "total_trades: 25732\n",
      "Sharpe: 0.540\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.7e+06  |\n",
      "|    total_cost         | 6.87e+03 |\n",
      "|    total_reward       | 7.03e+05 |\n",
      "|    total_reward_pct   | 70.3     |\n",
      "|    total_trades       | 25732    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.178   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 9.55     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.354    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 10.7     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.593    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 117      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 7.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 0.535    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.818    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.72e+06 |\n",
      "|    total_cost         | 6.94e+03 |\n",
      "|    total_reward       | 7.2e+05  |\n",
      "|    total_reward_pct   | 72       |\n",
      "|    total_trades       | 24912    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.0358  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -19.3    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.32     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 29.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.512    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -184     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 20.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.77e+06 |\n",
      "|    total_cost         | 7.05e+03 |\n",
      "|    total_reward       | 7.68e+05 |\n",
      "|    total_reward_pct   | 76.8     |\n",
      "|    total_trades       | 24894    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -59.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 129      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "======Trading from:  2017-01-03 to  2017-04-04\n",
      "============================================\n",
      "17.14024297613398\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2017-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_5\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.196    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -86.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0172  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -7.36    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.0423  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -56      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 6        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.25e+06 |\n",
      "|    total_cost         | 1.47e+05 |\n",
      "|    total_reward       | 1.25e+06 |\n",
      "|    total_reward_pct   | 125      |\n",
      "|    total_trades       | 48155    |\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.19     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 73.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.392   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 40       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.000597 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 42.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0286  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -13.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.95e+06 |\n",
      "|    total_cost         | 1.06e+05 |\n",
      "|    total_reward       | 9.49e+05 |\n",
      "|    total_reward_pct   | 94.9     |\n",
      "|    total_trades       | 43476    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0187   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -62.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0379  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 11       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.474    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 16       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.432    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.45e+06 |\n",
      "|    total_cost         | 8.22e+04 |\n",
      "|    total_reward       | 4.53e+05 |\n",
      "|    total_reward_pct   | 45.3     |\n",
      "|    total_trades       | 40958    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00844 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 20.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.365    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0706   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -67.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0548   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 63.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0346  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -23.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.799    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.71e+06 |\n",
      "|    total_cost         | 6.23e+04 |\n",
      "|    total_reward       | 7.08e+05 |\n",
      "|    total_reward_pct   | 70.8     |\n",
      "|    total_trades       | 37536    |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.131   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 91.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -109     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.127    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 94.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.95     |\n",
      "------------------------------------\n",
      "day: 1761, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1670978.28\n",
      "total_reward: 670978.28\n",
      "total_cost: 48764.05\n",
      "total_trades: 35865\n",
      "Sharpe: 0.503\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.67e+06 |\n",
      "|    total_cost         | 4.88e+04 |\n",
      "|    total_reward       | 6.71e+05 |\n",
      "|    total_reward_pct   | 67.1     |\n",
      "|    total_trades       | 35865    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00925 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -37.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0474   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 2.14     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0472   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 142       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 36.9      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.857     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.274   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -118     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.63e+06 |\n",
      "|    total_cost         | 7.38e+04 |\n",
      "|    total_reward       | 6.29e+05 |\n",
      "|    total_reward_pct   | 62.9     |\n",
      "|    total_trades       | 38046    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.000182 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 6.9      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -3.49    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.114    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0125  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 149      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 25.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.99e+06 |\n",
      "|    total_cost         | 5.63e+04 |\n",
      "|    total_reward       | 9.9e+05  |\n",
      "|    total_reward_pct   | 99       |\n",
      "|    total_trades       | 35534    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0386  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -136     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.113    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 61.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -6.2e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 80.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0175   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 65       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.85e+06 |\n",
      "|    total_cost         | 6.49e+04 |\n",
      "|    total_reward       | 8.45e+05 |\n",
      "|    total_reward_pct   | 84.5     |\n",
      "|    total_trades       | 36867    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0704   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -106     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.157   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -19.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.583    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0576   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -149     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.63e+06 |\n",
      "|    total_cost         | 1.09e+05 |\n",
      "|    total_reward       | 6.34e+05 |\n",
      "|    total_reward_pct   | 63.4     |\n",
      "|    total_trades       | 42206    |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.235    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -14.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.371    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.748   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 50.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.439   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -23.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 7.18     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.4      |\n",
      "------------------------------------\n",
      "day: 1761, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1770047.40\n",
      "total_reward: 770047.40\n",
      "total_cost: 81276.68\n",
      "total_trades: 38708\n",
      "Sharpe: 0.547\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.77e+06 |\n",
      "|    total_cost         | 8.13e+04 |\n",
      "|    total_reward       | 7.7e+05  |\n",
      "|    total_reward_pct   | 77       |\n",
      "|    total_trades       | 38708    |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.116   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 73       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.88     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 52.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.55    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 65.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.05e+06 |\n",
      "|    total_cost         | 8.23e+04 |\n",
      "|    total_reward       | 1.05e+06 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 39780    |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0365  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 65.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0829   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 125      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.801   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 145      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 22.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.39e+06 |\n",
      "|    total_cost         | 5.5e+04  |\n",
      "|    total_reward       | 1.39e+06 |\n",
      "|    total_reward_pct   | 139      |\n",
      "|    total_trades       | 36007    |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -66.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 94.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.262   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 32.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.1e+06  |\n",
      "|    total_cost         | 2.93e+04 |\n",
      "|    total_reward       | 1.1e+06  |\n",
      "|    total_reward_pct   | 110      |\n",
      "|    total_trades       | 31960    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0737  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 54.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.104   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -95.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 27.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.874    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 218      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 26.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.41e+06 |\n",
      "|    total_cost         | 1.87e+04 |\n",
      "|    total_reward       | 1.41e+06 |\n",
      "|    total_reward_pct   | 141      |\n",
      "|    total_trades       | 29885    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.466   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 33.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0165   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -119     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 43       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.6      |\n",
      "------------------------------------\n",
      "day: 1761, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2295195.99\n",
      "total_reward: 1295195.99\n",
      "total_cost: 16080.88\n",
      "total_trades: 29566\n",
      "Sharpe: 0.679\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.3e+06  |\n",
      "|    total_cost         | 1.61e+04 |\n",
      "|    total_reward       | 1.3e+06  |\n",
      "|    total_reward_pct   | 130      |\n",
      "|    total_trades       | 29566    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -2.57    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 68       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.00907 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -37.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -1.15    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 9.87     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -1.28    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.03e+06 |\n",
      "|    total_cost         | 1.75e+04 |\n",
      "|    total_reward       | 1.03e+06 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 28528    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0254   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -93.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0877   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 58       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -148     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 14.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.06e+06 |\n",
      "|    total_cost         | 1.65e+04 |\n",
      "|    total_reward       | 1.06e+06 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 27414    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 9.97     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.122    |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2017-01-03 to  2017-04-04\n",
      "A2C Sharpe Ratio:  0.10759401438556063\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_5\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.1e+06  |\n",
      "|    total_cost       | 1.72e+05 |\n",
      "|    total_reward     | 1.1e+06  |\n",
      "|    total_reward_pct | 110      |\n",
      "|    total_trades     | 51112    |\n",
      "| time/               |          |\n",
      "|    fps              | 166      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "day: 1761, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2046028.29\n",
      "total_reward: 1046028.29\n",
      "total_cost: 170912.74\n",
      "total_trades: 50787\n",
      "Sharpe: 0.812\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.05e+06    |\n",
      "|    total_cost           | 1.71e+05    |\n",
      "|    total_reward         | 1.05e+06    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 50787       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011657057 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0105     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.71        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 8.52        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.2e+06     |\n",
      "|    total_cost           | 1.71e+05    |\n",
      "|    total_reward         | 1.2e+06     |\n",
      "|    total_reward_pct     | 120         |\n",
      "|    total_trades         | 50578       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016683226 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0255     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.29        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.88        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.75e+06     |\n",
      "|    total_cost           | 1.64e+05     |\n",
      "|    total_reward         | 7.48e+05     |\n",
      "|    total_reward_pct     | 74.8         |\n",
      "|    total_trades         | 50077        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 161          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035581794 |\n",
      "|    clip_fraction        | 0.181        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.8        |\n",
      "|    explained_variance   | -0.0253      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.72         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0277      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 8.5          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.72e+06    |\n",
      "|    total_cost           | 1.62e+05    |\n",
      "|    total_reward         | 7.17e+05    |\n",
      "|    total_reward_pct     | 71.7        |\n",
      "|    total_trades         | 49814       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027332315 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0161      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.54        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.28        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.89e+06   |\n",
      "|    total_cost           | 1.62e+05   |\n",
      "|    total_reward         | 8.87e+05   |\n",
      "|    total_reward_pct     | 88.7       |\n",
      "|    total_trades         | 49885      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01937311 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | -0.0253    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.91       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0242    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 7.08       |\n",
      "----------------------------------------\n",
      "day: 1761, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1701560.22\n",
      "total_reward: 701560.22\n",
      "total_cost: 164224.29\n",
      "total_trades: 50113\n",
      "Sharpe: 0.659\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.86e+06   |\n",
      "|    total_cost           | 1.64e+05   |\n",
      "|    total_reward         | 8.64e+05   |\n",
      "|    total_reward_pct     | 86.4       |\n",
      "|    total_trades         | 50239      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03679713 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | -0.0193    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.99       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0254    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 7.16       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.82e+06    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 8.24e+05    |\n",
      "|    total_reward_pct     | 82.4        |\n",
      "|    total_trades         | 49831       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030607631 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0086      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.92        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.91e+06    |\n",
      "|    total_cost           | 1.66e+05    |\n",
      "|    total_reward         | 9.08e+05    |\n",
      "|    total_reward_pct     | 90.8        |\n",
      "|    total_trades         | 50240       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019002223 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0104     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.02        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.03e+06    |\n",
      "|    total_cost           | 1.57e+05    |\n",
      "|    total_reward         | 1.03e+06    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 49093       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021828253 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0246     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.02        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.47        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1761, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1773484.83\n",
      "total_reward: 773484.83\n",
      "total_cost: 162985.98\n",
      "total_trades: 49602\n",
      "Sharpe: 0.676\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.77e+06   |\n",
      "|    total_cost           | 1.63e+05   |\n",
      "|    total_reward         | 7.73e+05   |\n",
      "|    total_reward_pct     | 77.3       |\n",
      "|    total_trades         | 49602      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 140        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03571555 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.0232     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.74       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0264    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 9.42       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+06    |\n",
      "|    total_cost           | 1.64e+05    |\n",
      "|    total_reward         | 8.75e+05    |\n",
      "|    total_reward_pct     | 87.5        |\n",
      "|    total_trades         | 49794       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021734213 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -3.59e-05   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.73        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.85        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.96e+06    |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 9.56e+05    |\n",
      "|    total_reward_pct     | 95.6        |\n",
      "|    total_trades         | 49455       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022517638 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00425     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.8         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.26e+06   |\n",
      "|    total_cost           | 1.62e+05   |\n",
      "|    total_reward         | 1.26e+06   |\n",
      "|    total_reward_pct     | 126        |\n",
      "|    total_trades         | 49602      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 178        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01941782 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.0582     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.46       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0263    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 7.4        |\n",
      "----------------------------------------\n",
      "day: 1761, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1773029.37\n",
      "total_reward: 773029.37\n",
      "total_cost: 157208.95\n",
      "total_trades: 49109\n",
      "Sharpe: 0.666\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.77e+06    |\n",
      "|    total_cost           | 1.57e+05    |\n",
      "|    total_reward         | 7.73e+05    |\n",
      "|    total_reward_pct     | 77.3        |\n",
      "|    total_trades         | 49109       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022137336 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0788      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.33        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.02e+06    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 1.02e+06    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 49651       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014770325 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0624      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.29        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 7.23        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.37e+06   |\n",
      "|    total_cost           | 1.58e+05   |\n",
      "|    total_reward         | 1.37e+06   |\n",
      "|    total_reward_pct     | 137        |\n",
      "|    total_trades         | 49328      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 217        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02284339 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.146      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.04       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 8.94       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.15e+06   |\n",
      "|    total_cost           | 1.65e+05   |\n",
      "|    total_reward         | 1.15e+06   |\n",
      "|    total_reward_pct     | 115        |\n",
      "|    total_trades         | 49737      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 229        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02912214 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0667     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.02       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0254    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 10.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1761, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2004975.60\n",
      "total_reward: 1004975.60\n",
      "total_cost: 152527.87\n",
      "total_trades: 48915\n",
      "Sharpe: 0.799\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2e+06       |\n",
      "|    total_cost           | 1.53e+05    |\n",
      "|    total_reward         | 1e+06       |\n",
      "|    total_reward_pct     | 100         |\n",
      "|    total_trades         | 48915       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028465418 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0411      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.2         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.92e+06  |\n",
      "|    total_cost           | 1.61e+05  |\n",
      "|    total_reward         | 9.17e+05  |\n",
      "|    total_reward_pct     | 91.7      |\n",
      "|    total_trades         | 49297     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 160       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 255       |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0277241 |\n",
      "|    clip_fraction        | 0.265     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.5     |\n",
      "|    explained_variance   | 0.142     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 3.61      |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -0.0142   |\n",
      "|    std                  | 1.03      |\n",
      "|    value_loss           | 7.74      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.82e+06   |\n",
      "|    total_cost           | 1.63e+05   |\n",
      "|    total_reward         | 8.24e+05   |\n",
      "|    total_reward_pct     | 82.4       |\n",
      "|    total_trades         | 49749      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 267        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02034011 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0433     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.05       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0218    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 8.49       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.05e+06    |\n",
      "|    total_cost           | 1.55e+05    |\n",
      "|    total_reward         | 1.05e+06    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 49176       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020886999 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.84        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 7.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.08e+06    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | 1.08e+06    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 49134       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014176253 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.63        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.8         |\n",
      "-----------------------------------------\n",
      "day: 1761, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2207856.10\n",
      "total_reward: 1207856.10\n",
      "total_cost: 161154.66\n",
      "total_trades: 49482\n",
      "Sharpe: 0.863\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.21e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 1.21e+06    |\n",
      "|    total_reward_pct     | 121         |\n",
      "|    total_trades         | 49482       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023423512 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.75        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 8.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.87e+06    |\n",
      "|    total_cost           | 1.57e+05    |\n",
      "|    total_reward         | 8.69e+05    |\n",
      "|    total_reward_pct     | 86.9        |\n",
      "|    total_trades         | 48865       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022280727 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0989      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.03        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.97        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.18e+06    |\n",
      "|    total_cost           | 1.53e+05    |\n",
      "|    total_reward         | 1.18e+06    |\n",
      "|    total_reward_pct     | 118         |\n",
      "|    total_trades         | 48920       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019114686 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0902      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.6         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.95        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.08e+06    |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | 1.08e+06    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 49266       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026809718 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.85        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 8.34        |\n",
      "-----------------------------------------\n",
      "day: 1761, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2530078.60\n",
      "total_reward: 1530078.60\n",
      "total_cost: 162545.86\n",
      "total_trades: 49379\n",
      "Sharpe: 0.993\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.53e+06    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 1.53e+06    |\n",
      "|    total_reward_pct     | 153         |\n",
      "|    total_trades         | 49379       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024553407 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.2         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 8.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.93e+06    |\n",
      "|    total_cost           | 1.57e+05    |\n",
      "|    total_reward         | 9.32e+05    |\n",
      "|    total_reward_pct     | 93.2        |\n",
      "|    total_trades         | 48974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027035985 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0776      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.23        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.65        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.96e+06   |\n",
      "|    total_cost           | 1.54e+05   |\n",
      "|    total_reward         | 9.62e+05   |\n",
      "|    total_reward_pct     | 96.2       |\n",
      "|    total_trades         | 48598      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 382        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03824591 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0281     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.92       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 8.74       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.23e+06    |\n",
      "|    total_cost           | 1.57e+05    |\n",
      "|    total_reward         | 1.23e+06    |\n",
      "|    total_reward_pct     | 123         |\n",
      "|    total_trades         | 48675       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018417312 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0557      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.84        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "day: 1761, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2139737.71\n",
      "total_reward: 1139737.71\n",
      "total_cost: 154285.15\n",
      "total_trades: 48533\n",
      "Sharpe: 0.786\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.14e+06    |\n",
      "|    total_cost           | 1.54e+05    |\n",
      "|    total_reward         | 1.14e+06    |\n",
      "|    total_reward_pct     | 114         |\n",
      "|    total_trades         | 48533       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028646003 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.04        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.35        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.93e+06   |\n",
      "|    total_cost           | 1.44e+05   |\n",
      "|    total_reward         | 9.27e+05   |\n",
      "|    total_reward_pct     | 92.7       |\n",
      "|    total_trades         | 47389      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 420        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02213483 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.0915     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.65       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0185    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 8.71       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.65e+06    |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | 6.45e+05    |\n",
      "|    total_reward_pct     | 64.5        |\n",
      "|    total_trades         | 47999       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033446543 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | -0.00584    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.8         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.68e+06   |\n",
      "|    total_cost           | 1.46e+05   |\n",
      "|    total_reward         | 6.78e+05   |\n",
      "|    total_reward_pct     | 67.8       |\n",
      "|    total_trades         | 48043      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 445        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04184514 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.103      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.35       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0183    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 7.12       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.04e+06   |\n",
      "|    total_cost           | 1.55e+05   |\n",
      "|    total_reward         | 1.04e+06   |\n",
      "|    total_reward_pct     | 104        |\n",
      "|    total_trades         | 48604      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 458        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02792759 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0519     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.87       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0242    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 8.1        |\n",
      "----------------------------------------\n",
      "day: 1761, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2038095.47\n",
      "total_reward: 1038095.47\n",
      "total_cost: 146072.18\n",
      "total_trades: 47796\n",
      "Sharpe: 0.709\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.08e+06    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | 1.08e+06    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 48694       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029896904 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.73        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.2e+06     |\n",
      "|    total_cost           | 1.55e+05    |\n",
      "|    total_reward         | 1.2e+06     |\n",
      "|    total_reward_pct     | 120         |\n",
      "|    total_trades         | 48706       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 483         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030936223 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.053       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.91        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.25e+06   |\n",
      "|    total_cost           | 1.66e+05   |\n",
      "|    total_reward         | 1.25e+06   |\n",
      "|    total_reward_pct     | 125        |\n",
      "|    total_trades         | 49619      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 496        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04748209 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.142      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.44       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 12.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.18e+06    |\n",
      "|    total_cost           | 1.54e+05    |\n",
      "|    total_reward         | 1.18e+06    |\n",
      "|    total_reward_pct     | 118         |\n",
      "|    total_trades         | 48575       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022414606 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.29        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "day: 1761, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1883711.84\n",
      "total_reward: 883711.84\n",
      "total_cost: 155803.12\n",
      "total_trades: 49062\n",
      "Sharpe: 0.620\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+06    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | 8.84e+05    |\n",
      "|    total_reward_pct     | 88.4        |\n",
      "|    total_trades         | 49062       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 522         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028576836 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0461      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.13        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.94e+06   |\n",
      "|    total_cost           | 1.5e+05    |\n",
      "|    total_reward         | 9.42e+05   |\n",
      "|    total_reward_pct     | 94.2       |\n",
      "|    total_trades         | 48541      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 534        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03735551 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0115     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.98       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 10.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.48e+06    |\n",
      "|    total_cost           | 1.44e+05    |\n",
      "|    total_reward         | 4.81e+05    |\n",
      "|    total_reward_pct     | 48.1        |\n",
      "|    total_trades         | 47685       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 547         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030711543 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0817      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.66        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 9.89        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.98e+06   |\n",
      "|    total_cost           | 1.54e+05   |\n",
      "|    total_reward         | 9.76e+05   |\n",
      "|    total_reward_pct     | 97.6       |\n",
      "|    total_trades         | 48450      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 560        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03652513 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.11       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.58       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0238    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 10.5       |\n",
      "----------------------------------------\n",
      "day: 1761, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1819626.03\n",
      "total_reward: 819626.03\n",
      "total_cost: 152596.27\n",
      "total_trades: 48485\n",
      "Sharpe: 0.601\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.82e+06    |\n",
      "|    total_cost           | 1.53e+05    |\n",
      "|    total_reward         | 8.2e+05     |\n",
      "|    total_reward_pct     | 82          |\n",
      "|    total_trades         | 48485       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 573         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022531211 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.5         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.94e+06    |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | 9.41e+05    |\n",
      "|    total_reward_pct     | 94.1        |\n",
      "|    total_trades         | 48485       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033488587 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0966      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3           |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 9.82        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.85e+06   |\n",
      "|    total_cost           | 1.49e+05   |\n",
      "|    total_reward         | 8.47e+05   |\n",
      "|    total_reward_pct     | 84.7       |\n",
      "|    total_trades         | 48505      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 598        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04785599 |\n",
      "|    clip_fraction        | 0.361      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.113      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.39       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 10.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.9e+06     |\n",
      "|    total_cost           | 1.53e+05    |\n",
      "|    total_reward         | 8.98e+05    |\n",
      "|    total_reward_pct     | 89.8        |\n",
      "|    total_trades         | 48993       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034381825 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0889      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.75        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 7.68        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.53e+06   |\n",
      "|    total_cost           | 1.51e+05   |\n",
      "|    total_reward         | 5.26e+05   |\n",
      "|    total_reward_pct     | 52.6       |\n",
      "|    total_trades         | 48083      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 624        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03652996 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.133      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.06       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 9.14       |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2017-01-03 to  2017-04-04\n",
      "PPO Sharpe Ratio:  0.39814999711639154\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_5\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.16e+06 |\n",
      "|    total_cost       | 1.3e+03  |\n",
      "|    total_reward     | 1.16e+06 |\n",
      "|    total_reward_pct | 116      |\n",
      "|    total_trades     | 28247    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 57       |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total timesteps  | 7048     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 38.6     |\n",
      "|    critic_loss      | 58.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5286     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1761, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2141539.10\n",
      "total_reward: 1141539.10\n",
      "total_cost: 1290.30\n",
      "total_trades: 28196\n",
      "Sharpe: 0.792\n",
      "=================================\n",
      "======DDPG Validation from:  2017-01-03 to  2017-04-04\n",
      "======Best Model Retraining from:  2010-01-01 to  2017-04-04\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_189_2\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.99e+06 |\n",
      "|    total_cost       | 1.79e+05 |\n",
      "|    total_reward     | 9.87e+05 |\n",
      "|    total_reward_pct | 98.7     |\n",
      "|    total_trades     | 52590    |\n",
      "| time/               |          |\n",
      "|    fps              | 164      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.19e+06  |\n",
      "|    total_cost           | 1.83e+05  |\n",
      "|    total_reward         | 1.19e+06  |\n",
      "|    total_reward_pct     | 119       |\n",
      "|    total_trades         | 52614     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 160       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0089656 |\n",
      "|    clip_fraction        | 0.218     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -42.6     |\n",
      "|    explained_variance   | -0.039    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 3.61      |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | -0.0272   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.24      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.93e+06    |\n",
      "|    total_cost           | 1.78e+05    |\n",
      "|    total_reward         | 9.34e+05    |\n",
      "|    total_reward_pct     | 93.4        |\n",
      "|    total_trades         | 52669       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022235198 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0129     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.17        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.71        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.83e+06    |\n",
      "|    total_cost           | 1.76e+05    |\n",
      "|    total_reward         | 8.32e+05    |\n",
      "|    total_reward_pct     | 83.2        |\n",
      "|    total_trades         | 52281       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012099279 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0366     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.47        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 7.07        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1872507.51\n",
      "total_reward: 872507.51\n",
      "total_cost: 178545.97\n",
      "total_trades: 52495\n",
      "Sharpe: 0.711\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.87e+06    |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 8.73e+05    |\n",
      "|    total_reward_pct     | 87.3        |\n",
      "|    total_trades         | 52495       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019846695 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00436    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.27        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.76e+06    |\n",
      "|    total_cost           | 1.71e+05    |\n",
      "|    total_reward         | 7.61e+05    |\n",
      "|    total_reward_pct     | 76.1        |\n",
      "|    total_trades         | 51877       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021956496 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0237     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.74        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.05e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 1.05e+06    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 51705       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011992916 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0447     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.32        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.08        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.89e+06    |\n",
      "|    total_cost           | 1.72e+05    |\n",
      "|    total_reward         | 8.93e+05    |\n",
      "|    total_reward_pct     | 89.3        |\n",
      "|    total_trades         | 51497       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029504199 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0404     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.09        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.56        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1824, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2236812.61\n",
      "total_reward: 1236812.61\n",
      "total_cost: 166429.06\n",
      "total_trades: 51196\n",
      "Sharpe: 0.798\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.24e+06    |\n",
      "|    total_cost           | 1.66e+05    |\n",
      "|    total_reward         | 1.24e+06    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 51196       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025306644 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.000481   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.74        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.3e+06     |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 1.3e+06     |\n",
      "|    total_reward_pct     | 130         |\n",
      "|    total_trades         | 51202       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022678666 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0342      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.49        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.11e+06    |\n",
      "|    total_cost           | 1.67e+05    |\n",
      "|    total_reward         | 1.11e+06    |\n",
      "|    total_reward_pct     | 111         |\n",
      "|    total_trades         | 51037       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019529657 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.026      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.85        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.03e+06   |\n",
      "|    total_cost           | 1.69e+05   |\n",
      "|    total_reward         | 1.03e+06   |\n",
      "|    total_reward_pct     | 103        |\n",
      "|    total_trades         | 51312      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 157        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01900016 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | 0.0292     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.54       |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0248    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 10.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.06e+06    |\n",
      "|    total_cost           | 1.73e+05    |\n",
      "|    total_reward         | 1.06e+06    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 51561       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020543361 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.00383     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.44        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.95        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2008036.23\n",
      "total_reward: 1008036.23\n",
      "total_cost: 170631.91\n",
      "total_trades: 51566\n",
      "Sharpe: 0.752\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.01e+06    |\n",
      "|    total_cost           | 1.71e+05    |\n",
      "|    total_reward         | 1.01e+06    |\n",
      "|    total_reward_pct     | 101         |\n",
      "|    total_trades         | 51566       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021575818 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0576      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.91        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.89        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.22e+06    |\n",
      "|    total_cost           | 1.67e+05    |\n",
      "|    total_reward         | 1.22e+06    |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 51339       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021161893 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0634      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.76        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+06    |\n",
      "|    total_cost           | 1.72e+05    |\n",
      "|    total_reward         | 1.33e+06    |\n",
      "|    total_reward_pct     | 133         |\n",
      "|    total_trades         | 51321       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022606526 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0341      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.87        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.63e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 1.63e+06    |\n",
      "|    total_reward_pct     | 163         |\n",
      "|    total_trades         | 51246       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018865863 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0647      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.42        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2106650.44\n",
      "total_reward: 1106650.44\n",
      "total_cost: 167823.09\n",
      "total_trades: 51043\n",
      "Sharpe: 0.724\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.11e+06    |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 1.11e+06    |\n",
      "|    total_reward_pct     | 111         |\n",
      "|    total_trades         | 51043       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031409584 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.86        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.11e+06    |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 1.11e+06    |\n",
      "|    total_reward_pct     | 111         |\n",
      "|    total_trades         | 51145       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022795592 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0419      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.15        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+06    |\n",
      "|    total_cost           | 1.72e+05    |\n",
      "|    total_reward         | 1.45e+06    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 51561       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017044857 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.96        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.38e+06    |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 1.38e+06    |\n",
      "|    total_reward_pct     | 138         |\n",
      "|    total_trades         | 51199       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028056268 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0804      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.72        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.58e+06   |\n",
      "|    total_cost           | 1.61e+05   |\n",
      "|    total_reward         | 1.58e+06   |\n",
      "|    total_reward_pct     | 158        |\n",
      "|    total_trades         | 50689      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 287        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03137161 |\n",
      "|    clip_fraction        | 0.288      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0664     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.52       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 11.9       |\n",
      "----------------------------------------\n",
      "day: 1824, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2159081.83\n",
      "total_reward: 1159081.83\n",
      "total_cost: 170026.99\n",
      "total_trades: 51335\n",
      "Sharpe: 0.754\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.16e+06    |\n",
      "|    total_cost           | 1.7e+05     |\n",
      "|    total_reward         | 1.16e+06    |\n",
      "|    total_reward_pct     | 116         |\n",
      "|    total_trades         | 51335       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035824794 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0692      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.66        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.58e+06   |\n",
      "|    total_cost           | 1.7e+05    |\n",
      "|    total_reward         | 1.58e+06   |\n",
      "|    total_reward_pct     | 158        |\n",
      "|    total_trades         | 51213      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 313        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03482399 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0622     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.9        |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.019     |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 10.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+06    |\n",
      "|    total_cost           | 1.64e+05    |\n",
      "|    total_reward         | 1.45e+06    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 50494       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 327         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020944906 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0176      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.72        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.46e+06  |\n",
      "|    total_cost           | 1.65e+05  |\n",
      "|    total_reward         | 1.46e+06  |\n",
      "|    total_reward_pct     | 146       |\n",
      "|    total_trades         | 50600     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 156       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 340       |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0191117 |\n",
      "|    clip_fraction        | 0.253     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.5     |\n",
      "|    explained_variance   | 0.066     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 8.56      |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -0.0201   |\n",
      "|    std                  | 1.03      |\n",
      "|    value_loss           | 14.7      |\n",
      "---------------------------------------\n",
      "day: 1824, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2389383.71\n",
      "total_reward: 1389383.71\n",
      "total_cost: 172133.26\n",
      "total_trades: 51272\n",
      "Sharpe: 0.819\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.39e+06    |\n",
      "|    total_cost           | 1.72e+05    |\n",
      "|    total_reward         | 1.39e+06    |\n",
      "|    total_reward_pct     | 139         |\n",
      "|    total_trades         | 51272       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 353         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016492195 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0537      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.33e+06  |\n",
      "|    total_cost           | 1.62e+05  |\n",
      "|    total_reward         | 1.33e+06  |\n",
      "|    total_reward_pct     | 133       |\n",
      "|    total_trades         | 50284     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 156       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 366       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0316581 |\n",
      "|    clip_fraction        | 0.235     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.6     |\n",
      "|    explained_variance   | 0.0508    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 3.94      |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -0.0138   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 11.6      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.25e+06    |\n",
      "|    total_cost           | 1.65e+05    |\n",
      "|    total_reward         | 1.25e+06    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 50675       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024903726 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.0117     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.34        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.12e+06    |\n",
      "|    total_cost           | 1.69e+05    |\n",
      "|    total_reward         | 1.12e+06    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 50891       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048080884 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.49        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.6e+06     |\n",
      "|    total_cost           | 1.67e+05    |\n",
      "|    total_reward         | 1.6e+06     |\n",
      "|    total_reward_pct     | 160         |\n",
      "|    total_trades         | 50722       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027471451 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0624      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.08        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2141243.41\n",
      "total_reward: 1141243.41\n",
      "total_cost: 162004.34\n",
      "total_trades: 50324\n",
      "Sharpe: 0.709\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.14e+06    |\n",
      "|    total_cost           | 1.62e+05    |\n",
      "|    total_reward         | 1.14e+06    |\n",
      "|    total_reward_pct     | 114         |\n",
      "|    total_trades         | 50324       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021403296 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0728      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.54e+06   |\n",
      "|    total_cost           | 1.62e+05   |\n",
      "|    total_reward         | 1.54e+06   |\n",
      "|    total_reward_pct     | 154        |\n",
      "|    total_trades         | 50290      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 434        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02079864 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0337     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.53       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 16.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.18e+06    |\n",
      "|    total_cost           | 1.67e+05    |\n",
      "|    total_reward         | 1.18e+06    |\n",
      "|    total_reward_pct     | 118         |\n",
      "|    total_trades         | 50702       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 448         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031735808 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.09        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.52        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.86e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 8.61e+05    |\n",
      "|    total_reward_pct     | 86.1        |\n",
      "|    total_trades         | 50491       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 462         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031449694 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.22        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2019295.80\n",
      "total_reward: 1019295.80\n",
      "total_cost: 163982.87\n",
      "total_trades: 50890\n",
      "Sharpe: 0.675\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.02e+06    |\n",
      "|    total_cost           | 1.64e+05    |\n",
      "|    total_reward         | 1.02e+06    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 50890       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 477         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018263066 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.000546    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.28        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.11e+06    |\n",
      "|    total_cost           | 1.69e+05    |\n",
      "|    total_reward         | 1.11e+06    |\n",
      "|    total_reward_pct     | 111         |\n",
      "|    total_trades         | 51009       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 490         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033345066 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.89        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 8.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.79e+06    |\n",
      "|    total_cost           | 1.54e+05    |\n",
      "|    total_reward         | 7.87e+05    |\n",
      "|    total_reward_pct     | 78.7        |\n",
      "|    total_trades         | 49951       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034027655 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.35        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 9.92        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.97e+06    |\n",
      "|    total_cost           | 1.66e+05    |\n",
      "|    total_reward         | 9.71e+05    |\n",
      "|    total_reward_pct     | 97.1        |\n",
      "|    total_trades         | 50782       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 518         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031164179 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.83        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 8.64        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.91e+06    |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | 9.11e+05    |\n",
      "|    total_reward_pct     | 91.1        |\n",
      "|    total_trades         | 50144       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 532         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025531737 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0836      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.49        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 8.35        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1824, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2118596.20\n",
      "total_reward: 1118596.20\n",
      "total_cost: 159336.23\n",
      "total_trades: 50236\n",
      "Sharpe: 0.754\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.59e+06    |\n",
      "|    total_cost           | 1.59e+05    |\n",
      "|    total_reward         | 1.59e+06    |\n",
      "|    total_reward_pct     | 159         |\n",
      "|    total_trades         | 49981       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024828456 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0712      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.28        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 9.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.25e+06    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 1.25e+06    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 50365       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 559         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026073838 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0653      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.81        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.13e+06    |\n",
      "|    total_cost           | 1.62e+05    |\n",
      "|    total_reward         | 1.13e+06    |\n",
      "|    total_reward_pct     | 113         |\n",
      "|    total_trades         | 50301       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 573         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053074967 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.19        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.92e+06    |\n",
      "|    total_cost           | 1.54e+05    |\n",
      "|    total_reward         | 9.24e+05    |\n",
      "|    total_reward_pct     | 92.4        |\n",
      "|    total_trades         | 49705       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 588         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041097727 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0412      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.61        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1853962.96\n",
      "total_reward: 853962.96\n",
      "total_cost: 154291.13\n",
      "total_trades: 49814\n",
      "Sharpe: 0.630\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.85e+06   |\n",
      "|    total_cost           | 1.54e+05   |\n",
      "|    total_reward         | 8.54e+05   |\n",
      "|    total_reward_pct     | 85.4       |\n",
      "|    total_trades         | 49814      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 602        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01897546 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.0679     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.98       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 7.87       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.68e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 6.78e+05    |\n",
      "|    total_reward_pct     | 67.8        |\n",
      "|    total_trades         | 49357       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 615         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038324475 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0626      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.37        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 8.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.69e+06    |\n",
      "|    total_cost           | 1.46e+05    |\n",
      "|    total_reward         | 6.89e+05    |\n",
      "|    total_reward_pct     | 68.9        |\n",
      "|    total_trades         | 48929       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 628         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040795714 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0752      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4           |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 8.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.99e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 9.95e+05    |\n",
      "|    total_reward_pct     | 99.5        |\n",
      "|    total_trades         | 49099       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 641         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038195744 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0349      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.03        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 9.06        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.24e+06   |\n",
      "|    total_cost           | 1.51e+05   |\n",
      "|    total_reward         | 1.24e+06   |\n",
      "|    total_reward_pct     | 124        |\n",
      "|    total_trades         | 49037      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 654        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03991959 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | -0.016     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.27       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0192    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 16.2       |\n",
      "----------------------------------------\n",
      "======Trading from:  2017-04-04 to  2017-07-05\n",
      "============================================\n",
      "11.2902715795974\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2017-04-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_5\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.516    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 6.69     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.226    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0702   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -36.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00264 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -75.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.97e+06 |\n",
      "|    total_cost         | 1.23e+05 |\n",
      "|    total_reward       | 9.68e+05 |\n",
      "|    total_reward_pct   | 96.8     |\n",
      "|    total_trades       | 46697    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.367   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 49.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00813 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 2.95     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.183    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -4.94    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.134    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -22.2     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.332     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.82e+06 |\n",
      "|    total_cost         | 9.13e+04 |\n",
      "|    total_reward       | 8.25e+05 |\n",
      "|    total_reward_pct   | 82.5     |\n",
      "|    total_trades       | 43625    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0978  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -78.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.19    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 41.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.563    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 73.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.01e+06 |\n",
      "|    total_cost         | 1.08e+05 |\n",
      "|    total_reward       | 1.01e+06 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 44701    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 10.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.117    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.439    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -29.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.537    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -102     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -17.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.56e+06 |\n",
      "|    total_cost         | 5.24e+04 |\n",
      "|    total_reward       | 5.64e+05 |\n",
      "|    total_reward_pct   | 56.4     |\n",
      "|    total_trades       | 38556    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.155    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 18.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.198    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 93.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -96.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 8.48     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "day: 1824, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2141059.88\n",
      "total_reward: 1141059.88\n",
      "total_cost: 38582.88\n",
      "total_trades: 37352\n",
      "Sharpe: 0.731\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.14e+06 |\n",
      "|    total_cost         | 3.86e+04 |\n",
      "|    total_reward       | 1.14e+06 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 37352    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00953 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 50.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.81     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -17.8     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.425   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -50.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.35e+06 |\n",
      "|    total_cost         | 1e+05    |\n",
      "|    total_reward       | 1.35e+06 |\n",
      "|    total_reward_pct   | 135      |\n",
      "|    total_trades       | 43552    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -1.26    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 29.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.712    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -83.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.03     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 46.7      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.36      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -28.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.95e+06 |\n",
      "|    total_cost         | 5.62e+04 |\n",
      "|    total_reward       | 9.47e+05 |\n",
      "|    total_reward_pct   | 94.7     |\n",
      "|    total_trades       | 38561    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -127     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.6      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0781  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -106     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0171  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 63.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.63     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -149      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 14.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.28e+06 |\n",
      "|    total_cost         | 3.11e+04 |\n",
      "|    total_reward       | 1.28e+06 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 33317    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -150     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.128   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -6.32    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.914    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 14.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.19e+06 |\n",
      "|    total_cost         | 3.19e+04 |\n",
      "|    total_reward       | 1.19e+06 |\n",
      "|    total_reward_pct   | 119      |\n",
      "|    total_trades       | 32323    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.185    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 29.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.516    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -0.348   |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.525    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0636  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -60.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 61.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.64     |\n",
      "------------------------------------\n",
      "day: 1824, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2320536.90\n",
      "total_reward: 1320536.90\n",
      "total_cost: 68821.90\n",
      "total_trades: 39952\n",
      "Sharpe: 0.846\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.32e+06 |\n",
      "|    total_cost         | 6.88e+04 |\n",
      "|    total_reward       | 1.32e+06 |\n",
      "|    total_reward_pct   | 132      |\n",
      "|    total_trades       | 39952    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.423    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -2.36    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0795   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.393   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 43.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0555  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -235     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 35.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.00118  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 116      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.37     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.84e+06 |\n",
      "|    total_cost         | 7.09e+04 |\n",
      "|    total_reward       | 8.37e+05 |\n",
      "|    total_reward_pct   | 83.7     |\n",
      "|    total_trades       | 38941    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.029    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -3.52    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.536   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -85.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.00461  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -657     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 274      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.17e+06 |\n",
      "|    total_cost         | 1.09e+05 |\n",
      "|    total_reward       | 1.17e+06 |\n",
      "|    total_reward_pct   | 117      |\n",
      "|    total_trades       | 43391    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.063    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -204     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 24.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0149   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -126     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0497  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 30.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.715    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -10.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.224    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.13e+06 |\n",
      "|    total_cost         | 8.33e+04 |\n",
      "|    total_reward       | 1.13e+06 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 39375    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.155   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -45.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 17.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.393    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 73.1      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.98      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -7.15e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -20       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.733     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.5e+06  |\n",
      "|    total_cost         | 5.77e+04 |\n",
      "|    total_reward       | 5.04e+05 |\n",
      "|    total_reward_pct   | 50.4     |\n",
      "|    total_trades       | 35206    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.331    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 0.386    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -31.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 27.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.28     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1824, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1953323.61\n",
      "total_reward: 953323.61\n",
      "total_cost: 53644.10\n",
      "total_trades: 34530\n",
      "Sharpe: 0.711\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.95e+06 |\n",
      "|    total_cost         | 5.36e+04 |\n",
      "|    total_reward       | 9.53e+05 |\n",
      "|    total_reward_pct   | 95.3     |\n",
      "|    total_trades       | 34530    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.228   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -89      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 111      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 1.68     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.251    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 2.17     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.62e+06 |\n",
      "|    total_cost         | 3.14e+04 |\n",
      "|    total_reward       | 6.17e+05 |\n",
      "|    total_reward_pct   | 61.7     |\n",
      "|    total_trades       | 33051    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -8.21    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -38.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.33     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2017-04-04 to  2017-07-05\n",
      "A2C Sharpe Ratio:  0.3092947622390669\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_252_5\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.96e+06 |\n",
      "|    total_cost       | 1.79e+05 |\n",
      "|    total_reward     | 9.56e+05 |\n",
      "|    total_reward_pct | 95.6     |\n",
      "|    total_trades     | 52550    |\n",
      "| time/               |          |\n",
      "|    fps              | 162      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.95e+06   |\n",
      "|    total_cost           | 1.75e+05   |\n",
      "|    total_reward         | 9.49e+05   |\n",
      "|    total_reward_pct     | 94.9       |\n",
      "|    total_trades         | 52029      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02295579 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | -0.0401    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.41       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0331    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 7.97       |\n",
      "----------------------------------------\n",
      "day: 1824, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2402237.87\n",
      "total_reward: 1402237.87\n",
      "total_cost: 178920.76\n",
      "total_trades: 52482\n",
      "Sharpe: 0.925\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.4e+06     |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 1.4e+06     |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 52482       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015601905 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0163     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.25        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.68e+06    |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 6.83e+05    |\n",
      "|    total_reward_pct     | 68.3        |\n",
      "|    total_trades         | 51807       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013071036 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0166      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.51        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 1.19e+06    |\n",
      "|    total_reward_pct     | 119         |\n",
      "|    total_trades         | 52189       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014402064 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0536      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.21        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.46        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.68e+06    |\n",
      "|    total_cost           | 1.7e+05     |\n",
      "|    total_reward         | 6.81e+05    |\n",
      "|    total_reward_pct     | 68.1        |\n",
      "|    total_trades         | 51832       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020000678 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0239      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.65        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.59e+06    |\n",
      "|    total_cost           | 1.67e+05    |\n",
      "|    total_reward         | 5.9e+05     |\n",
      "|    total_reward_pct     | 59          |\n",
      "|    total_trades         | 51292       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014712501 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0318     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.42        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.16        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1717008.23\n",
      "total_reward: 717008.23\n",
      "total_cost: 168653.27\n",
      "total_trades: 51374\n",
      "Sharpe: 0.542\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.72e+06    |\n",
      "|    total_cost           | 1.69e+05    |\n",
      "|    total_reward         | 7.17e+05    |\n",
      "|    total_reward_pct     | 71.7        |\n",
      "|    total_trades         | 51374       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015532454 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0273      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.77        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.87e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 8.75e+05    |\n",
      "|    total_reward_pct     | 87.5        |\n",
      "|    total_trades         | 50930       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026123336 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0767      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.84        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.69e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 6.91e+05    |\n",
      "|    total_reward_pct     | 69.1        |\n",
      "|    total_trades         | 50853       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018050605 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0258      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.11        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.86e+06   |\n",
      "|    total_cost           | 1.67e+05   |\n",
      "|    total_reward         | 8.58e+05   |\n",
      "|    total_reward_pct     | 85.8       |\n",
      "|    total_trades         | 51231      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01547347 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | 0.0247     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.4        |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0286    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 11.6       |\n",
      "----------------------------------------\n",
      "day: 1824, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1731869.04\n",
      "total_reward: 731869.04\n",
      "total_cost: 163344.26\n",
      "total_trades: 50936\n",
      "Sharpe: 0.546\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.73e+06    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 7.32e+05    |\n",
      "|    total_reward_pct     | 73.2        |\n",
      "|    total_trades         | 50936       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025282552 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0562      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.92        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.59e+06    |\n",
      "|    total_cost           | 1.66e+05    |\n",
      "|    total_reward         | 5.87e+05    |\n",
      "|    total_reward_pct     | 58.7        |\n",
      "|    total_trades         | 51439       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026220331 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0473      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.85        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.23        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.91e+06    |\n",
      "|    total_cost           | 1.72e+05    |\n",
      "|    total_reward         | 9.05e+05    |\n",
      "|    total_reward_pct     | 90.5        |\n",
      "|    total_trades         | 51722       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038715065 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0525      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.18        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.96e+06    |\n",
      "|    total_cost           | 1.71e+05    |\n",
      "|    total_reward         | 9.62e+05    |\n",
      "|    total_reward_pct     | 96.2        |\n",
      "|    total_trades         | 51646       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024747469 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0674      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.56        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.87        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.19e+06   |\n",
      "|    total_cost           | 1.63e+05   |\n",
      "|    total_reward         | 1.19e+06   |\n",
      "|    total_reward_pct     | 119        |\n",
      "|    total_trades         | 51271      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 143        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 228        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03946929 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.05       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.33       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0249    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 10.8       |\n",
      "----------------------------------------\n",
      "day: 1824, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2017661.25\n",
      "total_reward: 1017661.25\n",
      "total_cost: 160715.57\n",
      "total_trades: 51325\n",
      "Sharpe: 0.704\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.12e+06  |\n",
      "|    total_cost           | 1.5e+05   |\n",
      "|    total_reward         | 1.12e+06  |\n",
      "|    total_reward_pct     | 112       |\n",
      "|    total_trades         | 49987     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 142       |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 244       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0313754 |\n",
      "|    clip_fraction        | 0.323     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.5     |\n",
      "|    explained_variance   | 0.0518    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 5.6       |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -0.026    |\n",
      "|    std                  | 1.03      |\n",
      "|    value_loss           | 12        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.03e+06    |\n",
      "|    total_cost           | 1.65e+05    |\n",
      "|    total_reward         | 1.03e+06    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 51535       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022491544 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.09        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.23e+06    |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 1.23e+06    |\n",
      "|    total_reward_pct     | 123         |\n",
      "|    total_trades         | 51560       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033023447 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0942      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.17        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.86e+06    |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 8.59e+05    |\n",
      "|    total_reward_pct     | 85.9        |\n",
      "|    total_trades         | 50803       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025150556 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0708      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.29        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2022894.15\n",
      "total_reward: 1022894.15\n",
      "total_cost: 166950.74\n",
      "total_trades: 51470\n",
      "Sharpe: 0.717\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.02e+06   |\n",
      "|    total_cost           | 1.67e+05   |\n",
      "|    total_reward         | 1.02e+06   |\n",
      "|    total_reward_pct     | 102        |\n",
      "|    total_trades         | 51470      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 136        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 315        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03375178 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.0998     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.48       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0259    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 8.83       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.88e+06   |\n",
      "|    total_cost           | 1.61e+05   |\n",
      "|    total_reward         | 8.84e+05   |\n",
      "|    total_reward_pct     | 88.4       |\n",
      "|    total_trades         | 50932      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 333        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03183168 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.0704     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.54       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0268    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 9.23       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.86e+06    |\n",
      "|    total_cost           | 1.64e+05    |\n",
      "|    total_reward         | 8.56e+05    |\n",
      "|    total_reward_pct     | 85.6        |\n",
      "|    total_trades         | 51061       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 350         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037337046 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.109      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.32        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.68        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.49e+06    |\n",
      "|    total_cost           | 1.54e+05    |\n",
      "|    total_reward         | 1.49e+06    |\n",
      "|    total_reward_pct     | 149         |\n",
      "|    total_trades         | 49706       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 366         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037907954 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0792      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.57        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.6        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1818406.63\n",
      "total_reward: 818406.63\n",
      "total_cost: 158754.83\n",
      "total_trades: 50286\n",
      "Sharpe: 0.571\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.82e+06   |\n",
      "|    total_cost           | 1.59e+05   |\n",
      "|    total_reward         | 8.18e+05   |\n",
      "|    total_reward_pct     | 81.8       |\n",
      "|    total_trades         | 50286      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 379        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02474267 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.00877    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.55       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0227    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 21         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+06     |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 1.5e+06     |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 51133       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031735487 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.74        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.31e+06    |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | 1.31e+06    |\n",
      "|    total_reward_pct     | 131         |\n",
      "|    total_trades         | 50017       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028799526 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.94        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+06    |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | 1.58e+06    |\n",
      "|    total_reward_pct     | 158         |\n",
      "|    total_trades         | 50015       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016471619 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.71        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.29e+06    |\n",
      "|    total_cost           | 1.59e+05    |\n",
      "|    total_reward         | 1.29e+06    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 50247       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037626438 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.9         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1824, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2904344.21\n",
      "total_reward: 1904344.21\n",
      "total_cost: 165552.77\n",
      "total_trades: 50863\n",
      "Sharpe: 1.005\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.9e+06     |\n",
      "|    total_cost           | 1.66e+05    |\n",
      "|    total_reward         | 1.9e+06     |\n",
      "|    total_reward_pct     | 190         |\n",
      "|    total_trades         | 50863       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 446         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030485952 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0352      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.47        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.67e+06    |\n",
      "|    total_cost           | 1.69e+05    |\n",
      "|    total_reward         | 1.67e+06    |\n",
      "|    total_reward_pct     | 167         |\n",
      "|    total_trades         | 50753       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040823013 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.7e+06     |\n",
      "|    total_cost           | 1.53e+05    |\n",
      "|    total_reward         | 1.7e+06     |\n",
      "|    total_reward_pct     | 170         |\n",
      "|    total_trades         | 49691       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 472         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029712938 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+06    |\n",
      "|    total_cost           | 1.41e+05    |\n",
      "|    total_reward         | 1.61e+06    |\n",
      "|    total_reward_pct     | 161         |\n",
      "|    total_trades         | 47966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 485         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034479022 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0677      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2797249.13\n",
      "total_reward: 1797249.13\n",
      "total_cost: 138066.28\n",
      "total_trades: 48122\n",
      "Sharpe: 0.878\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+06     |\n",
      "|    total_cost           | 1.38e+05    |\n",
      "|    total_reward         | 1.8e+06     |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 48122       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 498         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019164152 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.94        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.88e+06    |\n",
      "|    total_cost           | 1.29e+05    |\n",
      "|    total_reward         | 1.88e+06    |\n",
      "|    total_reward_pct     | 188         |\n",
      "|    total_trades         | 47162       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034904897 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+06    |\n",
      "|    total_cost           | 1.33e+05    |\n",
      "|    total_reward         | 1.78e+06    |\n",
      "|    total_reward_pct     | 178         |\n",
      "|    total_trades         | 47255       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 524         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018958805 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.54e+06   |\n",
      "|    total_cost           | 1.45e+05   |\n",
      "|    total_reward         | 1.54e+06   |\n",
      "|    total_reward_pct     | 154        |\n",
      "|    total_trades         | 48409      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 537        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04474765 |\n",
      "|    clip_fraction        | 0.447      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.196      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.56       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | 0.00278    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 23.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+06     |\n",
      "|    total_cost           | 1.35e+05    |\n",
      "|    total_reward         | 1.8e+06     |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 47441       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 550         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035133697 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2953472.76\n",
      "total_reward: 1953472.76\n",
      "total_cost: 130232.23\n",
      "total_trades: 46795\n",
      "Sharpe: 0.964\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.95e+06    |\n",
      "|    total_cost           | 1.3e+05     |\n",
      "|    total_reward         | 1.95e+06    |\n",
      "|    total_reward_pct     | 195         |\n",
      "|    total_trades         | 46795       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 563         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025223566 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 1.52e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 49137       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 576         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050981984 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0966      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.76        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+06     |\n",
      "|    total_cost           | 1.66e+05    |\n",
      "|    total_reward         | 1.5e+06     |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 50600       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028749436 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.94        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.53e+06    |\n",
      "|    total_cost           | 1.62e+05    |\n",
      "|    total_reward         | 1.53e+06    |\n",
      "|    total_reward_pct     | 153         |\n",
      "|    total_trades         | 50581       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033595905 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.38        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2271162.84\n",
      "total_reward: 1271162.84\n",
      "total_cost: 150823.84\n",
      "total_trades: 49567\n",
      "Sharpe: 0.870\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.27e+06   |\n",
      "|    total_cost           | 1.51e+05   |\n",
      "|    total_reward         | 1.27e+06   |\n",
      "|    total_reward_pct     | 127        |\n",
      "|    total_trades         | 49567      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 142        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 615        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03359988 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.308      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.82       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 9.12       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+06    |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 1.33e+06    |\n",
      "|    total_reward_pct     | 133         |\n",
      "|    total_trades         | 50263       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 143         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 628         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030385258 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.2         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 8.18        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.1e+06    |\n",
      "|    total_cost           | 1.63e+05   |\n",
      "|    total_reward         | 1.1e+06    |\n",
      "|    total_reward_pct     | 110        |\n",
      "|    total_trades         | 50672      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 143        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 642        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05432821 |\n",
      "|    clip_fraction        | 0.352      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.244      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.99       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0168    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 7.68       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.69e+06    |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | 1.69e+06    |\n",
      "|    total_reward_pct     | 169         |\n",
      "|    total_trades         | 48626       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 143         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 654         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019081697 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.6         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 7.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.47e+06    |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | 1.47e+06    |\n",
      "|    total_reward_pct     | 147         |\n",
      "|    total_trades         | 50210       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022493232 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.27        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "day: 1824, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2468756.47\n",
      "total_reward: 1468756.47\n",
      "total_cost: 150166.24\n",
      "total_trades: 49112\n",
      "Sharpe: 0.856\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.47e+06    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 1.47e+06    |\n",
      "|    total_reward_pct     | 147         |\n",
      "|    total_trades         | 49112       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 680         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037228756 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.27        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.14e+06    |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 1.14e+06    |\n",
      "|    total_reward_pct     | 114         |\n",
      "|    total_trades         | 49988       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 694         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029639496 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.094       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.51        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2017-04-04 to  2017-07-05\n",
      "PPO Sharpe Ratio:  0.26953847426762984\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_5\n",
      "day: 1824, episode: 75\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2426625.07\n",
      "total_reward: 1426625.07\n",
      "total_cost: 2461.00\n",
      "total_trades: 25009\n",
      "Sharpe: 0.893\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.25e+06 |\n",
      "|    total_cost       | 2.38e+03 |\n",
      "|    total_reward     | 1.25e+06 |\n",
      "|    total_reward_pct | 125      |\n",
      "|    total_trades     | 25655    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 57       |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total timesteps  | 7300     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -42      |\n",
      "|    critic_loss      | 153      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5475     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2017-04-04 to  2017-07-05\n",
      "======Best Model Retraining from:  2010-01-01 to  2017-07-05\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_252_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0177   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -86.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0388  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 83.3     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -99.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.47e+06 |\n",
      "|    total_cost         | 6.01e+04 |\n",
      "|    total_reward       | 4.68e+05 |\n",
      "|    total_reward_pct   | 46.8     |\n",
      "|    total_trades       | 38927    |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0184   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -42.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.2      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0069  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -32.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 3.34e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -27      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.616    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.57e+06 |\n",
      "|    total_cost         | 4.62e+04 |\n",
      "|    total_reward       | 5.71e+05 |\n",
      "|    total_reward_pct   | 57.1     |\n",
      "|    total_trades       | 35969    |\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0607  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -36.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0614  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -133     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 15.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -15.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00158  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -157     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 15.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.59e+06 |\n",
      "|    total_cost         | 3.92e+04 |\n",
      "|    total_reward       | 5.86e+05 |\n",
      "|    total_reward_pct   | 58.6     |\n",
      "|    total_trades       | 34612    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0415  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 154      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 15.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 142       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 18.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.06      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 2.28     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.143    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.61e+06 |\n",
      "|    total_cost         | 1.81e+04 |\n",
      "|    total_reward       | 6.15e+05 |\n",
      "|    total_reward_pct   | 61.5     |\n",
      "|    total_trades       | 32809    |\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 92.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.49     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -41.9     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.96      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -35.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.28     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1887, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1690271.45\n",
      "total_reward: 690271.45\n",
      "total_cost: 30092.36\n",
      "total_trades: 34464\n",
      "Sharpe: 0.476\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.69e+06 |\n",
      "|    total_cost         | 3.01e+04 |\n",
      "|    total_reward       | 6.9e+05  |\n",
      "|    total_reward_pct   | 69       |\n",
      "|    total_trades       | 34464    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.529   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 18.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.176    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 48.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -144     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 15.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 11.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.32e+06 |\n",
      "|    total_cost         | 4.24e+04 |\n",
      "|    total_reward       | 1.32e+06 |\n",
      "|    total_reward_pct   | 132      |\n",
      "|    total_trades       | 37237    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.23     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 86.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.153    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -15.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.923    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0461   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 37.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -47.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.68e+06 |\n",
      "|    total_cost         | 6.73e+04 |\n",
      "|    total_reward       | 6.75e+05 |\n",
      "|    total_reward_pct   | 67.5     |\n",
      "|    total_trades       | 40457    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.123    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 46.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.136   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -51.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 143      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.222    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 71.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.61e+06 |\n",
      "|    total_cost         | 7.66e+04 |\n",
      "|    total_reward       | 6.13e+05 |\n",
      "|    total_reward_pct   | 61.3     |\n",
      "|    total_trades       | 41279    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.109   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 76.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.63     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 142       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 23.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.808     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.00761 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 71.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.21e+06 |\n",
      "|    total_cost         | 7.24e+04 |\n",
      "|    total_reward       | 1.21e+06 |\n",
      "|    total_reward_pct   | 121      |\n",
      "|    total_trades       | 41362    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.02     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -111     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 143       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -26.8     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.05      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 111      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -85.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "day: 1887, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2095277.29\n",
      "total_reward: 1095277.29\n",
      "total_cost: 67816.40\n",
      "total_trades: 40438\n",
      "Sharpe: 0.694\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.1e+06  |\n",
      "|    total_cost         | 6.78e+04 |\n",
      "|    total_reward       | 1.1e+06  |\n",
      "|    total_reward_pct   | 110      |\n",
      "|    total_trades       | 40438    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.203    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 45.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.74     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 143       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -8.34e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 78.1      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5.98      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0137  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 12.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.678    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.148   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -4.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.182    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.07e+06 |\n",
      "|    total_cost         | 4.6e+04  |\n",
      "|    total_reward       | 1.07e+06 |\n",
      "|    total_reward_pct   | 107      |\n",
      "|    total_trades       | 37568    |\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -48.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 102      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0311  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 3.23     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.128    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 413      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 106      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.85e+06 |\n",
      "|    total_cost         | 8.76e+04 |\n",
      "|    total_reward       | 1.85e+06 |\n",
      "|    total_reward_pct   | 185      |\n",
      "|    total_trades       | 43991    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.00644  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -33.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.097   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 74.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.07     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 143       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 167       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 17.9      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.949     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0633   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 298      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 60.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.81e+06 |\n",
      "|    total_cost         | 5.1e+04  |\n",
      "|    total_reward       | 8.08e+05 |\n",
      "|    total_reward_pct   | 80.8     |\n",
      "|    total_trades       | 39352    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.105   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -42.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.321    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0248   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 289      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 60.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.6e+06  |\n",
      "|    total_cost         | 3.71e+04 |\n",
      "|    total_reward       | 5.96e+05 |\n",
      "|    total_reward_pct   | 59.6     |\n",
      "|    total_trades       | 37419    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.569   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -3.15    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.118    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -43.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 143       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 191       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 83.4      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.35      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 112      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "day: 1887, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1948803.08\n",
      "total_reward: 948803.08\n",
      "total_cost: 24183.40\n",
      "total_trades: 36372\n",
      "Sharpe: 0.570\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.95e+06 |\n",
      "|    total_cost         | 2.42e+04 |\n",
      "|    total_reward       | 9.49e+05 |\n",
      "|    total_reward_pct   | 94.9     |\n",
      "|    total_trades       | 36372    |\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 21.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.654    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.0683   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 40.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.39     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0121   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -60.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 1.79e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 7.31     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.366    |\n",
      "------------------------------------\n",
      "======Trading from:  2017-07-05 to  2017-10-03\n",
      "============================================\n",
      "63.29814197861714\n",
      "turbulence_threshold:  51.492391905857524\n",
      "======Model training from:  2010-01-01 to  2017-07-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_315_5\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -2.09    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -42.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 4.17e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -12.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.675    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0445   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -69.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.69e+06 |\n",
      "|    total_cost         | 1.31e+05 |\n",
      "|    total_reward       | 1.69e+06 |\n",
      "|    total_reward_pct   | 169      |\n",
      "|    total_trades       | 48988    |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.304    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -25.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0095  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -35.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -1.05    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 97.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0594   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 5.74     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.48e+06 |\n",
      "|    total_cost         | 1.05e+05 |\n",
      "|    total_reward       | 1.48e+06 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 45743    |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.416    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -34.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0728   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -91.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.154   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 162      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 43.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.18e+06  |\n",
      "|    total_cost         | 1.1e+05   |\n",
      "|    total_reward       | 1.18e+06  |\n",
      "|    total_reward_pct   | 118       |\n",
      "|    total_trades       | 46821     |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.79e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 70.9      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.97      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 142      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.194    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 49.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 54.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -58.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.4e+06  |\n",
      "|    total_cost         | 8.82e+04 |\n",
      "|    total_reward       | 1.4e+06  |\n",
      "|    total_reward_pct   | 140      |\n",
      "|    total_trades       | 44961    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.249    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -19      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.582    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -23.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.467    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.12    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -2.93    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "day: 1887, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1940274.59\n",
      "total_reward: 940274.59\n",
      "total_cost: 66173.78\n",
      "total_trades: 42363\n",
      "Sharpe: 0.619\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.94e+06 |\n",
      "|    total_cost         | 6.62e+04 |\n",
      "|    total_reward       | 9.4e+05  |\n",
      "|    total_reward_pct   | 94       |\n",
      "|    total_trades       | 42363    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.407    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -86.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.21     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -2.86e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 31.8      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.36      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.193   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -119     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0139  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -17.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.561    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.46e+06 |\n",
      "|    total_cost         | 7.36e+04 |\n",
      "|    total_reward       | 1.46e+06 |\n",
      "|    total_reward_pct   | 146      |\n",
      "|    total_trades       | 42597    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0556  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 74.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -32.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0571   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 15.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.00616 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -43.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.02     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.32e+06 |\n",
      "|    total_cost         | 5.01e+04 |\n",
      "|    total_reward       | 1.32e+06 |\n",
      "|    total_reward_pct   | 132      |\n",
      "|    total_trades       | 40171    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.174    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 31.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.955    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 31.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.916    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0532  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 83.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.18     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 29        |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.17      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.29e+06 |\n",
      "|    total_cost         | 2.95e+04 |\n",
      "|    total_reward       | 1.29e+06 |\n",
      "|    total_reward_pct   | 129      |\n",
      "|    total_trades       | 36963    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0367  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 39.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0403   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 42.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0376  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 54.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.46e+06 |\n",
      "|    total_cost         | 2.8e+04  |\n",
      "|    total_reward       | 1.46e+06 |\n",
      "|    total_reward_pct   | 146      |\n",
      "|    total_trades       | 36103    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.357   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -80.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -7.21    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.319    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 74.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 20.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.8      |\n",
      "------------------------------------\n",
      "day: 1887, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2506855.35\n",
      "total_reward: 1506855.35\n",
      "total_cost: 19884.00\n",
      "total_trades: 35326\n",
      "Sharpe: 0.918\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.51e+06 |\n",
      "|    total_cost         | 1.99e+04 |\n",
      "|    total_reward       | 1.51e+06 |\n",
      "|    total_reward_pct   | 151      |\n",
      "|    total_trades       | 35326    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0187   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 34.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 71.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.95     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.134    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 41.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.0808  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 18.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.52e+06 |\n",
      "|    total_cost         | 1.04e+04 |\n",
      "|    total_reward       | 1.52e+06 |\n",
      "|    total_reward_pct   | 152      |\n",
      "|    total_trades       | 33785    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -53.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 67.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -27.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.496    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 122      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 14.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.26e+06 |\n",
      "|    total_cost         | 9.18e+03 |\n",
      "|    total_reward       | 1.26e+06 |\n",
      "|    total_reward_pct   | 126      |\n",
      "|    total_trades       | 33140    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -23      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.893    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 22.1      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.965     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -44.4    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.0602   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 108      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 7        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.37e+06 |\n",
      "|    total_cost         | 8.23e+03 |\n",
      "|    total_reward       | 1.37e+06 |\n",
      "|    total_reward_pct   | 137      |\n",
      "|    total_trades       | 32153    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -57.8    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 84.7     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 6.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 191      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 24.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.25e+06  |\n",
      "|    total_cost         | 6.16e+03  |\n",
      "|    total_reward       | 1.25e+06  |\n",
      "|    total_reward_pct   | 125       |\n",
      "|    total_trades       | 29685     |\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 192       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 10.5      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.154     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 196       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -18.6     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.387     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 36.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 66.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.89     |\n",
      "------------------------------------\n",
      "day: 1887, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2314717.59\n",
      "total_reward: 1314717.59\n",
      "total_cost: 4679.01\n",
      "total_trades: 28477\n",
      "Sharpe: 0.867\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.31e+06 |\n",
      "|    total_cost         | 4.68e+03 |\n",
      "|    total_reward       | 1.31e+06 |\n",
      "|    total_reward_pct   | 131      |\n",
      "|    total_trades       | 28477    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 48.3     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 64.1     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 17.4     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.204    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 44       |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2017-07-05 to  2017-10-03\n",
      "A2C Sharpe Ratio:  0.029303455295138496\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_315_5\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.6e+06  |\n",
      "|    total_cost       | 1.88e+05 |\n",
      "|    total_reward     | 6.04e+05 |\n",
      "|    total_reward_pct | 60.4     |\n",
      "|    total_trades     | 54284    |\n",
      "| time/               |          |\n",
      "|    fps              | 145      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.21e+06    |\n",
      "|    total_cost           | 1.87e+05    |\n",
      "|    total_reward         | 1.21e+06    |\n",
      "|    total_reward_pct     | 121         |\n",
      "|    total_trades         | 54220       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016978618 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0356     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.06        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 5.96        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.29e+06    |\n",
      "|    total_cost           | 1.87e+05    |\n",
      "|    total_reward         | 1.29e+06    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 54349       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010767169 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00755    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.53        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 7.79        |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2146588.70\n",
      "total_reward: 1146588.70\n",
      "total_cost: 184937.61\n",
      "total_trades: 54108\n",
      "Sharpe: 0.781\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.15e+06    |\n",
      "|    total_cost           | 1.85e+05    |\n",
      "|    total_reward         | 1.15e+06    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 54108       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010478005 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.13        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.08e+06    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 1.08e+06    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 53932       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 143         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014503224 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.054       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.67        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.05e+06    |\n",
      "|    total_cost           | 1.8e+05     |\n",
      "|    total_reward         | 1.05e+06    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 53604       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016002022 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00109     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.18        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+06    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 1.04e+06    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 53761       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011076195 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0394      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.66        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.89e+06    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 8.9e+05     |\n",
      "|    total_reward_pct     | 89          |\n",
      "|    total_trades         | 53831       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018404678 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0288      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.99        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.18        |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2027189.16\n",
      "total_reward: 1027189.16\n",
      "total_cost: 178978.05\n",
      "total_trades: 53677\n",
      "Sharpe: 0.717\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.03e+06   |\n",
      "|    total_cost           | 1.79e+05   |\n",
      "|    total_reward         | 1.03e+06   |\n",
      "|    total_reward_pct     | 103        |\n",
      "|    total_trades         | 53677      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 125        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02171241 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | 0.122      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.43       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0232    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 7.74       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.87e+06    |\n",
      "|    total_cost           | 1.72e+05    |\n",
      "|    total_reward         | 8.7e+05     |\n",
      "|    total_reward_pct     | 87          |\n",
      "|    total_trades         | 53042       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014703084 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0613      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.13        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.72        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.06e+06    |\n",
      "|    total_cost           | 1.73e+05    |\n",
      "|    total_reward         | 1.06e+06    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 53021       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022340063 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.24        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.95e+06    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 9.47e+05    |\n",
      "|    total_reward_pct     | 94.7        |\n",
      "|    total_trades         | 53179       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024171622 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0632      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.27        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.24        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1887, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2130363.13\n",
      "total_reward: 1130363.13\n",
      "total_cost: 178335.10\n",
      "total_trades: 53675\n",
      "Sharpe: 0.800\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.13e+06   |\n",
      "|    total_cost           | 1.78e+05   |\n",
      "|    total_reward         | 1.13e+06   |\n",
      "|    total_reward_pct     | 113        |\n",
      "|    total_trades         | 53675      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 181        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02900898 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.0802     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.1        |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0286    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 7.57       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.31e+06    |\n",
      "|    total_cost           | 1.72e+05    |\n",
      "|    total_reward         | 1.31e+06    |\n",
      "|    total_reward_pct     | 131         |\n",
      "|    total_trades         | 53139       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031256452 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.96        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 6.93        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.97e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 9.66e+05    |\n",
      "|    total_reward_pct     | 96.6        |\n",
      "|    total_trades         | 53496       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014253439 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.46        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.79e+06    |\n",
      "|    total_cost           | 1.8e+05     |\n",
      "|    total_reward         | 7.9e+05     |\n",
      "|    total_reward_pct     | 79          |\n",
      "|    total_trades         | 53551       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022175835 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.99        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 6.84        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.06e+06   |\n",
      "|    total_cost           | 1.73e+05   |\n",
      "|    total_reward         | 1.06e+06   |\n",
      "|    total_reward_pct     | 106        |\n",
      "|    total_trades         | 53205      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 236        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02577689 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0475     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.14       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0297    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 6.39       |\n",
      "----------------------------------------\n",
      "day: 1887, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1904465.43\n",
      "total_reward: 904465.43\n",
      "total_cost: 172909.17\n",
      "total_trades: 53281\n",
      "Sharpe: 0.678\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.9e+06    |\n",
      "|    total_cost           | 1.73e+05   |\n",
      "|    total_reward         | 9.04e+05   |\n",
      "|    total_reward_pct     | 90.4       |\n",
      "|    total_trades         | 53281      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 249        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03417629 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0466     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.93       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0249    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 7.19       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.76e+06    |\n",
      "|    total_cost           | 1.67e+05    |\n",
      "|    total_reward         | 7.57e+05    |\n",
      "|    total_reward_pct     | 75.7        |\n",
      "|    total_trades         | 52318       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019466586 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0414      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.31        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 6.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.86e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 8.56e+05    |\n",
      "|    total_reward_pct     | 85.6        |\n",
      "|    total_trades         | 53168       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008588461 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0639      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.07        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 7.95        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.96e+06     |\n",
      "|    total_cost           | 1.72e+05     |\n",
      "|    total_reward         | 9.64e+05     |\n",
      "|    total_reward_pct     | 96.4         |\n",
      "|    total_trades         | 53145        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 148          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 290          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146164335 |\n",
      "|    clip_fraction        | 0.218        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.5        |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.09         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0253      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 6.08         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.74e+06    |\n",
      "|    total_cost           | 1.77e+05    |\n",
      "|    total_reward         | 7.44e+05    |\n",
      "|    total_reward_pct     | 74.4        |\n",
      "|    total_trades         | 52978       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040031288 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0638      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.27        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 6.75        |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2122740.63\n",
      "total_reward: 1122740.63\n",
      "total_cost: 182415.34\n",
      "total_trades: 53895\n",
      "Sharpe: 0.817\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.12e+06   |\n",
      "|    total_cost           | 1.82e+05   |\n",
      "|    total_reward         | 1.12e+06   |\n",
      "|    total_reward_pct     | 112        |\n",
      "|    total_trades         | 53895      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 317        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03265841 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.087      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.73       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 7.45       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.35e+06    |\n",
      "|    total_cost           | 1.52e+05    |\n",
      "|    total_reward         | 1.35e+06    |\n",
      "|    total_reward_pct     | 135         |\n",
      "|    total_trades         | 51760       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022574425 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.037       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.61        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.16        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.3e+06    |\n",
      "|    total_cost           | 1.54e+05   |\n",
      "|    total_reward         | 1.3e+06    |\n",
      "|    total_reward_pct     | 130        |\n",
      "|    total_trades         | 51606      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 344        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02597478 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0972     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.11       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 10.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.11e+06    |\n",
      "|    total_cost           | 1.52e+05    |\n",
      "|    total_reward         | 1.11e+06    |\n",
      "|    total_reward_pct     | 111         |\n",
      "|    total_trades         | 51374       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027373703 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0985      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.32        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.92        |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2115241.31\n",
      "total_reward: 1115241.31\n",
      "total_cost: 156138.07\n",
      "total_trades: 51721\n",
      "Sharpe: 0.757\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.12e+06   |\n",
      "|    total_cost           | 1.56e+05   |\n",
      "|    total_reward         | 1.12e+06   |\n",
      "|    total_reward_pct     | 112        |\n",
      "|    total_trades         | 51721      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 371        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03152632 |\n",
      "|    clip_fraction        | 0.288      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.194      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.16       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0213    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 6.74       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.31e+06    |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 1.31e+06    |\n",
      "|    total_reward_pct     | 131         |\n",
      "|    total_trades         | 52994       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026075821 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.24        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.71        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.26e+06    |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | 1.26e+06    |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 51519       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 399         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020115964 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.82        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 7.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.15e+06    |\n",
      "|    total_cost           | 1.41e+05    |\n",
      "|    total_reward         | 1.15e+06    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 50603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030234795 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0168      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.63        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 8.71        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.97e+06   |\n",
      "|    total_cost           | 1.51e+05   |\n",
      "|    total_reward         | 9.66e+05   |\n",
      "|    total_reward_pct     | 96.6       |\n",
      "|    total_trades         | 51506      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 426        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04216104 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.11       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.38       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 8.72       |\n",
      "----------------------------------------\n",
      "day: 1887, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1865203.79\n",
      "total_reward: 865203.79\n",
      "total_cost: 153971.97\n",
      "total_trades: 51602\n",
      "Sharpe: 0.632\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.87e+06   |\n",
      "|    total_cost           | 1.54e+05   |\n",
      "|    total_reward         | 8.65e+05   |\n",
      "|    total_reward_pct     | 86.5       |\n",
      "|    total_trades         | 51602      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 440        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02735123 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.192      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.58       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0183    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 6.53       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.93e+06   |\n",
      "|    total_cost           | 1.58e+05   |\n",
      "|    total_reward         | 9.31e+05   |\n",
      "|    total_reward_pct     | 93.1       |\n",
      "|    total_trades         | 52182      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 453        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03392476 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.149      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.49       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0168    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 5.72       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+06    |\n",
      "|    total_cost           | 1.59e+05    |\n",
      "|    total_reward         | 8.78e+05    |\n",
      "|    total_reward_pct     | 87.8        |\n",
      "|    total_trades         | 51886       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 467         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028873494 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0736      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.77        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 7.38        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.1e+06    |\n",
      "|    total_cost           | 1.51e+05   |\n",
      "|    total_reward         | 1.1e+06    |\n",
      "|    total_reward_pct     | 110        |\n",
      "|    total_trades         | 51370      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 480        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02350802 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.0656     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.82       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 7.12       |\n",
      "----------------------------------------\n",
      "day: 1887, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2438808.28\n",
      "total_reward: 1438808.28\n",
      "total_cost: 159301.12\n",
      "total_trades: 51913\n",
      "Sharpe: 0.901\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.44e+06    |\n",
      "|    total_cost           | 1.59e+05    |\n",
      "|    total_reward         | 1.44e+06    |\n",
      "|    total_reward_pct     | 144         |\n",
      "|    total_trades         | 51913       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035432406 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.31        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 6.96        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.27e+06    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 1.27e+06    |\n",
      "|    total_reward_pct     | 127         |\n",
      "|    total_trades         | 51729       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 507         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032134965 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.27        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 9.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.15e+06    |\n",
      "|    total_cost           | 1.62e+05    |\n",
      "|    total_reward         | 1.15e+06    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 51477       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020832835 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.62        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 6.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.23e+06    |\n",
      "|    total_cost           | 1.55e+05    |\n",
      "|    total_reward         | 1.23e+06    |\n",
      "|    total_reward_pct     | 123         |\n",
      "|    total_trades         | 51200       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028878525 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.54        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 5.88        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.12e+06    |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | 1.12e+06    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 51904       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035644256 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.36        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 6.48        |\n",
      "-----------------------------------------\n",
      "day: 1887, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1996054.76\n",
      "total_reward: 996054.76\n",
      "total_cost: 162821.95\n",
      "total_trades: 51635\n",
      "Sharpe: 0.715\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2e+06      |\n",
      "|    total_cost           | 1.63e+05   |\n",
      "|    total_reward         | 9.96e+05   |\n",
      "|    total_reward_pct     | 99.6       |\n",
      "|    total_trades         | 51635      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 562        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03491982 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.298      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.95       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0221    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 6.44       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.15e+06    |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 1.15e+06    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 51367       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032448888 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.77        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 6.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.42e+06    |\n",
      "|    total_cost           | 1.57e+05    |\n",
      "|    total_reward         | 1.42e+06    |\n",
      "|    total_reward_pct     | 142         |\n",
      "|    total_trades         | 51428       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036135163 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.65        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 6.63        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.82e+06  |\n",
      "|    total_cost           | 1.55e+05  |\n",
      "|    total_reward         | 8.15e+05  |\n",
      "|    total_reward_pct     | 81.5      |\n",
      "|    total_trades         | 50688     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 44        |\n",
      "|    time_elapsed         | 603       |\n",
      "|    total_timesteps      | 90112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0324479 |\n",
      "|    clip_fraction        | 0.318     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.6     |\n",
      "|    explained_variance   | 0.231     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 2.74      |\n",
      "|    n_updates            | 430       |\n",
      "|    policy_gradient_loss | -0.00763  |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 6.25      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2e+06      |\n",
      "|    total_cost           | 1.58e+05   |\n",
      "|    total_reward         | 9.95e+05   |\n",
      "|    total_reward_pct     | 99.5       |\n",
      "|    total_trades         | 51224      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 616        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03451337 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.152      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.7        |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0227    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 5.56       |\n",
      "----------------------------------------\n",
      "day: 1887, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1922866.71\n",
      "total_reward: 922866.71\n",
      "total_cost: 156370.67\n",
      "total_trades: 50694\n",
      "Sharpe: 0.728\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.92e+06    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | 9.23e+05    |\n",
      "|    total_reward_pct     | 92.3        |\n",
      "|    total_trades         | 50694       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039183572 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.33        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 6           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.79e+06    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 7.93e+05    |\n",
      "|    total_reward_pct     | 79.3        |\n",
      "|    total_trades         | 51566       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 643         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052889083 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.91        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 6.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2e+06       |\n",
      "|    total_cost           | 1.62e+05    |\n",
      "|    total_reward         | 9.96e+05    |\n",
      "|    total_reward_pct     | 99.6        |\n",
      "|    total_trades         | 51688       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 657         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019781679 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0891      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.75        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 6.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.89e+06    |\n",
      "|    total_cost           | 1.65e+05    |\n",
      "|    total_reward         | 8.88e+05    |\n",
      "|    total_reward_pct     | 88.8        |\n",
      "|    total_trades         | 51392       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 670         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038472913 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.69        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 6.03        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2017-07-05 to  2017-10-03\n",
      "PPO Sharpe Ratio:  -0.1250724001493993\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.28e+06 |\n",
      "|    total_cost       | 1.68e+03 |\n",
      "|    total_reward     | 1.28e+06 |\n",
      "|    total_reward_pct | 128      |\n",
      "|    total_trades     | 20587    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 55       |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total timesteps  | 7552     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -6.38    |\n",
      "|    critic_loss      | 9.21     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5664     |\n",
      "----------------------------------\n",
      "day: 1887, episode: 75\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2094910.35\n",
      "total_reward: 1094910.35\n",
      "total_cost: 1483.08\n",
      "total_trades: 22809\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "======DDPG Validation from:  2017-07-05 to  2017-10-03\n",
      "======Best Model Retraining from:  2010-01-01 to  2017-10-03\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_315_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.09e+06 |\n",
      "|    total_cost       | 1.35e+03 |\n",
      "|    total_reward     | 1.09e+06 |\n",
      "|    total_reward_pct | 109      |\n",
      "|    total_trades     | 29848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total timesteps  | 7804     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 36.5     |\n",
      "|    critic_loss      | 475      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5853     |\n",
      "----------------------------------\n",
      "day: 1950, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2008476.07\n",
      "total_reward: 1008476.07\n",
      "total_cost: 1745.72\n",
      "total_trades: 27477\n",
      "Sharpe: 0.681\n",
      "=================================\n",
      "======Trading from:  2017-10-03 to  2018-01-03\n",
      "============================================\n",
      "16.813210198800224\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2017-10-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_378_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -1.09    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -23.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.684    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0458   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -71.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.54     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -28.8     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.99      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.36e+06 |\n",
      "|    total_cost         | 1.35e+05 |\n",
      "|    total_reward       | 1.36e+06 |\n",
      "|    total_reward_pct   | 136      |\n",
      "|    total_trades       | 49311    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 3.36     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0301   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.162    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 11.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.116    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 104      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.94     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 226       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 31.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.41e+06 |\n",
      "|    total_cost         | 1.25e+05 |\n",
      "|    total_reward       | 2.41e+06 |\n",
      "|    total_reward_pct   | 241      |\n",
      "|    total_trades       | 48059    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.149    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -75.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.00782  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -106     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.181   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -140     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.104    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -44.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.07e+06 |\n",
      "|    total_cost         | 1.35e+05 |\n",
      "|    total_reward       | 2.07e+06 |\n",
      "|    total_reward_pct   | 207      |\n",
      "|    total_trades       | 48644    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.875   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.203   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.123   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -22.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.42     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -9.47     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.409     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.111    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.75e+06 |\n",
      "|    total_cost         | 1.29e+05 |\n",
      "|    total_reward       | 7.46e+05 |\n",
      "|    total_reward_pct   | 74.6     |\n",
      "|    total_trades       | 48366    |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.285   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 77.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.66    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -44.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0536   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 45.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0171   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 60.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.83     |\n",
      "------------------------------------\n",
      "day: 1950, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2278285.95\n",
      "total_reward: 1278285.95\n",
      "total_cost: 83437.24\n",
      "total_trades: 42852\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.28e+06 |\n",
      "|    total_cost         | 8.34e+04 |\n",
      "|    total_reward       | 1.28e+06 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 42852    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -2.52    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 16.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.297    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.627   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 20.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.445    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 3.81     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.551    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -60.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.14e+06 |\n",
      "|    total_cost         | 7.32e+04 |\n",
      "|    total_reward       | 1.14e+06 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 41509    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -67      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.82     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -30.1     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.15      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 64.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.24     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 140       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 11        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.27e+06 |\n",
      "|    total_cost         | 6.34e+04 |\n",
      "|    total_reward       | 2.27e+06 |\n",
      "|    total_reward_pct   | 227      |\n",
      "|    total_trades       | 39453    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.284    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.706    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 146      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 13.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0245   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -183     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 20.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 118      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.63e+06 |\n",
      "|    total_cost         | 6.28e+04 |\n",
      "|    total_reward       | 2.63e+06 |\n",
      "|    total_reward_pct   | 263      |\n",
      "|    total_trades       | 38629    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -31.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.597    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.12e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 4.22      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.665     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -138     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 63.8      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5.8       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.93e+06 |\n",
      "|    total_cost         | 6.08e+04 |\n",
      "|    total_reward       | 1.93e+06 |\n",
      "|    total_reward_pct   | 193      |\n",
      "|    total_trades       | 39712    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.102   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -22.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -29.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 140       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 73.7      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 6.51      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.247    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 119      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.31     |\n",
      "------------------------------------\n",
      "day: 1950, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2727531.41\n",
      "total_reward: 1727531.41\n",
      "total_cost: 74669.95\n",
      "total_trades: 39652\n",
      "Sharpe: 1.024\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.73e+06 |\n",
      "|    total_cost         | 7.47e+04 |\n",
      "|    total_reward       | 1.73e+06 |\n",
      "|    total_reward_pct   | 173      |\n",
      "|    total_trades       | 39652    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.0989  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 73.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.00814 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -110     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.0945   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -34.7    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.912    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.43e+06 |\n",
      "|    total_cost         | 7.47e+04 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 143      |\n",
      "|    total_trades       | 41827    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -32      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.0292  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -26.7    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.536    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.00886 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 139      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 16.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -458     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 140      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.26e+06 |\n",
      "|    total_cost         | 5.61e+04 |\n",
      "|    total_reward       | 2.26e+06 |\n",
      "|    total_reward_pct   | 226      |\n",
      "|    total_trades       | 39450    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.203   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -35.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 19.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.381    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.0069   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 126      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.00278 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 51.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.57e+06 |\n",
      "|    total_cost         | 4.15e+04 |\n",
      "|    total_reward       | 1.57e+06 |\n",
      "|    total_reward_pct   | 157      |\n",
      "|    total_trades       | 38430    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.208    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 44       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.0214  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -43.9    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.237    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 40.8     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.00371  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -103     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.31e+06 |\n",
      "|    total_cost         | 4.47e+04 |\n",
      "|    total_reward       | 2.31e+06 |\n",
      "|    total_reward_pct   | 231      |\n",
      "|    total_trades       | 37958    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.0183  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 32.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 138      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -107     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 9.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -145     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "day: 1950, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4200335.22\n",
      "total_reward: 3200335.22\n",
      "total_cost: 30978.72\n",
      "total_trades: 34921\n",
      "Sharpe: 1.267\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.2e+06  |\n",
      "|    total_cost         | 3.1e+04  |\n",
      "|    total_reward       | 3.2e+06  |\n",
      "|    total_reward_pct   | 320      |\n",
      "|    total_trades       | 34921    |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0.324    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 60.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 36.3     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.24     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2017-10-03 to  2018-01-03\n",
      "A2C Sharpe Ratio:  0.7000235040831941\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_378_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.26e+06 |\n",
      "|    total_cost       | 1.99e+05 |\n",
      "|    total_reward     | 1.26e+06 |\n",
      "|    total_reward_pct | 126      |\n",
      "|    total_trades     | 56308    |\n",
      "| time/               |          |\n",
      "|    fps              | 152      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+06    |\n",
      "|    total_cost           | 1.94e+05    |\n",
      "|    total_reward         | 1.04e+06    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 55872       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011026323 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0395     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.01        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 7.34        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.38e+06     |\n",
      "|    total_cost           | 1.89e+05     |\n",
      "|    total_reward         | 1.38e+06     |\n",
      "|    total_reward_pct     | 138          |\n",
      "|    total_trades         | 55326        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 148          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102811325 |\n",
      "|    clip_fraction        | 0.217        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.0338      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.16         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0318      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 7.07         |\n",
      "------------------------------------------\n",
      "day: 1950, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2124048.98\n",
      "total_reward: 1124048.98\n",
      "total_cost: 190771.24\n",
      "total_trades: 55646\n",
      "Sharpe: 0.790\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.12e+06    |\n",
      "|    total_cost           | 1.91e+05    |\n",
      "|    total_reward         | 1.12e+06    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 55646       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017339023 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.91        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.18e+06    |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 1.18e+06    |\n",
      "|    total_reward_pct     | 118         |\n",
      "|    total_trades         | 54614       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007747313 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00511    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.44        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.8         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.32e+06    |\n",
      "|    total_cost           | 1.86e+05    |\n",
      "|    total_reward         | 1.32e+06    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 55305       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022035344 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0181      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.15        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.3e+06     |\n",
      "|    total_cost           | 1.83e+05    |\n",
      "|    total_reward         | 1.3e+06     |\n",
      "|    total_reward_pct     | 130         |\n",
      "|    total_trades         | 55002       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014912793 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0265      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.8         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.08e+06    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 1.08e+06    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 54782       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013748923 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.000349    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.76        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "day: 1950, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2484925.51\n",
      "total_reward: 1484925.51\n",
      "total_cost: 176231.07\n",
      "total_trades: 54315\n",
      "Sharpe: 0.914\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.48e+06   |\n",
      "|    total_cost           | 1.76e+05   |\n",
      "|    total_reward         | 1.48e+06   |\n",
      "|    total_reward_pct     | 148        |\n",
      "|    total_trades         | 54315      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 143        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 128        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01475404 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | 0.0549     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.57       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0216    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 7.78       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.39e+06   |\n",
      "|    total_cost           | 1.75e+05   |\n",
      "|    total_reward         | 1.39e+06   |\n",
      "|    total_reward_pct     | 139        |\n",
      "|    total_trades         | 54484      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 142        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 143        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01791763 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | 0.0473     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.59       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0236    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 9.77       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.07e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 2.07e+06    |\n",
      "|    total_reward_pct     | 207         |\n",
      "|    total_trades         | 53200       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 143         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025272602 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.26        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.59        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.71e+06  |\n",
      "|    total_cost           | 1.65e+05  |\n",
      "|    total_reward         | 1.71e+06  |\n",
      "|    total_reward_pct     | 171       |\n",
      "|    total_trades         | 53536     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 142       |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 172       |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0306615 |\n",
      "|    clip_fraction        | 0.281     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.1     |\n",
      "|    explained_variance   | 0.0618    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 8.95      |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | -0.0255   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 18.5      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.45e+06   |\n",
      "|    total_cost           | 1.56e+05   |\n",
      "|    total_reward         | 2.45e+06   |\n",
      "|    total_reward_pct     | 245        |\n",
      "|    total_trades         | 52466      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 187        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03225891 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.104      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.41       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0247    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 15.5       |\n",
      "----------------------------------------\n",
      "day: 1950, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2711090.50\n",
      "total_reward: 1711090.50\n",
      "total_cost: 157444.62\n",
      "total_trades: 52708\n",
      "Sharpe: 0.971\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.71e+06    |\n",
      "|    total_cost           | 1.57e+05    |\n",
      "|    total_reward         | 1.71e+06    |\n",
      "|    total_reward_pct     | 171         |\n",
      "|    total_trades         | 52708       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023363316 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0364      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.22        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.99e+06    |\n",
      "|    total_cost           | 1.46e+05    |\n",
      "|    total_reward         | 1.99e+06    |\n",
      "|    total_reward_pct     | 199         |\n",
      "|    total_trades         | 51671       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023935903 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.22        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.28e+06    |\n",
      "|    total_cost           | 1.67e+05    |\n",
      "|    total_reward         | 2.28e+06    |\n",
      "|    total_reward_pct     | 228         |\n",
      "|    total_trades         | 53344       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027197944 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.27        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.09e+06    |\n",
      "|    total_cost           | 1.59e+05    |\n",
      "|    total_reward         | 2.09e+06    |\n",
      "|    total_reward_pct     | 209         |\n",
      "|    total_trades         | 52546       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018285098 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0162     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.35e+06    |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | 2.35e+06    |\n",
      "|    total_reward_pct     | 235         |\n",
      "|    total_trades         | 51435       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026656091 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0388      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.97        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "day: 1950, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3237234.00\n",
      "total_reward: 2237234.00\n",
      "total_cost: 158490.66\n",
      "total_trades: 52586\n",
      "Sharpe: 1.068\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.24e+06    |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | 2.24e+06    |\n",
      "|    total_reward_pct     | 224         |\n",
      "|    total_trades         | 52586       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029838892 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.47        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.39e+06    |\n",
      "|    total_cost           | 1.65e+05    |\n",
      "|    total_reward         | 2.39e+06    |\n",
      "|    total_reward_pct     | 239         |\n",
      "|    total_trades         | 53075       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011083577 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0408      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.18        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.54e+06    |\n",
      "|    total_cost           | 1.53e+05    |\n",
      "|    total_reward         | 2.54e+06    |\n",
      "|    total_reward_pct     | 254         |\n",
      "|    total_trades         | 51654       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023961473 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.76e+06   |\n",
      "|    total_cost           | 1.32e+05   |\n",
      "|    total_reward         | 2.76e+06   |\n",
      "|    total_reward_pct     | 276        |\n",
      "|    total_trades         | 49962      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 136        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 330        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03879296 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.203      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.17       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 22.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1950, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3632514.09\n",
      "total_reward: 2632514.09\n",
      "total_cost: 136771.12\n",
      "total_trades: 50250\n",
      "Sharpe: 1.015\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.63e+06    |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 2.63e+06    |\n",
      "|    total_reward_pct     | 263         |\n",
      "|    total_trades         | 50250       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016790628 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.06e+06    |\n",
      "|    total_cost           | 1.25e+05    |\n",
      "|    total_reward         | 3.06e+06    |\n",
      "|    total_reward_pct     | 306         |\n",
      "|    total_trades         | 49154       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018134024 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.59e+06    |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | 2.59e+06    |\n",
      "|    total_reward_pct     | 259         |\n",
      "|    total_trades         | 52435       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024409069 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.000207   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.51e+06    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 2.51e+06    |\n",
      "|    total_reward_pct     | 251         |\n",
      "|    total_trades         | 52467       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022685079 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.68        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.7e+06     |\n",
      "|    total_cost           | 1.52e+05    |\n",
      "|    total_reward         | 2.7e+06     |\n",
      "|    total_reward_pct     | 270         |\n",
      "|    total_trades         | 51406       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035398684 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.64        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "day: 1950, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3225847.76\n",
      "total_reward: 2225847.76\n",
      "total_cost: 146264.34\n",
      "total_trades: 51106\n",
      "Sharpe: 1.049\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.23e+06    |\n",
      "|    total_cost           | 1.46e+05    |\n",
      "|    total_reward         | 2.23e+06    |\n",
      "|    total_reward_pct     | 223         |\n",
      "|    total_trades         | 51106       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011403782 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.96e+06    |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | 2.96e+06    |\n",
      "|    total_reward_pct     | 296         |\n",
      "|    total_trades         | 51265       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 439         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022068005 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.92        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.46e+06    |\n",
      "|    total_cost           | 1.59e+05    |\n",
      "|    total_reward         | 2.46e+06    |\n",
      "|    total_reward_pct     | 246         |\n",
      "|    total_trades         | 52079       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 457         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032792307 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.53e+06    |\n",
      "|    total_cost           | 1.51e+05    |\n",
      "|    total_reward         | 2.53e+06    |\n",
      "|    total_reward_pct     | 253         |\n",
      "|    total_trades         | 51052       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038271323 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.73        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.06e+06   |\n",
      "|    total_cost           | 1.57e+05   |\n",
      "|    total_reward         | 3.06e+06   |\n",
      "|    total_reward_pct     | 306        |\n",
      "|    total_trades         | 51762      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 484        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01956982 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.42       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.4       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0178    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 24.3       |\n",
      "----------------------------------------\n",
      "day: 1950, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3873694.60\n",
      "total_reward: 2873694.60\n",
      "total_cost: 133005.31\n",
      "total_trades: 49772\n",
      "Sharpe: 1.055\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.87e+06    |\n",
      "|    total_cost           | 1.33e+05    |\n",
      "|    total_reward         | 2.87e+06    |\n",
      "|    total_reward_pct     | 287         |\n",
      "|    total_trades         | 49772       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014997574 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.5e+06     |\n",
      "|    total_cost           | 1.43e+05    |\n",
      "|    total_reward         | 3.5e+06     |\n",
      "|    total_reward_pct     | 350         |\n",
      "|    total_trades         | 50708       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 513         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044782743 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.54        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.21e+06   |\n",
      "|    total_cost           | 1.21e+05   |\n",
      "|    total_reward         | 3.21e+06   |\n",
      "|    total_reward_pct     | 321        |\n",
      "|    total_trades         | 48976      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 527        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01484862 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.489      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.1       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 38.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.85e+06    |\n",
      "|    total_cost           | 1.17e+05    |\n",
      "|    total_reward         | 2.85e+06    |\n",
      "|    total_reward_pct     | 285         |\n",
      "|    total_trades         | 48324       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 542         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017685467 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 3.62e+06     |\n",
      "|    total_cost           | 1.4e+05      |\n",
      "|    total_reward         | 2.62e+06     |\n",
      "|    total_reward_pct     | 262          |\n",
      "|    total_trades         | 50348        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 136          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 556          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148115065 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44          |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0166      |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "day: 1950, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4138068.87\n",
      "total_reward: 3138068.87\n",
      "total_cost: 130386.02\n",
      "total_trades: 49494\n",
      "Sharpe: 1.066\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.14e+06    |\n",
      "|    total_cost           | 1.3e+05     |\n",
      "|    total_reward         | 3.14e+06    |\n",
      "|    total_reward_pct     | 314         |\n",
      "|    total_trades         | 49494       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022168022 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.31e+06    |\n",
      "|    total_cost           | 1.08e+05    |\n",
      "|    total_reward         | 3.31e+06    |\n",
      "|    total_reward_pct     | 331         |\n",
      "|    total_trades         | 46988       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 584         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014775269 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.29e+06   |\n",
      "|    total_cost           | 1.22e+05   |\n",
      "|    total_reward         | 3.29e+06   |\n",
      "|    total_reward_pct     | 329        |\n",
      "|    total_trades         | 48534      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 136        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 598        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03944858 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.438      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.7       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.005     |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 43.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.29e+06    |\n",
      "|    total_cost           | 1.22e+05    |\n",
      "|    total_reward         | 3.29e+06    |\n",
      "|    total_reward_pct     | 329         |\n",
      "|    total_trades         | 48622       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 612         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011222588 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n",
      "day: 1950, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4251152.27\n",
      "total_reward: 3251152.27\n",
      "total_cost: 130492.11\n",
      "total_trades: 49417\n",
      "Sharpe: 1.126\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.25e+06    |\n",
      "|    total_cost           | 1.3e+05     |\n",
      "|    total_reward         | 3.25e+06    |\n",
      "|    total_reward_pct     | 325         |\n",
      "|    total_trades         | 49417       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 628         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023030337 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.35e+06    |\n",
      "|    total_cost           | 1.15e+05    |\n",
      "|    total_reward         | 3.35e+06    |\n",
      "|    total_reward_pct     | 335         |\n",
      "|    total_trades         | 47794       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 642         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030009625 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 4.37e+06     |\n",
      "|    total_cost           | 1.23e+05     |\n",
      "|    total_reward         | 3.37e+06     |\n",
      "|    total_reward_pct     | 337          |\n",
      "|    total_trades         | 48997        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 137          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 656          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026507098 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.2        |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.6         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.41e+06    |\n",
      "|    total_cost           | 1.26e+05    |\n",
      "|    total_reward         | 3.41e+06    |\n",
      "|    total_reward_pct     | 341         |\n",
      "|    total_trades         | 49007       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 670         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013351601 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.59e+06   |\n",
      "|    total_cost           | 1.15e+05   |\n",
      "|    total_reward         | 3.59e+06   |\n",
      "|    total_reward_pct     | 359        |\n",
      "|    total_trades         | 47857      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 137        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 684        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00804561 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.439      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.4       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.009     |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 43         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1950, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4854759.30\n",
      "total_reward: 3854759.30\n",
      "total_cost: 118944.70\n",
      "total_trades: 48625\n",
      "Sharpe: 1.207\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.85e+06    |\n",
      "|    total_cost           | 1.19e+05    |\n",
      "|    total_reward         | 3.85e+06    |\n",
      "|    total_reward_pct     | 385         |\n",
      "|    total_trades         | 48625       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 699         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026974153 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.61e+06    |\n",
      "|    total_cost           | 1.02e+05    |\n",
      "|    total_reward         | 3.61e+06    |\n",
      "|    total_reward_pct     | 361         |\n",
      "|    total_trades         | 46713       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 713         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022006959 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.92e+06    |\n",
      "|    total_cost           | 1.19e+05    |\n",
      "|    total_reward         | 2.92e+06    |\n",
      "|    total_reward_pct     | 292         |\n",
      "|    total_trades         | 48395       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 727         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014672609 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2017-10-03 to  2018-01-03\n",
      "PPO Sharpe Ratio:  0.664932307168685\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_4\n",
      "day: 1950, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2237643.79\n",
      "total_reward: 1237643.79\n",
      "total_cost: 1849.94\n",
      "total_trades: 24308\n",
      "Sharpe: 0.716\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.38e+06 |\n",
      "|    total_cost       | 1.53e+03 |\n",
      "|    total_reward     | 1.38e+06 |\n",
      "|    total_reward_pct | 138      |\n",
      "|    total_trades     | 27585    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 52       |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total timesteps  | 7804     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 66.9     |\n",
      "|    critic_loss      | 74       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5853     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2017-10-03 to  2018-01-03\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-01-03\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_378_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -2.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -47.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.644   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -85.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0515   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -35.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 25.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.51e+06 |\n",
      "|    total_cost         | 1.13e+05 |\n",
      "|    total_reward       | 1.51e+06 |\n",
      "|    total_reward_pct   | 151      |\n",
      "|    total_trades       | 47353    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.19    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 118      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -1.09    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -1.74    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.133    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.019   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 154      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.916   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -66      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.51e+06 |\n",
      "|    total_cost         | 1.26e+05 |\n",
      "|    total_reward       | 1.51e+06 |\n",
      "|    total_reward_pct   | 151      |\n",
      "|    total_trades       | 47042    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.245   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 61.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.32     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 136       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -0.000359 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 25.4      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.653     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -96.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 48.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.18e+06 |\n",
      "|    total_cost         | 1.07e+05 |\n",
      "|    total_reward       | 1.18e+06 |\n",
      "|    total_reward_pct   | 118      |\n",
      "|    total_trades       | 47047    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.069   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -18.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.649    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0371  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 88.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0365  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 87.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.883   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 48.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.26e+06 |\n",
      "|    total_cost         | 1.14e+05 |\n",
      "|    total_reward       | 1.26e+06 |\n",
      "|    total_reward_pct   | 126      |\n",
      "|    total_trades       | 46676    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.241    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 76.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.253    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 7.9      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.691    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -36.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.167   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 61.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.8      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2013, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2328089.34\n",
      "total_reward: 1328089.34\n",
      "total_cost: 96754.21\n",
      "total_trades: 45687\n",
      "Sharpe: 0.794\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.33e+06 |\n",
      "|    total_cost         | 9.68e+04 |\n",
      "|    total_reward       | 1.33e+06 |\n",
      "|    total_reward_pct   | 133      |\n",
      "|    total_trades       | 45687    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0299  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -123     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -5.77    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.153    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -145     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 39.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -15      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3e+06    |\n",
      "|    total_cost         | 5.41e+04 |\n",
      "|    total_reward       | 2e+06    |\n",
      "|    total_reward_pct   | 200      |\n",
      "|    total_trades       | 40300    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0614   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -109     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -84.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 71.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 14.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0542   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 104      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.87e+06 |\n",
      "|    total_cost         | 4.99e+04 |\n",
      "|    total_reward       | 1.87e+06 |\n",
      "|    total_reward_pct   | 187      |\n",
      "|    total_trades       | 38557    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -84.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -4.95    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.235    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -101     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 15.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.706    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.12e+06 |\n",
      "|    total_cost         | 3.75e+04 |\n",
      "|    total_reward       | 2.12e+06 |\n",
      "|    total_reward_pct   | 212      |\n",
      "|    total_trades       | 36899    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -50.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.99     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0247  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 118      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 76.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 34.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.99e+06 |\n",
      "|    total_cost         | 2.03e+04 |\n",
      "|    total_reward       | 1.99e+06 |\n",
      "|    total_reward_pct   | 199      |\n",
      "|    total_trades       | 32990    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 53.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 21.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0311   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 22.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 42       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2        |\n",
      "------------------------------------\n",
      "day: 2013, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2762614.17\n",
      "total_reward: 1762614.17\n",
      "total_cost: 21074.36\n",
      "total_trades: 32916\n",
      "Sharpe: 0.861\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.76e+06 |\n",
      "|    total_cost         | 2.11e+04 |\n",
      "|    total_reward       | 1.76e+06 |\n",
      "|    total_reward_pct   | 176      |\n",
      "|    total_trades       | 32916    |\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -72.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.00279 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -88.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.25     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 136       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -72.4     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 5.78      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -319     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 60.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.92e+06 |\n",
      "|    total_cost         | 3.46e+04 |\n",
      "|    total_reward       | 1.92e+06 |\n",
      "|    total_reward_pct   | 192      |\n",
      "|    total_trades       | 34615    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.409   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.959    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.398    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 56.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 21.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.38     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.303   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 49.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.43e+06 |\n",
      "|    total_cost         | 5.54e+04 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 143      |\n",
      "|    total_trades       | 39376    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.0635   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 86.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -73.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 88.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.107    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 59.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.62e+06 |\n",
      "|    total_cost         | 1.06e+05 |\n",
      "|    total_reward       | 1.62e+06 |\n",
      "|    total_reward_pct   | 162      |\n",
      "|    total_trades       | 45366    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.0361  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 19.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.478    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.483    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 23.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.141    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -25.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.102    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 71.4     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.46e+06 |\n",
      "|    total_cost         | 8.15e+04 |\n",
      "|    total_reward       | 1.46e+06 |\n",
      "|    total_reward_pct   | 146      |\n",
      "|    total_trades       | 42599    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -76.5    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 4.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.154   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 53.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.0338  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -104     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 6.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 26.1     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.726    |\n",
      "------------------------------------\n",
      "======Trading from:  2018-01-03 to  2018-04-05\n",
      "============================================\n",
      "51.44269269004415\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2018-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_441_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.905   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -95      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 6.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.185    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -34.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -39.4     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.06      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.128   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -30.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.88e+06 |\n",
      "|    total_cost         | 1.34e+05 |\n",
      "|    total_reward       | 8.85e+05 |\n",
      "|    total_reward_pct   | 88.5     |\n",
      "|    total_trades       | 49527    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0953   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 79.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -2.29    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 49.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0401   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 150      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 3.22e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -9.64    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.34e+06 |\n",
      "|    total_cost         | 1.43e+05 |\n",
      "|    total_reward       | 1.34e+06 |\n",
      "|    total_reward_pct   | 134      |\n",
      "|    total_trades       | 49597    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0699  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 109      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 29       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0272   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 25.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.737    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.85e+06 |\n",
      "|    total_cost         | 8.43e+04 |\n",
      "|    total_reward       | 8.51e+05 |\n",
      "|    total_reward_pct   | 85.1     |\n",
      "|    total_trades       | 44730    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.587   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 51.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0909  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 111      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.87     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0507  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 92.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.035   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.59e+06 |\n",
      "|    total_cost         | 1.42e+05 |\n",
      "|    total_reward       | 1.59e+06 |\n",
      "|    total_reward_pct   | 159      |\n",
      "|    total_trades       | 49705    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.143   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 34.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0816   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -35.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.113   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -133     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.035    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 163      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.5     |\n",
      "------------------------------------\n",
      "day: 2013, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3444560.83\n",
      "total_reward: 2444560.83\n",
      "total_cost: 127532.06\n",
      "total_trades: 48512\n",
      "Sharpe: 1.197\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.44e+06 |\n",
      "|    total_cost         | 1.28e+05 |\n",
      "|    total_reward       | 2.44e+06 |\n",
      "|    total_reward_pct   | 244      |\n",
      "|    total_trades       | 48512    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -127     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.657   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 3.92     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.442    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.2      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -110     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 17.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 86        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 30.9      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.89      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.99e+06 |\n",
      "|    total_cost         | 1.3e+05  |\n",
      "|    total_reward       | 1.99e+06 |\n",
      "|    total_reward_pct   | 199      |\n",
      "|    total_trades       | 48277    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0221  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -161     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -123     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -99.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 165      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 27.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.63e+06 |\n",
      "|    total_cost         | 1.05e+05 |\n",
      "|    total_reward       | 2.63e+06 |\n",
      "|    total_reward_pct   | 263      |\n",
      "|    total_trades       | 47063    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -102     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0396   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 4.05     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0743   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0846   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -190     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 20.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0215  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -31      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.951    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.1e+06  |\n",
      "|    total_cost         | 1.13e+05 |\n",
      "|    total_reward       | 2.1e+06  |\n",
      "|    total_reward_pct   | 210      |\n",
      "|    total_trades       | 46665    |\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.313    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -51.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.184    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 135      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 47.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -105     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.74     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.2e+06   |\n",
      "|    total_cost         | 7.78e+04  |\n",
      "|    total_reward       | 2.2e+06   |\n",
      "|    total_reward_pct   | 220       |\n",
      "|    total_trades       | 44496     |\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 69.5      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.9       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0712   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 109      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 26.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 108      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "day: 2013, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4038872.44\n",
      "total_reward: 3038872.44\n",
      "total_cost: 34122.94\n",
      "total_trades: 39361\n",
      "Sharpe: 1.283\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.04e+06 |\n",
      "|    total_cost         | 3.41e+04 |\n",
      "|    total_reward       | 3.04e+06 |\n",
      "|    total_reward_pct   | 304      |\n",
      "|    total_trades       | 39361    |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.49e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -59.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.81     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -35.3     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.84      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.241   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -63.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -132     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.06e+06 |\n",
      "|    total_cost         | 1.77e+04 |\n",
      "|    total_reward       | 3.06e+06 |\n",
      "|    total_reward_pct   | 306      |\n",
      "|    total_trades       | 37087    |\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 3.55     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.208    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 108      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.00723  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -47      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 257      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 55.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.04e+06 |\n",
      "|    total_cost         | 1.22e+04 |\n",
      "|    total_reward       | 3.04e+06 |\n",
      "|    total_reward_pct   | 304      |\n",
      "|    total_trades       | 34902    |\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.407   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 36.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.997    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -97.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 46.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.00962 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -27.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.52e+06 |\n",
      "|    total_cost         | 8.97e+03 |\n",
      "|    total_reward       | 2.52e+06 |\n",
      "|    total_reward_pct   | 252      |\n",
      "|    total_trades       | 32563    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.492    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 11.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.186    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 131       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 204       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.67e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 65.3      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.32      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 37.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.98     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 36       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.63e+06 |\n",
      "|    total_cost         | 9.06e+03 |\n",
      "|    total_reward       | 2.63e+06 |\n",
      "|    total_reward_pct   | 263      |\n",
      "|    total_trades       | 31983    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.19     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -11.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.208    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.622    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 62.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -31.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.982    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -7.84    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.621    |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2018-01-03 to  2018-04-05\n",
      "A2C Sharpe Ratio:  -0.07168344284405975\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_441_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.38e+06 |\n",
      "|    total_cost       | 2.11e+05 |\n",
      "|    total_reward     | 1.38e+06 |\n",
      "|    total_reward_pct | 138      |\n",
      "|    total_trades     | 58281    |\n",
      "| time/               |          |\n",
      "|    fps              | 123      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 2.1e+05     |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 58333       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010445442 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0344     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.49        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 8.45        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.59e+06    |\n",
      "|    total_cost           | 2.04e+05    |\n",
      "|    total_reward         | 1.59e+06    |\n",
      "|    total_reward_pct     | 159         |\n",
      "|    total_trades         | 57599       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013742011 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0193      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.17        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 2.08e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 57632       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008697802 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0495     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.06        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1640616.08\n",
      "total_reward: 640616.08\n",
      "total_cost: 200782.13\n",
      "total_trades: 57274\n",
      "Sharpe: 0.518\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.64e+06    |\n",
      "|    total_cost           | 2.01e+05    |\n",
      "|    total_reward         | 6.41e+05    |\n",
      "|    total_reward_pct     | 64.1        |\n",
      "|    total_trades         | 57274       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021993944 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.044      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.17        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.88        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.4e+06     |\n",
      "|    total_cost           | 2.01e+05    |\n",
      "|    total_reward         | 1.4e+06     |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 57346       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021864563 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0192      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.15        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.01        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.25e+06    |\n",
      "|    total_cost           | 1.99e+05    |\n",
      "|    total_reward         | 1.25e+06    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 56962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025704361 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0214     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.86        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.7         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.95e+06   |\n",
      "|    total_cost           | 2e+05      |\n",
      "|    total_reward         | 1.95e+06   |\n",
      "|    total_reward_pct     | 195        |\n",
      "|    total_trades         | 57139      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 119        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 136        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02056218 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | -0.0861    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.89       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0256    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 7.2        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.97e+06    |\n",
      "|    total_cost           | 2.01e+05    |\n",
      "|    total_reward         | 1.97e+06    |\n",
      "|    total_reward_pct     | 197         |\n",
      "|    total_trades         | 57057       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023971358 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.00078     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.61        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2383103.61\n",
      "total_reward: 1383103.61\n",
      "total_cost: 200662.44\n",
      "total_trades: 56843\n",
      "Sharpe: 0.901\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.38e+06    |\n",
      "|    total_cost           | 2.01e+05    |\n",
      "|    total_reward         | 1.38e+06    |\n",
      "|    total_reward_pct     | 138         |\n",
      "|    total_trades         | 56843       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029997125 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0347      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.98        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+06    |\n",
      "|    total_cost           | 2.02e+05    |\n",
      "|    total_reward         | 1.65e+06    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 57149       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019201476 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0195      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.92        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.5e+06     |\n",
      "|    total_cost           | 1.96e+05    |\n",
      "|    total_reward         | 2.5e+06     |\n",
      "|    total_reward_pct     | 250         |\n",
      "|    total_trades         | 56367       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025656996 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0512      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.02        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.85        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.11e+06    |\n",
      "|    total_cost           | 1.93e+05    |\n",
      "|    total_reward         | 3.11e+06    |\n",
      "|    total_reward_pct     | 311         |\n",
      "|    total_trades         | 56041       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012528202 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.45        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.6e+06     |\n",
      "|    total_cost           | 1.8e+05     |\n",
      "|    total_reward         | 2.6e+06     |\n",
      "|    total_reward_pct     | 260         |\n",
      "|    total_trades         | 55075       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023829414 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0739      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2013, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2779365.25\n",
      "total_reward: 1779365.25\n",
      "total_cost: 202114.34\n",
      "total_trades: 57106\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+06    |\n",
      "|    total_cost           | 2.02e+05    |\n",
      "|    total_reward         | 1.78e+06    |\n",
      "|    total_reward_pct     | 178         |\n",
      "|    total_trades         | 57106       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026243668 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0476      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.22        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.7e+06     |\n",
      "|    total_cost           | 1.94e+05    |\n",
      "|    total_reward         | 1.7e+06     |\n",
      "|    total_reward_pct     | 170         |\n",
      "|    total_trades         | 56551       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021924084 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.028       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.41        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.6e+06     |\n",
      "|    total_cost           | 2.03e+05    |\n",
      "|    total_reward         | 1.6e+06     |\n",
      "|    total_reward_pct     | 160         |\n",
      "|    total_trades         | 56861       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024520103 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0931      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.27        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.56e+06    |\n",
      "|    total_cost           | 1.97e+05    |\n",
      "|    total_reward         | 1.56e+06    |\n",
      "|    total_reward_pct     | 156         |\n",
      "|    total_trades         | 56399       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024959315 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.51e+06    |\n",
      "|    total_cost           | 2e+05       |\n",
      "|    total_reward         | 1.51e+06    |\n",
      "|    total_reward_pct     | 151         |\n",
      "|    total_trades         | 56354       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015681695 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.17        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.46        |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2590249.00\n",
      "total_reward: 1590249.00\n",
      "total_cost: 204603.85\n",
      "total_trades: 57026\n",
      "Sharpe: 0.926\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.59e+06    |\n",
      "|    total_cost           | 2.05e+05    |\n",
      "|    total_reward         | 1.59e+06    |\n",
      "|    total_reward_pct     | 159         |\n",
      "|    total_trades         | 57026       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 342         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025765058 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.67        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.63e+06    |\n",
      "|    total_cost           | 1.92e+05    |\n",
      "|    total_reward         | 1.63e+06    |\n",
      "|    total_reward_pct     | 163         |\n",
      "|    total_trades         | 56013       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031615913 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.072       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.83        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.32e+06    |\n",
      "|    total_cost           | 1.89e+05    |\n",
      "|    total_reward         | 1.32e+06    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 55687       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030694585 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.15        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.08e+06   |\n",
      "|    total_cost           | 1.91e+05   |\n",
      "|    total_reward         | 1.08e+06   |\n",
      "|    total_reward_pct     | 108        |\n",
      "|    total_trades         | 55860      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 119        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 393        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03305726 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.034      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.53       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0206    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 10.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.22e+06    |\n",
      "|    total_cost           | 1.92e+05    |\n",
      "|    total_reward         | 1.22e+06    |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 55974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023155482 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.85        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.82        |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2479765.50\n",
      "total_reward: 1479765.50\n",
      "total_cost: 190180.70\n",
      "total_trades: 55390\n",
      "Sharpe: 0.831\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.48e+06    |\n",
      "|    total_cost           | 1.9e+05     |\n",
      "|    total_reward         | 1.48e+06    |\n",
      "|    total_reward_pct     | 148         |\n",
      "|    total_trades         | 55390       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 427         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013927521 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.27        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.62e+06    |\n",
      "|    total_cost           | 1.94e+05    |\n",
      "|    total_reward         | 1.62e+06    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 55536       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041907296 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0957      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.49        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.32e+06    |\n",
      "|    total_cost           | 1.66e+05    |\n",
      "|    total_reward         | 1.32e+06    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 53115       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046276912 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.84        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.54e+06   |\n",
      "|    total_cost           | 1.84e+05   |\n",
      "|    total_reward         | 1.54e+06   |\n",
      "|    total_reward_pct     | 154        |\n",
      "|    total_trades         | 55043      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 119        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 478        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03368227 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.139      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.95       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 12.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.89e+06    |\n",
      "|    total_cost           | 1.76e+05    |\n",
      "|    total_reward         | 1.89e+06    |\n",
      "|    total_reward_pct     | 189         |\n",
      "|    total_trades         | 54116       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028899599 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.34        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.91        |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2478131.72\n",
      "total_reward: 1478131.72\n",
      "total_cost: 161492.16\n",
      "total_trades: 52640\n",
      "Sharpe: 0.833\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.48e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 1.48e+06    |\n",
      "|    total_reward_pct     | 148         |\n",
      "|    total_trades         | 52640       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 513         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030689796 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.35        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.59        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.03e+06    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 2.03e+06    |\n",
      "|    total_reward_pct     | 203         |\n",
      "|    total_trades         | 54675       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 530         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023018051 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.65        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 9.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.74e+06    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 1.74e+06    |\n",
      "|    total_reward_pct     | 174         |\n",
      "|    total_trades         | 54545       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 547         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029168308 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.25        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.37e+06    |\n",
      "|    total_cost           | 1.87e+05    |\n",
      "|    total_reward         | 1.37e+06    |\n",
      "|    total_reward_pct     | 137         |\n",
      "|    total_trades         | 55090       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 567         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030631566 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.04        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.94e+06   |\n",
      "|    total_cost           | 1.76e+05   |\n",
      "|    total_reward         | 1.94e+06   |\n",
      "|    total_reward_pct     | 194        |\n",
      "|    total_trades         | 53669      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 119        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 582        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02949443 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.307      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.99       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 8.81       |\n",
      "----------------------------------------\n",
      "day: 2013, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3069710.20\n",
      "total_reward: 2069710.20\n",
      "total_cost: 173275.92\n",
      "total_trades: 53356\n",
      "Sharpe: 1.000\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.07e+06   |\n",
      "|    total_cost           | 1.73e+05   |\n",
      "|    total_reward         | 2.07e+06   |\n",
      "|    total_reward_pct     | 207        |\n",
      "|    total_trades         | 53356      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 120        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 596        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03256651 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.376      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.18       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0171    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 11         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.77e+06   |\n",
      "|    total_cost           | 1.58e+05   |\n",
      "|    total_reward         | 1.77e+06   |\n",
      "|    total_reward_pct     | 177        |\n",
      "|    total_trades         | 52320      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 120        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 610        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03269564 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.387      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.85       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 10.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.39e+06   |\n",
      "|    total_cost           | 1.68e+05   |\n",
      "|    total_reward         | 2.39e+06   |\n",
      "|    total_reward_pct     | 239        |\n",
      "|    total_trades         | 53324      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 624        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03673197 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.293      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.19       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0165    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 9.18       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.41e+06    |\n",
      "|    total_cost           | 1.55e+05    |\n",
      "|    total_reward         | 2.41e+06    |\n",
      "|    total_reward_pct     | 241         |\n",
      "|    total_trades         | 51980       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 638         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024363741 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.71        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.18e+06    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 2.18e+06    |\n",
      "|    total_reward_pct     | 218         |\n",
      "|    total_trades         | 52963       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027641485 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.51        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3347463.78\n",
      "total_reward: 2347463.78\n",
      "total_cost: 177677.81\n",
      "total_trades: 55200\n",
      "Sharpe: 1.083\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.35e+06    |\n",
      "|    total_cost           | 1.78e+05    |\n",
      "|    total_reward         | 2.35e+06    |\n",
      "|    total_reward_pct     | 235         |\n",
      "|    total_trades         | 55200       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037555996 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.25        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.63e+06    |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | 2.63e+06    |\n",
      "|    total_reward_pct     | 263         |\n",
      "|    total_trades         | 53314       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 681         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026083106 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.37        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.62e+06    |\n",
      "|    total_cost           | 1.53e+05    |\n",
      "|    total_reward         | 1.62e+06    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 51599       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 696         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022973208 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.07        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.3e+06     |\n",
      "|    total_cost           | 1.73e+05    |\n",
      "|    total_reward         | 2.3e+06     |\n",
      "|    total_reward_pct     | 230         |\n",
      "|    total_trades         | 53839       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 710         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032437507 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0873      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.46        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.79e+06    |\n",
      "|    total_cost           | 1.59e+05    |\n",
      "|    total_reward         | 2.79e+06    |\n",
      "|    total_reward_pct     | 279         |\n",
      "|    total_trades         | 53029       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 724         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037541177 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.3         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "day: 2013, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3566602.97\n",
      "total_reward: 2566602.97\n",
      "total_cost: 170495.17\n",
      "total_trades: 53901\n",
      "Sharpe: 1.121\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.57e+06   |\n",
      "|    total_cost           | 1.7e+05    |\n",
      "|    total_reward         | 2.57e+06   |\n",
      "|    total_reward_pct     | 257        |\n",
      "|    total_trades         | 53901      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 124        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 738        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04263176 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.303      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.46       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 17.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.07e+06    |\n",
      "|    total_cost           | 1.55e+05    |\n",
      "|    total_reward         | 2.07e+06    |\n",
      "|    total_reward_pct     | 207         |\n",
      "|    total_trades         | 52182       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 752         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030900076 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.04        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.53e+06     |\n",
      "|    total_cost           | 1.54e+05     |\n",
      "|    total_reward         | 1.53e+06     |\n",
      "|    total_reward_pct     | 153          |\n",
      "|    total_trades         | 52405        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 125          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 767          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076082405 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.5        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.76         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 13.4         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.75e+06   |\n",
      "|    total_cost           | 1.48e+05   |\n",
      "|    total_reward         | 1.75e+06   |\n",
      "|    total_reward_pct     | 175        |\n",
      "|    total_trades         | 51680      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 781        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02959785 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.35       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.95       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 11.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.81e+06    |\n",
      "|    total_cost           | 1.46e+05    |\n",
      "|    total_reward         | 1.81e+06    |\n",
      "|    total_reward_pct     | 181         |\n",
      "|    total_trades         | 51590       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 795         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012965621 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.82        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2018-01-03 to  2018-04-05\n",
      "PPO Sharpe Ratio:  -0.13790073242509504\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.6e+06  |\n",
      "|    total_cost       | 1.36e+03 |\n",
      "|    total_reward     | 1.6e+06  |\n",
      "|    total_reward_pct | 160      |\n",
      "|    total_trades     | 32125    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 55       |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total timesteps  | 8056     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 47.8     |\n",
      "|    critic_loss      | 26.9     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6042     |\n",
      "----------------------------------\n",
      "day: 2013, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2681528.25\n",
      "total_reward: 1681528.25\n",
      "total_cost: 1143.20\n",
      "total_trades: 34106\n",
      "Sharpe: 0.892\n",
      "=================================\n",
      "======DDPG Validation from:  2018-01-03 to  2018-04-05\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-04-05\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_441_2\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.2e+06  |\n",
      "|    total_cost       | 1.17e+03 |\n",
      "|    total_reward     | 1.2e+06  |\n",
      "|    total_reward_pct | 120      |\n",
      "|    total_trades     | 36553    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total timesteps  | 8308     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.96    |\n",
      "|    critic_loss      | 25.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6231     |\n",
      "----------------------------------\n",
      "day: 2076, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2183494.83\n",
      "total_reward: 1183494.83\n",
      "total_cost: 1149.71\n",
      "total_trades: 33215\n",
      "Sharpe: 0.669\n",
      "=================================\n",
      "======Trading from:  2018-04-05 to  2018-07-05\n",
      "============================================\n",
      "36.94596100672523\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2018-04-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_504_4\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.000276 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -15.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.362    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.000123 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 3.98     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0155  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -11      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -120     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 24.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.46e+06 |\n",
      "|    total_cost         | 8.95e+04 |\n",
      "|    total_reward       | 2.46e+06 |\n",
      "|    total_reward_pct   | 246      |\n",
      "|    total_trades       | 45053    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 85.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0686   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -53.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -388     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 87.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.106   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 50.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.88     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.36e+06  |\n",
      "|    total_cost         | 5.03e+04  |\n",
      "|    total_reward       | 1.36e+06  |\n",
      "|    total_reward_pct   | 136       |\n",
      "|    total_trades       | 39709     |\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 1.94      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.234     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 94.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0576  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 93.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0109   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 41.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.01e+06 |\n",
      "|    total_cost         | 5.68e+04 |\n",
      "|    total_reward       | 1.01e+06 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 41975    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0062   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -5.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0903   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.67    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 28.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -27.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -108     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.97e+06 |\n",
      "|    total_cost         | 3.61e+04 |\n",
      "|    total_reward       | 9.74e+05 |\n",
      "|    total_reward_pct   | 97.4     |\n",
      "|    total_trades       | 38312    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -1.55    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -10.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -53.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.82     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -4.63    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.118   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -74.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.81     |\n",
      "------------------------------------\n",
      "day: 2076, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2833801.26\n",
      "total_reward: 1833801.26\n",
      "total_cost: 57739.76\n",
      "total_trades: 41450\n",
      "Sharpe: 0.879\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.83e+06 |\n",
      "|    total_cost         | 5.77e+04 |\n",
      "|    total_reward       | 1.83e+06 |\n",
      "|    total_reward_pct   | 183      |\n",
      "|    total_trades       | 41450    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.389   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 91.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0566  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -50.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.477   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 24.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.546    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.191    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 39.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.39e+06 |\n",
      "|    total_cost         | 1.06e+05 |\n",
      "|    total_reward       | 1.39e+06 |\n",
      "|    total_reward_pct   | 139      |\n",
      "|    total_trades       | 47067    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 15.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.336    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.488    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -11.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.223    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 136       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 94.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0301  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -50.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.61e+06 |\n",
      "|    total_cost         | 3.6e+04  |\n",
      "|    total_reward       | 6.14e+05 |\n",
      "|    total_reward_pct   | 61.4     |\n",
      "|    total_trades       | 38451    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 186      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 21.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 112      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 58.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.67     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -0.000469 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 33.3      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.721     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.03e+06 |\n",
      "|    total_cost         | 4.4e+04  |\n",
      "|    total_reward       | 1.03e+06 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 39264    |\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0662   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 55.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.258   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 20.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.897    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -6.4      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.28      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0528   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -53.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.17e+06 |\n",
      "|    total_cost         | 1.04e+05 |\n",
      "|    total_reward       | 1.17e+06 |\n",
      "|    total_reward_pct   | 117      |\n",
      "|    total_trades       | 47088    |\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.142    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -164     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 13.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 17.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.408    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -79.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 47.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.59     |\n",
      "------------------------------------\n",
      "day: 2076, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2073848.61\n",
      "total_reward: 1073848.61\n",
      "total_cost: 42416.39\n",
      "total_trades: 38417\n",
      "Sharpe: 0.645\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.07e+06 |\n",
      "|    total_cost         | 4.24e+04 |\n",
      "|    total_reward       | 1.07e+06 |\n",
      "|    total_reward_pct   | 107      |\n",
      "|    total_trades       | 38417    |\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.242    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -97.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.124   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 48.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -61.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.00106  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 91.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.65e+06 |\n",
      "|    total_cost         | 3.72e+04 |\n",
      "|    total_reward       | 6.46e+05 |\n",
      "|    total_reward_pct   | 64.6     |\n",
      "|    total_trades       | 36022    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 10.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.358    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 95.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 7.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.142    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 22.8     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.581    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.234   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 104      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 8.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.29e+06 |\n",
      "|    total_cost         | 4.79e+04 |\n",
      "|    total_reward       | 1.29e+06 |\n",
      "|    total_reward_pct   | 129      |\n",
      "|    total_trades       | 35368    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -232     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 29.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0.321    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -123     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 8.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.114   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 6.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 200      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 24.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0.0156   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -50.9    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 4.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.05e+06 |\n",
      "|    total_cost         | 5.12e+04 |\n",
      "|    total_reward       | 1.05e+06 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 36645    |\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0.0774   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -19.4    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.748    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0.0953   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -103     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 6.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -65.4    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 5.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 125      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.7e+06  |\n",
      "|    total_cost         | 8.07e+04 |\n",
      "|    total_reward       | 1.7e+06  |\n",
      "|    total_reward_pct   | 170      |\n",
      "|    total_trades       | 42429    |\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0.06     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 7.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0.139    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -22.7    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.319    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======A2C Validation from:  2018-04-05 to  2018-07-05\n",
      "A2C Sharpe Ratio:  -0.19151553340589403\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_504_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 144  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 14   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.41e+06    |\n",
      "|    total_cost           | 2.23e+05    |\n",
      "|    total_reward         | 1.41e+06    |\n",
      "|    total_reward_pct     | 141         |\n",
      "|    total_trades         | 59897       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018054303 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0273     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.73        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 8.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.3e+06     |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 1.3e+06     |\n",
      "|    total_reward_pct     | 130         |\n",
      "|    total_trades         | 59928       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012585979 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0164      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.08        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.76e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 1.76e+06    |\n",
      "|    total_reward_pct     | 176         |\n",
      "|    total_trades         | 59302       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028734753 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0654     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.76        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.89        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.9e+06     |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 9.01e+05    |\n",
      "|    total_reward_pct     | 90.1        |\n",
      "|    total_trades         | 59084       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017142117 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0063     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.54        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.25        |\n",
      "-----------------------------------------\n",
      "day: 2076, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2894333.84\n",
      "total_reward: 1894333.84\n",
      "total_cost: 215694.25\n",
      "total_trades: 59062\n",
      "Sharpe: 1.016\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.89e+06    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 1.89e+06    |\n",
      "|    total_reward_pct     | 189         |\n",
      "|    total_trades         | 59062       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026905647 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0267     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.25        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.59e+06    |\n",
      "|    total_cost           | 2.06e+05    |\n",
      "|    total_reward         | 1.59e+06    |\n",
      "|    total_reward_pct     | 159         |\n",
      "|    total_trades         | 58750       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026268259 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0255     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| environment/            |          |\n",
      "|    portfolio_value      | 2.73e+06 |\n",
      "|    total_cost           | 2.14e+05 |\n",
      "|    total_reward         | 1.73e+06 |\n",
      "|    total_reward_pct     | 173      |\n",
      "|    total_trades         | 59158    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 141      |\n",
      "|    iterations           | 8        |\n",
      "|    time_elapsed         | 115      |\n",
      "|    total_timesteps      | 16384    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.013131 |\n",
      "|    clip_fraction        | 0.217    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -42.9    |\n",
      "|    explained_variance   | 0.0103   |\n",
      "|    learning_rate        | 0.00025  |\n",
      "|    loss                 | 5.24     |\n",
      "|    n_updates            | 70       |\n",
      "|    policy_gradient_loss | -0.0246  |\n",
      "|    std                  | 1.01     |\n",
      "|    value_loss           | 12.3     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.15e+06    |\n",
      "|    total_cost           | 2.1e+05     |\n",
      "|    total_reward         | 2.15e+06    |\n",
      "|    total_reward_pct     | 215         |\n",
      "|    total_trades         | 58435       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021289948 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.00585    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.24        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.57e+06    |\n",
      "|    total_cost           | 1.99e+05    |\n",
      "|    total_reward         | 1.57e+06    |\n",
      "|    total_reward_pct     | 157         |\n",
      "|    total_trades         | 57583       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027594972 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.00597     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.06        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.6        |\n",
      "-----------------------------------------\n",
      "day: 2076, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1533797.37\n",
      "total_reward: 533797.37\n",
      "total_cost: 177510.90\n",
      "total_trades: 56015\n",
      "Sharpe: 0.408\n",
      "=================================\n",
      "--------------------------------------\n",
      "| environment/            |          |\n",
      "|    portfolio_value      | 1.53e+06 |\n",
      "|    total_cost           | 1.78e+05 |\n",
      "|    total_reward         | 5.34e+05 |\n",
      "|    total_reward_pct     | 53.4     |\n",
      "|    total_trades         | 56015    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 141      |\n",
      "|    iterations           | 11       |\n",
      "|    time_elapsed         | 159      |\n",
      "|    total_timesteps      | 22528    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.018362 |\n",
      "|    clip_fraction        | 0.203    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -43.2    |\n",
      "|    explained_variance   | 0.184    |\n",
      "|    learning_rate        | 0.00025  |\n",
      "|    loss                 | 3.49     |\n",
      "|    n_updates            | 100      |\n",
      "|    policy_gradient_loss | -0.0226  |\n",
      "|    std                  | 1.02     |\n",
      "|    value_loss           | 10.8     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.93e+06   |\n",
      "|    total_cost           | 1.95e+05   |\n",
      "|    total_reward         | 9.27e+05   |\n",
      "|    total_reward_pct     | 92.7       |\n",
      "|    total_trades         | 57244      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 174        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01702031 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.116      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.31       |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0176    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 10         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.17e+06   |\n",
      "|    total_cost           | 1.86e+05   |\n",
      "|    total_reward         | 1.17e+06   |\n",
      "|    total_reward_pct     | 117        |\n",
      "|    total_trades         | 56656      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 188        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02861121 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0968     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.45       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 10.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.06e+06   |\n",
      "|    total_cost           | 1.88e+05   |\n",
      "|    total_reward         | 1.06e+06   |\n",
      "|    total_reward_pct     | 106        |\n",
      "|    total_trades         | 56584      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01927622 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0532     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.95       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 8.82       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.46e+06    |\n",
      "|    total_cost           | 1.84e+05    |\n",
      "|    total_reward         | 1.46e+06    |\n",
      "|    total_reward_pct     | 146         |\n",
      "|    total_trades         | 56286       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020327318 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.00234    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.15        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9           |\n",
      "-----------------------------------------\n",
      "day: 2076, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2872221.82\n",
      "total_reward: 1872221.82\n",
      "total_cost: 186052.36\n",
      "total_trades: 55978\n",
      "Sharpe: 0.954\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.87e+06   |\n",
      "|    total_cost           | 1.86e+05   |\n",
      "|    total_reward         | 1.87e+06   |\n",
      "|    total_reward_pct     | 187        |\n",
      "|    total_trades         | 55978      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 231        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02493275 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0506     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.83       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0223    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 10         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3e+06       |\n",
      "|    total_cost           | 1.88e+05    |\n",
      "|    total_reward         | 2e+06       |\n",
      "|    total_reward_pct     | 200         |\n",
      "|    total_trades         | 56168       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025274742 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0386      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.16        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 12.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.43e+06    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 1.43e+06    |\n",
      "|    total_reward_pct     | 143         |\n",
      "|    total_trades         | 55451       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024074413 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.26        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.86e+06    |\n",
      "|    total_cost           | 1.89e+05    |\n",
      "|    total_reward         | 1.86e+06    |\n",
      "|    total_reward_pct     | 186         |\n",
      "|    total_trades         | 56287       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023350805 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.33        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.24e+06    |\n",
      "|    total_cost           | 1.87e+05    |\n",
      "|    total_reward         | 2.24e+06    |\n",
      "|    total_reward_pct     | 224         |\n",
      "|    total_trades         | 55961       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010250488 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.08        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "day: 2076, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2701073.27\n",
      "total_reward: 1701073.27\n",
      "total_cost: 184913.18\n",
      "total_trades: 55747\n",
      "Sharpe: 0.886\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.7e+06     |\n",
      "|    total_cost           | 1.85e+05    |\n",
      "|    total_reward         | 1.7e+06     |\n",
      "|    total_reward_pct     | 170         |\n",
      "|    total_trades         | 55747       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017048033 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.56        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.06e+06    |\n",
      "|    total_cost           | 1.83e+05    |\n",
      "|    total_reward         | 2.06e+06    |\n",
      "|    total_reward_pct     | 206         |\n",
      "|    total_trades         | 55776       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025799753 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.08        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.06e+06    |\n",
      "|    total_cost           | 1.86e+05    |\n",
      "|    total_reward         | 2.06e+06    |\n",
      "|    total_reward_pct     | 206         |\n",
      "|    total_trades         | 55843       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024270358 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.56        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.12e+06    |\n",
      "|    total_cost           | 1.84e+05    |\n",
      "|    total_reward         | 2.12e+06    |\n",
      "|    total_reward_pct     | 212         |\n",
      "|    total_trades         | 55488       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024875406 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.96        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.04e+06    |\n",
      "|    total_cost           | 1.91e+05    |\n",
      "|    total_reward         | 2.04e+06    |\n",
      "|    total_reward_pct     | 204         |\n",
      "|    total_trades         | 56132       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027302787 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.43        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2076, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3181388.87\n",
      "total_reward: 2181388.87\n",
      "total_cost: 186671.33\n",
      "total_trades: 55894\n",
      "Sharpe: 0.966\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.18e+06  |\n",
      "|    total_cost           | 1.87e+05  |\n",
      "|    total_reward         | 2.18e+06  |\n",
      "|    total_reward_pct     | 218       |\n",
      "|    total_trades         | 55894     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 140       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 377       |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0196211 |\n",
      "|    clip_fraction        | 0.306     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.8     |\n",
      "|    explained_variance   | 0.0595    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 6.69      |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -0.0154   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 14.4      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.84e+06   |\n",
      "|    total_cost           | 1.92e+05   |\n",
      "|    total_reward         | 1.84e+06   |\n",
      "|    total_reward_pct     | 184        |\n",
      "|    total_trades         | 56442      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 392        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03050038 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.173      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.97       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 16.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.87e+06    |\n",
      "|    total_cost           | 1.9e+05     |\n",
      "|    total_reward         | 1.87e+06    |\n",
      "|    total_reward_pct     | 187         |\n",
      "|    total_trades         | 56308       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 406         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040348545 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0692      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.92        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.28e+06   |\n",
      "|    total_cost           | 1.82e+05   |\n",
      "|    total_reward         | 1.28e+06   |\n",
      "|    total_reward_pct     | 128        |\n",
      "|    total_trades         | 55406      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 421        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03138861 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.237      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.06       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 13.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.19e+06   |\n",
      "|    total_cost           | 1.81e+05   |\n",
      "|    total_reward         | 1.19e+06   |\n",
      "|    total_reward_pct     | 119        |\n",
      "|    total_trades         | 55136      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 436        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02058821 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.0921     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.24       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 12.2       |\n",
      "----------------------------------------\n",
      "day: 2076, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2340075.80\n",
      "total_reward: 1340075.80\n",
      "total_cost: 183180.45\n",
      "total_trades: 55915\n",
      "Sharpe: 0.682\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.34e+06   |\n",
      "|    total_cost           | 1.83e+05   |\n",
      "|    total_reward         | 1.34e+06   |\n",
      "|    total_reward_pct     | 134        |\n",
      "|    total_trades         | 55915      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 450        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02693645 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.0888     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.6        |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 13.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+06    |\n",
      "|    total_cost           | 1.85e+05    |\n",
      "|    total_reward         | 1.45e+06    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 56102       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 465         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024215706 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.78        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.62e+06    |\n",
      "|    total_cost           | 1.86e+05    |\n",
      "|    total_reward         | 1.62e+06    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 56075       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032968815 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.25        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+06    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 1.78e+06    |\n",
      "|    total_reward_pct     | 178         |\n",
      "|    total_trades         | 55655       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017724896 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0731      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.46        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.83e+06    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 1.83e+06    |\n",
      "|    total_reward_pct     | 183         |\n",
      "|    total_trades         | 55416       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 508         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028307974 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.47        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "day: 2076, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3204756.42\n",
      "total_reward: 2204756.42\n",
      "total_cost: 178520.62\n",
      "total_trades: 55806\n",
      "Sharpe: 1.049\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.2e+06     |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 2.2e+06     |\n",
      "|    total_reward_pct     | 220         |\n",
      "|    total_trades         | 55806       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 523         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033573225 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.69        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.13e+06    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | 2.13e+06    |\n",
      "|    total_reward_pct     | 213         |\n",
      "|    total_trades         | 55301       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 537         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038664345 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.54        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.71e+06    |\n",
      "|    total_cost           | 1.8e+05     |\n",
      "|    total_reward         | 1.71e+06    |\n",
      "|    total_reward_pct     | 171         |\n",
      "|    total_trades         | 55785       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 551         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025781438 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.17        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 1.73e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 55335       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 566         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021048116 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | -0.00106    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.26        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.68e+06   |\n",
      "|    total_cost           | 1.72e+05   |\n",
      "|    total_reward         | 1.68e+06   |\n",
      "|    total_reward_pct     | 168        |\n",
      "|    total_trades         | 54845      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 580        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04067859 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.00194    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.6        |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.00987   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 20.1       |\n",
      "----------------------------------------\n",
      "day: 2076, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2246698.04\n",
      "total_reward: 1246698.04\n",
      "total_cost: 155470.05\n",
      "total_trades: 54068\n",
      "Sharpe: 0.621\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.25e+06    |\n",
      "|    total_cost           | 1.55e+05    |\n",
      "|    total_reward         | 1.25e+06    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 54068       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030011686 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0976      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.12        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.27e+06    |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | 1.27e+06    |\n",
      "|    total_reward_pct     | 127         |\n",
      "|    total_trades         | 53114       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 610         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023419287 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0558      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.77        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.16e+06    |\n",
      "|    total_cost           | 1.52e+05    |\n",
      "|    total_reward         | 1.16e+06    |\n",
      "|    total_reward_pct     | 116         |\n",
      "|    total_trades         | 53061       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 625         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030613653 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.87        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.17e+06   |\n",
      "|    total_cost           | 1.69e+05   |\n",
      "|    total_reward         | 1.17e+06   |\n",
      "|    total_reward_pct     | 117        |\n",
      "|    total_trades         | 54619      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 639        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02856588 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.172      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.5       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 19.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.24e+06   |\n",
      "|    total_cost           | 1.76e+05   |\n",
      "|    total_reward         | 1.24e+06   |\n",
      "|    total_reward_pct     | 124        |\n",
      "|    total_trades         | 54901      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 654        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02064154 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.158      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.82       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 15.7       |\n",
      "----------------------------------------\n",
      "day: 2076, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2228148.38\n",
      "total_reward: 1228148.38\n",
      "total_cost: 156347.64\n",
      "total_trades: 53444\n",
      "Sharpe: 0.599\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.23e+06    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | 1.23e+06    |\n",
      "|    total_reward_pct     | 123         |\n",
      "|    total_trades         | 53444       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 668         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027865954 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0695      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.56        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.9e+06     |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 8.98e+05    |\n",
      "|    total_reward_pct     | 89.8        |\n",
      "|    total_trades         | 53657       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 683         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019089393 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.67        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.4e+06     |\n",
      "|    total_cost           | 1.69e+05    |\n",
      "|    total_reward         | 1.4e+06     |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 54453       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 697         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037262365 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.41e+06    |\n",
      "|    total_cost           | 1.46e+05    |\n",
      "|    total_reward         | 1.41e+06    |\n",
      "|    total_reward_pct     | 141         |\n",
      "|    total_trades         | 52359       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 711         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013413426 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.63        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 19.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-04-05 to  2018-07-05\n",
      "PPO Sharpe Ratio:  -0.05914720771530428\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_4\n",
      "day: 2076, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2894932.87\n",
      "total_reward: 1894932.87\n",
      "total_cost: 7466.06\n",
      "total_trades: 33749\n",
      "Sharpe: 0.986\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.02e+06 |\n",
      "|    total_cost       | 1.85e+03 |\n",
      "|    total_reward     | 2.02e+06 |\n",
      "|    total_reward_pct | 202      |\n",
      "|    total_trades     | 31896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 55       |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total timesteps  | 8308     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -158     |\n",
      "|    critic_loss      | 728      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6231     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2018-04-05 to  2018-07-05\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-07-05\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_504_2\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.1e+06  |\n",
      "|    total_cost       | 1.41e+03 |\n",
      "|    total_reward     | 1.1e+06  |\n",
      "|    total_reward_pct | 110      |\n",
      "|    total_trades     | 30819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total timesteps  | 8560     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 35       |\n",
      "|    critic_loss      | 53.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6420     |\n",
      "----------------------------------\n",
      "day: 2139, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2088704.29\n",
      "total_reward: 1088704.29\n",
      "total_cost: 1333.25\n",
      "total_trades: 31762\n",
      "Sharpe: 0.642\n",
      "=================================\n",
      "======Trading from:  2018-07-05 to  2018-10-03\n",
      "============================================\n",
      "19.69340107412405\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2018-07-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_567_4\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -24.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.627    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -32.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0384   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -45.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0291   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 177      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 36.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.07e+06 |\n",
      "|    total_cost         | 1.67e+05 |\n",
      "|    total_reward       | 3.07e+06 |\n",
      "|    total_reward_pct   | 307      |\n",
      "|    total_trades       | 54463    |\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.119   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -10.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.683    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -8.87    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.448    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -2.71    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -18.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.265    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.622    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -262     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 35.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.33e+06 |\n",
      "|    total_cost         | 1.33e+05 |\n",
      "|    total_reward       | 2.33e+06 |\n",
      "|    total_reward_pct   | 233      |\n",
      "|    total_trades       | 50831    |\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -9.88    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00107  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 4.18     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.499    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00487  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 48.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 167      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 18.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.51e+06 |\n",
      "|    total_cost         | 1.09e+05 |\n",
      "|    total_reward       | 2.51e+06 |\n",
      "|    total_reward_pct   | 251      |\n",
      "|    total_trades       | 47095    |\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -17.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.00521  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 62.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -144     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 13.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0629  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -120     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 27.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.56e+06 |\n",
      "|    total_cost         | 1.01e+05 |\n",
      "|    total_reward       | 2.56e+06 |\n",
      "|    total_reward_pct   | 256      |\n",
      "|    total_trades       | 48904    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.000996 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -221     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 38.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 27       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0477   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 159      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 129      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 20       |\n",
      "------------------------------------\n",
      "day: 2139, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3769400.89\n",
      "total_reward: 2769400.89\n",
      "total_cost: 55812.68\n",
      "total_trades: 44158\n",
      "Sharpe: 0.935\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.77e+06 |\n",
      "|    total_cost         | 5.58e+04 |\n",
      "|    total_reward       | 2.77e+06 |\n",
      "|    total_reward_pct   | 277      |\n",
      "|    total_trades       | 44158    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -62      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0215   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 12.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.965    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 132       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -41.1     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.15      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 4.77e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 140      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.35e+06 |\n",
      "|    total_cost         | 2.93e+04 |\n",
      "|    total_reward       | 2.35e+06 |\n",
      "|    total_reward_pct   | 235      |\n",
      "|    total_trades       | 41189    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0463  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -98      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.131    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 42.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -51.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -8.86    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.155    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.96e+06 |\n",
      "|    total_cost         | 3.76e+04 |\n",
      "|    total_reward       | 1.96e+06 |\n",
      "|    total_reward_pct   | 196      |\n",
      "|    total_trades       | 40856    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -28.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.962    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.61     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 132       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 42.5      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -128     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 21.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 64.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.03e+06 |\n",
      "|    total_cost         | 4.62e+04 |\n",
      "|    total_reward       | 1.03e+06 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 42323    |\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0796   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 91.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.134    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 32.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 97.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.78     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.33e+06 |\n",
      "|    total_cost         | 2.55e+04 |\n",
      "|    total_reward       | 2.33e+06 |\n",
      "|    total_reward_pct   | 233      |\n",
      "|    total_trades       | 38810    |\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 8.15     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.321    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -63.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 59.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 133       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 60        |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.91      |\n",
      "-------------------------------------\n",
      "day: 2139, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2848768.20\n",
      "total_reward: 1848768.20\n",
      "total_cost: 9624.87\n",
      "total_trades: 35829\n",
      "Sharpe: 0.850\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.85e+06 |\n",
      "|    total_cost         | 9.62e+03 |\n",
      "|    total_reward       | 1.85e+06 |\n",
      "|    total_reward_pct   | 185      |\n",
      "|    total_trades       | 35829    |\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.0184  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -245     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 32.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -144     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 13.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 66.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -94.8    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -238     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 33.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.1e+06  |\n",
      "|    total_cost         | 1.46e+04 |\n",
      "|    total_reward       | 2.1e+06  |\n",
      "|    total_reward_pct   | 210      |\n",
      "|    total_trades       | 37395    |\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.187   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 76.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.0272   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.0801   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -223     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 26       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 132       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 193       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 63.8      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 7.03      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.18e+06 |\n",
      "|    total_cost         | 1.71e+04 |\n",
      "|    total_reward       | 3.18e+06 |\n",
      "|    total_reward_pct   | 318      |\n",
      "|    total_trades       | 38364    |\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.0248   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 2.76     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.217    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.528   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -89.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.18     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 131       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 205       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -7.46e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -215      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 34.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -273     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 39       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.94e+06 |\n",
      "|    total_cost         | 3.79e+04 |\n",
      "|    total_reward       | 2.94e+06 |\n",
      "|    total_reward_pct   | 294      |\n",
      "|    total_trades       | 39653    |\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.0231  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 23.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.287   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 83.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.193    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -42.7    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.212   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -28.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.18e+06 |\n",
      "|    total_cost         | 4.82e+04 |\n",
      "|    total_reward       | 2.18e+06 |\n",
      "|    total_reward_pct   | 218      |\n",
      "|    total_trades       | 40949    |\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 1.71     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0783   |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2018-07-05 to  2018-10-03\n",
      "A2C Sharpe Ratio:  0.2541241148221099\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_567_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 137  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 14   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.53e+06     |\n",
      "|    total_cost           | 2.39e+05     |\n",
      "|    total_reward         | 1.53e+06     |\n",
      "|    total_reward_pct     | 153          |\n",
      "|    total_trades         | 61928        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027809478 |\n",
      "|    clip_fraction        | 0.183        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.0163      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.76         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0276      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 11           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.28e+06     |\n",
      "|    total_cost           | 2.31e+05     |\n",
      "|    total_reward         | 1.28e+06     |\n",
      "|    total_reward_pct     | 128          |\n",
      "|    total_trades         | 61292        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078414995 |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.00822     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.62         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0286      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 8.27         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.22e+06    |\n",
      "|    total_cost           | 2.31e+05    |\n",
      "|    total_reward         | 1.22e+06    |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 61295       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021504184 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00531     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.85        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.69e+06    |\n",
      "|    total_cost           | 2.25e+05    |\n",
      "|    total_reward         | 1.69e+06    |\n",
      "|    total_reward_pct     | 169         |\n",
      "|    total_trades         | 60968       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009345854 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0155     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.07        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1882119.71\n",
      "total_reward: 882119.71\n",
      "total_cost: 214524.83\n",
      "total_trades: 60149\n",
      "Sharpe: 0.615\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 8.82e+05    |\n",
      "|    total_reward_pct     | 88.2        |\n",
      "|    total_trades         | 60149       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014109349 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0152      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.33        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.99e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 9.86e+05    |\n",
      "|    total_reward_pct     | 98.6        |\n",
      "|    total_trades         | 60231       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013376338 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00811     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.01        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.85        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.16e+06    |\n",
      "|    total_cost           | 2.25e+05    |\n",
      "|    total_reward         | 1.16e+06    |\n",
      "|    total_reward_pct     | 116         |\n",
      "|    total_trades         | 60655       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014515568 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.83        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.09e+06    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 1.09e+06    |\n",
      "|    total_reward_pct     | 109         |\n",
      "|    total_trades         | 60642       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028095556 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0142     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.08        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.64        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+06    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 1.33e+06    |\n",
      "|    total_reward_pct     | 133         |\n",
      "|    total_trades         | 60365       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026233155 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.000243   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.01        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1817527.97\n",
      "total_reward: 817527.97\n",
      "total_cost: 216941.47\n",
      "total_trades: 60314\n",
      "Sharpe: 0.584\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.82e+06   |\n",
      "|    total_cost           | 2.17e+05   |\n",
      "|    total_reward         | 8.18e+05   |\n",
      "|    total_reward_pct     | 81.8       |\n",
      "|    total_trades         | 60314      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 174        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02189556 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | 0.0278     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.35       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 11.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.38e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 1.38e+06    |\n",
      "|    total_reward_pct     | 138         |\n",
      "|    total_trades         | 60320       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031682815 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0539      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.95        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.45        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.91e+06    |\n",
      "|    total_cost           | 2.12e+05    |\n",
      "|    total_reward         | 9.11e+05    |\n",
      "|    total_reward_pct     | 91.1        |\n",
      "|    total_trades         | 59684       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031844422 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0235      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.43        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.74e+06    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 1.74e+06    |\n",
      "|    total_reward_pct     | 174         |\n",
      "|    total_trades         | 60465       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019275647 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0376      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.98        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.12e+06    |\n",
      "|    total_cost           | 2.21e+05    |\n",
      "|    total_reward         | 1.12e+06    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 60228       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020041782 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0366      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.79        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2123580.73\n",
      "total_reward: 1123580.73\n",
      "total_cost: 227258.31\n",
      "total_trades: 60426\n",
      "Sharpe: 0.710\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.12e+06    |\n",
      "|    total_cost           | 2.27e+05    |\n",
      "|    total_reward         | 1.12e+06    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 60426       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028513325 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.00412    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.76        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.95        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.07e+06   |\n",
      "|    total_cost           | 2.17e+05   |\n",
      "|    total_reward         | 1.07e+06   |\n",
      "|    total_reward_pct     | 107        |\n",
      "|    total_trades         | 59646      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 269        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03958305 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | -0.0491    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.68       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0236    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 8.61       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.46e+06    |\n",
      "|    total_cost           | 2.23e+05    |\n",
      "|    total_reward         | 1.46e+06    |\n",
      "|    total_reward_pct     | 146         |\n",
      "|    total_trades         | 60326       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041005775 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0167      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.75        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+06    |\n",
      "|    total_cost           | 2.09e+05    |\n",
      "|    total_reward         | 1.04e+06    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 59279       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026659923 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | -0.0344     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.97        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.43e+06    |\n",
      "|    total_cost           | 2.13e+05    |\n",
      "|    total_reward         | 1.43e+06    |\n",
      "|    total_reward_pct     | 143         |\n",
      "|    total_trades         | 59431       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025752189 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.0158     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.93        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10          |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2640231.87\n",
      "total_reward: 1640231.87\n",
      "total_cost: 211385.45\n",
      "total_trades: 59447\n",
      "Sharpe: 0.923\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.64e+06    |\n",
      "|    total_cost           | 2.11e+05    |\n",
      "|    total_reward         | 1.64e+06    |\n",
      "|    total_reward_pct     | 164         |\n",
      "|    total_trades         | 59447       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016793784 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0191      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.02        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.91e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 1.91e+06    |\n",
      "|    total_reward_pct     | 191         |\n",
      "|    total_trades         | 59653       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026186476 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0745      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.42        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.63e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 1.63e+06    |\n",
      "|    total_reward_pct     | 163         |\n",
      "|    total_trades         | 59714       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027283395 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0599      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.84        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038462095 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.00287    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.39        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+06    |\n",
      "|    total_cost           | 1.99e+05    |\n",
      "|    total_reward         | 8.82e+05    |\n",
      "|    total_reward_pct     | 88.2        |\n",
      "|    total_trades         | 58518       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040797804 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0535      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.45        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 7.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.82e+06    |\n",
      "|    total_cost           | 1.9e+05     |\n",
      "|    total_reward         | 8.15e+05    |\n",
      "|    total_reward_pct     | 81.5        |\n",
      "|    total_trades         | 57546       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034015197 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0168      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.11        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 8.16        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2679609.13\n",
      "total_reward: 1679609.13\n",
      "total_cost: 191644.03\n",
      "total_trades: 57882\n",
      "Sharpe: 0.868\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.68e+06   |\n",
      "|    total_cost           | 1.92e+05   |\n",
      "|    total_reward         | 1.68e+06   |\n",
      "|    total_reward_pct     | 168        |\n",
      "|    total_trades         | 57882      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 429        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03147587 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.147      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.61       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 11.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.18e+06   |\n",
      "|    total_cost           | 2.04e+05   |\n",
      "|    total_reward         | 2.18e+06   |\n",
      "|    total_reward_pct     | 218        |\n",
      "|    total_trades         | 59104      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 446        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04285399 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.105      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.56       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 12.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.28e+06    |\n",
      "|    total_cost           | 2.05e+05    |\n",
      "|    total_reward         | 1.28e+06    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 59222       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 462         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027895948 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.37        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.18e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 2.18e+06    |\n",
      "|    total_reward_pct     | 218         |\n",
      "|    total_trades         | 59509       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 477         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030903215 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.16        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.32e+06   |\n",
      "|    total_cost           | 1.95e+05   |\n",
      "|    total_reward         | 2.32e+06   |\n",
      "|    total_reward_pct     | 232        |\n",
      "|    total_trades         | 58968      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 492        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03743557 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.166      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.94       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 14.5       |\n",
      "----------------------------------------\n",
      "day: 2139, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2074964.07\n",
      "total_reward: 1074964.07\n",
      "total_cost: 176370.76\n",
      "total_trades: 56063\n",
      "Sharpe: 0.670\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.07e+06    |\n",
      "|    total_cost           | 1.76e+05    |\n",
      "|    total_reward         | 1.07e+06    |\n",
      "|    total_reward_pct     | 107         |\n",
      "|    total_trades         | 56063       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 506         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045567557 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0186      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.12        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+06     |\n",
      "|    total_cost           | 1.92e+05    |\n",
      "|    total_reward         | 1.5e+06     |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 57881       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 522         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040321946 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.23        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 8.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 1.71e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 55912       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 537         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035435732 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.62        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.9e+06     |\n",
      "|    total_cost           | 1.98e+05    |\n",
      "|    total_reward         | 2.9e+06     |\n",
      "|    total_reward_pct     | 290         |\n",
      "|    total_trades         | 58847       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 552         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026131896 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.83        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.99e+06    |\n",
      "|    total_cost           | 1.91e+05    |\n",
      "|    total_reward         | 1.99e+06    |\n",
      "|    total_reward_pct     | 199         |\n",
      "|    total_trades         | 57807       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 567         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027791627 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2635649.98\n",
      "total_reward: 1635649.98\n",
      "total_cost: 197056.22\n",
      "total_trades: 58608\n",
      "Sharpe: 0.906\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.64e+06    |\n",
      "|    total_cost           | 1.97e+05    |\n",
      "|    total_reward         | 1.64e+06    |\n",
      "|    total_reward_pct     | 164         |\n",
      "|    total_trades         | 58608       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 582         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036370303 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.59        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.71e+06    |\n",
      "|    total_cost           | 1.88e+05    |\n",
      "|    total_reward         | 2.71e+06    |\n",
      "|    total_reward_pct     | 271         |\n",
      "|    total_trades         | 57910       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010964939 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.13        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.36e+06    |\n",
      "|    total_cost           | 1.77e+05    |\n",
      "|    total_reward         | 1.36e+06    |\n",
      "|    total_reward_pct     | 136         |\n",
      "|    total_trades         | 56153       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035232924 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.000195   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.57e+06   |\n",
      "|    total_cost           | 1.96e+05   |\n",
      "|    total_reward         | 2.57e+06   |\n",
      "|    total_reward_pct     | 257        |\n",
      "|    total_trades         | 58433      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 130        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 626        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03380752 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.18       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.46       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.00974   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 10.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.59e+06    |\n",
      "|    total_cost           | 1.64e+05    |\n",
      "|    total_reward         | 5.9e+05     |\n",
      "|    total_reward_pct     | 59          |\n",
      "|    total_trades         | 54648       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 641         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042908948 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.89        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3540579.97\n",
      "total_reward: 2540579.97\n",
      "total_cost: 189582.42\n",
      "total_trades: 57606\n",
      "Sharpe: 1.064\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.54e+06    |\n",
      "|    total_cost           | 1.9e+05     |\n",
      "|    total_reward         | 2.54e+06    |\n",
      "|    total_reward_pct     | 254         |\n",
      "|    total_trades         | 57606       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 656         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031224329 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.19        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 9.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.66e+06    |\n",
      "|    total_cost           | 1.81e+05    |\n",
      "|    total_reward         | 2.66e+06    |\n",
      "|    total_reward_pct     | 266         |\n",
      "|    total_trades         | 57267       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 671         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027727138 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.31e+06    |\n",
      "|    total_cost           | 1.78e+05    |\n",
      "|    total_reward         | 3.31e+06    |\n",
      "|    total_reward_pct     | 331         |\n",
      "|    total_trades         | 56975       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 686         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021169804 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.33        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.87e+06   |\n",
      "|    total_cost           | 1.62e+05   |\n",
      "|    total_reward         | 3.87e+06   |\n",
      "|    total_reward_pct     | 387        |\n",
      "|    total_trades         | 55972      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 701        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04524775 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.0121     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.7       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.00849   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 30.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.32e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 3.32e+06    |\n",
      "|    total_reward_pct     | 332         |\n",
      "|    total_trades         | 55801       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 716         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031067228 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0894      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026156208 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "day: 2139, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4343845.32\n",
      "total_reward: 3343845.32\n",
      "total_cost: 161060.00\n",
      "total_trades: 55323\n",
      "Sharpe: 1.191\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.34e+06    |\n",
      "|    total_cost           | 1.61e+05    |\n",
      "|    total_reward         | 3.34e+06    |\n",
      "|    total_reward_pct     | 334         |\n",
      "|    total_trades         | 55323       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 746         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034266964 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.38        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.61e+06    |\n",
      "|    total_cost           | 1.76e+05    |\n",
      "|    total_reward         | 3.61e+06    |\n",
      "|    total_reward_pct     | 361         |\n",
      "|    total_trades         | 56923       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 761         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030252669 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.63        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2018-07-05 to  2018-10-03\n",
      "PPO Sharpe Ratio:  0.38631767103531905\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_567_4\n",
      "day: 2139, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2463703.39\n",
      "total_reward: 1463703.39\n",
      "total_cost: 1130.63\n",
      "total_trades: 41876\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.75e+06 |\n",
      "|    total_cost       | 1.35e+03 |\n",
      "|    total_reward     | 1.75e+06 |\n",
      "|    total_reward_pct | 175      |\n",
      "|    total_trades     | 40679    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total timesteps  | 8560     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -7.31    |\n",
      "|    critic_loss      | 44.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6420     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2018-07-05 to  2018-10-03\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-10-03\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_567_3\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.5e+06  |\n",
      "|    total_cost       | 1.37e+03 |\n",
      "|    total_reward     | 1.5e+06  |\n",
      "|    total_reward_pct | 150      |\n",
      "|    total_trades     | 26540    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total timesteps  | 8812     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -16.4    |\n",
      "|    critic_loss      | 192      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6609     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2202, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2461265.46\n",
      "total_reward: 1461265.46\n",
      "total_cost: 1501.64\n",
      "total_trades: 28489\n",
      "Sharpe: 0.754\n",
      "=================================\n",
      "======Trading from:  2018-10-03 to  2019-01-04\n",
      "============================================\n",
      "24.34258398865855\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2018-10-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_630_4\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -42.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0969  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 20.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.54    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 8.16     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 132      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 22.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.67e+06 |\n",
      "|    total_cost         | 1.46e+05 |\n",
      "|    total_reward       | 1.67e+06 |\n",
      "|    total_reward_pct   | 167      |\n",
      "|    total_trades       | 52394    |\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 11.4     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.406    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.107   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 66.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -62.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 25.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.468    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.24e+06 |\n",
      "|    total_cost         | 7.6e+04  |\n",
      "|    total_reward       | 1.24e+06 |\n",
      "|    total_reward_pct   | 124      |\n",
      "|    total_trades       | 43996    |\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0704   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 80.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.699   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -98.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -37.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 68.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 215      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 53.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.41e+06 |\n",
      "|    total_cost         | 5.26e+04 |\n",
      "|    total_reward       | 1.41e+06 |\n",
      "|    total_reward_pct   | 141      |\n",
      "|    total_trades       | 40360    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.00618 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -4.76    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.081    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 96.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0933  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -62.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -39.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.1e+06  |\n",
      "|    total_cost         | 9.33e+04 |\n",
      "|    total_reward       | 1.1e+06  |\n",
      "|    total_reward_pct   | 110      |\n",
      "|    total_trades       | 46748    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0893  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 33.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0234   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 40       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 44.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -79      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00753 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 56.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.95     |\n",
      "------------------------------------\n",
      "day: 2202, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1593714.47\n",
      "total_reward: 593714.47\n",
      "total_cost: 61095.11\n",
      "total_trades: 43901\n",
      "Sharpe: 0.405\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.59e+06  |\n",
      "|    total_cost         | 6.11e+04  |\n",
      "|    total_reward       | 5.94e+05  |\n",
      "|    total_reward_pct   | 59.4      |\n",
      "|    total_trades       | 43901     |\n",
      "| time/                 |           |\n",
      "|    fps                | 130       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -0.000512 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 31.6      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.58      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 87.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.53     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 130       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 117       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.72      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.164   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -78      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.72e+06 |\n",
      "|    total_cost         | 1.34e+05 |\n",
      "|    total_reward       | 1.72e+06 |\n",
      "|    total_reward_pct   | 172      |\n",
      "|    total_trades       | 51304    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.208   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 99.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.69     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.343   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 4.05     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -166     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 22.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 122      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.94e+06 |\n",
      "|    total_cost         | 1.21e+05 |\n",
      "|    total_reward       | 1.94e+06 |\n",
      "|    total_reward_pct   | 194      |\n",
      "|    total_trades       | 52798    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.255   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -66.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -3.28    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -151     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.144   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -35.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -142     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 24       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.75e+06 |\n",
      "|    total_cost         | 1.08e+05 |\n",
      "|    total_reward       | 2.75e+06 |\n",
      "|    total_reward_pct   | 275      |\n",
      "|    total_trades       | 49301    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0534   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -20      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -163     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 17.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -34.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.111    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 51.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.48e+06 |\n",
      "|    total_cost         | 3.84e+04 |\n",
      "|    total_reward       | 1.48e+06 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 41925    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 53.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.00115 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -28.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 71.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 3.78     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -44.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.58     |\n",
      "------------------------------------\n",
      "day: 2202, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2369542.34\n",
      "total_reward: 1369542.34\n",
      "total_cost: 52836.85\n",
      "total_trades: 40883\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.37e+06 |\n",
      "|    total_cost         | 5.28e+04 |\n",
      "|    total_reward       | 1.37e+06 |\n",
      "|    total_reward_pct   | 137      |\n",
      "|    total_trades       | 40883    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.0965  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 7.24     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -22.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.819    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 47.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 37.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.873    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.64e+06 |\n",
      "|    total_cost         | 6.89e+04 |\n",
      "|    total_reward       | 1.64e+06 |\n",
      "|    total_reward_pct   | 164      |\n",
      "|    total_trades       | 42003    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 26.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.658    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 15.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.203    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 109      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 9.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 40.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.36e+06 |\n",
      "|    total_cost         | 3.81e+04 |\n",
      "|    total_reward       | 1.36e+06 |\n",
      "|    total_reward_pct   | 136      |\n",
      "|    total_trades       | 38255    |\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.158   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 0.999    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0701   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 71.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.23     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 68.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 283      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 38.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.77e+06  |\n",
      "|    total_cost         | 1.98e+04  |\n",
      "|    total_reward       | 1.77e+06  |\n",
      "|    total_reward_pct   | 177       |\n",
      "|    total_trades       | 38247     |\n",
      "| time/                 |           |\n",
      "|    fps                | 130       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 221       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -87       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.85      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 130       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -43.6     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.37      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -78.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.19     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2018-10-03 to  2019-01-04\n",
      "A2C Sharpe Ratio:  -0.29942057788089543\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_630_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 139  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 14   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "day: 2202, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2688050.07\n",
      "total_reward: 1688050.07\n",
      "total_cost: 249330.50\n",
      "total_trades: 63748\n",
      "Sharpe: 0.957\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.69e+06   |\n",
      "|    total_cost           | 2.49e+05   |\n",
      "|    total_reward         | 1.69e+06   |\n",
      "|    total_reward_pct     | 169        |\n",
      "|    total_trades         | 63748      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 136        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02003161 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.00646   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.42       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0256    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 8.96       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.21e+06     |\n",
      "|    total_cost           | 2.36e+05     |\n",
      "|    total_reward         | 1.21e+06     |\n",
      "|    total_reward_pct     | 121          |\n",
      "|    total_trades         | 62768        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 136          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115382895 |\n",
      "|    clip_fraction        | 0.191        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.8        |\n",
      "|    explained_variance   | -0.00468     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.91         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0267      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 9.14         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.27e+06    |\n",
      "|    total_cost           | 2.37e+05    |\n",
      "|    total_reward         | 1.27e+06    |\n",
      "|    total_reward_pct     | 127         |\n",
      "|    total_trades         | 62644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016116383 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.00161    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.96        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.26e+06    |\n",
      "|    total_cost           | 2.34e+05    |\n",
      "|    total_reward         | 1.26e+06    |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 62656       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013838068 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00984    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.63        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.23e+06    |\n",
      "|    total_cost           | 2.32e+05    |\n",
      "|    total_reward         | 1.23e+06    |\n",
      "|    total_reward_pct     | 123         |\n",
      "|    total_trades         | 62580       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020598758 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00858     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.26        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.97        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2202, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2027439.50\n",
      "total_reward: 1027439.50\n",
      "total_cost: 219753.79\n",
      "total_trades: 61585\n",
      "Sharpe: 0.658\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.03e+06    |\n",
      "|    total_cost           | 2.2e+05     |\n",
      "|    total_reward         | 1.03e+06    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 61585       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019616831 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0306      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.86        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.11e+06    |\n",
      "|    total_cost           | 2.25e+05    |\n",
      "|    total_reward         | 1.11e+06    |\n",
      "|    total_reward_pct     | 111         |\n",
      "|    total_trades         | 62124       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022733077 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0395      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.32        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.14        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.68e+06   |\n",
      "|    total_cost           | 2.36e+05   |\n",
      "|    total_reward         | 1.68e+06   |\n",
      "|    total_reward_pct     | 168        |\n",
      "|    total_trades         | 62828      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02622721 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | 0.0863     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.48       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.022     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 8.76       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.89e+06   |\n",
      "|    total_cost           | 2.26e+05   |\n",
      "|    total_reward         | 1.89e+06   |\n",
      "|    total_reward_pct     | 189        |\n",
      "|    total_trades         | 61985      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 152        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01420779 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.0578     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.96       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 10.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+06    |\n",
      "|    total_cost           | 2.35e+05    |\n",
      "|    total_reward         | 1.65e+06    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 62453       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025205541 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0585      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "day: 2202, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2299427.06\n",
      "total_reward: 1299427.06\n",
      "total_cost: 223693.95\n",
      "total_trades: 61554\n",
      "Sharpe: 0.675\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.3e+06     |\n",
      "|    total_cost           | 2.24e+05    |\n",
      "|    total_reward         | 1.3e+06     |\n",
      "|    total_reward_pct     | 130         |\n",
      "|    total_trades         | 61554       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033247463 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0549      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.89        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.2e+06     |\n",
      "|    total_cost           | 2.28e+05    |\n",
      "|    total_reward         | 1.2e+06     |\n",
      "|    total_reward_pct     | 120         |\n",
      "|    total_trades         | 62136       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019057777 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0197      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.31        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+06    |\n",
      "|    total_cost           | 2.34e+05    |\n",
      "|    total_reward         | 1.58e+06    |\n",
      "|    total_reward_pct     | 158         |\n",
      "|    total_trades         | 62459       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027843978 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0432      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.6         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.2         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040056475 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0352      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.37        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.18e+06    |\n",
      "|    total_cost           | 2.23e+05    |\n",
      "|    total_reward         | 1.18e+06    |\n",
      "|    total_reward_pct     | 118         |\n",
      "|    total_trades         | 61461       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022096256 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0374      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.11        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.12e+06   |\n",
      "|    total_cost           | 2.13e+05   |\n",
      "|    total_reward         | 1.12e+06   |\n",
      "|    total_reward_pct     | 112        |\n",
      "|    total_trades         | 60379      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 263        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02809775 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.22       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0227    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 9.54       |\n",
      "----------------------------------------\n",
      "day: 2202, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3027832.52\n",
      "total_reward: 2027832.52\n",
      "total_cost: 213999.79\n",
      "total_trades: 60523\n",
      "Sharpe: 0.957\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.03e+06    |\n",
      "|    total_cost           | 2.14e+05    |\n",
      "|    total_reward         | 2.03e+06    |\n",
      "|    total_reward_pct     | 203         |\n",
      "|    total_trades         | 60523       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040776134 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0505      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.33        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.2e+06     |\n",
      "|    total_cost           | 2.05e+05    |\n",
      "|    total_reward         | 2.2e+06     |\n",
      "|    total_reward_pct     | 220         |\n",
      "|    total_trades         | 59683       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030469313 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0562      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.45        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.91e+06    |\n",
      "|    total_cost           | 2.15e+05    |\n",
      "|    total_reward         | 1.91e+06    |\n",
      "|    total_reward_pct     | 191         |\n",
      "|    total_trades         | 60803       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039150055 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0881      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.32        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.86e+06    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 1.86e+06    |\n",
      "|    total_reward_pct     | 186         |\n",
      "|    total_trades         | 61336       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 327         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025437465 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0391      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.44        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.75e+06   |\n",
      "|    total_cost           | 2.17e+05   |\n",
      "|    total_reward         | 1.75e+06   |\n",
      "|    total_reward_pct     | 175        |\n",
      "|    total_trades         | 60622      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 343        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03218247 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0252     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4          |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 12.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2202, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2485864.45\n",
      "total_reward: 1485864.45\n",
      "total_cost: 212969.98\n",
      "total_trades: 60438\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.49e+06   |\n",
      "|    total_cost           | 2.13e+05   |\n",
      "|    total_reward         | 1.49e+06   |\n",
      "|    total_reward_pct     | 149        |\n",
      "|    total_trades         | 60438      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 358        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02642831 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0784     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.3        |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0237    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 12         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.06e+06   |\n",
      "|    total_cost           | 2.14e+05   |\n",
      "|    total_reward         | 2.06e+06   |\n",
      "|    total_reward_pct     | 206        |\n",
      "|    total_trades         | 60421      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 375        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03204926 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0782     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.47       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0154    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 11.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.83e+06    |\n",
      "|    total_cost           | 1.98e+05    |\n",
      "|    total_reward         | 1.83e+06    |\n",
      "|    total_reward_pct     | 183         |\n",
      "|    total_trades         | 59366       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 391         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028831262 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0938      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.78        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.62e+06    |\n",
      "|    total_cost           | 2.02e+05    |\n",
      "|    total_reward         | 1.62e+06    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 59159       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025622275 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0271      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.79e+06    |\n",
      "|    total_cost           | 2e+05       |\n",
      "|    total_reward         | 1.79e+06    |\n",
      "|    total_reward_pct     | 179         |\n",
      "|    total_trades         | 58812       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017313516 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.34        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "day: 2202, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2599816.86\n",
      "total_reward: 1599816.86\n",
      "total_cost: 206796.97\n",
      "total_trades: 59626\n",
      "Sharpe: 0.904\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.6e+06     |\n",
      "|    total_cost           | 2.07e+05    |\n",
      "|    total_reward         | 1.6e+06     |\n",
      "|    total_reward_pct     | 160         |\n",
      "|    total_trades         | 59626       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024392188 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0999      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.15        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 457        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03706769 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.109      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.54       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 10.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.44e+06    |\n",
      "|    total_cost           | 1.94e+05    |\n",
      "|    total_reward         | 2.44e+06    |\n",
      "|    total_reward_pct     | 244         |\n",
      "|    total_trades         | 58322       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 473         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044974986 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.93        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.52e+06    |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 3.52e+06    |\n",
      "|    total_reward_pct     | 352         |\n",
      "|    total_trades         | 57408       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 489         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029251184 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.62        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.1e+06     |\n",
      "|    total_cost           | 1.77e+05    |\n",
      "|    total_reward         | 3.1e+06     |\n",
      "|    total_reward_pct     | 310         |\n",
      "|    total_trades         | 57090       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 504         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029998839 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.88e+06    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | 3.88e+06    |\n",
      "|    total_reward_pct     | 388         |\n",
      "|    total_trades         | 55300       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 519         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031884532 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "day: 2202, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4486741.91\n",
      "total_reward: 3486741.91\n",
      "total_cost: 168175.05\n",
      "total_trades: 56299\n",
      "Sharpe: 1.108\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.49e+06   |\n",
      "|    total_cost           | 1.68e+05   |\n",
      "|    total_reward         | 3.49e+06   |\n",
      "|    total_reward_pct     | 349        |\n",
      "|    total_trades         | 56299      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 130        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 534        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03831134 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.269      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.3       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.00572   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 38.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.43e+06    |\n",
      "|    total_cost           | 1.69e+05    |\n",
      "|    total_reward         | 3.43e+06    |\n",
      "|    total_reward_pct     | 343         |\n",
      "|    total_trades         | 56215       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 549         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030202856 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.22e+06   |\n",
      "|    total_cost           | 1.84e+05   |\n",
      "|    total_reward         | 3.22e+06   |\n",
      "|    total_reward_pct     | 322        |\n",
      "|    total_trades         | 57773      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 130        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 564        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03181517 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.454      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.1       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.00713   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 29.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.21e+06    |\n",
      "|    total_cost           | 2.1e+05     |\n",
      "|    total_reward         | 2.21e+06    |\n",
      "|    total_reward_pct     | 221         |\n",
      "|    total_trades         | 59731       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023719558 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.22e+06    |\n",
      "|    total_cost           | 2.05e+05    |\n",
      "|    total_reward         | 2.22e+06    |\n",
      "|    total_reward_pct     | 222         |\n",
      "|    total_trades         | 58989       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 594         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023522653 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.96        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2202, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3040378.73\n",
      "total_reward: 2040378.73\n",
      "total_cost: 184165.24\n",
      "total_trades: 57826\n",
      "Sharpe: 0.869\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.04e+06   |\n",
      "|    total_cost           | 1.84e+05   |\n",
      "|    total_reward         | 2.04e+06   |\n",
      "|    total_reward_pct     | 204        |\n",
      "|    total_trades         | 57826      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 609        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03424373 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.417      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.43       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00584   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 18.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.68e+06    |\n",
      "|    total_cost           | 1.87e+05    |\n",
      "|    total_reward         | 2.68e+06    |\n",
      "|    total_reward_pct     | 268         |\n",
      "|    total_trades         | 57516       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 624         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026008278 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.68        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.92e+06    |\n",
      "|    total_cost           | 1.94e+05    |\n",
      "|    total_reward         | 1.92e+06    |\n",
      "|    total_reward_pct     | 192         |\n",
      "|    total_trades         | 57893       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 639         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021333976 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.91        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.55e+06   |\n",
      "|    total_cost           | 1.86e+05   |\n",
      "|    total_reward         | 2.55e+06   |\n",
      "|    total_reward_pct     | 255        |\n",
      "|    total_trades         | 57232      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 654        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05156316 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.543      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.62       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.00503   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 14.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 670        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03229461 |\n",
      "|    clip_fraction        | 0.326      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.541      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.46       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 19.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.22e+06   |\n",
      "|    total_cost           | 1.77e+05   |\n",
      "|    total_reward         | 2.22e+06   |\n",
      "|    total_reward_pct     | 222        |\n",
      "|    total_trades         | 55968      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 685        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04500518 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.418      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.33       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00505   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 15.8       |\n",
      "----------------------------------------\n",
      "day: 2202, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4118770.77\n",
      "total_reward: 3118770.77\n",
      "total_cost: 175388.16\n",
      "total_trades: 55997\n",
      "Sharpe: 1.114\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.12e+06   |\n",
      "|    total_cost           | 1.75e+05   |\n",
      "|    total_reward         | 3.12e+06   |\n",
      "|    total_reward_pct     | 312        |\n",
      "|    total_trades         | 55997      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 700        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02773058 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.484      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.08       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.00753   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 17.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.6e+06    |\n",
      "|    total_cost           | 1.87e+05   |\n",
      "|    total_reward         | 1.6e+06    |\n",
      "|    total_reward_pct     | 160        |\n",
      "|    total_trades         | 56821      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 715        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01813168 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.494      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.8       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 17.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.96e+06    |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | 1.96e+06    |\n",
      "|    total_reward_pct     | 196         |\n",
      "|    total_trades         | 57887       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 730         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038634572 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.31        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.15e+06   |\n",
      "|    total_cost           | 1.71e+05   |\n",
      "|    total_reward         | 3.15e+06   |\n",
      "|    total_reward_pct     | 315        |\n",
      "|    total_trades         | 55709      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 745        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02852307 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.37       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7          |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00967   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 17.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.48e+06   |\n",
      "|    total_cost           | 1.84e+05   |\n",
      "|    total_reward         | 3.48e+06   |\n",
      "|    total_reward_pct     | 348        |\n",
      "|    total_trades         | 56915      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 760        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03680159 |\n",
      "|    clip_fraction        | 0.345      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.47       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00557   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 24.5       |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2018-10-03 to  2019-01-04\n",
      "PPO Sharpe Ratio:  -0.25907223337520247\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_630_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.82e+06 |\n",
      "|    total_cost       | 1.35e+03 |\n",
      "|    total_reward     | 1.82e+06 |\n",
      "|    total_reward_pct | 182      |\n",
      "|    total_trades     | 29505    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total timesteps  | 8812     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 38.4     |\n",
      "|    critic_loss      | 28.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6609     |\n",
      "----------------------------------\n",
      "day: 2202, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3072071.11\n",
      "total_reward: 2072071.11\n",
      "total_cost: 1326.26\n",
      "total_trades: 35677\n",
      "Sharpe: 1.019\n",
      "=================================\n",
      "======DDPG Validation from:  2018-10-03 to  2019-01-04\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-01-04\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_630_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.62e+06 |\n",
      "|    total_cost       | 1.52e+03 |\n",
      "|    total_reward     | 1.62e+06 |\n",
      "|    total_reward_pct | 162      |\n",
      "|    total_trades     | 37119    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total timesteps  | 9064     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -33.7    |\n",
      "|    critic_loss      | 48.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6798     |\n",
      "----------------------------------\n",
      "day: 2265, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2739589.02\n",
      "total_reward: 1739589.02\n",
      "total_cost: 1529.77\n",
      "total_trades: 36297\n",
      "Sharpe: 0.747\n",
      "=================================\n",
      "======Trading from:  2019-01-04 to  2019-04-05\n",
      "============================================\n",
      "45.21128772353635\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2019-01-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_693_4\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.269   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -68.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0444  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -34.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0975   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -38.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 39.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.23     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.14e+06 |\n",
      "|    total_cost         | 1.65e+05 |\n",
      "|    total_reward       | 1.14e+06 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 58350    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.906   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.606    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.154   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 66.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -1.64    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 20.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.483    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0985   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 9.16     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 154      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 19.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.16e+06 |\n",
      "|    total_cost         | 2.05e+05 |\n",
      "|    total_reward       | 1.16e+06 |\n",
      "|    total_reward_pct   | 116      |\n",
      "|    total_trades       | 60597    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0107  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -48.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 18.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.517    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.112    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 25       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0179  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -10.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.568    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.87e+06 |\n",
      "|    total_cost         | 1.27e+05 |\n",
      "|    total_reward       | 8.7e+05  |\n",
      "|    total_reward_pct   | 87       |\n",
      "|    total_trades       | 53289    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.122   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 5.28     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0798   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.328   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 35.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.992    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.116   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 30.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 40.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0654   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 26.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.73e+06 |\n",
      "|    total_cost         | 1.41e+05 |\n",
      "|    total_reward       | 7.33e+05 |\n",
      "|    total_reward_pct   | 73.3     |\n",
      "|    total_trades       | 54812    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.106   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 34.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.00438 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 52.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0882   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -39      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 45.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n",
      "day: 2265, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1569455.84\n",
      "total_reward: 569455.84\n",
      "total_cost: 108478.81\n",
      "total_trades: 51526\n",
      "Sharpe: 0.433\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.57e+06 |\n",
      "|    total_cost         | 1.08e+05 |\n",
      "|    total_reward       | 5.69e+05 |\n",
      "|    total_reward_pct   | 56.9     |\n",
      "|    total_trades       | 51526    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -36.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -52.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0454   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 40.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 54       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 127       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -19.1     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.551     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.64e+06 |\n",
      "|    total_cost         | 5.87e+04 |\n",
      "|    total_reward       | 6.42e+05 |\n",
      "|    total_reward_pct   | 64.2     |\n",
      "|    total_trades       | 44454    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.153    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -92.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.96     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 127       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -67.9     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.04      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -104     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.278    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.868   |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.86e+06 |\n",
      "|    total_cost         | 3.33e+04 |\n",
      "|    total_reward       | 8.56e+05 |\n",
      "|    total_reward_pct   | 85.6     |\n",
      "|    total_trades       | 42278    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.171    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 65.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.58     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0421  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -113     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 26.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -15.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -341     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 79.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.99e+06 |\n",
      "|    total_cost         | 5.59e+04 |\n",
      "|    total_reward       | 9.94e+05 |\n",
      "|    total_reward_pct   | 99.4     |\n",
      "|    total_trades       | 47309    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.0133  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -8.47    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -35.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 75.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 4.35     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.225    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.04e+06 |\n",
      "|    total_cost         | 2.43e+04 |\n",
      "|    total_reward       | 1.04e+06 |\n",
      "|    total_reward_pct   | 104      |\n",
      "|    total_trades       | 45733    |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.238    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 22.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.0082   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 24.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -130     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.353   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -137     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 10.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 175       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 351       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 80.3      |\n",
      "-------------------------------------\n",
      "day: 2265, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2698340.49\n",
      "total_reward: 1698340.49\n",
      "total_cost: 69050.17\n",
      "total_trades: 48337\n",
      "Sharpe: 0.765\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.7e+06   |\n",
      "|    total_cost         | 6.91e+04  |\n",
      "|    total_reward       | 1.7e+06   |\n",
      "|    total_reward_pct   | 170       |\n",
      "|    total_trades       | 48337     |\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 46.9      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 3.51      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.00524 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 65       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 9.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.0998   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 71.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.75     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 191       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -28.9     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.74      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.88e+06 |\n",
      "|    total_cost         | 1.04e+05 |\n",
      "|    total_reward       | 1.88e+06 |\n",
      "|    total_reward_pct   | 188      |\n",
      "|    total_trades       | 48553    |\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.412   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 57.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.89     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -0.000533 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -37.2     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.31      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 55.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.91     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 127       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 108       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 7.96      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -582     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 184      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.41e+06  |\n",
      "|    total_cost         | 5.58e+04  |\n",
      "|    total_reward       | 1.41e+06  |\n",
      "|    total_reward_pct   | 141       |\n",
      "|    total_trades       | 43038     |\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 214       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -39.5     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.73      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.108   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -39.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.47     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 128       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 222       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -146      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 16.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -23.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.37e+06 |\n",
      "|    total_cost         | 3.15e+04 |\n",
      "|    total_reward       | 1.37e+06 |\n",
      "|    total_reward_pct   | 137      |\n",
      "|    total_trades       | 43465    |\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -2.97    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 71.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 59.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.26     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======A2C Validation from:  2019-01-04 to  2019-04-05\n",
      "A2C Sharpe Ratio:  0.5422628850095511\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_693_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 136  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 14   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "day: 2265, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2394353.55\n",
      "total_reward: 1394353.55\n",
      "total_cost: 259967.30\n",
      "total_trades: 65588\n",
      "Sharpe: 0.832\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.39e+06   |\n",
      "|    total_cost           | 2.6e+05    |\n",
      "|    total_reward         | 1.39e+06   |\n",
      "|    total_reward_pct     | 139        |\n",
      "|    total_trades         | 65588      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 133        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01915181 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | 0.00757    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.7        |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0219    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 9.3        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.85e+06    |\n",
      "|    total_cost           | 2.51e+05    |\n",
      "|    total_reward         | 8.52e+05    |\n",
      "|    total_reward_pct     | 85.2        |\n",
      "|    total_trades         | 64580       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016798923 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0433     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.18        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.18e+06    |\n",
      "|    total_cost           | 2.55e+05    |\n",
      "|    total_reward         | 1.18e+06    |\n",
      "|    total_reward_pct     | 118         |\n",
      "|    total_trades         | 64946       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021213282 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0049      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.44        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.59e+06  |\n",
      "|    total_cost           | 2.49e+05  |\n",
      "|    total_reward         | 1.59e+06  |\n",
      "|    total_reward_pct     | 159       |\n",
      "|    total_trades         | 64515     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 131       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 77        |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0163284 |\n",
      "|    clip_fraction        | 0.199     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -42.8     |\n",
      "|    explained_variance   | -0.00592  |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 3.28      |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.0246   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 11.2      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.38e+06    |\n",
      "|    total_cost           | 2.55e+05    |\n",
      "|    total_reward         | 1.38e+06    |\n",
      "|    total_reward_pct     | 138         |\n",
      "|    total_trades         | 65050       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017238436 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00109     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.13        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2151393.45\n",
      "total_reward: 1151393.45\n",
      "total_cost: 244929.99\n",
      "total_trades: 64100\n",
      "Sharpe: 0.702\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.15e+06   |\n",
      "|    total_cost           | 2.45e+05   |\n",
      "|    total_reward         | 1.15e+06   |\n",
      "|    total_reward_pct     | 115        |\n",
      "|    total_trades         | 64100      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 108        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01755633 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | -0.000317  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.51       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0214    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 12.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+06    |\n",
      "|    total_cost           | 2.45e+05    |\n",
      "|    total_reward         | 1.65e+06    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 63825       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022888528 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0332     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.93        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.93e+06    |\n",
      "|    total_cost           | 2.52e+05    |\n",
      "|    total_reward         | 9.3e+05     |\n",
      "|    total_reward_pct     | 93          |\n",
      "|    total_trades         | 64628       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013380889 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0187      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.92        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.12e+06    |\n",
      "|    total_cost           | 2.32e+05    |\n",
      "|    total_reward         | 1.12e+06    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 62896       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023767961 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.026      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.69        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018752625 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0164     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.68        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.24e+06    |\n",
      "|    total_cost           | 2.33e+05    |\n",
      "|    total_reward         | 1.24e+06    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 63455       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022907391 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.00266    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.93        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.76        |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2235533.35\n",
      "total_reward: 1235533.35\n",
      "total_cost: 239051.98\n",
      "total_trades: 63601\n",
      "Sharpe: 0.724\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.24e+06    |\n",
      "|    total_cost           | 2.39e+05    |\n",
      "|    total_reward         | 1.24e+06    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 63601       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022355327 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00261     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4           |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.65        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.18e+06    |\n",
      "|    total_cost           | 2.38e+05    |\n",
      "|    total_reward         | 1.18e+06    |\n",
      "|    total_reward_pct     | 118         |\n",
      "|    total_trades         | 63437       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015869725 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00635     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.78        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.84        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.32e+06    |\n",
      "|    total_cost           | 2.23e+05    |\n",
      "|    total_reward         | 1.32e+06    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 62610       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016125605 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0165     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.62        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.28e+06    |\n",
      "|    total_cost           | 2.17e+05    |\n",
      "|    total_reward         | 1.28e+06    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 62012       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035326503 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0432     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.72        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.66e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 1.66e+06    |\n",
      "|    total_reward_pct     | 166         |\n",
      "|    total_trades         | 62192       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025812183 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.00704     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.59        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2265, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2330613.41\n",
      "total_reward: 1330613.41\n",
      "total_cost: 229872.66\n",
      "total_trades: 62870\n",
      "Sharpe: 0.744\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+06    |\n",
      "|    total_cost           | 2.3e+05     |\n",
      "|    total_reward         | 1.33e+06    |\n",
      "|    total_reward_pct     | 133         |\n",
      "|    total_trades         | 62870       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028986039 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0111      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.15        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.63e+06    |\n",
      "|    total_cost           | 2.31e+05    |\n",
      "|    total_reward         | 1.63e+06    |\n",
      "|    total_reward_pct     | 163         |\n",
      "|    total_trades         | 62779       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023480853 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0502      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.45        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.28e+06    |\n",
      "|    total_cost           | 2.32e+05    |\n",
      "|    total_reward         | 1.28e+06    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 63413       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027238203 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0804      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.97        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041560106 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.00792     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.58        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.19e+06   |\n",
      "|    total_cost           | 2.34e+05   |\n",
      "|    total_reward         | 1.19e+06   |\n",
      "|    total_reward_pct     | 119        |\n",
      "|    total_trades         | 63355      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 340        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03144315 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | -0.0178    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.44       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0146    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 11         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.09e+06   |\n",
      "|    total_cost           | 2.24e+05   |\n",
      "|    total_reward         | 1.09e+06   |\n",
      "|    total_reward_pct     | 109        |\n",
      "|    total_trades         | 62420      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 356        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03446262 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0618     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.16       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 8.95       |\n",
      "----------------------------------------\n",
      "day: 2265, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2866997.05\n",
      "total_reward: 1866997.05\n",
      "total_cost: 229333.41\n",
      "total_trades: 62356\n",
      "Sharpe: 0.878\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.87e+06    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 1.87e+06    |\n",
      "|    total_reward_pct     | 187         |\n",
      "|    total_trades         | 62356       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 371         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030983582 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.0493     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.92        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+06    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 1.04e+06    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 62583       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 386         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033008594 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0383      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.07e+06    |\n",
      "|    total_cost           | 2.35e+05    |\n",
      "|    total_reward         | 1.07e+06    |\n",
      "|    total_reward_pct     | 107         |\n",
      "|    total_trades         | 63020       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 402         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038699873 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.71        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+06    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 1.19e+06    |\n",
      "|    total_reward_pct     | 119         |\n",
      "|    total_trades         | 62469       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033511832 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0224      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.56        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.16e+06    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 1.16e+06    |\n",
      "|    total_reward_pct     | 116         |\n",
      "|    total_trades         | 62395       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047956318 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0555      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.71        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2212746.18\n",
      "total_reward: 1212746.18\n",
      "total_cost: 231240.11\n",
      "total_trades: 62590\n",
      "Sharpe: 0.723\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.21e+06   |\n",
      "|    total_cost           | 2.31e+05   |\n",
      "|    total_reward         | 1.21e+06   |\n",
      "|    total_reward_pct     | 121        |\n",
      "|    total_trades         | 62590      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 449        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03226289 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0384     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.92       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 11.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.91e+06    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 9.06e+05    |\n",
      "|    total_reward_pct     | 90.6        |\n",
      "|    total_trades         | 61498       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 464         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023857456 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | -0.0196     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.19        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.51e+06   |\n",
      "|    total_cost           | 2.32e+05   |\n",
      "|    total_reward         | 1.51e+06   |\n",
      "|    total_reward_pct     | 151        |\n",
      "|    total_trades         | 62934      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 480        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03340517 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | -0.0472    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.3        |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 9.87       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 495         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021841725 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0206      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.68        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.11e+06    |\n",
      "|    total_cost           | 2.36e+05    |\n",
      "|    total_reward         | 1.11e+06    |\n",
      "|    total_reward_pct     | 111         |\n",
      "|    total_trades         | 63066       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034858704 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0487      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.4         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 9.05        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.2e+06    |\n",
      "|    total_cost           | 2.2e+05    |\n",
      "|    total_reward         | 1.2e+06    |\n",
      "|    total_reward_pct     | 120        |\n",
      "|    total_trades         | 62022      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 527        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03806694 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0426     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.37       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 12.1       |\n",
      "----------------------------------------\n",
      "day: 2265, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1937825.38\n",
      "total_reward: 937825.38\n",
      "total_cost: 228422.85\n",
      "total_trades: 62306\n",
      "Sharpe: 0.577\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.94e+06    |\n",
      "|    total_cost           | 2.28e+05    |\n",
      "|    total_reward         | 9.38e+05    |\n",
      "|    total_reward_pct     | 93.8        |\n",
      "|    total_trades         | 62306       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 544         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036844343 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0319      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.61        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.81e+06   |\n",
      "|    total_cost           | 2.28e+05   |\n",
      "|    total_reward         | 1.81e+06   |\n",
      "|    total_reward_pct     | 181        |\n",
      "|    total_trades         | 62334      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 561        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04221501 |\n",
      "|    clip_fraction        | 0.378      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.0918     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.02       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0196    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 11.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.62e+06   |\n",
      "|    total_cost           | 2.31e+05   |\n",
      "|    total_reward         | 1.62e+06   |\n",
      "|    total_reward_pct     | 162        |\n",
      "|    total_trades         | 62758      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 577        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03730634 |\n",
      "|    clip_fraction        | 0.345      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.025      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.2       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.007     |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 20.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.19e+06   |\n",
      "|    total_cost           | 2.33e+05   |\n",
      "|    total_reward         | 1.19e+06   |\n",
      "|    total_reward_pct     | 119        |\n",
      "|    total_trades         | 62224      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 593        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03366947 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.023      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.5       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 20.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 2.24e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 61700       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 610         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027111806 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0806      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.02        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2259156.38\n",
      "total_reward: 1259156.38\n",
      "total_cost: 230345.64\n",
      "total_trades: 62225\n",
      "Sharpe: 0.724\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.26e+06    |\n",
      "|    total_cost           | 2.3e+05     |\n",
      "|    total_reward         | 1.26e+06    |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 62225       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 627         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033321958 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0867      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.1         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.72e+06    |\n",
      "|    total_cost           | 2.4e+05     |\n",
      "|    total_reward         | 1.72e+06    |\n",
      "|    total_reward_pct     | 172         |\n",
      "|    total_trades         | 63032       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 643         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030091807 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0717      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.63        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 659         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039650977 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | -0.00406    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.4         |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.57e+06    |\n",
      "|    total_cost           | 2.44e+05    |\n",
      "|    total_reward         | 1.57e+06    |\n",
      "|    total_reward_pct     | 157         |\n",
      "|    total_trades         | 62853       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 675         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027804604 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | -0.0644     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.33        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.73e+06   |\n",
      "|    total_cost           | 2.45e+05   |\n",
      "|    total_reward         | 1.73e+06   |\n",
      "|    total_reward_pct     | 173        |\n",
      "|    total_trades         | 63000      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 130        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 692        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03341466 |\n",
      "|    clip_fraction        | 0.366      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.022      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.41       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 14.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.09e+06    |\n",
      "|    total_cost           | 2.37e+05    |\n",
      "|    total_reward         | 1.09e+06    |\n",
      "|    total_reward_pct     | 109         |\n",
      "|    total_trades         | 62179       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 709         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031782232 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0437      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.93        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "day: 2265, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1862763.85\n",
      "total_reward: 862763.85\n",
      "total_cost: 242868.44\n",
      "total_trades: 63144\n",
      "Sharpe: 0.534\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.86e+06   |\n",
      "|    total_cost           | 2.43e+05   |\n",
      "|    total_reward         | 8.63e+05   |\n",
      "|    total_reward_pct     | 86.3       |\n",
      "|    total_trades         | 63144      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 725        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02405835 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.0385     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.72       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0183    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 10.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.85e+06    |\n",
      "|    total_cost           | 2.36e+05    |\n",
      "|    total_reward         | 8.45e+05    |\n",
      "|    total_reward_pct     | 84.5        |\n",
      "|    total_trades         | 62020       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035223424 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0136      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.82        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.33e+06   |\n",
      "|    total_cost           | 2.33e+05   |\n",
      "|    total_reward         | 1.33e+06   |\n",
      "|    total_reward_pct     | 133        |\n",
      "|    total_trades         | 62326      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 758        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03456884 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.0364     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.76       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0199    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 10.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.86e+06   |\n",
      "|    total_cost           | 2.33e+05   |\n",
      "|    total_reward         | 1.86e+06   |\n",
      "|    total_reward_pct     | 186        |\n",
      "|    total_trades         | 62367      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 775        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02539196 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.0416     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.72       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00343   |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 14.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-01-04 to  2019-04-05\n",
      "PPO Sharpe Ratio:  0.3810186008113343\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_693_4\n",
      "day: 2265, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3338746.72\n",
      "total_reward: 2338746.72\n",
      "total_cost: 9085.90\n",
      "total_trades: 33599\n",
      "Sharpe: 1.014\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.27e+06 |\n",
      "|    total_cost       | 1.39e+03 |\n",
      "|    total_reward     | 2.27e+06 |\n",
      "|    total_reward_pct | 227      |\n",
      "|    total_trades     | 29532    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total timesteps  | 9064     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 8.68     |\n",
      "|    critic_loss      | 66.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6798     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2019-01-04 to  2019-04-05\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-04-05\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_693_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00625  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -35      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.881    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -15.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -39.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.99     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 120       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 93.9      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 11        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.8e+06  |\n",
      "|    total_cost         | 6.97e+04 |\n",
      "|    total_reward       | 1.8e+06  |\n",
      "|    total_reward_pct   | 180      |\n",
      "|    total_trades       | 48755    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -9.02    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.419    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0258   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -58.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.5      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 121       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 79        |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.15      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -18.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -34.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.27     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.58e+06  |\n",
      "|    total_cost         | 2.38e+04  |\n",
      "|    total_reward       | 1.58e+06  |\n",
      "|    total_reward_pct   | 158       |\n",
      "|    total_trades       | 41480     |\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -5.57e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -92.1     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.85      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 40.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00524 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -10.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.542    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 164      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 19.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.51e+06  |\n",
      "|    total_cost         | 2.39e+04  |\n",
      "|    total_reward       | 1.51e+06  |\n",
      "|    total_reward_pct   | 151       |\n",
      "|    total_trades       | 42388     |\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -1.64     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.00369   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0229  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 5.08     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.461    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -45.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -13.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 22.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.34e+06 |\n",
      "|    total_cost         | 3.85e+04 |\n",
      "|    total_reward       | 1.34e+06 |\n",
      "|    total_reward_pct   | 134      |\n",
      "|    total_trades       | 44582    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.396    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 20.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.234    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.0643   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.992    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -104     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0642  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 8.41     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.436    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 120      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.4      |\n",
      "------------------------------------\n",
      "day: 2328, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2345536.37\n",
      "total_reward: 1345536.37\n",
      "total_cost: 32213.21\n",
      "total_trades: 44461\n",
      "Sharpe: 0.676\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.35e+06 |\n",
      "|    total_cost         | 3.22e+04 |\n",
      "|    total_reward       | 1.35e+06 |\n",
      "|    total_reward_pct   | 135      |\n",
      "|    total_trades       | 44461    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -76.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 102      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 14.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.77     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 4.41     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.499    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.87e+06 |\n",
      "|    total_cost         | 3.36e+04 |\n",
      "|    total_reward       | 8.75e+05 |\n",
      "|    total_reward_pct   | 87.5     |\n",
      "|    total_trades       | 44022    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 6.2      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0878   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.648   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -58.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0115  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -224     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 25.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -199     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 25.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 44.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.52e+06 |\n",
      "|    total_cost         | 3.5e+04  |\n",
      "|    total_reward       | 5.25e+05 |\n",
      "|    total_reward_pct   | 52.5     |\n",
      "|    total_trades       | 42655    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 29.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.864    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 14.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.376    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -57.6     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.45      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.00224  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 2.47     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0465  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 54.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.06e+06 |\n",
      "|    total_cost         | 4.36e+04 |\n",
      "|    total_reward       | 1.06e+06 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 44496    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.352    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -56.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0128   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 58.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -71.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.74     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.209   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -59.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.75e+06 |\n",
      "|    total_cost         | 1.51e+04 |\n",
      "|    total_reward       | 7.53e+05 |\n",
      "|    total_reward_pct   | 75.3     |\n",
      "|    total_trades       | 41085    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -13.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.135    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 175       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -39.4     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.14      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 116      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 70.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 121      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.08     |\n",
      "------------------------------------\n",
      "day: 2328, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2379912.85\n",
      "total_reward: 1379912.85\n",
      "total_cost: 17287.86\n",
      "total_trades: 42661\n",
      "Sharpe: 0.677\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.38e+06  |\n",
      "|    total_cost         | 1.73e+04  |\n",
      "|    total_reward       | 1.38e+06  |\n",
      "|    total_reward_pct   | 138       |\n",
      "|    total_trades       | 42661     |\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 191       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 21.2      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.492     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.23     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 53.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -155     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 15       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 4.17e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -126     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -26      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.41e+06 |\n",
      "|    total_cost         | 3.05e+04 |\n",
      "|    total_reward       | 1.41e+06 |\n",
      "|    total_reward_pct   | 141      |\n",
      "|    total_trades       | 43822    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.111    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 158      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 16.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.149   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 144      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 219       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 22.6      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.934     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.779   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 37.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.56e+06  |\n",
      "|    total_cost         | 5.5e+04   |\n",
      "|    total_reward       | 1.56e+06  |\n",
      "|    total_reward_pct   | 156       |\n",
      "|    total_trades       | 43406     |\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 13.5      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.103     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.218   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -117     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 109      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -21.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.895    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -8.63    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.66     |\n",
      "------------------------------------\n",
      "======Trading from:  2019-04-05 to  2019-07-08\n",
      "============================================\n",
      "17.68894224154312\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2019-04-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_756_4\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.2      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -31      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.692    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0106  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 96.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -57.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.56     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 124       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 17.3      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.44      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.98e+06 |\n",
      "|    total_cost         | 1.01e+05 |\n",
      "|    total_reward       | 9.8e+05  |\n",
      "|    total_reward_pct   | 98       |\n",
      "|    total_trades       | 52446    |\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.992   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 3.29     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.542    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -49.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.58     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 124       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 30.7      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.949     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 13.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.677    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.419    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -61.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.79e+06 |\n",
      "|    total_cost         | 4.75e+04 |\n",
      "|    total_reward       | 7.94e+05 |\n",
      "|    total_reward_pct   | 79.4     |\n",
      "|    total_trades       | 47742    |\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -129     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 1.33     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.222    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0956  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 58.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.14     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -13       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.516     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.34e+06 |\n",
      "|    total_cost         | 2.66e+04 |\n",
      "|    total_reward       | 1.34e+06 |\n",
      "|    total_reward_pct   | 134      |\n",
      "|    total_trades       | 46695    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.653    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.00116  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -1.93    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.354    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -56.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 6.13     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.369    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -77.1     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.74      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.46e+06  |\n",
      "|    total_cost         | 2.51e+04  |\n",
      "|    total_reward       | 1.46e+06  |\n",
      "|    total_reward_pct   | 146       |\n",
      "|    total_trades       | 46798     |\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -8.89e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 54.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.00282  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 17.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.837    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -43.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 3.87     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.279    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 22.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.42      |\n",
      "-------------------------------------\n",
      "day: 2328, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2747139.40\n",
      "total_reward: 1747139.40\n",
      "total_cost: 69314.06\n",
      "total_trades: 50442\n",
      "Sharpe: 0.800\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.75e+06 |\n",
      "|    total_cost         | 6.93e+04 |\n",
      "|    total_reward       | 1.75e+06 |\n",
      "|    total_reward_pct   | 175      |\n",
      "|    total_trades       | 50442    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 7.63e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -38.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 113      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 36       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0754  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.553   |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.432    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.51e+06 |\n",
      "|    total_cost         | 6.03e+04 |\n",
      "|    total_reward       | 1.51e+06 |\n",
      "|    total_reward_pct   | 151      |\n",
      "|    total_trades       | 49706    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 5.24     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0851   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -42.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0674   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -131     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -79.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 140      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.54e+06 |\n",
      "|    total_cost         | 4.46e+04 |\n",
      "|    total_reward       | 1.54e+06 |\n",
      "|    total_reward_pct   | 154      |\n",
      "|    total_trades       | 49790    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 22       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.583    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 33.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0247  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -58.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 78.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.93     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 66.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.89     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.62e+06  |\n",
      "|    total_cost         | 5.65e+04  |\n",
      "|    total_reward       | 1.62e+06  |\n",
      "|    total_reward_pct   | 162       |\n",
      "|    total_trades       | 50050     |\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -42.1     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.37      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 12.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0567   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -92.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.12     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 16.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.457    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.64e+06 |\n",
      "|    total_cost         | 4.55e+04 |\n",
      "|    total_reward       | 1.64e+06 |\n",
      "|    total_reward_pct   | 164      |\n",
      "|    total_trades       | 51032    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -8.79    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0731   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -37.1     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.993     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.023    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 97.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -71.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0339   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -73.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "day: 2328, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2620217.72\n",
      "total_reward: 1620217.72\n",
      "total_cost: 25016.69\n",
      "total_trades: 43875\n",
      "Sharpe: 0.753\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.62e+06 |\n",
      "|    total_cost         | 2.5e+04  |\n",
      "|    total_reward       | 1.62e+06 |\n",
      "|    total_reward_pct   | 162      |\n",
      "|    total_trades       | 43875    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.0774  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 27.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.822    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 46.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.00069 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -256     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 46.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 198       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -55.5     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 3.91      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -81.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.06e+06 |\n",
      "|    total_cost         | 2.49e+04 |\n",
      "|    total_reward       | 2.06e+06 |\n",
      "|    total_reward_pct   | 206      |\n",
      "|    total_trades       | 41672    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.033    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.0735  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 81       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 50       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.65     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 218       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 39.3      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.921     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.8e+06  |\n",
      "|    total_cost         | 2.45e+04 |\n",
      "|    total_reward       | 1.8e+06  |\n",
      "|    total_reward_pct   | 180      |\n",
      "|    total_trades       | 42439    |\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 18.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.231    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -102     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 73.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 24       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -135     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-04-05 to  2019-07-08\n",
      "A2C Sharpe Ratio:  0.1360883871605928\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_756_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 132  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 15   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.24e+06    |\n",
      "|    total_cost           | 2.68e+05    |\n",
      "|    total_reward         | 1.24e+06    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 67077       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007547885 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0332     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.72        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 8.45        |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2780205.28\n",
      "total_reward: 1780205.28\n",
      "total_cost: 263601.29\n",
      "total_trades: 66763\n",
      "Sharpe: 0.834\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+06    |\n",
      "|    total_cost           | 2.64e+05    |\n",
      "|    total_reward         | 1.78e+06    |\n",
      "|    total_reward_pct     | 178         |\n",
      "|    total_trades         | 66763       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019767575 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.000256    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.41        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.46e+06    |\n",
      "|    total_cost           | 2.54e+05    |\n",
      "|    total_reward         | 1.46e+06    |\n",
      "|    total_reward_pct     | 146         |\n",
      "|    total_trades         | 66230       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013730761 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.025       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+06     |\n",
      "|    total_cost           | 2.55e+05    |\n",
      "|    total_reward         | 1.5e+06     |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 66275       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011663636 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0632     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.31        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.05e+06    |\n",
      "|    total_cost           | 2.42e+05    |\n",
      "|    total_reward         | 1.05e+06    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 65684       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021906458 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00618     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.07        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.56e+06    |\n",
      "|    total_cost           | 2.52e+05    |\n",
      "|    total_reward         | 2.56e+06    |\n",
      "|    total_reward_pct     | 256         |\n",
      "|    total_trades         | 66305       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021572718 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0102     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.98        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2620362.13\n",
      "total_reward: 1620362.13\n",
      "total_cost: 252762.93\n",
      "total_trades: 66011\n",
      "Sharpe: 0.787\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.62e+06    |\n",
      "|    total_cost           | 2.53e+05    |\n",
      "|    total_reward         | 1.62e+06    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 66011       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023813257 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0359     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.07        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030053658 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0191     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.18        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+06    |\n",
      "|    total_cost           | 2.4e+05     |\n",
      "|    total_reward         | 1.58e+06    |\n",
      "|    total_reward_pct     | 158         |\n",
      "|    total_trades         | 65282       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013725344 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0166     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.91        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.16e+06    |\n",
      "|    total_cost           | 2.43e+05    |\n",
      "|    total_reward         | 2.16e+06    |\n",
      "|    total_reward_pct     | 216         |\n",
      "|    total_trades         | 64810       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011799071 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0345      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.09        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+06    |\n",
      "|    total_cost           | 2.47e+05    |\n",
      "|    total_reward         | 1.19e+06    |\n",
      "|    total_reward_pct     | 119         |\n",
      "|    total_trades         | 65068       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014875796 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0299      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.59e+06    |\n",
      "|    total_cost           | 2.48e+05    |\n",
      "|    total_reward         | 1.59e+06    |\n",
      "|    total_reward_pct     | 159         |\n",
      "|    total_trades         | 64999       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022480669 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0147      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.12        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2421962.17\n",
      "total_reward: 1421962.17\n",
      "total_cost: 245788.29\n",
      "total_trades: 65214\n",
      "Sharpe: 0.703\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.42e+06    |\n",
      "|    total_cost           | 2.46e+05    |\n",
      "|    total_reward         | 1.42e+06    |\n",
      "|    total_reward_pct     | 142         |\n",
      "|    total_trades         | 65214       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023594974 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0719      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.14        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.62e+06    |\n",
      "|    total_cost           | 2.36e+05    |\n",
      "|    total_reward         | 1.62e+06    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 64164       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021998234 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0322      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.15        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.18e+06    |\n",
      "|    total_cost           | 2.26e+05    |\n",
      "|    total_reward         | 2.18e+06    |\n",
      "|    total_reward_pct     | 218         |\n",
      "|    total_trades         | 63129       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021768333 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.07        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.11        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014876943 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0327      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.92e+06   |\n",
      "|    total_cost           | 2.34e+05   |\n",
      "|    total_reward         | 1.92e+06   |\n",
      "|    total_reward_pct     | 192        |\n",
      "|    total_trades         | 63597      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 285        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01687129 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0179     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.55       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 19.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+06     |\n",
      "|    total_cost           | 2.43e+05    |\n",
      "|    total_reward         | 1.8e+06     |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 64907       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030837545 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0943      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.77        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2328, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1922366.90\n",
      "total_reward: 922366.90\n",
      "total_cost: 235400.90\n",
      "total_trades: 64550\n",
      "Sharpe: 0.551\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.92e+06    |\n",
      "|    total_cost           | 2.35e+05    |\n",
      "|    total_reward         | 9.22e+05    |\n",
      "|    total_reward_pct     | 92.2        |\n",
      "|    total_trades         | 64550       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027991908 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0767      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.94        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 2.43e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 64867       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034185544 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0839      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.92        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.27        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.96e+06   |\n",
      "|    total_cost           | 2.37e+05   |\n",
      "|    total_reward         | 1.96e+06   |\n",
      "|    total_reward_pct     | 196        |\n",
      "|    total_trades         | 64418      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 348        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01911362 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0571     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.62       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 16.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.51e+06    |\n",
      "|    total_cost           | 2.34e+05    |\n",
      "|    total_reward         | 1.51e+06    |\n",
      "|    total_reward_pct     | 151         |\n",
      "|    total_trades         | 63877       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022281572 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0354      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.28e+06    |\n",
      "|    total_cost           | 2.41e+05    |\n",
      "|    total_reward         | 1.28e+06    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 64681       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016159723 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.35        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031542644 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0399      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.98        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2848010.52\n",
      "total_reward: 1848010.52\n",
      "total_cost: 215569.24\n",
      "total_trades: 62414\n",
      "Sharpe: 0.762\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.85e+06    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 1.85e+06    |\n",
      "|    total_reward_pct     | 185         |\n",
      "|    total_trades         | 62414       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025347281 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.45e+06   |\n",
      "|    total_cost           | 2.22e+05   |\n",
      "|    total_reward         | 2.45e+06   |\n",
      "|    total_reward_pct     | 245        |\n",
      "|    total_trades         | 63116      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 426        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02638685 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0903     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.27       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 16.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.8e+06    |\n",
      "|    total_cost           | 2.21e+05   |\n",
      "|    total_reward         | 1.8e+06    |\n",
      "|    total_reward_pct     | 180        |\n",
      "|    total_trades         | 63338      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 442        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04904778 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0413     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18         |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 21.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.69e+06    |\n",
      "|    total_cost           | 2.11e+05    |\n",
      "|    total_reward         | 2.69e+06    |\n",
      "|    total_reward_pct     | 269         |\n",
      "|    total_trades         | 62346       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 458         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027532922 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0852      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.49        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.3e+06    |\n",
      "|    total_cost           | 2.27e+05   |\n",
      "|    total_reward         | 2.3e+06    |\n",
      "|    total_reward_pct     | 230        |\n",
      "|    total_trades         | 63511      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 474        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02552876 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.0703     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.3       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 27.6       |\n",
      "----------------------------------------\n",
      "day: 2328, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2536655.10\n",
      "total_reward: 1536655.10\n",
      "total_cost: 222475.75\n",
      "total_trades: 63169\n",
      "Sharpe: 0.731\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.54e+06    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 1.54e+06    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 63169       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 490         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023689792 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0584      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.97        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.67e+06    |\n",
      "|    total_cost           | 2.37e+05    |\n",
      "|    total_reward         | 6.72e+05    |\n",
      "|    total_reward_pct     | 67.2        |\n",
      "|    total_trades         | 64325       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 505         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018651832 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.71        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.68e+06    |\n",
      "|    total_cost           | 2.4e+05     |\n",
      "|    total_reward         | 1.68e+06    |\n",
      "|    total_reward_pct     | 168         |\n",
      "|    total_trades         | 64186       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024921643 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0757      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.55        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 8.45        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 537         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037081398 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | -0.0127     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.59        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.07e+06    |\n",
      "|    total_cost           | 2.43e+05    |\n",
      "|    total_reward         | 2.07e+06    |\n",
      "|    total_reward_pct     | 207         |\n",
      "|    total_trades         | 64080       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 553         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032724954 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0556      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.03        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.32e+06    |\n",
      "|    total_cost           | 2.45e+05    |\n",
      "|    total_reward         | 1.32e+06    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 64434       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023875322 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.064       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.85        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2270725.88\n",
      "total_reward: 1270725.88\n",
      "total_cost: 234610.47\n",
      "total_trades: 63649\n",
      "Sharpe: 0.682\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.27e+06   |\n",
      "|    total_cost           | 2.35e+05   |\n",
      "|    total_reward         | 1.27e+06   |\n",
      "|    total_reward_pct     | 127        |\n",
      "|    total_trades         | 63649      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 584        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03230604 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.0665     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.92       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 11.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.6e+06     |\n",
      "|    total_cost           | 2.08e+05    |\n",
      "|    total_reward         | 6.01e+05    |\n",
      "|    total_reward_pct     | 60.1        |\n",
      "|    total_trades         | 61916       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 600         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030928358 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | -0.0316     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.34        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.32e+06    |\n",
      "|    total_cost           | 2.33e+05    |\n",
      "|    total_reward         | 1.32e+06    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 63887       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039674133 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.08        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 8.71        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.36e+06    |\n",
      "|    total_cost           | 2.45e+05    |\n",
      "|    total_reward         | 1.36e+06    |\n",
      "|    total_reward_pct     | 136         |\n",
      "|    total_trades         | 64268       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 632         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039873406 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0631      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.87        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.14e+06    |\n",
      "|    total_cost           | 2.28e+05    |\n",
      "|    total_reward         | 2.14e+06    |\n",
      "|    total_reward_pct     | 214         |\n",
      "|    total_trades         | 63219       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 647         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045195773 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.011       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.12        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 9.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 663         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025991615 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.07        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.27        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2494176.06\n",
      "total_reward: 1494176.06\n",
      "total_cost: 239213.09\n",
      "total_trades: 63804\n",
      "Sharpe: 0.765\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.49e+06    |\n",
      "|    total_cost           | 2.39e+05    |\n",
      "|    total_reward         | 1.49e+06    |\n",
      "|    total_reward_pct     | 149         |\n",
      "|    total_trades         | 63804       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 679         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039031826 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | -0.122      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.15        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 8.12        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.52e+06   |\n",
      "|    total_cost           | 2.35e+05   |\n",
      "|    total_reward         | 1.52e+06   |\n",
      "|    total_reward_pct     | 152        |\n",
      "|    total_trades         | 63557      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 695        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04864902 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.0157     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.33       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0208    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 8.56       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+06    |\n",
      "|    total_cost           | 2.28e+05    |\n",
      "|    total_reward         | 1.45e+06    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 63138       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 711         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017421069 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0622      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.16        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.67e+06   |\n",
      "|    total_cost           | 2.33e+05   |\n",
      "|    total_reward         | 6.67e+05   |\n",
      "|    total_reward_pct     | 66.7       |\n",
      "|    total_trades         | 62982      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 129        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 727        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03619305 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.114      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.18       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0206    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 9.09       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.13e+06    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 1.13e+06    |\n",
      "|    total_reward_pct     | 113         |\n",
      "|    total_trades         | 63151       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 742         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032633156 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.25        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 7.65        |\n",
      "-----------------------------------------\n",
      "day: 2328, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3200940.20\n",
      "total_reward: 2200940.20\n",
      "total_cost: 227465.23\n",
      "total_trades: 63149\n",
      "Sharpe: 0.876\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.2e+06     |\n",
      "|    total_cost           | 2.27e+05    |\n",
      "|    total_reward         | 2.2e+06     |\n",
      "|    total_reward_pct     | 220         |\n",
      "|    total_trades         | 63149       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 758         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036515128 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.0845      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.77        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 9.07        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.12e+06    |\n",
      "|    total_cost           | 2.41e+05    |\n",
      "|    total_reward         | 2.12e+06    |\n",
      "|    total_reward_pct     | 212         |\n",
      "|    total_trades         | 64104       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 774         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034947515 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.049       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-04-05 to  2019-07-08\n",
      "PPO Sharpe Ratio:  0.1524105869069622\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_756_4\n",
      "day: 2328, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2734853.30\n",
      "total_reward: 1734853.30\n",
      "total_cost: 2068.77\n",
      "total_trades: 35888\n",
      "Sharpe: 0.808\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.27e+06 |\n",
      "|    total_cost       | 1.79e+03 |\n",
      "|    total_reward     | 2.27e+06 |\n",
      "|    total_reward_pct | 227      |\n",
      "|    total_trades     | 48346    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total timesteps  | 9316     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -16.3    |\n",
      "|    critic_loss      | 51.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6987     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2019-04-05 to  2019-07-08\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-07-08\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_756_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 131  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 15   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.92e+06    |\n",
      "|    total_cost           | 2.83e+05    |\n",
      "|    total_reward         | 1.92e+06    |\n",
      "|    total_reward_pct     | 192         |\n",
      "|    total_trades         | 69164       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018020345 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0271     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.03        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 10          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.87e+06    |\n",
      "|    total_cost           | 2.77e+05    |\n",
      "|    total_reward         | 1.87e+06    |\n",
      "|    total_reward_pct     | 187         |\n",
      "|    total_trades         | 68599       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015114237 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00521     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.78        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.36e+06   |\n",
      "|    total_cost           | 2.72e+05   |\n",
      "|    total_reward         | 1.36e+06   |\n",
      "|    total_reward_pct     | 136        |\n",
      "|    total_trades         | 68188      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 63         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01814004 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.0272    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.01       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0247    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 10.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.64e+06     |\n",
      "|    total_cost           | 2.72e+05     |\n",
      "|    total_reward         | 1.64e+06     |\n",
      "|    total_reward_pct     | 164          |\n",
      "|    total_trades         | 68177        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 128          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116018485 |\n",
      "|    clip_fraction        | 0.187        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.7        |\n",
      "|    explained_variance   | -0.0113      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.57         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0254      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 9.68         |\n",
      "------------------------------------------\n",
      "day: 2391, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2429534.65\n",
      "total_reward: 1429534.65\n",
      "total_cost: 266491.87\n",
      "total_trades: 67838\n",
      "Sharpe: 0.748\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.43e+06    |\n",
      "|    total_cost           | 2.66e+05    |\n",
      "|    total_reward         | 1.43e+06    |\n",
      "|    total_reward_pct     | 143         |\n",
      "|    total_trades         | 67838       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031029524 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0206     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.04        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017801285 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0514     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.52        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.55e+06   |\n",
      "|    total_cost           | 2.64e+05   |\n",
      "|    total_reward         | 1.55e+06   |\n",
      "|    total_reward_pct     | 155        |\n",
      "|    total_trades         | 67941      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 127        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02164152 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | -0.0187    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.54       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0261    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 10.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.26e+06    |\n",
      "|    total_cost           | 2.67e+05    |\n",
      "|    total_reward         | 1.26e+06    |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 67613       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030760791 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0318      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.51        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.25        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.23e+06    |\n",
      "|    total_cost           | 2.55e+05    |\n",
      "|    total_reward         | 1.23e+06    |\n",
      "|    total_reward_pct     | 123         |\n",
      "|    total_trades         | 66504       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032050166 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0196     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.53        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.6e+06     |\n",
      "|    total_cost           | 2.62e+05    |\n",
      "|    total_reward         | 1.6e+06     |\n",
      "|    total_reward_pct     | 160         |\n",
      "|    total_trades         | 67211       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024853975 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0319      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.51        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.68        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2079016.53\n",
      "total_reward: 1079016.53\n",
      "total_cost: 247978.20\n",
      "total_trades: 66475\n",
      "Sharpe: 0.615\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.08e+06    |\n",
      "|    total_cost           | 2.48e+05    |\n",
      "|    total_reward         | 1.08e+06    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 66475       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026261538 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.64        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.15e+06    |\n",
      "|    total_cost           | 2.45e+05    |\n",
      "|    total_reward         | 1.15e+06    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 66126       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025213392 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0152     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.48        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028210433 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0488      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.82        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+06    |\n",
      "|    total_cost           | 2.4e+05     |\n",
      "|    total_reward         | 1.04e+06    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 65490       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014700497 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0322      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.54        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.75        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.05e+06    |\n",
      "|    total_cost           | 2.47e+05    |\n",
      "|    total_reward         | 1.05e+06    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 66621       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016991189 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.00623     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.67        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 6.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.62e+06    |\n",
      "|    total_cost           | 2.63e+05    |\n",
      "|    total_reward         | 1.62e+06    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 67476       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027460076 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.00632     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.37        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.12        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2391, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2638305.32\n",
      "total_reward: 1638305.32\n",
      "total_cost: 255950.58\n",
      "total_trades: 67086\n",
      "Sharpe: 0.787\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.64e+06    |\n",
      "|    total_cost           | 2.56e+05    |\n",
      "|    total_reward         | 1.64e+06    |\n",
      "|    total_reward_pct     | 164         |\n",
      "|    total_trades         | 67086       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025123522 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.87        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.9e+06     |\n",
      "|    total_cost           | 2.65e+05    |\n",
      "|    total_reward         | 1.9e+06     |\n",
      "|    total_reward_pct     | 190         |\n",
      "|    total_trades         | 67835       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 303         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022017198 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.94        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.57e+06    |\n",
      "|    total_cost           | 2.6e+05     |\n",
      "|    total_reward         | 1.57e+06    |\n",
      "|    total_reward_pct     | 157         |\n",
      "|    total_trades         | 67535       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044368055 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0831      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.23        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 335        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02573896 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.111      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.85       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0212    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 8.55       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+06    |\n",
      "|    total_cost           | 2.6e+05     |\n",
      "|    total_reward         | 1.19e+06    |\n",
      "|    total_reward_pct     | 119         |\n",
      "|    total_trades         | 67363       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034345254 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0981      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.04        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 7.64        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.84e+06    |\n",
      "|    total_cost           | 2.63e+05    |\n",
      "|    total_reward         | 1.84e+06    |\n",
      "|    total_reward_pct     | 184         |\n",
      "|    total_trades         | 67608       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 367         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027438141 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.58        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.45        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2543445.81\n",
      "total_reward: 1543445.81\n",
      "total_cost: 251077.74\n",
      "total_trades: 66150\n",
      "Sharpe: 0.734\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.54e+06    |\n",
      "|    total_cost           | 2.51e+05    |\n",
      "|    total_reward         | 1.54e+06    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 66150       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030501157 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.69        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.21e+06    |\n",
      "|    total_cost           | 2.57e+05    |\n",
      "|    total_reward         | 2.21e+06    |\n",
      "|    total_reward_pct     | 221         |\n",
      "|    total_trades         | 66391       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 399         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029324625 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.36        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 8.55        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+06    |\n",
      "|    total_cost           | 2.51e+05    |\n",
      "|    total_reward         | 1.33e+06    |\n",
      "|    total_reward_pct     | 133         |\n",
      "|    total_trades         | 66097       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036213554 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.88        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.59e+06    |\n",
      "|    total_cost           | 2.57e+05    |\n",
      "|    total_reward         | 1.59e+06    |\n",
      "|    total_reward_pct     | 159         |\n",
      "|    total_trades         | 66355       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 431         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027373595 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.06        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 9.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 449         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032093152 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.83        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 9.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.01e+06    |\n",
      "|    total_cost           | 2.54e+05    |\n",
      "|    total_reward         | 2.01e+06    |\n",
      "|    total_reward_pct     | 201         |\n",
      "|    total_trades         | 66500       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 466         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027607571 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0442      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.93        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2526223.15\n",
      "total_reward: 1526223.15\n",
      "total_cost: 259727.84\n",
      "total_trades: 66974\n",
      "Sharpe: 0.795\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.53e+06    |\n",
      "|    total_cost           | 2.6e+05     |\n",
      "|    total_reward         | 1.53e+06    |\n",
      "|    total_reward_pct     | 153         |\n",
      "|    total_trades         | 66974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 483         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029877625 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.71        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 6.43        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.86e+06  |\n",
      "|    total_cost           | 2.46e+05  |\n",
      "|    total_reward         | 1.86e+06  |\n",
      "|    total_reward_pct     | 186       |\n",
      "|    total_trades         | 65556     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 127       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 499       |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0323026 |\n",
      "|    clip_fraction        | 0.307     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44       |\n",
      "|    explained_variance   | 0.161     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 4.31      |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -0.0191   |\n",
      "|    std                  | 1.05      |\n",
      "|    value_loss           | 9.39      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.35e+06   |\n",
      "|    total_cost           | 2.38e+05   |\n",
      "|    total_reward         | 3.35e+06   |\n",
      "|    total_reward_pct     | 335        |\n",
      "|    total_trades         | 64747      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 126        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 516        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04989203 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.17       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.3        |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 10         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.24e+06    |\n",
      "|    total_cost           | 2.52e+05    |\n",
      "|    total_reward         | 1.24e+06    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 66065       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 534         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034728743 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | -0.109      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 64.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.5e+06    |\n",
      "|    total_cost           | 2.42e+05   |\n",
      "|    total_reward         | 1.5e+06    |\n",
      "|    total_reward_pct     | 150        |\n",
      "|    total_trades         | 65313      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 126        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 551        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03212414 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.154      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.14       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 7.95       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 567         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048846263 |\n",
      "|    clip_fraction        | 0.417       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.35        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 9.26        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3702889.75\n",
      "total_reward: 2702889.75\n",
      "total_cost: 249640.92\n",
      "total_trades: 66147\n",
      "Sharpe: 0.946\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.7e+06     |\n",
      "|    total_cost           | 2.5e+05     |\n",
      "|    total_reward         | 2.7e+06     |\n",
      "|    total_reward_pct     | 270         |\n",
      "|    total_trades         | 66147       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 584         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034678444 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0493      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.4e+06     |\n",
      "|    total_cost           | 2.41e+05    |\n",
      "|    total_reward         | 2.4e+06     |\n",
      "|    total_reward_pct     | 240         |\n",
      "|    total_trades         | 65722       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 602         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039035708 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.24        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.19e+06    |\n",
      "|    total_cost           | 2.02e+05    |\n",
      "|    total_reward         | 3.19e+06    |\n",
      "|    total_reward_pct     | 319         |\n",
      "|    total_trades         | 63177       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 619         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030498236 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0748      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.89e+06    |\n",
      "|    total_cost           | 2.23e+05    |\n",
      "|    total_reward         | 2.89e+06    |\n",
      "|    total_reward_pct     | 289         |\n",
      "|    total_trades         | 64871       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 635         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032618947 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0989      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.3        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 88          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.54e+06    |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | 3.54e+06    |\n",
      "|    total_reward_pct     | 354         |\n",
      "|    total_trades         | 62492       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 652         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017060703 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4431399.51\n",
      "total_reward: 3431399.51\n",
      "total_cost: 242177.83\n",
      "total_trades: 65827\n",
      "Sharpe: 1.033\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.43e+06   |\n",
      "|    total_cost           | 2.42e+05   |\n",
      "|    total_reward         | 3.43e+06   |\n",
      "|    total_reward_pct     | 343        |\n",
      "|    total_trades         | 65827      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 669        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01951408 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.0999     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48.8       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0098    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 107        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 687         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020604804 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.97e+06    |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | 3.97e+06    |\n",
      "|    total_reward_pct     | 397         |\n",
      "|    total_trades         | 62503       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 703         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018987462 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0706      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.93e+06    |\n",
      "|    total_cost           | 1.93e+05    |\n",
      "|    total_reward         | 3.93e+06    |\n",
      "|    total_reward_pct     | 393         |\n",
      "|    total_trades         | 62203       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 719         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019021764 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.37e+06    |\n",
      "|    total_cost           | 1.88e+05    |\n",
      "|    total_reward         | 4.37e+06    |\n",
      "|    total_reward_pct     | 437         |\n",
      "|    total_trades         | 61605       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 735         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015146788 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.3        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.38e+06    |\n",
      "|    total_cost           | 1.96e+05    |\n",
      "|    total_reward         | 4.38e+06    |\n",
      "|    total_reward_pct     | 438         |\n",
      "|    total_trades         | 63081       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 751         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030617736 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.5        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4783618.58\n",
      "total_reward: 3783618.58\n",
      "total_cost: 170114.38\n",
      "total_trades: 60852\n",
      "Sharpe: 0.968\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.78e+06   |\n",
      "|    total_cost           | 1.7e+05    |\n",
      "|    total_reward         | 3.78e+06   |\n",
      "|    total_reward_pct     | 378        |\n",
      "|    total_trades         | 60852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 767        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03387057 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.0921     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.3       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.00714   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 76.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.06e+06    |\n",
      "|    total_cost           | 2.11e+05    |\n",
      "|    total_reward         | 4.06e+06    |\n",
      "|    total_reward_pct     | 406         |\n",
      "|    total_trades         | 64150       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 783         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025867203 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.00301     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 87.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 799        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04864253 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.169      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.5       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | 0.00241    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 73.5       |\n",
      "----------------------------------------\n",
      "======Trading from:  2019-07-08 to  2019-10-04\n",
      "============================================\n",
      "16.502334183745877\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2019-07-08\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_819_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.532    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -19      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.262    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.00401 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 41.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.249    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -53.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0241   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -16.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.12e+06 |\n",
      "|    total_cost         | 2.16e+05 |\n",
      "|    total_reward       | 3.12e+06 |\n",
      "|    total_reward_pct   | 312      |\n",
      "|    total_trades       | 63403    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0805  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 49.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.95     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -9.54e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 89.6      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.89      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.278   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 42.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 4.33     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 240      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 44.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.3e+06  |\n",
      "|    total_cost         | 1.26e+05 |\n",
      "|    total_reward       | 2.3e+06  |\n",
      "|    total_reward_pct   | 230      |\n",
      "|    total_trades       | 56271    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.31     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 29.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.473    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -58.6     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.49      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 160      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 18.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 107      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0115  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -471     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 226      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.03e+06 |\n",
      "|    total_cost         | 1.22e+05 |\n",
      "|    total_reward       | 3.03e+06 |\n",
      "|    total_reward_pct   | 303      |\n",
      "|    total_trades       | 53470    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -32.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.573    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 55.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -9.82    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0117  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -144     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -7.8e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -654     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 258      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.44e+06 |\n",
      "|    total_cost         | 1e+05    |\n",
      "|    total_reward       | 3.44e+06 |\n",
      "|    total_reward_pct   | 344      |\n",
      "|    total_trades       | 51049    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.165   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 1.74     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 89.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -91.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 14.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -2.79    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -50.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.35     |\n",
      "------------------------------------\n",
      "day: 2391, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4071097.65\n",
      "total_reward: 3071097.65\n",
      "total_cost: 115953.50\n",
      "total_trades: 52767\n",
      "Sharpe: 1.011\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.07e+06 |\n",
      "|    total_cost         | 1.16e+05 |\n",
      "|    total_reward       | 3.07e+06 |\n",
      "|    total_reward_pct   | 307      |\n",
      "|    total_trades       | 52767    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -3.44    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 58.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0954   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 19.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.276    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0649   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 126      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -368     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 103      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -249     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 30.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.95e+06 |\n",
      "|    total_cost         | 5.51e+04 |\n",
      "|    total_reward       | 1.95e+06 |\n",
      "|    total_reward_pct   | 195      |\n",
      "|    total_trades       | 47368    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.389    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -25.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.517    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -55.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -22.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.726    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.29     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 92.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 122      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.96     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.32e+06  |\n",
      "|    total_cost         | 6.03e+04  |\n",
      "|    total_reward       | 1.32e+06  |\n",
      "|    total_reward_pct   | 132       |\n",
      "|    total_trades       | 50796     |\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -25.6     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.516     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0235  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -47      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 172      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 28.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -5.15    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -97.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.28e+06  |\n",
      "|    total_cost         | 2.12e+04  |\n",
      "|    total_reward       | 1.28e+06  |\n",
      "|    total_reward_pct   | 128       |\n",
      "|    total_trades       | 46590     |\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -76.9     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 5.03      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -48.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -116     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.89     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 12.9      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.1       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -225     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 29.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.1e+06  |\n",
      "|    total_cost         | 4.14e+04 |\n",
      "|    total_reward       | 2.1e+06  |\n",
      "|    total_reward_pct   | 210      |\n",
      "|    total_trades       | 47870    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.08e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 81.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 60.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 13       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0868   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 71.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.54     |\n",
      "------------------------------------\n",
      "day: 2391, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2784176.04\n",
      "total_reward: 1784176.04\n",
      "total_cost: 45247.97\n",
      "total_trades: 47914\n",
      "Sharpe: 0.825\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.78e+06 |\n",
      "|    total_cost         | 4.52e+04 |\n",
      "|    total_reward       | 1.78e+06 |\n",
      "|    total_reward_pct   | 178      |\n",
      "|    total_trades       | 47914    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.461   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 45.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -14.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.728    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -92.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.062    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -61.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.37     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 123       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 79.6      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 9.02      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.12e+06 |\n",
      "|    total_cost         | 3.17e+04 |\n",
      "|    total_reward       | 2.12e+06 |\n",
      "|    total_reward_pct   | 212      |\n",
      "|    total_trades       | 45628    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 35.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.867    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 40.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -6.57    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.498    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.107    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -259     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 36.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 60.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.51e+06 |\n",
      "|    total_cost         | 4.79e+04 |\n",
      "|    total_reward       | 2.51e+06 |\n",
      "|    total_reward_pct   | 251      |\n",
      "|    total_trades       | 47299    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.0445   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -16      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.345    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.152   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 36.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -9.82    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.134    |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-07-08 to  2019-10-04\n",
      "A2C Sharpe Ratio:  -0.006452899927698245\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_819_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 132  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 15   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.98e+06    |\n",
      "|    total_cost           | 2.82e+05    |\n",
      "|    total_reward         | 1.98e+06    |\n",
      "|    total_reward_pct     | 198         |\n",
      "|    total_trades         | 68969       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010834737 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00247    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.56        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.48        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2490644.67\n",
      "total_reward: 1490644.67\n",
      "total_cost: 276632.88\n",
      "total_trades: 68640\n",
      "Sharpe: 0.741\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.49e+06    |\n",
      "|    total_cost           | 2.77e+05    |\n",
      "|    total_reward         | 1.49e+06    |\n",
      "|    total_reward_pct     | 149         |\n",
      "|    total_trades         | 68640       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020963278 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0263      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.05        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+06    |\n",
      "|    total_cost           | 2.77e+05    |\n",
      "|    total_reward         | 1.65e+06    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 68517       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012736144 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0335     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.65        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.4e+06     |\n",
      "|    total_cost           | 2.65e+05    |\n",
      "|    total_reward         | 1.4e+06     |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 67660       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019528255 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0142     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.18        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.26e+06    |\n",
      "|    total_cost           | 2.7e+05     |\n",
      "|    total_reward         | 1.26e+06    |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 68108       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032815307 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.000688    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.12        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025608541 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.00373    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.16e+06    |\n",
      "|    total_cost           | 2.68e+05    |\n",
      "|    total_reward         | 1.16e+06    |\n",
      "|    total_reward_pct     | 116         |\n",
      "|    total_trades         | 68013       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018772092 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0147     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.44        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1959641.23\n",
      "total_reward: 959641.23\n",
      "total_cost: 251497.03\n",
      "total_trades: 66737\n",
      "Sharpe: 0.508\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.96e+06     |\n",
      "|    total_cost           | 2.51e+05     |\n",
      "|    total_reward         | 9.6e+05      |\n",
      "|    total_reward_pct     | 96           |\n",
      "|    total_trades         | 66737        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 128          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 143          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120722875 |\n",
      "|    clip_fraction        | 0.205        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.9        |\n",
      "|    explained_variance   | 0.0464       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.05         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0275      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 10.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+06    |\n",
      "|    total_cost           | 2.51e+05    |\n",
      "|    total_reward         | 8.82e+05    |\n",
      "|    total_reward_pct     | 88.2        |\n",
      "|    total_trades         | 66561       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018181935 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0278     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.34        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.75e+06    |\n",
      "|    total_cost           | 2.68e+05    |\n",
      "|    total_reward         | 1.75e+06    |\n",
      "|    total_reward_pct     | 175         |\n",
      "|    total_trades         | 67565       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017485727 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0661      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.22        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 2.64e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 67257       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024663284 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.9         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.26e+06    |\n",
      "|    total_cost           | 2.54e+05    |\n",
      "|    total_reward         | 1.26e+06    |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 66635       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015857268 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0179      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.69        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 223        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02162927 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.0152     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.54       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0248    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 15.7       |\n",
      "----------------------------------------\n",
      "day: 2391, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1909561.79\n",
      "total_reward: 909561.79\n",
      "total_cost: 248552.84\n",
      "total_trades: 66330\n",
      "Sharpe: 0.495\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.91e+06    |\n",
      "|    total_cost           | 2.49e+05    |\n",
      "|    total_reward         | 9.1e+05     |\n",
      "|    total_reward_pct     | 91          |\n",
      "|    total_trades         | 66330       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024146548 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0347      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.57        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+06    |\n",
      "|    total_cost           | 2.44e+05    |\n",
      "|    total_reward         | 8.83e+05    |\n",
      "|    total_reward_pct     | 88.3        |\n",
      "|    total_trades         | 65845       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017722024 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.57        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.38e+06    |\n",
      "|    total_cost           | 2.54e+05    |\n",
      "|    total_reward         | 1.38e+06    |\n",
      "|    total_reward_pct     | 138         |\n",
      "|    total_trades         | 66778       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018321797 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.000685   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.17        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.01e+06    |\n",
      "|    total_cost           | 2.47e+05    |\n",
      "|    total_reward         | 1.01e+06    |\n",
      "|    total_reward_pct     | 101         |\n",
      "|    total_trades         | 66089       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030625777 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0266      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.23        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.46e+06    |\n",
      "|    total_cost           | 2.5e+05     |\n",
      "|    total_reward         | 1.46e+06    |\n",
      "|    total_reward_pct     | 146         |\n",
      "|    total_trades         | 66107       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 303         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027875442 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.00258     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.17        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.42        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3346543.06\n",
      "total_reward: 2346543.06\n",
      "total_cost: 263512.77\n",
      "total_trades: 67030\n",
      "Sharpe: 0.933\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.35e+06    |\n",
      "|    total_cost           | 2.64e+05    |\n",
      "|    total_reward         | 2.35e+06    |\n",
      "|    total_reward_pct     | 235         |\n",
      "|    total_trades         | 67030       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019666536 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0506      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.63        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041102912 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0656      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.47e+06    |\n",
      "|    total_cost           | 2.46e+05    |\n",
      "|    total_reward         | 1.47e+06    |\n",
      "|    total_reward_pct     | 147         |\n",
      "|    total_trades         | 66159       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022549251 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | -0.00754    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.46        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.85e+06    |\n",
      "|    total_cost           | 2.5e+05     |\n",
      "|    total_reward         | 1.85e+06    |\n",
      "|    total_reward_pct     | 185         |\n",
      "|    total_trades         | 65980       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 367         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030467622 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | -0.0108     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.62        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.78e+06   |\n",
      "|    total_cost           | 2.56e+05   |\n",
      "|    total_reward         | 1.78e+06   |\n",
      "|    total_reward_pct     | 178        |\n",
      "|    total_trades         | 66906      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 383        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02680838 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0494     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.27       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0292    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 16.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.4e+06     |\n",
      "|    total_cost           | 2.57e+05    |\n",
      "|    total_reward         | 2.4e+06     |\n",
      "|    total_reward_pct     | 240         |\n",
      "|    total_trades         | 66615       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 399         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021141555 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.66        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2737205.94\n",
      "total_reward: 1737205.94\n",
      "total_cost: 254165.70\n",
      "total_trades: 66448\n",
      "Sharpe: 0.764\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.74e+06    |\n",
      "|    total_cost           | 2.54e+05    |\n",
      "|    total_reward         | 1.74e+06    |\n",
      "|    total_reward_pct     | 174         |\n",
      "|    total_trades         | 66448       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040900175 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0688      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 4.09e+06  |\n",
      "|    total_cost           | 2.36e+05  |\n",
      "|    total_reward         | 3.09e+06  |\n",
      "|    total_reward_pct     | 309       |\n",
      "|    total_trades         | 65368     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 128       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 431       |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0275896 |\n",
      "|    clip_fraction        | 0.305     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.7     |\n",
      "|    explained_variance   | 0.0427    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 6.51      |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -0.013    |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 19        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 447         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037780017 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0405      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.88        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.08e+06    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 3.08e+06    |\n",
      "|    total_reward_pct     | 308         |\n",
      "|    total_trades         | 65014       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 463         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023748184 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.041       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.04e+06    |\n",
      "|    total_cost           | 2.59e+05    |\n",
      "|    total_reward         | 2.04e+06    |\n",
      "|    total_reward_pct     | 204         |\n",
      "|    total_trades         | 67246       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028737687 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.00877     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.82        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.05e+06   |\n",
      "|    total_cost           | 2.57e+05   |\n",
      "|    total_reward         | 1.05e+06   |\n",
      "|    total_reward_pct     | 105        |\n",
      "|    total_trades         | 66722      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 495        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03726525 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.103      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.18       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0168    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 16.4       |\n",
      "----------------------------------------\n",
      "day: 2391, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3172943.62\n",
      "total_reward: 2172943.62\n",
      "total_cost: 241788.13\n",
      "total_trades: 65709\n",
      "Sharpe: 0.837\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.17e+06    |\n",
      "|    total_cost           | 2.42e+05    |\n",
      "|    total_reward         | 2.17e+06    |\n",
      "|    total_reward_pct     | 217         |\n",
      "|    total_trades         | 65709       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030274361 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0677      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.91        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.74e+06    |\n",
      "|    total_cost           | 2.46e+05    |\n",
      "|    total_reward         | 1.74e+06    |\n",
      "|    total_reward_pct     | 174         |\n",
      "|    total_trades         | 66354       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 527         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029927164 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0865      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.27        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.33e+06   |\n",
      "|    total_cost           | 2.48e+05   |\n",
      "|    total_reward         | 2.33e+06   |\n",
      "|    total_reward_pct     | 233        |\n",
      "|    total_trades         | 66015      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 543        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03478024 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.181      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.26       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 16.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 559         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016402094 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0127      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.03        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.95e+06   |\n",
      "|    total_cost           | 2.4e+05    |\n",
      "|    total_reward         | 1.95e+06   |\n",
      "|    total_reward_pct     | 195        |\n",
      "|    total_trades         | 65325      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 576        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02942296 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0593     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.48       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0232    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 13.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.53e+06   |\n",
      "|    total_cost           | 2.5e+05    |\n",
      "|    total_reward         | 2.53e+06   |\n",
      "|    total_reward_pct     | 253        |\n",
      "|    total_trades         | 66302      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 592        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03742061 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.0635     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.64       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0176    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 12.1       |\n",
      "----------------------------------------\n",
      "day: 2391, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3475387.48\n",
      "total_reward: 2475387.48\n",
      "total_cost: 249756.91\n",
      "total_trades: 66272\n",
      "Sharpe: 0.937\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.48e+06    |\n",
      "|    total_cost           | 2.5e+05     |\n",
      "|    total_reward         | 2.48e+06    |\n",
      "|    total_reward_pct     | 248         |\n",
      "|    total_trades         | 66272       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 608         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039878417 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0459      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.54e+06    |\n",
      "|    total_cost           | 2.49e+05    |\n",
      "|    total_reward         | 2.54e+06    |\n",
      "|    total_reward_pct     | 254         |\n",
      "|    total_trades         | 66454       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 626         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032037407 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0362      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.74        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.42e+06    |\n",
      "|    total_cost           | 2.36e+05    |\n",
      "|    total_reward         | 1.42e+06    |\n",
      "|    total_reward_pct     | 142         |\n",
      "|    total_trades         | 65134       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 642         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039216183 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0321      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.44e+06    |\n",
      "|    total_cost           | 2.39e+05    |\n",
      "|    total_reward         | 2.44e+06    |\n",
      "|    total_reward_pct     | 244         |\n",
      "|    total_trades         | 65148       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 658         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044581376 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0726      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.33        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 674         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038361527 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0449      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.07        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.09e+06    |\n",
      "|    total_cost           | 2.51e+05    |\n",
      "|    total_reward         | 2.09e+06    |\n",
      "|    total_reward_pct     | 209         |\n",
      "|    total_trades         | 66651       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 690         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061485052 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.042       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.81        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "day: 2391, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2858480.68\n",
      "total_reward: 1858480.68\n",
      "total_cost: 215609.28\n",
      "total_trades: 63790\n",
      "Sharpe: 0.785\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.86e+06    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 1.86e+06    |\n",
      "|    total_reward_pct     | 186         |\n",
      "|    total_trades         | 63790       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 707         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041921835 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0245      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.29        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 8.48        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.84e+06   |\n",
      "|    total_cost           | 2.22e+05   |\n",
      "|    total_reward         | 2.84e+06   |\n",
      "|    total_reward_pct     | 284        |\n",
      "|    total_trades         | 63571      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 723        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08466178 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.0604     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.52       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.00826   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 16.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.86e+06    |\n",
      "|    total_cost           | 2.46e+05    |\n",
      "|    total_reward         | 1.86e+06    |\n",
      "|    total_reward_pct     | 186         |\n",
      "|    total_trades         | 65471       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 739         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047006138 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0311      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.66e+06   |\n",
      "|    total_cost           | 2.36e+05   |\n",
      "|    total_reward         | 1.66e+06   |\n",
      "|    total_reward_pct     | 166        |\n",
      "|    total_trades         | 65257      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 755        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03693051 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.168      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.15       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0118    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 16.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.71e+06   |\n",
      "|    total_cost           | 2.24e+05   |\n",
      "|    total_reward         | 1.71e+06   |\n",
      "|    total_reward_pct     | 171        |\n",
      "|    total_trades         | 64599      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 771        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04047989 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.0858     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.21       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 13.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 786         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054322198 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0368      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.65        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-07-08 to  2019-10-04\n",
      "PPO Sharpe Ratio:  -0.18196968729823912\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_819_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.72e+06 |\n",
      "|    total_cost       | 1.92e+03 |\n",
      "|    total_reward     | 2.72e+06 |\n",
      "|    total_reward_pct | 272      |\n",
      "|    total_trades     | 28418    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total timesteps  | 9568     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -40.4    |\n",
      "|    critic_loss      | 8.87     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7176     |\n",
      "----------------------------------\n",
      "day: 2391, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3582446.39\n",
      "total_reward: 2582446.39\n",
      "total_cost: 1648.66\n",
      "total_trades: 26244\n",
      "Sharpe: 0.902\n",
      "=================================\n",
      "======DDPG Validation from:  2019-07-08 to  2019-10-04\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-10-04\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_819_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.0528   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 6.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.244    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -53.4    |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 4.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.198   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -32.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0659  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 36.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.67e+06 |\n",
      "|    total_cost         | 2.25e+05 |\n",
      "|    total_reward       | 2.67e+06 |\n",
      "|    total_reward_pct   | 267      |\n",
      "|    total_trades       | 65236    |\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.651    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.0134   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -3.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 25       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.744    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.934   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 14.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.374    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 232      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 34.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0456   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -148     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 35.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.4e+06  |\n",
      "|    total_cost         | 1.5e+05  |\n",
      "|    total_reward       | 1.4e+06  |\n",
      "|    total_reward_pct   | 140      |\n",
      "|    total_trades       | 57377    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -158     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0219   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 72.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -33      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -23.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.502    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 314      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 56.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.29e+06 |\n",
      "|    total_cost         | 7.63e+04 |\n",
      "|    total_reward       | 2.29e+06 |\n",
      "|    total_reward_pct   | 229      |\n",
      "|    total_trades       | 46077    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.48    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 89.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0165   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 88       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.28     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 7.46     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.149    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0016   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -230     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 33.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0915  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -151     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 18.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.68e+06 |\n",
      "|    total_cost         | 1.52e+05 |\n",
      "|    total_reward       | 1.68e+06 |\n",
      "|    total_reward_pct   | 168      |\n",
      "|    total_trades       | 55642    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.48    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 48.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 41.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.77     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.09    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 14.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.197    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 121       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 94        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 12.2      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.164     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -60      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.03     |\n",
      "------------------------------------\n",
      "day: 2454, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2724981.85\n",
      "total_reward: 1724981.85\n",
      "total_cost: 108800.93\n",
      "total_trades: 52830\n",
      "Sharpe: 0.697\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.72e+06 |\n",
      "|    total_cost         | 1.09e+05 |\n",
      "|    total_reward       | 1.72e+06 |\n",
      "|    total_reward_pct   | 172      |\n",
      "|    total_trades       | 52830    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.21     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -90.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.00734 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -83.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 92.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.66     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 121       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -34.6     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.885     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -164     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 37.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.44e+06 |\n",
      "|    total_cost         | 1.23e+05 |\n",
      "|    total_reward       | 1.44e+06 |\n",
      "|    total_reward_pct   | 144      |\n",
      "|    total_trades       | 55298    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.947   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -15.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.198    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.364    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 7.54     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0682   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -17.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -2.47    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -14.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.359    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -128     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.62e+06 |\n",
      "|    total_cost         | 1.11e+05 |\n",
      "|    total_reward       | 1.62e+06 |\n",
      "|    total_reward_pct   | 162      |\n",
      "|    total_trades       | 52999    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -24.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.364    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -6.16    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.202    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -7.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.05     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 121       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -25.4     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.399     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 111      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.29     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.05e+06  |\n",
      "|    total_cost         | 4.64e+04  |\n",
      "|    total_reward       | 1.05e+06  |\n",
      "|    total_reward_pct   | 105       |\n",
      "|    total_trades       | 43989     |\n",
      "| time/                 |           |\n",
      "|    fps                | 121       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -67.7     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 3.14      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -42      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 22.7     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.442    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -163     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -217     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 41.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.36e+06 |\n",
      "|    total_cost         | 3.58e+04 |\n",
      "|    total_reward       | 1.36e+06 |\n",
      "|    total_reward_pct   | 136      |\n",
      "|    total_trades       | 42201    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -416     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 86.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 52.7     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -129     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 15.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 17.7     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.272    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -110     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2454, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2746568.76\n",
      "total_reward: 1746568.76\n",
      "total_cost: 42150.44\n",
      "total_trades: 44559\n",
      "Sharpe: 0.667\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.75e+06 |\n",
      "|    total_cost         | 4.22e+04 |\n",
      "|    total_reward       | 1.75e+06 |\n",
      "|    total_reward_pct   | 175      |\n",
      "|    total_trades       | 44559    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 66.8     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.84     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 121       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -88.9     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 5.91      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.0478  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 69.4     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -76.8    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -76.2    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 4.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.08e+06 |\n",
      "|    total_cost         | 3.25e+04 |\n",
      "|    total_reward       | 2.08e+06 |\n",
      "|    total_reward_pct   | 208      |\n",
      "|    total_trades       | 42733    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -73      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 16.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -134     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 8.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 144      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.42e+06  |\n",
      "|    total_cost         | 1.21e+04  |\n",
      "|    total_reward       | 2.42e+06  |\n",
      "|    total_reward_pct   | 242       |\n",
      "|    total_trades       | 40048     |\n",
      "| time/                 |           |\n",
      "|    fps                | 122       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 241       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 0.69      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.103     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 12       |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.535    |\n",
      "------------------------------------\n",
      "======Trading from:  2019-10-04 to  2020-01-06\n",
      "============================================\n",
      "25.91719135748758\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2019-10-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_882_4\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.225    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -90.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.238   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -39.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0257  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 51.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 5.73     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.67e+06 |\n",
      "|    total_cost         | 9.29e+04 |\n",
      "|    total_reward       | 1.67e+06 |\n",
      "|    total_reward_pct   | 167      |\n",
      "|    total_trades       | 52162    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 6.05     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0856   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 17.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.177    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 121       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 34.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.62      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 121       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 174       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 19.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -315     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 96.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.37e+06 |\n",
      "|    total_cost         | 3.95e+04 |\n",
      "|    total_reward       | 2.37e+06 |\n",
      "|    total_reward_pct   | 237      |\n",
      "|    total_trades       | 45154    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0409  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -202     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 22.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.106    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 40.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -46.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0684  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 43.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 126      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.41e+06 |\n",
      "|    total_cost         | 1.22e+05 |\n",
      "|    total_reward       | 1.41e+06 |\n",
      "|    total_reward_pct   | 141      |\n",
      "|    total_trades       | 55224    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 75.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0191   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 90.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.83     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -5.37    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.315    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0253  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -184     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 20       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0897   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -120     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.6e+06  |\n",
      "|    total_cost         | 4.64e+04 |\n",
      "|    total_reward       | 6.04e+05 |\n",
      "|    total_reward_pct   | 60.4     |\n",
      "|    total_trades       | 47240    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.000207 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 64.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0175  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 147      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.519   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0388   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -4.9e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 33.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.784    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -4.15    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.77     |\n",
      "------------------------------------\n",
      "day: 2454, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1769811.52\n",
      "total_reward: 769811.52\n",
      "total_cost: 84632.62\n",
      "total_trades: 51239\n",
      "Sharpe: 0.401\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.77e+06 |\n",
      "|    total_cost         | 8.46e+04 |\n",
      "|    total_reward       | 7.7e+05  |\n",
      "|    total_reward_pct   | 77       |\n",
      "|    total_trades       | 51239    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.151    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -75.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.281   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -74.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.179    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 32.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.979    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.107    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -71.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.242    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -104     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.36e+06 |\n",
      "|    total_cost         | 1.41e+05 |\n",
      "|    total_reward       | 3.59e+05 |\n",
      "|    total_reward_pct   | 35.9     |\n",
      "|    total_trades       | 55206    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.00652 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -67.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.45     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.0815   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 97.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -104     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0545  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 84.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.021   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 45.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.95e+06 |\n",
      "|    total_cost         | 1.08e+05 |\n",
      "|    total_reward       | 9.46e+05 |\n",
      "|    total_reward_pct   | 94.6     |\n",
      "|    total_trades       | 50757    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.235   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -36.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.878    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 17.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -15.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.738    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.312   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -33.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.835    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.133   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 20.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.83e+06 |\n",
      "|    total_cost         | 8.58e+04 |\n",
      "|    total_reward       | 8.34e+05 |\n",
      "|    total_reward_pct   | 83.4     |\n",
      "|    total_trades       | 49637    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.437   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -48.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 95.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 61.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.00584 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -327     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 55.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.00649 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -179     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 27.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 4.02e+04 |\n",
      "|    total_reward       | 9.3e+05  |\n",
      "|    total_reward_pct   | 93       |\n",
      "|    total_trades       | 42612    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.144   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -191     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 22       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.0453  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 77.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -145     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 15.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 39.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "day: 2454, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1931245.99\n",
      "total_reward: 931245.99\n",
      "total_cost: 67440.73\n",
      "total_trades: 47052\n",
      "Sharpe: 0.418\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 6.74e+04 |\n",
      "|    total_reward       | 9.31e+05 |\n",
      "|    total_reward_pct   | 93.1     |\n",
      "|    total_trades       | 47052    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.0345  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 4.63     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.164    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -53.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.131    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -20.8    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.489   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 10.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.138   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -59.8    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.83e+06 |\n",
      "|    total_cost         | 6.83e+04 |\n",
      "|    total_reward       | 8.35e+05 |\n",
      "|    total_reward_pct   | 83.5     |\n",
      "|    total_trades       | 43040    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.000123 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -21.9    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.544    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.00166 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -11.7    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.831    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 121       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 233       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -129      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 7.9       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.265   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 77.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.52     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.55e+06 |\n",
      "|    total_cost         | 1.17e+05 |\n",
      "|    total_reward       | 1.55e+06 |\n",
      "|    total_reward_pct   | 155      |\n",
      "|    total_trades       | 49333    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.166    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -12.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -41.5    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.21     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-10-04 to  2020-01-06\n",
      "A2C Sharpe Ratio:  0.36685383331026183\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_882_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 129  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 15   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.27e+06    |\n",
      "|    total_cost           | 2.95e+05    |\n",
      "|    total_reward         | 1.27e+06    |\n",
      "|    total_reward_pct     | 127         |\n",
      "|    total_trades         | 70819       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007442767 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0348     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.96        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 8.23        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2647785.87\n",
      "total_reward: 1647785.87\n",
      "total_cost: 295009.84\n",
      "total_trades: 70773\n",
      "Sharpe: 0.817\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+06    |\n",
      "|    total_cost           | 2.95e+05    |\n",
      "|    total_reward         | 1.65e+06    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 70773       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017532485 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00467    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.24        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.25e+06   |\n",
      "|    total_cost           | 2.86e+05   |\n",
      "|    total_reward         | 1.25e+06   |\n",
      "|    total_reward_pct     | 125        |\n",
      "|    total_trades         | 70241      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02004783 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | 0.0198     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.34       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0262    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 11.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.66e+06    |\n",
      "|    total_cost           | 2.87e+05    |\n",
      "|    total_reward         | 1.66e+06    |\n",
      "|    total_reward_pct     | 166         |\n",
      "|    total_trades         | 70355       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014104368 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0203      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.73        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.2e+06     |\n",
      "|    total_cost           | 2.74e+05    |\n",
      "|    total_reward         | 1.2e+06     |\n",
      "|    total_reward_pct     | 120         |\n",
      "|    total_trades         | 69510       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013366325 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0101     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.95        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015835313 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0182     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.42        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.15e+06    |\n",
      "|    total_cost           | 2.71e+05    |\n",
      "|    total_reward         | 1.15e+06    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 69156       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018541196 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.00147    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.65        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2454, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2247286.16\n",
      "total_reward: 1247286.16\n",
      "total_cost: 276825.96\n",
      "total_trades: 69630\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.25e+06   |\n",
      "|    total_cost           | 2.77e+05   |\n",
      "|    total_reward         | 1.25e+06   |\n",
      "|    total_reward_pct     | 125        |\n",
      "|    total_trades         | 69630      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 146        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01780857 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | -0.0297    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.95       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 13         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.02e+06    |\n",
      "|    total_cost           | 2.69e+05    |\n",
      "|    total_reward         | 1.02e+06    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 68753       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015576251 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.028       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.92        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.12        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.93e+06   |\n",
      "|    total_cost           | 2.63e+05   |\n",
      "|    total_reward         | 9.34e+05   |\n",
      "|    total_reward_pct     | 93.4       |\n",
      "|    total_trades         | 68478      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 179        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02499684 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.031      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.68       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0198    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 9.7        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.9e+06     |\n",
      "|    total_cost           | 2.7e+05     |\n",
      "|    total_reward         | 8.97e+05    |\n",
      "|    total_reward_pct     | 89.7        |\n",
      "|    total_trades         | 68710       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018737717 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.000859   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.98        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 212        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02265803 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.00237    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.86       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0201    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 10.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.77e+06    |\n",
      "|    total_cost           | 2.62e+05    |\n",
      "|    total_reward         | 7.72e+05    |\n",
      "|    total_reward_pct     | 77.2        |\n",
      "|    total_trades         | 67992       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027325436 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0326      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.9         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 7.88        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2340578.50\n",
      "total_reward: 1340578.50\n",
      "total_cost: 274248.44\n",
      "total_trades: 69047\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.34e+06    |\n",
      "|    total_cost           | 2.74e+05    |\n",
      "|    total_reward         | 1.34e+06    |\n",
      "|    total_reward_pct     | 134         |\n",
      "|    total_trades         | 69047       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016132837 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0341      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.82        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.01e+06    |\n",
      "|    total_cost           | 2.64e+05    |\n",
      "|    total_reward         | 2.01e+06    |\n",
      "|    total_reward_pct     | 201         |\n",
      "|    total_trades         | 68428       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027405655 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0396      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.21        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.49e+06    |\n",
      "|    total_cost           | 2.74e+05    |\n",
      "|    total_reward         | 1.49e+06    |\n",
      "|    total_reward_pct     | 149         |\n",
      "|    total_trades         | 69093       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033560343 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0142      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.91        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.87e+06   |\n",
      "|    total_cost           | 2.62e+05   |\n",
      "|    total_reward         | 1.87e+06   |\n",
      "|    total_reward_pct     | 187        |\n",
      "|    total_trades         | 67971      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 294        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03617075 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0394     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.89       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 13.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016608996 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.00216    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.39        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.33e+06   |\n",
      "|    total_cost           | 2.68e+05   |\n",
      "|    total_reward         | 1.33e+06   |\n",
      "|    total_reward_pct     | 133        |\n",
      "|    total_trades         | 68678      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 327        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03080322 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | -0.00896   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.95       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 6.44       |\n",
      "----------------------------------------\n",
      "day: 2454, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2743937.84\n",
      "total_reward: 1743937.84\n",
      "total_cost: 256461.97\n",
      "total_trades: 67671\n",
      "Sharpe: 0.862\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.74e+06    |\n",
      "|    total_cost           | 2.56e+05    |\n",
      "|    total_reward         | 1.74e+06    |\n",
      "|    total_reward_pct     | 174         |\n",
      "|    total_trades         | 67671       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026934665 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0278      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.19        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.95e+06    |\n",
      "|    total_cost           | 2.72e+05    |\n",
      "|    total_reward         | 1.95e+06    |\n",
      "|    total_reward_pct     | 195         |\n",
      "|    total_trades         | 68547       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027472388 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0515      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+06    |\n",
      "|    total_cost           | 2.4e+05     |\n",
      "|    total_reward         | 1.45e+06    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 66514       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 380         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028083984 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0591      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.75        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.66e+06    |\n",
      "|    total_cost           | 2.46e+05    |\n",
      "|    total_reward         | 1.66e+06    |\n",
      "|    total_reward_pct     | 166         |\n",
      "|    total_trades         | 66904       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020597853 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0183      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.91        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 123          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 414          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126400385 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44          |\n",
      "|    explained_variance   | -0.0156      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.99         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0154      |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 14.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.96e+06    |\n",
      "|    total_cost           | 2.45e+05    |\n",
      "|    total_reward         | 1.96e+06    |\n",
      "|    total_reward_pct     | 196         |\n",
      "|    total_trades         | 66591       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027834913 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | -0.04       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.67        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2760805.11\n",
      "total_reward: 1760805.11\n",
      "total_cost: 248076.21\n",
      "total_trades: 66423\n",
      "Sharpe: 0.816\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.76e+06    |\n",
      "|    total_cost           | 2.48e+05    |\n",
      "|    total_reward         | 1.76e+06    |\n",
      "|    total_reward_pct     | 176         |\n",
      "|    total_trades         | 66423       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 449         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024554985 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0897      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.46        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.89e+06    |\n",
      "|    total_cost           | 2.52e+05    |\n",
      "|    total_reward         | 1.89e+06    |\n",
      "|    total_reward_pct     | 189         |\n",
      "|    total_trades         | 66896       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 465         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025748398 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0229      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.71        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+06    |\n",
      "|    total_cost           | 2.26e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 65315       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 483         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026612336 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0462      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.79        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+06     |\n",
      "|    total_cost           | 2.28e+05    |\n",
      "|    total_reward         | 1.5e+06     |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 65773       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021422327 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0744      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.71        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 519        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01899162 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0145     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.78       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 16.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.95e+06    |\n",
      "|    total_cost           | 2.25e+05    |\n",
      "|    total_reward         | 9.48e+05    |\n",
      "|    total_reward_pct     | 94.8        |\n",
      "|    total_trades         | 64937       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 536         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022050876 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.77        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 7.02        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3092281.24\n",
      "total_reward: 2092281.24\n",
      "total_cost: 236299.73\n",
      "total_trades: 66191\n",
      "Sharpe: 0.849\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.09e+06    |\n",
      "|    total_cost           | 2.36e+05    |\n",
      "|    total_reward         | 2.09e+06    |\n",
      "|    total_reward_pct     | 209         |\n",
      "|    total_trades         | 66191       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 553         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022972552 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.054       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.57        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 8.07        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.05e+06    |\n",
      "|    total_cost           | 2.34e+05    |\n",
      "|    total_reward         | 2.05e+06    |\n",
      "|    total_reward_pct     | 205         |\n",
      "|    total_trades         | 66119       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017366225 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0552      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.69e+06  |\n",
      "|    total_cost           | 2.27e+05  |\n",
      "|    total_reward         | 1.69e+06  |\n",
      "|    total_reward_pct     | 169       |\n",
      "|    total_trades         | 65193     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 121       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 589       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0289004 |\n",
      "|    clip_fraction        | 0.225     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.5     |\n",
      "|    explained_variance   | 0.0296    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 8.32      |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -0.0215   |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 26        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.67e+06    |\n",
      "|    total_cost           | 2.26e+05    |\n",
      "|    total_reward         | 2.67e+06    |\n",
      "|    total_reward_pct     | 267         |\n",
      "|    total_trades         | 64983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 605         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028040828 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.6         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 622         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020291815 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | -0.0292     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.56        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.18e+06    |\n",
      "|    total_cost           | 2.35e+05    |\n",
      "|    total_reward         | 3.18e+06    |\n",
      "|    total_reward_pct     | 318         |\n",
      "|    total_trades         | 65609       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 638         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029880734 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | -0.032      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2827156.80\n",
      "total_reward: 1827156.80\n",
      "total_cost: 255495.59\n",
      "total_trades: 66967\n",
      "Sharpe: 0.848\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.83e+06   |\n",
      "|    total_cost           | 2.55e+05   |\n",
      "|    total_reward         | 1.83e+06   |\n",
      "|    total_reward_pct     | 183        |\n",
      "|    total_trades         | 66967      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 655        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03502121 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.0514     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.5       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 42.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.83e+06    |\n",
      "|    total_cost           | 2.52e+05    |\n",
      "|    total_reward         | 1.83e+06    |\n",
      "|    total_reward_pct     | 183         |\n",
      "|    total_trades         | 66914       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 671         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036743574 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.28        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.66e+06    |\n",
      "|    total_cost           | 2.28e+05    |\n",
      "|    total_reward         | 1.66e+06    |\n",
      "|    total_reward_pct     | 166         |\n",
      "|    total_trades         | 65212       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 688         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033465758 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0228      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.29        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.15e+06    |\n",
      "|    total_cost           | 2.44e+05    |\n",
      "|    total_reward         | 2.15e+06    |\n",
      "|    total_reward_pct     | 215         |\n",
      "|    total_trades         | 66053       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 704         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038383402 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0771      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.4         |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 720         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035412535 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0806      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.42e+06    |\n",
      "|    total_cost           | 2.35e+05    |\n",
      "|    total_reward         | 2.42e+06    |\n",
      "|    total_reward_pct     | 242         |\n",
      "|    total_trades         | 65772       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 737         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054193582 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.52        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "day: 2454, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2997913.81\n",
      "total_reward: 1997913.81\n",
      "total_cost: 234102.29\n",
      "total_trades: 65467\n",
      "Sharpe: 0.838\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3e+06       |\n",
      "|    total_cost           | 2.34e+05    |\n",
      "|    total_reward         | 2e+06       |\n",
      "|    total_reward_pct     | 200         |\n",
      "|    total_trades         | 65467       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 753         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036828592 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.17        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.77e+06   |\n",
      "|    total_cost           | 2.32e+05   |\n",
      "|    total_reward         | 1.77e+06   |\n",
      "|    total_reward_pct     | 177        |\n",
      "|    total_trades         | 65254      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 769        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03424584 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.2      |\n",
      "|    explained_variance   | 0.128      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.43       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 18.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.48e+06    |\n",
      "|    total_cost           | 2.27e+05    |\n",
      "|    total_reward         | 1.48e+06    |\n",
      "|    total_reward_pct     | 148         |\n",
      "|    total_trades         | 64671       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 786         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052195985 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.08        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 9.82        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.49e+06   |\n",
      "|    total_cost           | 2.35e+05   |\n",
      "|    total_reward         | 1.49e+06   |\n",
      "|    total_reward_pct     | 149        |\n",
      "|    total_trades         | 65497      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 802        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04525231 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | 0.0987     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.87       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00953   |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 12.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 818         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042898156 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0093      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.74        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-10-04 to  2020-01-06\n",
      "PPO Sharpe Ratio:  0.43434016554227034\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_882_4\n",
      "day: 2454, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2686404.53\n",
      "total_reward: 1686404.53\n",
      "total_cost: 8147.42\n",
      "total_trades: 35759\n",
      "Sharpe: 0.698\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.51e+06 |\n",
      "|    total_cost       | 1.35e+03 |\n",
      "|    total_reward     | 1.51e+06 |\n",
      "|    total_reward_pct | 151      |\n",
      "|    total_trades     | 29527    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 52       |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total timesteps  | 9820     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -50.8    |\n",
      "|    critic_loss      | 47.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7365     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2019-10-04 to  2020-01-06\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-01-06\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_882_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 124  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 16   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.94e+06    |\n",
      "|    total_cost           | 3.1e+05     |\n",
      "|    total_reward         | 1.94e+06    |\n",
      "|    total_reward_pct     | 194         |\n",
      "|    total_trades         | 72756       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023445576 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00424    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.84        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+06    |\n",
      "|    total_cost           | 2.99e+05    |\n",
      "|    total_reward         | 1.33e+06    |\n",
      "|    total_reward_pct     | 133         |\n",
      "|    total_trades         | 71854       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007599393 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00275     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.73        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.15e+06    |\n",
      "|    total_cost           | 3.02e+05    |\n",
      "|    total_reward         | 1.15e+06    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 71862       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008776709 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0243     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.06        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.69        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.38e+06    |\n",
      "|    total_cost           | 2.98e+05    |\n",
      "|    total_reward         | 2.38e+06    |\n",
      "|    total_reward_pct     | 238         |\n",
      "|    total_trades         | 71391       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017193528 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00645     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.33        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.75        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014121642 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0115     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2476173.22\n",
      "total_reward: 1476173.22\n",
      "total_cost: 293952.27\n",
      "total_trades: 71186\n",
      "Sharpe: 0.707\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.48e+06    |\n",
      "|    total_cost           | 2.94e+05    |\n",
      "|    total_reward         | 1.48e+06    |\n",
      "|    total_reward_pct     | 148         |\n",
      "|    total_trades         | 71186       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022776727 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0154      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.13        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.19        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.86e+06    |\n",
      "|    total_cost           | 2.96e+05    |\n",
      "|    total_reward         | 1.86e+06    |\n",
      "|    total_reward_pct     | 186         |\n",
      "|    total_trades         | 71179       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014903156 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0244     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.65        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.25e+06    |\n",
      "|    total_cost           | 2.98e+05    |\n",
      "|    total_reward         | 3.25e+06    |\n",
      "|    total_reward_pct     | 325         |\n",
      "|    total_trades         | 71098       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022668976 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.00758    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.24        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.96e+06    |\n",
      "|    total_cost           | 2.91e+05    |\n",
      "|    total_reward         | 1.96e+06    |\n",
      "|    total_reward_pct     | 196         |\n",
      "|    total_trades         | 70706       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031348452 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.00495    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.83        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014854979 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0278      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.68        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.18e+06    |\n",
      "|    total_cost           | 2.88e+05    |\n",
      "|    total_reward         | 2.18e+06    |\n",
      "|    total_reward_pct     | 218         |\n",
      "|    total_trades         | 70706       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017308159 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0105     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4340095.69\n",
      "total_reward: 3340095.69\n",
      "total_cost: 291427.73\n",
      "total_trades: 71236\n",
      "Sharpe: 1.096\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 4.34e+06  |\n",
      "|    total_cost           | 2.91e+05  |\n",
      "|    total_reward         | 3.34e+06  |\n",
      "|    total_reward_pct     | 334       |\n",
      "|    total_trades         | 71236     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 122       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 216       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0323693 |\n",
      "|    clip_fraction        | 0.265     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.3     |\n",
      "|    explained_variance   | 0.0998    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 7.37      |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -0.0256   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 14.8      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.89e+06    |\n",
      "|    total_cost           | 2.77e+05    |\n",
      "|    total_reward         | 2.89e+06    |\n",
      "|    total_reward_pct     | 289         |\n",
      "|    total_trades         | 69903       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030916529 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0295      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.15e+06    |\n",
      "|    total_cost           | 2.79e+05    |\n",
      "|    total_reward         | 3.15e+06    |\n",
      "|    total_reward_pct     | 315         |\n",
      "|    total_trades         | 70123       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017541217 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.72e+06   |\n",
      "|    total_cost           | 2.81e+05   |\n",
      "|    total_reward         | 2.72e+06   |\n",
      "|    total_reward_pct     | 272        |\n",
      "|    total_trades         | 69744      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 266        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03552614 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0398     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.2       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0225    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 32         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 283        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02587862 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0211     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.2       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0218    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 28.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.24e+06    |\n",
      "|    total_cost           | 2.84e+05    |\n",
      "|    total_reward         | 2.24e+06    |\n",
      "|    total_reward_pct     | 224         |\n",
      "|    total_trades         | 70330       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030802814 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.91        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3225141.24\n",
      "total_reward: 2225141.24\n",
      "total_cost: 274529.95\n",
      "total_trades: 69945\n",
      "Sharpe: 0.851\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.23e+06    |\n",
      "|    total_cost           | 2.75e+05    |\n",
      "|    total_reward         | 2.23e+06    |\n",
      "|    total_reward_pct     | 223         |\n",
      "|    total_trades         | 69945       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032655142 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0348      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.56        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.26e+06   |\n",
      "|    total_cost           | 2.93e+05   |\n",
      "|    total_reward         | 2.26e+06   |\n",
      "|    total_reward_pct     | 226        |\n",
      "|    total_trades         | 71137      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 333        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02068249 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0963     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.97       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 19         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+06     |\n",
      "|    total_cost           | 2.83e+05    |\n",
      "|    total_reward         | 1.5e+06     |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 70518       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030054957 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0104      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 366        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01730661 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | -0.0055    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.93       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0214    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 10.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.97e+06    |\n",
      "|    total_cost           | 2.95e+05    |\n",
      "|    total_reward         | 1.97e+06    |\n",
      "|    total_reward_pct     | 197         |\n",
      "|    total_trades         | 71315       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021594398 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.0022     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.04        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.41e+06    |\n",
      "|    total_cost           | 2.88e+05    |\n",
      "|    total_reward         | 2.41e+06    |\n",
      "|    total_reward_pct     | 241         |\n",
      "|    total_trades         | 71015       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 399         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030817278 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0223      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.53        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2517, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2791485.57\n",
      "total_reward: 1791485.57\n",
      "total_cost: 286547.89\n",
      "total_trades: 70850\n",
      "Sharpe: 0.743\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.79e+06   |\n",
      "|    total_cost           | 2.87e+05   |\n",
      "|    total_reward         | 1.79e+06   |\n",
      "|    total_reward_pct     | 179        |\n",
      "|    total_trades         | 70850      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 416        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03513827 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0166     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 22.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.74e+06   |\n",
      "|    total_cost           | 2.77e+05   |\n",
      "|    total_reward         | 2.74e+06   |\n",
      "|    total_reward_pct     | 274        |\n",
      "|    total_trades         | 70048      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 432        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01705676 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0178     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.7        |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0211    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 16.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 449        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03570754 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0325     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.2       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 24.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.6e+06    |\n",
      "|    total_cost           | 2.78e+05   |\n",
      "|    total_reward         | 1.6e+06    |\n",
      "|    total_reward_pct     | 160        |\n",
      "|    total_trades         | 69862      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 466        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03902804 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | -0.00867   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.82       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 14         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.97e+06    |\n",
      "|    total_cost           | 2.7e+05     |\n",
      "|    total_reward         | 9.72e+05    |\n",
      "|    total_reward_pct     | 97.2        |\n",
      "|    total_trades         | 69615       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 483         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036297657 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0206      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.72        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 8.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.72e+06    |\n",
      "|    total_cost           | 2.69e+05    |\n",
      "|    total_reward         | 1.72e+06    |\n",
      "|    total_reward_pct     | 172         |\n",
      "|    total_trades         | 69456       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031678632 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.44        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 9.87        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2602795.21\n",
      "total_reward: 1602795.21\n",
      "total_cost: 279058.57\n",
      "total_trades: 69181\n",
      "Sharpe: 0.703\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.6e+06     |\n",
      "|    total_cost           | 2.79e+05    |\n",
      "|    total_reward         | 1.6e+06     |\n",
      "|    total_reward_pct     | 160         |\n",
      "|    total_trades         | 69181       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021252796 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0262      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.96        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.84e+06    |\n",
      "|    total_cost           | 2.68e+05    |\n",
      "|    total_reward         | 1.84e+06    |\n",
      "|    total_reward_pct     | 184         |\n",
      "|    total_trades         | 68503       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 532         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036944706 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0582      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.46        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 549         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026723478 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | -0.0176     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.8         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.36e+06   |\n",
      "|    total_cost           | 2.66e+05   |\n",
      "|    total_reward         | 1.36e+06   |\n",
      "|    total_reward_pct     | 136        |\n",
      "|    total_trades         | 69022      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 566        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03625398 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.00158    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.64       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0233    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 10.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.66e+06    |\n",
      "|    total_cost           | 2.61e+05    |\n",
      "|    total_reward         | 1.66e+06    |\n",
      "|    total_reward_pct     | 166         |\n",
      "|    total_trades         | 68262       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 582         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028935276 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.045       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.02        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+06    |\n",
      "|    total_cost           | 2.54e+05    |\n",
      "|    total_reward         | 1.33e+06    |\n",
      "|    total_reward_pct     | 133         |\n",
      "|    total_trades         | 67539       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 599         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047038704 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0381      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.97        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2800924.04\n",
      "total_reward: 1800924.04\n",
      "total_cost: 270102.57\n",
      "total_trades: 68736\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+06     |\n",
      "|    total_cost           | 2.7e+05     |\n",
      "|    total_reward         | 1.8e+06     |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 68736       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036548086 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0663      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.56        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 632         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018293204 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0537      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.87        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.37e+06    |\n",
      "|    total_cost           | 2.34e+05    |\n",
      "|    total_reward         | 1.37e+06    |\n",
      "|    total_reward_pct     | 137         |\n",
      "|    total_trades         | 66462       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 649         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036997378 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | -0.0358     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.28        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.42e+06    |\n",
      "|    total_cost           | 2.68e+05    |\n",
      "|    total_reward         | 1.42e+06    |\n",
      "|    total_reward_pct     | 142         |\n",
      "|    total_trades         | 68397       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 665         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039747532 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.07        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 8.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.71e+06    |\n",
      "|    total_cost           | 2.69e+05    |\n",
      "|    total_reward         | 1.71e+06    |\n",
      "|    total_reward_pct     | 171         |\n",
      "|    total_trades         | 68469       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 682         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027329335 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0834      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.36        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.48e+06   |\n",
      "|    total_cost           | 2.6e+05    |\n",
      "|    total_reward         | 1.48e+06   |\n",
      "|    total_reward_pct     | 148        |\n",
      "|    total_trades         | 68150      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 123        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 699        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03251981 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.0784     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.02       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 14.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 715         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025748955 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.21        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2674159.73\n",
      "total_reward: 1674159.73\n",
      "total_cost: 243247.34\n",
      "total_trades: 66302\n",
      "Sharpe: 0.705\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.67e+06    |\n",
      "|    total_cost           | 2.43e+05    |\n",
      "|    total_reward         | 1.67e+06    |\n",
      "|    total_reward_pct     | 167         |\n",
      "|    total_trades         | 66302       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022000514 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0704      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9           |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.3e+06     |\n",
      "|    total_cost           | 2.44e+05    |\n",
      "|    total_reward         | 1.3e+06     |\n",
      "|    total_reward_pct     | 130         |\n",
      "|    total_trades         | 66152       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 748         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041763432 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.79        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 8.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.48e+06    |\n",
      "|    total_cost           | 2.27e+05    |\n",
      "|    total_reward         | 1.48e+06    |\n",
      "|    total_reward_pct     | 148         |\n",
      "|    total_trades         | 65451       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 766         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026189577 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.72        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.46e+06    |\n",
      "|    total_cost           | 2.21e+05    |\n",
      "|    total_reward         | 1.46e+06    |\n",
      "|    total_reward_pct     | 146         |\n",
      "|    total_trades         | 64994       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031564593 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.73        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.44e+06    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 1.44e+06    |\n",
      "|    total_reward_pct     | 144         |\n",
      "|    total_trades         | 64891       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 799         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034423843 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.99        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 815        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03684218 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.72       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00387   |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 17.7       |\n",
      "----------------------------------------\n",
      "======Trading from:  2020-01-06 to  2020-04-06\n",
      "============================================\n",
      "14.976886630566314\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2020-01-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_945_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.584   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -115     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 8.82     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 118       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 35.3      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.61      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 167      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 37.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0241  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 3.95     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.524    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -57.4    |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.21e+06 |\n",
      "|    total_cost         | 2.05e+05 |\n",
      "|    total_reward       | 1.21e+06 |\n",
      "|    total_reward_pct   | 121      |\n",
      "|    total_trades       | 62090    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.0634   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -90.4    |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 8.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -1.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 3.03     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 0.451    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.00455  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -270     |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 39.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 0.00535  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 30.9     |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 0.698    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 0.0158   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 134      |\n",
      "|    std                | 0.995    |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.37e+06 |\n",
      "|    total_cost         | 1.68e+05 |\n",
      "|    total_reward       | 1.37e+06 |\n",
      "|    total_reward_pct   | 137      |\n",
      "|    total_trades       | 59931    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 0.243    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 161      |\n",
      "|    std                | 0.995    |\n",
      "|    value_loss         | 15.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | -1.34    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 9.34     |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 0.216    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 96.6     |\n",
      "|    std                | 0.995    |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -47.3    |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 2.05     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.0175   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 38       |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 3.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.24e+06 |\n",
      "|    total_cost         | 1.33e+05 |\n",
      "|    total_reward       | 2.24e+06 |\n",
      "|    total_reward_pct   | 224      |\n",
      "|    total_trades       | 56828    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.0298   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -173     |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 17.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.247   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -62.7    |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 2.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0127   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -64.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.00616  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -5.21    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 1.43     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.71e+06 |\n",
      "|    total_cost         | 1.56e+05 |\n",
      "|    total_reward       | 1.71e+06 |\n",
      "|    total_reward_pct   | 171      |\n",
      "|    total_trades       | 58697    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.185   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.373   |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -1.89    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 80.4     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0793  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 234      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 39.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 119       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -0.000903 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -34.3     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 3.4       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 15.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 17.7     |\n",
      "------------------------------------\n",
      "day: 2517, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3404250.75\n",
      "total_reward: 2404250.75\n",
      "total_cost: 150983.60\n",
      "total_trades: 59733\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.4e+06  |\n",
      "|    total_cost         | 1.51e+05 |\n",
      "|    total_reward       | 2.4e+06  |\n",
      "|    total_reward_pct   | 240      |\n",
      "|    total_trades       | 59733    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.00823  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.189    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -56.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.16     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -50.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.00173  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 825      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 587      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 119       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 125       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -0.000979 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -695      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 304       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.04e+06 |\n",
      "|    total_cost         | 8.83e+04 |\n",
      "|    total_reward       | 3.04e+06 |\n",
      "|    total_reward_pct   | 304      |\n",
      "|    total_trades       | 53412    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -60.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0108  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 47.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -52.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.15     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 119       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 148       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 14.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -27.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.63e+06 |\n",
      "|    total_cost         | 5.11e+04 |\n",
      "|    total_reward       | 1.63e+06 |\n",
      "|    total_reward_pct   | 163      |\n",
      "|    total_trades       | 48497    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 7.43e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 75.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 42.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 29.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.278    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -34.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 183      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 18.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.51e+06 |\n",
      "|    total_cost         | 7.02e+04 |\n",
      "|    total_reward       | 1.51e+06 |\n",
      "|    total_reward_pct   | 151      |\n",
      "|    total_trades       | 49458    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.117   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -49.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -36      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.737    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.234   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 28.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.59     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 119       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 183       |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | -18       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.276     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -140     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.36e+06 |\n",
      "|    total_cost         | 7.23e+04 |\n",
      "|    total_reward       | 1.36e+06 |\n",
      "|    total_reward_pct   | 136      |\n",
      "|    total_trades       | 51592    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.818    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 10.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.166    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0911   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 5.04     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.196    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 19.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 24.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.615    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -3.06    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.841    |\n",
      "------------------------------------\n",
      "day: 2517, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3031603.72\n",
      "total_reward: 2031603.72\n",
      "total_cost: 114055.73\n",
      "total_trades: 54253\n",
      "Sharpe: 0.801\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.03e+06 |\n",
      "|    total_cost         | 1.14e+05 |\n",
      "|    total_reward       | 2.03e+06 |\n",
      "|    total_reward_pct   | 203      |\n",
      "|    total_trades       | 54253    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.232    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 36.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.93     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 119       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 217       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 30.9      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.626     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -178     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 18.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 119       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -35.5     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.35      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 15.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.29e+06 |\n",
      "|    total_cost         | 2.96e+04 |\n",
      "|    total_reward       | 2.29e+06 |\n",
      "|    total_reward_pct   | 229      |\n",
      "|    total_trades       | 43040    |\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 11.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.77     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 66       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.66     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 119       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 242       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 74.3      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 65.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -93.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 25.3     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-01-06 to  2020-04-06\n",
      "A2C Sharpe Ratio:  -0.4364716093306496\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_945_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 125  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 16   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.57e+06     |\n",
      "|    total_cost           | 3.04e+05     |\n",
      "|    total_reward         | 1.57e+06     |\n",
      "|    total_reward_pct     | 157          |\n",
      "|    total_trades         | 72529        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 117          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022281352 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.00545     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.97         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0269      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 9.08         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.54e+06    |\n",
      "|    total_cost           | 2.98e+05    |\n",
      "|    total_reward         | 1.54e+06    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 72121       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011866555 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3496478.98\n",
      "total_reward: 2496478.98\n",
      "total_cost: 307492.45\n",
      "total_trades: 72040\n",
      "Sharpe: 0.866\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.5e+06     |\n",
      "|    total_cost           | 3.07e+05    |\n",
      "|    total_reward         | 2.5e+06     |\n",
      "|    total_reward_pct     | 250         |\n",
      "|    total_trades         | 72040       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007423809 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0386     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.16        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.29e+06    |\n",
      "|    total_cost           | 2.92e+05    |\n",
      "|    total_reward         | 1.29e+06    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 71234       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018700678 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00114    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018077942 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0368      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.05        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.39e+06    |\n",
      "|    total_cost           | 2.97e+05    |\n",
      "|    total_reward         | 1.39e+06    |\n",
      "|    total_reward_pct     | 139         |\n",
      "|    total_trades         | 71875       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016506864 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.00485    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.31        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.7         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.26e+06    |\n",
      "|    total_cost           | 2.96e+05    |\n",
      "|    total_reward         | 2.26e+06    |\n",
      "|    total_reward_pct     | 226         |\n",
      "|    total_trades         | 71494       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014629871 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00967     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.68        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 2.82e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 70625       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018580386 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0157      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2255197.92\n",
      "total_reward: 1255197.92\n",
      "total_cost: 283951.30\n",
      "total_trades: 70687\n",
      "Sharpe: 0.591\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.26e+06    |\n",
      "|    total_cost           | 2.84e+05    |\n",
      "|    total_reward         | 1.26e+06    |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 70687       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017934443 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.99        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015111301 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 7.17e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.76        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.47e+06    |\n",
      "|    total_cost           | 2.72e+05    |\n",
      "|    total_reward         | 1.47e+06    |\n",
      "|    total_reward_pct     | 147         |\n",
      "|    total_trades         | 70178       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018324554 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.000934   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.75        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.1e+06     |\n",
      "|    total_cost           | 2.83e+05    |\n",
      "|    total_reward         | 2.1e+06     |\n",
      "|    total_reward_pct     | 210         |\n",
      "|    total_trades         | 70447       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028325174 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0319      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.16        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.55e+06    |\n",
      "|    total_cost           | 2.74e+05    |\n",
      "|    total_reward         | 1.55e+06    |\n",
      "|    total_reward_pct     | 155         |\n",
      "|    total_trades         | 70063       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022968996 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.00501     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.6         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.39e+06    |\n",
      "|    total_cost           | 2.68e+05    |\n",
      "|    total_reward         | 2.39e+06    |\n",
      "|    total_reward_pct     | 239         |\n",
      "|    total_trades         | 69504       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017693253 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0108     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.53        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2517, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4096103.35\n",
      "total_reward: 3096103.35\n",
      "total_cost: 274404.06\n",
      "total_trades: 69918\n",
      "Sharpe: 0.977\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.1e+06     |\n",
      "|    total_cost           | 2.74e+05    |\n",
      "|    total_reward         | 3.1e+06     |\n",
      "|    total_reward_pct     | 310         |\n",
      "|    total_trades         | 69918       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033066586 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0175      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027322397 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0148     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.39e+06    |\n",
      "|    total_cost           | 2.65e+05    |\n",
      "|    total_reward         | 2.39e+06    |\n",
      "|    total_reward_pct     | 239         |\n",
      "|    total_trades         | 68771       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023410836 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.032       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.65        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.72e+06    |\n",
      "|    total_cost           | 2.38e+05    |\n",
      "|    total_reward         | 2.72e+06    |\n",
      "|    total_reward_pct     | 272         |\n",
      "|    total_trades         | 67372       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025437387 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0749      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.85        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.56e+06    |\n",
      "|    total_cost           | 2.6e+05     |\n",
      "|    total_reward         | 2.56e+06    |\n",
      "|    total_reward_pct     | 256         |\n",
      "|    total_trades         | 68644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 353         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018664697 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0417      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.26e+06   |\n",
      "|    total_cost           | 2.23e+05   |\n",
      "|    total_reward         | 3.26e+06   |\n",
      "|    total_reward_pct     | 326        |\n",
      "|    total_trades         | 65968      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 371        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01828652 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0779     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.6       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0205    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 25.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 388         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018331926 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0312      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4130265.32\n",
      "total_reward: 3130265.32\n",
      "total_cost: 222144.90\n",
      "total_trades: 65810\n",
      "Sharpe: 0.980\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.13e+06    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 3.13e+06    |\n",
      "|    total_reward_pct     | 313         |\n",
      "|    total_trades         | 65810       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022712184 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0582      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.61        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.29e+06    |\n",
      "|    total_cost           | 2.05e+05    |\n",
      "|    total_reward         | 2.29e+06    |\n",
      "|    total_reward_pct     | 229         |\n",
      "|    total_trades         | 64998       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 424         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020038769 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0761      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.92        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.19e+06    |\n",
      "|    total_cost           | 2.48e+05    |\n",
      "|    total_reward         | 2.19e+06    |\n",
      "|    total_reward_pct     | 219         |\n",
      "|    total_trades         | 67869       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024208875 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.56e+06    |\n",
      "|    total_cost           | 2.53e+05    |\n",
      "|    total_reward         | 2.56e+06    |\n",
      "|    total_reward_pct     | 256         |\n",
      "|    total_trades         | 68056       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024649473 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.8         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 476         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028247287 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0619      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.16e+06    |\n",
      "|    total_cost           | 2.27e+05    |\n",
      "|    total_reward         | 2.16e+06    |\n",
      "|    total_reward_pct     | 216         |\n",
      "|    total_trades         | 65221       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022647552 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0761      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.42        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2491907.15\n",
      "total_reward: 1491907.15\n",
      "total_cost: 236959.81\n",
      "total_trades: 66617\n",
      "Sharpe: 0.635\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.49e+06   |\n",
      "|    total_cost           | 2.37e+05   |\n",
      "|    total_reward         | 1.49e+06   |\n",
      "|    total_reward_pct     | 149        |\n",
      "|    total_trades         | 66617      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 512        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03457117 |\n",
      "|    clip_fraction        | 0.34       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.101      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.46       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0225    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 13.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.44e+06   |\n",
      "|    total_cost           | 2.53e+05   |\n",
      "|    total_reward         | 1.44e+06   |\n",
      "|    total_reward_pct     | 144        |\n",
      "|    total_trades         | 67722      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 530        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03213632 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0516     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.49       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 13.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.62e+06    |\n",
      "|    total_cost           | 2.48e+05    |\n",
      "|    total_reward         | 1.62e+06    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 67367       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 547         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028539553 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.47        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+06     |\n",
      "|    total_cost           | 2.45e+05    |\n",
      "|    total_reward         | 1.5e+06     |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 67158       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 564         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032938886 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0571      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.61        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 583        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02908556 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0184     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11         |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 16.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.81e+06    |\n",
      "|    total_cost           | 2.5e+05     |\n",
      "|    total_reward         | 1.81e+06    |\n",
      "|    total_reward_pct     | 181         |\n",
      "|    total_trades         | 66768       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 601         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038499646 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.049       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.09        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2738987.64\n",
      "total_reward: 1738987.64\n",
      "total_cost: 248227.60\n",
      "total_trades: 67042\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.74e+06    |\n",
      "|    total_cost           | 2.48e+05    |\n",
      "|    total_reward         | 1.74e+06    |\n",
      "|    total_reward_pct     | 174         |\n",
      "|    total_trades         | 67042       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 618         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035267457 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0263      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.95        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.12e+06    |\n",
      "|    total_cost           | 2.63e+05    |\n",
      "|    total_reward         | 2.12e+06    |\n",
      "|    total_reward_pct     | 212         |\n",
      "|    total_trades         | 68276       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 635         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049524926 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0663      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.22        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+06    |\n",
      "|    total_cost           | 2.41e+05    |\n",
      "|    total_reward         | 1.65e+06    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 67311       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 652         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026819352 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0115      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 668         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038443092 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0913      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.2         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.51e+06   |\n",
      "|    total_cost           | 2.6e+05    |\n",
      "|    total_reward         | 1.51e+06   |\n",
      "|    total_reward_pct     | 151        |\n",
      "|    total_trades         | 68827      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 685        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05102016 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.0152     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.44       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 12.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.55e+06    |\n",
      "|    total_cost           | 2.58e+05    |\n",
      "|    total_reward         | 1.55e+06    |\n",
      "|    total_reward_pct     | 155         |\n",
      "|    total_trades         | 68076       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 702         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034071736 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0744      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.46        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2517, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3137777.52\n",
      "total_reward: 2137777.52\n",
      "total_cost: 256604.02\n",
      "total_trades: 67845\n",
      "Sharpe: 0.801\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.14e+06    |\n",
      "|    total_cost           | 2.57e+05    |\n",
      "|    total_reward         | 2.14e+06    |\n",
      "|    total_reward_pct     | 214         |\n",
      "|    total_trades         | 67845       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 718         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056002755 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0796      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.51        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.98e+06   |\n",
      "|    total_cost           | 2.68e+05   |\n",
      "|    total_reward         | 1.98e+06   |\n",
      "|    total_reward_pct     | 198        |\n",
      "|    total_trades         | 68216      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 117        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 735        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05255519 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.167      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.15       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 16         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 752         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018930268 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0102      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.85e+06    |\n",
      "|    total_cost           | 2.51e+05    |\n",
      "|    total_reward         | 1.85e+06    |\n",
      "|    total_reward_pct     | 185         |\n",
      "|    total_trades         | 66851       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 768         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017183853 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | -0.00303    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.58        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.49e+06    |\n",
      "|    total_cost           | 2.41e+05    |\n",
      "|    total_reward         | 2.49e+06    |\n",
      "|    total_reward_pct     | 249         |\n",
      "|    total_trades         | 66946       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 785         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039056223 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.18        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.33e+06    |\n",
      "|    total_cost           | 2.23e+05    |\n",
      "|    total_reward         | 2.33e+06    |\n",
      "|    total_reward_pct     | 233         |\n",
      "|    total_trades         | 65865       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 801         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024764856 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.38        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "day: 2517, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3656557.68\n",
      "total_reward: 2656557.68\n",
      "total_cost: 240292.69\n",
      "total_trades: 66846\n",
      "Sharpe: 0.882\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.66e+06    |\n",
      "|    total_cost           | 2.4e+05     |\n",
      "|    total_reward         | 2.66e+06    |\n",
      "|    total_reward_pct     | 266         |\n",
      "|    total_trades         | 66846       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 818         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031870566 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0747      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.2e+06    |\n",
      "|    total_cost           | 2.37e+05   |\n",
      "|    total_reward         | 2.2e+06    |\n",
      "|    total_reward_pct     | 220        |\n",
      "|    total_trades         | 66623      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 117        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 835        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03336787 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.126      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.8       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 24.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 851         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044575065 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.57        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-01-06 to  2020-04-06\n",
      "PPO Sharpe Ratio:  -0.4347753193585164\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_945_4\n",
      "day: 2517, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3923240.73\n",
      "total_reward: 2923240.73\n",
      "total_cost: 1057.82\n",
      "total_trades: 37253\n",
      "Sharpe: 1.018\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.07e+06 |\n",
      "|    total_cost       | 1.11e+03 |\n",
      "|    total_reward     | 2.07e+06 |\n",
      "|    total_reward_pct | 207      |\n",
      "|    total_trades     | 37030    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total timesteps  | 10072    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -65.9    |\n",
      "|    critic_loss      | 216      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7554     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-01-06 to  2020-04-06\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-04-06\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_945_3\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.94e+06 |\n",
      "|    total_cost       | 1.65e+03 |\n",
      "|    total_reward     | 9.42e+05 |\n",
      "|    total_reward_pct | 94.2     |\n",
      "|    total_trades     | 39595    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total timesteps  | 10324    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -33.6    |\n",
      "|    critic_loss      | 119      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7743     |\n",
      "----------------------------------\n",
      "======Trading from:  2020-04-06 to  2020-07-07\n",
      "============================================\n",
      "169.48991065644063\n",
      "turbulence_threshold:  51.492391905857524\n",
      "======Model training from:  2010-01-01 to  2020-04-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_1008_4\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.015    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -87.7    |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 5.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0703   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 41.7     |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 2.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0652   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -114     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 14.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0269  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 42.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0156  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -127     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 14.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.76e+06 |\n",
      "|    total_cost         | 2.49e+05 |\n",
      "|    total_reward       | 2.76e+06 |\n",
      "|    total_reward_pct   | 276      |\n",
      "|    total_trades       | 66437    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0149   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 112      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.263    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -125     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.687   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 70.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.51     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.325    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -138     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0151  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -258     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 64       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.62e+06 |\n",
      "|    total_cost         | 2.8e+05  |\n",
      "|    total_reward       | 1.62e+06 |\n",
      "|    total_reward_pct   | 162      |\n",
      "|    total_trades       | 68873    |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.124   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 93.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.379    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 63.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0511  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -3.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0845  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 93       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.298    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -64.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.13e+06 |\n",
      "|    total_cost         | 2.24e+05 |\n",
      "|    total_reward       | 1.13e+06 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 65511    |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.29     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 63       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0058  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -80.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0629  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 179      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 29.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 116       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 31.8      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.09      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 27.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.69e+06 |\n",
      "|    total_cost         | 1.05e+05 |\n",
      "|    total_reward       | 6.91e+05 |\n",
      "|    total_reward_pct   | 69.1     |\n",
      "|    total_trades       | 56434    |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0262  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 53.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -73      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.18     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 116       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -10.1     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.153     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -22.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.478    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 185      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.8     |\n",
      "------------------------------------\n",
      "day: 2580, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1797749.09\n",
      "total_reward: 797749.09\n",
      "total_cost: 40066.87\n",
      "total_trades: 53124\n",
      "Sharpe: 0.420\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.8e+06  |\n",
      "|    total_cost         | 4.01e+04 |\n",
      "|    total_reward       | 7.98e+05 |\n",
      "|    total_reward_pct   | 79.8     |\n",
      "|    total_trades       | 53124    |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.184   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 24       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -95.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 32.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.637    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 8.34     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -124     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.42e+06 |\n",
      "|    total_cost         | 2.82e+04 |\n",
      "|    total_reward       | 4.22e+05 |\n",
      "|    total_reward_pct   | 42.2     |\n",
      "|    total_trades       | 49248    |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -23.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.346    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 31.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.706    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -14.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -122     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 4.87     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.184    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 192      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 22       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.18e+06 |\n",
      "|    total_cost         | 5.82e+04 |\n",
      "|    total_reward       | 1.18e+06 |\n",
      "|    total_reward_pct   | 118      |\n",
      "|    total_trades       | 49221    |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 19.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 71.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0628  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -52.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 43.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 116       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 175       |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | -74.1     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 5.82      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.52e+06 |\n",
      "|    total_cost         | 7.56e+04 |\n",
      "|    total_reward       | 5.21e+05 |\n",
      "|    total_reward_pct   | 52.1     |\n",
      "|    total_trades       | 52940    |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -25.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 123      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 50.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.47     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 116       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 192       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 17.9      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.504     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -120     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.45e+06 |\n",
      "|    total_cost         | 5.78e+04 |\n",
      "|    total_reward       | 1.45e+06 |\n",
      "|    total_reward_pct   | 145      |\n",
      "|    total_trades       | 47792    |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.217   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 33.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.19     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 116       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 205       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | -0.664    |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.0201    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -168     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0173   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 136      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 18.2     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 272      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 61.5     |\n",
      "------------------------------------\n",
      "day: 2580, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4656357.69\n",
      "total_reward: 3656357.69\n",
      "total_cost: 39831.31\n",
      "total_trades: 45409\n",
      "Sharpe: 0.840\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.66e+06 |\n",
      "|    total_cost         | 3.98e+04 |\n",
      "|    total_reward       | 3.66e+06 |\n",
      "|    total_reward_pct   | 366      |\n",
      "|    total_trades       | 45409    |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 39.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0247  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -0.113   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.196    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0666   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 5.25     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.231    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -137     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 14.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -188     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 27.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.61e+06 |\n",
      "|    total_cost         | 6.79e+04 |\n",
      "|    total_reward       | 2.61e+06 |\n",
      "|    total_reward_pct   | 261      |\n",
      "|    total_trades       | 47810    |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0376  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 15.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.877    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -28      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.22     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 117       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 252       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 25.1      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.81      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -116     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.54     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-04-06 to  2020-07-07\n",
      "A2C Sharpe Ratio:  -0.16728198729166327\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_1008_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 122  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 16   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.23e+06    |\n",
      "|    total_cost           | 3.19e+05    |\n",
      "|    total_reward         | 1.23e+06    |\n",
      "|    total_reward_pct     | 123         |\n",
      "|    total_trades         | 74170       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019321483 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0272     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.1         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.91e+06    |\n",
      "|    total_cost           | 3.13e+05    |\n",
      "|    total_reward         | 9.12e+05    |\n",
      "|    total_reward_pct     | 91.2        |\n",
      "|    total_trades         | 73737       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012498153 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0123     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2580, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2321110.51\n",
      "total_reward: 1321110.51\n",
      "total_cost: 313537.00\n",
      "total_trades: 74054\n",
      "Sharpe: 0.602\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.32e+06    |\n",
      "|    total_cost           | 3.14e+05    |\n",
      "|    total_reward         | 1.32e+06    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 74054       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019777214 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.012      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020449685 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0045     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.26e+06    |\n",
      "|    total_cost           | 3.07e+05    |\n",
      "|    total_reward         | 1.26e+06    |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 73408       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017509133 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00282     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.39        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.74e+06     |\n",
      "|    total_cost           | 2.88e+05     |\n",
      "|    total_reward         | 7.4e+05      |\n",
      "|    total_reward_pct     | 74           |\n",
      "|    total_trades         | 72185        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 120          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 118          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080063045 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.9        |\n",
      "|    explained_variance   | -0.0401      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0254      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.49e+06    |\n",
      "|    total_cost           | 2.97e+05    |\n",
      "|    total_reward         | 1.49e+06    |\n",
      "|    total_reward_pct     | 149         |\n",
      "|    total_trades         | 73076       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013779605 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.00187     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.19e+06   |\n",
      "|    total_cost           | 2.96e+05   |\n",
      "|    total_reward         | 1.19e+06   |\n",
      "|    total_reward_pct     | 119        |\n",
      "|    total_trades         | 72785      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 120        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 152        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02696483 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | -0.00497   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.7       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0178    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 42.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 120        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 169        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02416934 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | -0.017     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.1       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0228    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 29.5       |\n",
      "----------------------------------------\n",
      "day: 2580, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1905292.67\n",
      "total_reward: 905292.67\n",
      "total_cost: 301489.04\n",
      "total_trades: 73229\n",
      "Sharpe: 0.473\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.91e+06    |\n",
      "|    total_cost           | 3.01e+05    |\n",
      "|    total_reward         | 9.05e+05    |\n",
      "|    total_reward_pct     | 90.5        |\n",
      "|    total_trades         | 73229       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020545162 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0486     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.59        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.67e+06    |\n",
      "|    total_cost           | 2.88e+05    |\n",
      "|    total_reward         | 6.66e+05    |\n",
      "|    total_reward_pct     | 66.6        |\n",
      "|    total_trades         | 71739       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023899654 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0325      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.37        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.22e+06    |\n",
      "|    total_cost           | 3.03e+05    |\n",
      "|    total_reward         | 1.22e+06    |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 73204       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015246676 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0996      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.78        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.73e+06    |\n",
      "|    total_cost           | 2.96e+05    |\n",
      "|    total_reward         | 7.31e+05    |\n",
      "|    total_reward_pct     | 73.1        |\n",
      "|    total_trades         | 72774       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012432579 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00737     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 119        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 256        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02701512 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.0669     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.3       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.019     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 27.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.82e+06    |\n",
      "|    total_cost           | 2.94e+05    |\n",
      "|    total_reward         | 8.22e+05    |\n",
      "|    total_reward_pct     | 82.2        |\n",
      "|    total_trades         | 72199       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025617719 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0567      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.08        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "day: 2580, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1336536.37\n",
      "total_reward: 336536.37\n",
      "total_cost: 279153.95\n",
      "total_trades: 70831\n",
      "Sharpe: 0.252\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.34e+06     |\n",
      "|    total_cost           | 2.79e+05     |\n",
      "|    total_reward         | 3.37e+05     |\n",
      "|    total_reward_pct     | 33.7         |\n",
      "|    total_trades         | 70831        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 119          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 290          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146512855 |\n",
      "|    clip_fraction        | 0.206        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.3        |\n",
      "|    explained_variance   | 0.0422       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.56         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0203      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.53e+06    |\n",
      "|    total_cost           | 2.87e+05    |\n",
      "|    total_reward         | 5.32e+05    |\n",
      "|    total_reward_pct     | 53.2        |\n",
      "|    total_trades         | 71646       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021079803 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.85        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.39e+06    |\n",
      "|    total_cost           | 2.87e+05    |\n",
      "|    total_reward         | 3.94e+05    |\n",
      "|    total_reward_pct     | 39.4        |\n",
      "|    total_trades         | 71455       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016960816 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0987      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018282855 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0822      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.31        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.46e+06   |\n",
      "|    total_cost           | 3.04e+05   |\n",
      "|    total_reward         | 1.46e+06   |\n",
      "|    total_reward_pct     | 146        |\n",
      "|    total_trades         | 73041      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 119        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 358        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02757305 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | -0.046     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.98       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.018     |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 20.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.57e+06    |\n",
      "|    total_cost           | 2.86e+05    |\n",
      "|    total_reward         | 5.72e+05    |\n",
      "|    total_reward_pct     | 57.2        |\n",
      "|    total_trades         | 71155       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 377         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038977057 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0228      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.54        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "day: 2580, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1846293.36\n",
      "total_reward: 846293.36\n",
      "total_cost: 296970.74\n",
      "total_trades: 72072\n",
      "Sharpe: 0.455\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.85e+06    |\n",
      "|    total_cost           | 2.97e+05    |\n",
      "|    total_reward         | 8.46e+05    |\n",
      "|    total_reward_pct     | 84.6        |\n",
      "|    total_trades         | 72072       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024771916 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.82        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.58e+06   |\n",
      "|    total_cost           | 3.01e+05   |\n",
      "|    total_reward         | 5.78e+05   |\n",
      "|    total_reward_pct     | 57.8       |\n",
      "|    total_trades         | 72037      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 118        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 413        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02784478 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.105      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.05       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0171    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 21         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 431         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014708275 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0489      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.2e+06    |\n",
      "|    total_cost           | 2.69e+05   |\n",
      "|    total_reward         | 1.99e+05   |\n",
      "|    total_reward_pct     | 19.9       |\n",
      "|    total_trades         | 69838      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 118        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 449        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04720969 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0373     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.72       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 10.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.28e+06    |\n",
      "|    total_cost           | 2.91e+05    |\n",
      "|    total_reward         | 1.28e+06    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 71550       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 467         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014862705 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.82        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.44e+06  |\n",
      "|    total_cost           | 2.82e+05  |\n",
      "|    total_reward         | 4.37e+05  |\n",
      "|    total_reward_pct     | 43.7      |\n",
      "|    total_trades         | 70908     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 117       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 486       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0254968 |\n",
      "|    clip_fraction        | 0.312     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.8     |\n",
      "|    explained_variance   | 0.0583    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 5.53      |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -0.0096   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 28.3      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2580, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1028053.59\n",
      "total_reward: 28053.59\n",
      "total_cost: 243713.97\n",
      "total_trades: 68142\n",
      "Sharpe: 0.104\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.03e+06   |\n",
      "|    total_cost           | 2.44e+05   |\n",
      "|    total_reward         | 2.81e+04   |\n",
      "|    total_reward_pct     | 2.81       |\n",
      "|    total_trades         | 68142      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 118        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 503        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02470377 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.0885     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.4       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 17.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 117        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 520        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03046941 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.209      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.98       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 21.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.12e+06    |\n",
      "|    total_cost           | 2.55e+05    |\n",
      "|    total_reward         | 1.16e+05    |\n",
      "|    total_reward_pct     | 11.6        |\n",
      "|    total_trades         | 68477       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 539         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044796303 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.56        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 9.56        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.3e+05    |\n",
      "|    total_cost           | 2.38e+05   |\n",
      "|    total_reward         | -6.99e+04  |\n",
      "|    total_reward_pct     | -6.99      |\n",
      "|    total_trades         | 67287      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 117        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 558        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02361771 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.316      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.1        |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 20.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.51e+06    |\n",
      "|    total_cost           | 2.7e+05     |\n",
      "|    total_reward         | 5.15e+05    |\n",
      "|    total_reward_pct     | 51.5        |\n",
      "|    total_trades         | 70222       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021104759 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.93        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 117        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 592        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03150113 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.323      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.1       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 28.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.67e+05    |\n",
      "|    total_cost           | 2e+05       |\n",
      "|    total_reward         | -1.33e+05   |\n",
      "|    total_reward_pct     | -13.3       |\n",
      "|    total_trades         | 64745       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015177986 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.13        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "day: 2580, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 862181.14\n",
      "total_reward: -137818.86\n",
      "total_cost: 178037.60\n",
      "total_trades: 62245\n",
      "Sharpe: 0.025\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.62e+05   |\n",
      "|    total_cost           | 1.78e+05   |\n",
      "|    total_reward         | -1.38e+05  |\n",
      "|    total_reward_pct     | -13.8      |\n",
      "|    total_trades         | 62245      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 117        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 629        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02892326 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.478      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.48       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.00435   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 17.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.85e+05    |\n",
      "|    total_cost           | 2.17e+05    |\n",
      "|    total_reward         | -1.15e+05   |\n",
      "|    total_reward_pct     | -11.5       |\n",
      "|    total_trades         | 65299       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 647         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023204125 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.23        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0085     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.66e+05    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | -3.44e+04   |\n",
      "|    total_reward_pct     | -3.44       |\n",
      "|    total_trades         | 64684       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 664         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018520232 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 682         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030679572 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.42e+06    |\n",
      "|    total_cost           | 2.63e+05    |\n",
      "|    total_reward         | 4.24e+05    |\n",
      "|    total_reward_pct     | 42.4        |\n",
      "|    total_trades         | 69052       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 701         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030384155 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.7         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.75e+06    |\n",
      "|    total_cost           | 2.71e+05    |\n",
      "|    total_reward         | 7.49e+05    |\n",
      "|    total_reward_pct     | 74.9        |\n",
      "|    total_trades         | 70060       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 720         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037995454 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.82        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "day: 2580, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2128677.37\n",
      "total_reward: 1128677.37\n",
      "total_cost: 276642.22\n",
      "total_trades: 70239\n",
      "Sharpe: 0.514\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.13e+06   |\n",
      "|    total_cost           | 2.77e+05   |\n",
      "|    total_reward         | 1.13e+06   |\n",
      "|    total_reward_pct     | 113        |\n",
      "|    total_trades         | 70239      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 737        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04403051 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.0685     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.59       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 29.1       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.82e+06  |\n",
      "|    total_cost           | 2.85e+05  |\n",
      "|    total_reward         | 8.23e+05  |\n",
      "|    total_reward_pct     | 82.3      |\n",
      "|    total_trades         | 71125     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 116       |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 754       |\n",
      "|    total_timesteps      | 88064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0533984 |\n",
      "|    clip_fraction        | 0.397     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.5     |\n",
      "|    explained_variance   | -0.0421   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 17.2      |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | -0.00977  |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 32.6      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 773         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038815476 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.53        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.52e+06   |\n",
      "|    total_cost           | 2.69e+05   |\n",
      "|    total_reward         | 1.52e+06   |\n",
      "|    total_reward_pct     | 152        |\n",
      "|    total_trades         | 69573      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 792        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05848536 |\n",
      "|    clip_fraction        | 0.403      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | -0.0621    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.9       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 21.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.24e+06    |\n",
      "|    total_cost           | 2.75e+05    |\n",
      "|    total_reward         | 1.24e+06    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 69799       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 810         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036038905 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | -0.0975     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.75        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.12e+06    |\n",
      "|    total_cost           | 2.63e+05    |\n",
      "|    total_reward         | 2.12e+06    |\n",
      "|    total_reward_pct     | 212         |\n",
      "|    total_trades         | 68847       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 827         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025704302 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "day: 2580, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3183801.60\n",
      "total_reward: 2183801.60\n",
      "total_cost: 254374.31\n",
      "total_trades: 68117\n",
      "Sharpe: 0.712\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.18e+06    |\n",
      "|    total_cost           | 2.54e+05    |\n",
      "|    total_reward         | 2.18e+06    |\n",
      "|    total_reward_pct     | 218         |\n",
      "|    total_trades         | 68117       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 845         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029963663 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.00728     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 60.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 863         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031140992 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | -0.0341     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-04-06 to  2020-07-07\n",
      "PPO Sharpe Ratio:  -0.198378101980262\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1008_4\n",
      "day: 2580, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2096457.99\n",
      "total_reward: 1096457.99\n",
      "total_cost: 1311.30\n",
      "total_trades: 46442\n",
      "Sharpe: 0.489\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.1e+06  |\n",
      "|    total_cost       | 1.31e+03 |\n",
      "|    total_reward     | 1.1e+06  |\n",
      "|    total_reward_pct | 110      |\n",
      "|    total_trades     | 46442    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total timesteps  | 10324    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 46.5     |\n",
      "|    critic_loss      | 190      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7743     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-04-06 to  2020-07-07\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-07-07\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_1008_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00819 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -9.66    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.445    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.00133 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -6.11    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0645   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -41.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -5.96e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -48.4     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 4.82      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 9.85e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -21.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.9e+06  |\n",
      "|    total_cost         | 2.14e+05 |\n",
      "|    total_reward       | 2.9e+06  |\n",
      "|    total_reward_pct   | 290      |\n",
      "|    total_trades       | 66043    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -1.42    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -69.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.37     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -64.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 92.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.293   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 3.05     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.592    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -137     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.66e+06 |\n",
      "|    total_cost         | 8.84e+04 |\n",
      "|    total_reward       | 1.66e+06 |\n",
      "|    total_reward_pct   | 166      |\n",
      "|    total_trades       | 51882    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.247    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -64      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -1.09    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -11.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.829    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.026    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 152      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0368  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -130     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 15       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0308   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 92.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.52e+06 |\n",
      "|    total_cost         | 1.79e+05 |\n",
      "|    total_reward       | 4.52e+06 |\n",
      "|    total_reward_pct   | 452      |\n",
      "|    total_trades       | 62391    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0474  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 47.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.189    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -2.11    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0344  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 34.3     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.155    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -436     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 140      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -0.00198  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | -1.73e+03 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.08e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.92e+06 |\n",
      "|    total_cost         | 1.57e+05 |\n",
      "|    total_reward       | 1.92e+06 |\n",
      "|    total_reward_pct   | 192      |\n",
      "|    total_trades       | 62143    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 90.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.00095  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -69.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0608   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -605     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 241      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -89.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -125     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 26.9     |\n",
      "------------------------------------\n",
      "day: 2643, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5405204.79\n",
      "total_reward: 4405204.79\n",
      "total_cost: 65770.96\n",
      "total_trades: 54110\n",
      "Sharpe: 0.881\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.41e+06 |\n",
      "|    total_cost         | 6.58e+04 |\n",
      "|    total_reward       | 4.41e+06 |\n",
      "|    total_reward_pct   | 441      |\n",
      "|    total_trades       | 54110    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0163   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 73.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -16.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -47.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -44.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 156      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 16.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.04e+06  |\n",
      "|    total_cost         | 3.01e+04  |\n",
      "|    total_reward       | 4.04e+06  |\n",
      "|    total_reward_pct   | 404       |\n",
      "|    total_trades       | 47124     |\n",
      "| time/                 |           |\n",
      "|    fps                | 115       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 103       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.94      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.00883 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 47.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 45.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.31     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -222     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 35.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -355     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 87.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00223 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 288      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 235      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.86e+06  |\n",
      "|    total_cost         | 2.77e+04  |\n",
      "|    total_reward       | 4.86e+06  |\n",
      "|    total_reward_pct   | 486       |\n",
      "|    total_trades       | 44988     |\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.31e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 18        |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.417     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -26.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.444    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.227   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.648    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.99     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 307       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 85.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.94e+06 |\n",
      "|    total_cost         | 1.58e+04 |\n",
      "|    total_reward       | 3.94e+06 |\n",
      "|    total_reward_pct   | 394      |\n",
      "|    total_trades       | 42021    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -94.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0118   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 38.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -90.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.73     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 200       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 101       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.18      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 204       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 145       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 20.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.24e+06  |\n",
      "|    total_cost         | 8.37e+03  |\n",
      "|    total_reward       | 5.24e+06  |\n",
      "|    total_reward_pct   | 524       |\n",
      "|    total_trades       | 41126     |\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 208       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 33.4      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.622     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 213       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -134      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 12.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 70.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -5.51    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.02     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 115       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 226       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 33.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.53      |\n",
      "-------------------------------------\n",
      "day: 2643, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5093730.52\n",
      "total_reward: 4093730.52\n",
      "total_cost: 9830.22\n",
      "total_trades: 41963\n",
      "Sharpe: 0.892\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.09e+06 |\n",
      "|    total_cost         | 9.83e+03 |\n",
      "|    total_reward       | 4.09e+06 |\n",
      "|    total_reward_pct   | 409      |\n",
      "|    total_trades       | 41963    |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.162    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -15.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.196    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 115       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 234       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 70.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.94      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -118     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 30.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -133     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 59       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 115       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 251       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -7.15e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -1.12e+03 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 812       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.71e+06  |\n",
      "|    total_cost         | 3.02e+04  |\n",
      "|    total_reward       | 2.71e+06  |\n",
      "|    total_reward_pct   | 271       |\n",
      "|    total_trades       | 43890     |\n",
      "| time/                 |           |\n",
      "|    fps                | 115       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 256       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -291      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 55.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0966   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -75      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.57     |\n",
      "------------------------------------\n",
      "======Trading from:  2020-07-07 to  2020-10-05\n",
      "============================================\n",
      "28.36177978445478\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2020-07-07\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_1071_4\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.398   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -46.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.7      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.018   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 59.2     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -33      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -0.000251 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 109       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 21.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -188     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 23.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.85e+06 |\n",
      "|    total_cost         | 1.49e+05 |\n",
      "|    total_reward       | 1.85e+06 |\n",
      "|    total_reward_pct   | 185      |\n",
      "|    total_trades       | 57257    |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0846  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -22.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -1.03    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 8.06     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.325    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 15.7      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.837     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 29.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.716    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -108     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.82e+06 |\n",
      "|    total_cost         | 1.01e+05 |\n",
      "|    total_reward       | 8.19e+05 |\n",
      "|    total_reward_pct   | 81.9     |\n",
      "|    total_trades       | 52793    |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.237    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -29.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.478    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.265   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -1.37    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.396    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0957   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 107      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -53      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.48e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -40.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.36     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.05e+06 |\n",
      "|    total_cost         | 4.8e+04  |\n",
      "|    total_reward       | 1.05e+06 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 44362    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.324   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -14.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.248    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -23.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.992    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 17.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.676    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 35.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -4.72    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -531     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 238      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+06 |\n",
      "|    total_cost         | 1.85e+04 |\n",
      "|    total_reward       | 8.01e+04 |\n",
      "|    total_reward_pct   | 8.01     |\n",
      "|    total_trades       | 39273    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0513   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 84.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 41.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0744   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -556     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 193      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -131     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -319     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 62.5     |\n",
      "------------------------------------\n",
      "day: 2643, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1330798.34\n",
      "total_reward: 330798.34\n",
      "total_cost: 8008.42\n",
      "total_trades: 42508\n",
      "Sharpe: 0.234\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.33e+06 |\n",
      "|    total_cost         | 8.01e+03 |\n",
      "|    total_reward       | 3.31e+05 |\n",
      "|    total_reward_pct   | 33.1     |\n",
      "|    total_trades       | 42508    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 8.37e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 50.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -29.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.945    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -113     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.46     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -80.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 113      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.55e+06 |\n",
      "|    total_cost         | 6.28e+03 |\n",
      "|    total_reward       | 5.47e+05 |\n",
      "|    total_reward_pct   | 54.7     |\n",
      "|    total_trades       | 45982    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.146   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 78.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0151   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 55.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.88     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -4.05e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -11.3     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.33      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -272     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 37.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -291     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 57.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -33.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 48.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.88e+06 |\n",
      "|    total_cost         | 6.2e+03  |\n",
      "|    total_reward       | 8.77e+05 |\n",
      "|    total_reward_pct   | 87.7     |\n",
      "|    total_trades       | 46051    |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 19.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.372    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -16.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.259    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -32.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.948    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 31       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -26.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.35e+06 |\n",
      "|    total_cost         | 4.5e+03  |\n",
      "|    total_reward       | 1.35e+06 |\n",
      "|    total_reward_pct   | 135      |\n",
      "|    total_trades       | 46989    |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -64.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.88     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -19.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.443    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.00604  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -104     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.0232  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 9.78     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.431    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 121      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.84e+06  |\n",
      "|    total_cost         | 6.13e+03  |\n",
      "|    total_reward       | 1.84e+06  |\n",
      "|    total_reward_pct   | 184       |\n",
      "|    total_trades       | 49101     |\n",
      "| time/                 |           |\n",
      "|    fps                | 115       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 208       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -6.93e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 0.212     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.115     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -70.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 107      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.82     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 115       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 221       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 7.2       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.801     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -11      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.45     |\n",
      "------------------------------------\n",
      "day: 2643, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4008975.56\n",
      "total_reward: 3008975.56\n",
      "total_cost: 7303.81\n",
      "total_trades: 45818\n",
      "Sharpe: 0.741\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.01e+06 |\n",
      "|    total_cost         | 7.3e+03  |\n",
      "|    total_reward       | 3.01e+06 |\n",
      "|    total_reward_pct   | 301      |\n",
      "|    total_trades       | 45818    |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.314   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 4.53     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0971   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 31       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -133     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 91.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.81     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 115       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 247       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -132      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 61.4      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.00343  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -1.9e+03 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.25e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.67e+06 |\n",
      "|    total_cost         | 7.83e+03 |\n",
      "|    total_reward       | 3.67e+06 |\n",
      "|    total_reward_pct   | 367      |\n",
      "|    total_trades       | 46704    |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -207     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 26       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.069    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -102     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.9      |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-07-07 to  2020-10-05\n",
      "A2C Sharpe Ratio:  0.0019436457347181565\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_1071_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 121  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 16   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.9e+06     |\n",
      "|    total_cost           | 3.39e+05    |\n",
      "|    total_reward         | 1.9e+06     |\n",
      "|    total_reward_pct     | 190         |\n",
      "|    total_trades         | 76295       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015096094 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00203    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.53        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.35e+06    |\n",
      "|    total_cost           | 3.25e+05    |\n",
      "|    total_reward         | 1.35e+06    |\n",
      "|    total_reward_pct     | 135         |\n",
      "|    total_trades         | 75684       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012218343 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00636     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "day: 2643, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2625298.24\n",
      "total_reward: 1625298.24\n",
      "total_cost: 316853.46\n",
      "total_trades: 75107\n",
      "Sharpe: 0.615\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.63e+06    |\n",
      "|    total_cost           | 3.17e+05    |\n",
      "|    total_reward         | 1.63e+06    |\n",
      "|    total_reward_pct     | 163         |\n",
      "|    total_trades         | 75107       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020363435 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00898     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.52        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 118       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0165428 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -42.8     |\n",
      "|    explained_variance   | -0.0169   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 15.4      |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.0237   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 28.3      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.86e+06   |\n",
      "|    total_cost           | 3.2e+05    |\n",
      "|    total_reward         | 1.86e+06   |\n",
      "|    total_reward_pct     | 186        |\n",
      "|    total_trades         | 75436      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 118        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 103        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02087543 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | 0.0233     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.83       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0273    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 12.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+06    |\n",
      "|    total_cost           | 3.1e+05     |\n",
      "|    total_reward         | 1.45e+06    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 74670       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013618002 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00576     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.14e+06  |\n",
      "|    total_cost           | 2.94e+05  |\n",
      "|    total_reward         | 1.14e+06  |\n",
      "|    total_reward_pct     | 114       |\n",
      "|    total_trades         | 73682     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 118       |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 138       |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0194292 |\n",
      "|    clip_fraction        | 0.286     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -42.9     |\n",
      "|    explained_variance   | 0.0168    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 8.49      |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -0.0175   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 23.9      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 118          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112617165 |\n",
      "|    clip_fraction        | 0.238        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43          |\n",
      "|    explained_variance   | 0.00344      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0238      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.13e+06    |\n",
      "|    total_cost           | 3.13e+05    |\n",
      "|    total_reward         | 1.13e+06    |\n",
      "|    total_reward_pct     | 113         |\n",
      "|    total_trades         | 74376       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019129453 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0286      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.42        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "day: 2643, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3196207.54\n",
      "total_reward: 2196207.54\n",
      "total_cost: 316004.18\n",
      "total_trades: 74705\n",
      "Sharpe: 0.726\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.2e+06     |\n",
      "|    total_cost           | 3.16e+05    |\n",
      "|    total_reward         | 2.2e+06     |\n",
      "|    total_reward_pct     | 220         |\n",
      "|    total_trades         | 74705       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035556372 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0211     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.93        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.76e+06    |\n",
      "|    total_cost           | 3.17e+05    |\n",
      "|    total_reward         | 1.76e+06    |\n",
      "|    total_reward_pct     | 176         |\n",
      "|    total_trades         | 74413       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029930197 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0235      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.6e+06     |\n",
      "|    total_cost           | 2.94e+05    |\n",
      "|    total_reward         | 1.6e+06     |\n",
      "|    total_reward_pct     | 160         |\n",
      "|    total_trades         | 72972       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026544867 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0231      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022503005 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.7e+06    |\n",
      "|    total_cost           | 3.11e+05   |\n",
      "|    total_reward         | 1.7e+06    |\n",
      "|    total_reward_pct     | 170        |\n",
      "|    total_trades         | 74012      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 118        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 259        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02789142 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.00106    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.5        |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0196    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 8.76       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.1e+06    |\n",
      "|    total_cost           | 3.04e+05   |\n",
      "|    total_reward         | 3.1e+06    |\n",
      "|    total_reward_pct     | 310        |\n",
      "|    total_trades         | 73610      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 118        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02311364 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0153     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.3       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 33.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2643, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2947465.08\n",
      "total_reward: 1947465.08\n",
      "total_cost: 311035.18\n",
      "total_trades: 73755\n",
      "Sharpe: 0.698\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.95e+06    |\n",
      "|    total_cost           | 3.11e+05    |\n",
      "|    total_reward         | 1.95e+06    |\n",
      "|    total_reward_pct     | 195         |\n",
      "|    total_trades         | 73755       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019097833 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.00374    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042484894 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0191     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.79e+06   |\n",
      "|    total_cost           | 2.98e+05   |\n",
      "|    total_reward         | 1.79e+06   |\n",
      "|    total_reward_pct     | 179        |\n",
      "|    total_trades         | 72813      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 118        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 328        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03793321 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0115     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.3        |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 15.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+06    |\n",
      "|    total_cost           | 2.85e+05    |\n",
      "|    total_reward         | 1.19e+06    |\n",
      "|    total_reward_pct     | 119         |\n",
      "|    total_trades         | 71964       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024946833 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.00326     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.89e+06    |\n",
      "|    total_cost           | 2.99e+05    |\n",
      "|    total_reward         | 1.89e+06    |\n",
      "|    total_reward_pct     | 189         |\n",
      "|    total_trades         | 73094       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030484084 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | -0.00297    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 2.77e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 71511       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 381         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025013937 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.00263     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025651613 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.26        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "day: 2643, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1690409.83\n",
      "total_reward: 690409.83\n",
      "total_cost: 282426.08\n",
      "total_trades: 71845\n",
      "Sharpe: 0.375\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.69e+06    |\n",
      "|    total_cost           | 2.82e+05    |\n",
      "|    total_reward         | 6.9e+05     |\n",
      "|    total_reward_pct     | 69          |\n",
      "|    total_trades         | 71845       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029090032 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.35        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.71        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.56e+06    |\n",
      "|    total_cost           | 2.82e+05    |\n",
      "|    total_reward         | 1.56e+06    |\n",
      "|    total_reward_pct     | 156         |\n",
      "|    total_trades         | 71497       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036462214 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | -0.0042     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.06        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+06    |\n",
      "|    total_cost           | 2.9e+05     |\n",
      "|    total_reward         | 1.04e+06    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 71348       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041144993 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.00457     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.8         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 467         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039034307 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | -0.00645    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.59        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+06    |\n",
      "|    total_cost           | 2.87e+05    |\n",
      "|    total_reward         | 1.19e+06    |\n",
      "|    total_reward_pct     | 119         |\n",
      "|    total_trades         | 71124       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 487         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020881379 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | -0.000769   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.24        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.98e+06    |\n",
      "|    total_cost           | 2.73e+05    |\n",
      "|    total_reward         | 9.77e+05    |\n",
      "|    total_reward_pct     | 97.7        |\n",
      "|    total_trades         | 70451       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 504         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026190726 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0121      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.42        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "day: 2643, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1941025.48\n",
      "total_reward: 941025.48\n",
      "total_cost: 281655.68\n",
      "total_trades: 70856\n",
      "Sharpe: 0.446\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.94e+06   |\n",
      "|    total_cost           | 2.82e+05   |\n",
      "|    total_reward         | 9.41e+05   |\n",
      "|    total_reward_pct     | 94.1       |\n",
      "|    total_trades         | 70856      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 117        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 521        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03431274 |\n",
      "|    clip_fraction        | 0.257      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.0256     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.2       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 24.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 2.78e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 70847       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 538         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043807693 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0031      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 556         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031728946 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0234      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.06e+06   |\n",
      "|    total_cost           | 2.48e+05   |\n",
      "|    total_reward         | 1.06e+06   |\n",
      "|    total_reward_pct     | 106        |\n",
      "|    total_trades         | 69217      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 117        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 573        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03842952 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0041     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.27       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 8.1        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.83e+06    |\n",
      "|    total_cost           | 2.64e+05    |\n",
      "|    total_reward         | 8.27e+05    |\n",
      "|    total_reward_pct     | 82.7        |\n",
      "|    total_trades         | 70146       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 590         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013138076 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0314      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.31        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.13e+06   |\n",
      "|    total_cost           | 2.51e+05   |\n",
      "|    total_reward         | 1.13e+06   |\n",
      "|    total_reward_pct     | 113        |\n",
      "|    total_trades         | 69205      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 117        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 608        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02427116 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.0287     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.9       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 23.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 625         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037073486 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0139      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "day: 2643, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2065252.97\n",
      "total_reward: 1065252.97\n",
      "total_cost: 246869.83\n",
      "total_trades: 69271\n",
      "Sharpe: 0.493\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.07e+06    |\n",
      "|    total_cost           | 2.47e+05    |\n",
      "|    total_reward         | 1.07e+06    |\n",
      "|    total_reward_pct     | 107         |\n",
      "|    total_trades         | 69271       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 642         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028260808 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0513      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.21        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.9e+06     |\n",
      "|    total_cost           | 2.53e+05    |\n",
      "|    total_reward         | 1.9e+06     |\n",
      "|    total_reward_pct     | 190         |\n",
      "|    total_trades         | 69363       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 659         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020315614 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.028       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.71        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.13e+06    |\n",
      "|    total_cost           | 2.65e+05    |\n",
      "|    total_reward         | 2.13e+06    |\n",
      "|    total_reward_pct     | 213         |\n",
      "|    total_trades         | 70637       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 677         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026001265 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.00932     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 695         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033044264 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.94e+06    |\n",
      "|    total_cost           | 2.43e+05    |\n",
      "|    total_reward         | 1.94e+06    |\n",
      "|    total_reward_pct     | 194         |\n",
      "|    total_trades         | 69282       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 715         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016340824 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.025       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.16e+06   |\n",
      "|    total_cost           | 2.27e+05   |\n",
      "|    total_reward         | 2.16e+06   |\n",
      "|    total_reward_pct     | 216        |\n",
      "|    total_trades         | 67786      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 117        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 733        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03384023 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.123      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.26       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 12.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2643, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3174852.13\n",
      "total_reward: 2174852.13\n",
      "total_cost: 245327.26\n",
      "total_trades: 69202\n",
      "Sharpe: 0.657\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.17e+06    |\n",
      "|    total_cost           | 2.45e+05    |\n",
      "|    total_reward         | 2.17e+06    |\n",
      "|    total_reward_pct     | 217         |\n",
      "|    total_trades         | 69202       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 750         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018496163 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0691      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 53          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.83e+06    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 1.83e+06    |\n",
      "|    total_reward_pct     | 183         |\n",
      "|    total_trades         | 67923       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 769         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026905397 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0218      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 67.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 787         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027596088 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0384      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00655    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.24e+06   |\n",
      "|    total_cost           | 2.19e+05   |\n",
      "|    total_reward         | 2.24e+06   |\n",
      "|    total_reward_pct     | 224        |\n",
      "|    total_trades         | 66863      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 806        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03283888 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.2      |\n",
      "|    explained_variance   | 0.0456     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.1       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.00565   |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 20         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.78e+06  |\n",
      "|    total_cost           | 2.17e+05  |\n",
      "|    total_reward         | 1.78e+06  |\n",
      "|    total_reward_pct     | 178       |\n",
      "|    total_trades         | 66722     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 116       |\n",
      "|    iterations           | 47        |\n",
      "|    time_elapsed         | 824       |\n",
      "|    total_timesteps      | 96256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0400075 |\n",
      "|    clip_fraction        | 0.251     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -45.2     |\n",
      "|    explained_variance   | 0.0716    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 36.9      |\n",
      "|    n_updates            | 460       |\n",
      "|    policy_gradient_loss | -0.00656  |\n",
      "|    std                  | 1.09      |\n",
      "|    value_loss           | 56.5      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.98e+06    |\n",
      "|    total_cost           | 2.19e+05    |\n",
      "|    total_reward         | 1.98e+06    |\n",
      "|    total_reward_pct     | 198         |\n",
      "|    total_trades         | 67304       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 841         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012724303 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0318      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 860         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024067549 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0369      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.5        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 76.8        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-07-07 to  2020-10-05\n",
      "PPO Sharpe Ratio:  0.00916241907938114\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1071_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.04e+06 |\n",
      "|    total_cost       | 2.5e+03  |\n",
      "|    total_reward     | 3.04e+06 |\n",
      "|    total_reward_pct | 304      |\n",
      "|    total_trades     | 42465    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total timesteps  | 10576    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -38.6    |\n",
      "|    critic_loss      | 23.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7932     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-07-07 to  2020-10-05\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-10-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_1071_2\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.24e+06 |\n",
      "|    total_cost       | 1.24e+03 |\n",
      "|    total_reward     | 2.24e+06 |\n",
      "|    total_reward_pct | 224      |\n",
      "|    total_trades     | 35289    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total timesteps  | 10828    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 27.3     |\n",
      "|    critic_loss      | 35       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8121     |\n",
      "----------------------------------\n",
      "======Trading from:  2020-10-05 to  2021-01-05\n",
      "============================================\n",
      "14.697780459408165\n",
      "turbulence_threshold:  299.0428503713953\n",
      "======Model training from:  2010-01-01 to  2020-10-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_1134_4\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.174   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -115     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.441   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -35.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.114   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -39.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -5.6e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 62.3     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.254    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -95.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.84e+06 |\n",
      "|    total_cost         | 2.33e+05 |\n",
      "|    total_reward       | 8.43e+05 |\n",
      "|    total_reward_pct   | 84.3     |\n",
      "|    total_trades       | 68405    |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00617 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -77.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0807   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -91.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.036   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 133      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.129    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 56.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 66.1     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.31e+06 |\n",
      "|    total_cost         | 1.43e+05 |\n",
      "|    total_reward       | 2.31e+06 |\n",
      "|    total_reward_pct   | 231      |\n",
      "|    total_trades       | 60806    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.129    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -106     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0636   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -35.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.878    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 94.3     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 26.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 218      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 34.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 649       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 230       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.28e+06 |\n",
      "|    total_cost         | 5.4e+04  |\n",
      "|    total_reward       | 1.28e+06 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 48256    |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -8.82    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -111     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 21.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 16.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 313      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 80.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.06e+06 |\n",
      "|    total_cost         | 4.08e+04 |\n",
      "|    total_reward       | 1.06e+06 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 47201    |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 85.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.155    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -5.92    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.184    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.551    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 36.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.68      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -73.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.74     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 39.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.36     |\n",
      "------------------------------------\n",
      "day: 2706, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1329150.97\n",
      "total_reward: 329150.97\n",
      "total_cost: 14125.39\n",
      "total_trades: 39148\n",
      "Sharpe: 0.231\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.33e+06 |\n",
      "|    total_cost         | 1.41e+04 |\n",
      "|    total_reward       | 3.29e+05 |\n",
      "|    total_reward_pct   | 32.9     |\n",
      "|    total_trades       | 39148    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 132      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 2.16      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.109     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -33.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 71.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0508  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 93.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.76e+06 |\n",
      "|    total_cost         | 2.84e+04 |\n",
      "|    total_reward       | 7.56e+05 |\n",
      "|    total_reward_pct   | 75.6     |\n",
      "|    total_trades       | 42189    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 28.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 19.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0662   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 149      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 17.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 47.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.0032   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -130     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.95e+06 |\n",
      "|    total_cost         | 1.33e+05 |\n",
      "|    total_reward       | 9.49e+05 |\n",
      "|    total_reward_pct   | 94.9     |\n",
      "|    total_trades       | 55640    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.147    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 37.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -5.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -79.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.117    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 38       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.93     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.0523   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -25.7    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.02     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 185       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -2.54e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -143      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 11.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.00461 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 44       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.18e+06 |\n",
      "|    total_cost         | 1.01e+05 |\n",
      "|    total_reward       | 1.18e+06 |\n",
      "|    total_reward_pct   | 118      |\n",
      "|    total_trades       | 55165    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.0426   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -58.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.233    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 23.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 25       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 89.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 111      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.18e+06 |\n",
      "|    total_cost         | 1.58e+04 |\n",
      "|    total_reward       | 1.83e+05 |\n",
      "|    total_reward_pct   | 18.3     |\n",
      "|    total_trades       | 41271    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 78.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -4.51    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 33.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.619    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -57.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 42.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -0.59    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.9      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2706, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1885588.36\n",
      "total_reward: 885588.36\n",
      "total_cost: 23401.73\n",
      "total_trades: 44637\n",
      "Sharpe: 0.394\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 2.34e+04 |\n",
      "|    total_reward       | 8.86e+05 |\n",
      "|    total_reward_pct   | 88.6     |\n",
      "|    total_trades       | 44637    |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -116     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 9.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 14.4     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 92.1     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 35.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 97       |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 5.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 75.5     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 4.88     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.24e+06  |\n",
      "|    total_cost         | 4.51e+04  |\n",
      "|    total_reward       | 2.4e+05   |\n",
      "|    total_reward_pct   | 24        |\n",
      "|    total_trades       | 46144     |\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 265       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -1.18     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.379     |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2020-10-05 to  2021-01-05\n",
      "A2C Sharpe Ratio:  0.10563656201244269\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_1134_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 119  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 17   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.41e+06     |\n",
      "|    total_cost           | 3.46e+05     |\n",
      "|    total_reward         | 1.41e+06     |\n",
      "|    total_reward_pct     | 141          |\n",
      "|    total_trades         | 78251        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 117          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066343322 |\n",
      "|    clip_fraction        | 0.217        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.0136      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.1          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0283      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 9.56         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.29e+06    |\n",
      "|    total_cost           | 3.45e+05    |\n",
      "|    total_reward         | 2.29e+06    |\n",
      "|    total_reward_pct     | 229         |\n",
      "|    total_trades         | 78009       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015507702 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.01       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.89        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "day: 2706, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2970744.97\n",
      "total_reward: 1970744.97\n",
      "total_cost: 333559.26\n",
      "total_trades: 77282\n",
      "Sharpe: 0.686\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.97e+06    |\n",
      "|    total_cost           | 3.34e+05    |\n",
      "|    total_reward         | 1.97e+06    |\n",
      "|    total_reward_pct     | 197         |\n",
      "|    total_trades         | 77282       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020427007 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00307    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 88         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01712592 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | 0.000228   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.2       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 36         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.24e+06    |\n",
      "|    total_cost           | 3.35e+05    |\n",
      "|    total_reward         | 1.24e+06    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 77218       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015650475 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00583     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.59        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.55e+06    |\n",
      "|    total_cost           | 3.33e+05    |\n",
      "|    total_reward         | 1.55e+06    |\n",
      "|    total_reward_pct     | 155         |\n",
      "|    total_trades         | 77077       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021043314 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00763    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+06    |\n",
      "|    total_cost           | 3.21e+05    |\n",
      "|    total_reward         | 1.61e+06    |\n",
      "|    total_reward_pct     | 161         |\n",
      "|    total_trades         | 75996       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016444582 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00753    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012577593 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.00607     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.74e+06    |\n",
      "|    total_cost           | 3.2e+05     |\n",
      "|    total_reward         | 1.74e+06    |\n",
      "|    total_reward_pct     | 174         |\n",
      "|    total_trades         | 75893       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023400793 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0181     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.45        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.87        |\n",
      "-----------------------------------------\n",
      "day: 2706, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2523464.63\n",
      "total_reward: 1523464.63\n",
      "total_cost: 306412.91\n",
      "total_trades: 75131\n",
      "Sharpe: 0.609\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.52e+06     |\n",
      "|    total_cost           | 3.06e+05     |\n",
      "|    total_reward         | 1.52e+06     |\n",
      "|    total_reward_pct     | 152          |\n",
      "|    total_trades         | 75131        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 116          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115026925 |\n",
      "|    clip_fraction        | 0.203        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.1        |\n",
      "|    explained_variance   | 0.00649      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.9          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.69e+06    |\n",
      "|    total_cost           | 3.14e+05    |\n",
      "|    total_reward         | 2.69e+06    |\n",
      "|    total_reward_pct     | 269         |\n",
      "|    total_trades         | 75697       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025604611 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0378      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021946806 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.00511    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.13e+06    |\n",
      "|    total_cost           | 3.23e+05    |\n",
      "|    total_reward         | 2.13e+06    |\n",
      "|    total_reward_pct     | 213         |\n",
      "|    total_trades         | 75672       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018661624 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -5.48e-05   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.25        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.88e+06    |\n",
      "|    total_cost           | 3.25e+05    |\n",
      "|    total_reward         | 1.88e+06    |\n",
      "|    total_reward_pct     | 188         |\n",
      "|    total_trades         | 76166       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010124149 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0185      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.56e+06    |\n",
      "|    total_cost           | 3.24e+05    |\n",
      "|    total_reward         | 3.56e+06    |\n",
      "|    total_reward_pct     | 356         |\n",
      "|    total_trades         | 75511       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022051053 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0234      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 300        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02424571 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0109     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.6       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 68.6       |\n",
      "----------------------------------------\n",
      "day: 2706, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3215380.32\n",
      "total_reward: 2215380.32\n",
      "total_cost: 307104.27\n",
      "total_trades: 74725\n",
      "Sharpe: 0.743\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.22e+06    |\n",
      "|    total_cost           | 3.07e+05    |\n",
      "|    total_reward         | 2.22e+06    |\n",
      "|    total_reward_pct     | 222         |\n",
      "|    total_trades         | 74725       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025561916 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | -0.0112     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.82        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.47e+06    |\n",
      "|    total_cost           | 3.14e+05    |\n",
      "|    total_reward         | 2.47e+06    |\n",
      "|    total_reward_pct     | 247         |\n",
      "|    total_trades         | 74967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033364564 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0291      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.5e+06     |\n",
      "|    total_cost           | 2.98e+05    |\n",
      "|    total_reward         | 2.5e+06     |\n",
      "|    total_reward_pct     | 250         |\n",
      "|    total_trades         | 74176       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 353         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019002704 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0125      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 370        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02169405 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0221     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.5       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 56.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.55e+06    |\n",
      "|    total_cost           | 3.02e+05    |\n",
      "|    total_reward         | 1.55e+06    |\n",
      "|    total_reward_pct     | 155         |\n",
      "|    total_trades         | 74427       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 388         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026373075 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0416      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.84        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.31e+06    |\n",
      "|    total_cost           | 2.99e+05    |\n",
      "|    total_reward         | 2.31e+06    |\n",
      "|    total_reward_pct     | 231         |\n",
      "|    total_trades         | 74590       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 406         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030791562 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0488      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.96        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2706, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2909325.28\n",
      "total_reward: 1909325.28\n",
      "total_cost: 302467.06\n",
      "total_trades: 74803\n",
      "Sharpe: 0.629\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.91e+06    |\n",
      "|    total_cost           | 3.02e+05    |\n",
      "|    total_reward         | 1.91e+06    |\n",
      "|    total_reward_pct     | 191         |\n",
      "|    total_trades         | 74803       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 424         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021081395 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.00847    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 56          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 441        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03710249 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.012      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 44.3       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 48.1       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.37e+06  |\n",
      "|    total_cost           | 3.1e+05   |\n",
      "|    total_reward         | 2.37e+06  |\n",
      "|    total_reward_pct     | 237       |\n",
      "|    total_trades         | 75588     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 115       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 459       |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0325166 |\n",
      "|    clip_fraction        | 0.258     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.9     |\n",
      "|    explained_variance   | 0.0476    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 7.96      |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -0.0208   |\n",
      "|    std                  | 1.05      |\n",
      "|    value_loss           | 16        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.56e+06    |\n",
      "|    total_cost           | 2.86e+05    |\n",
      "|    total_reward         | 1.56e+06    |\n",
      "|    total_reward_pct     | 156         |\n",
      "|    total_trades         | 73740       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 476         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029284315 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0316      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.59e+06   |\n",
      "|    total_cost           | 2.93e+05   |\n",
      "|    total_reward         | 2.59e+06   |\n",
      "|    total_reward_pct     | 259        |\n",
      "|    total_trades         | 73777      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 494        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03635167 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.00768    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.9       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 48.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 512         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032791793 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0487      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 53          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.46e+06    |\n",
      "|    total_cost           | 2.87e+05    |\n",
      "|    total_reward         | 1.46e+06    |\n",
      "|    total_reward_pct     | 146         |\n",
      "|    total_trades         | 73252       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 530         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028336907 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0582      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "day: 2706, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3364220.13\n",
      "total_reward: 2364220.13\n",
      "total_cost: 309557.22\n",
      "total_trades: 74356\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.36e+06    |\n",
      "|    total_cost           | 3.1e+05     |\n",
      "|    total_reward         | 2.36e+06    |\n",
      "|    total_reward_pct     | 236         |\n",
      "|    total_trades         | 74356       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 547         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048138563 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0827      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.26        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.43e+06   |\n",
      "|    total_cost           | 3.19e+05   |\n",
      "|    total_reward         | 1.43e+06   |\n",
      "|    total_reward_pct     | 143        |\n",
      "|    total_trades         | 75688      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 565        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02687687 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0354     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 45.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 583         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038908765 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | -0.00484    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.97e+06    |\n",
      "|    total_cost           | 3.16e+05    |\n",
      "|    total_reward         | 1.97e+06    |\n",
      "|    total_reward_pct     | 197         |\n",
      "|    total_trades         | 75181       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 601         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021316646 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0305      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.64        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.46e+06    |\n",
      "|    total_cost           | 2.96e+05    |\n",
      "|    total_reward         | 1.46e+06    |\n",
      "|    total_reward_pct     | 146         |\n",
      "|    total_trades         | 74025       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 618         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026913008 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.69        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 8.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.09e+06    |\n",
      "|    total_cost           | 3.08e+05    |\n",
      "|    total_reward         | 1.09e+06    |\n",
      "|    total_reward_pct     | 109         |\n",
      "|    total_trades         | 74821       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 636         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024162559 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0422      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.03        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028828103 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 67          |\n",
      "-----------------------------------------\n",
      "day: 2706, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2417844.33\n",
      "total_reward: 1417844.33\n",
      "total_cost: 287606.29\n",
      "total_trades: 73449\n",
      "Sharpe: 0.509\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.42e+06   |\n",
      "|    total_cost           | 2.88e+05   |\n",
      "|    total_reward         | 1.42e+06   |\n",
      "|    total_reward_pct     | 142        |\n",
      "|    total_trades         | 73449      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 671        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02607889 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | -0.0121    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 49.2       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 74.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.91e+06    |\n",
      "|    total_cost           | 2.76e+05    |\n",
      "|    total_reward         | 1.91e+06    |\n",
      "|    total_reward_pct     | 191         |\n",
      "|    total_trades         | 72484       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 689         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037855566 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.71        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 9.18        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.65e+06   |\n",
      "|    total_cost           | 2.53e+05   |\n",
      "|    total_reward         | 1.65e+06   |\n",
      "|    total_reward_pct     | 165        |\n",
      "|    total_trades         | 71049      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 706        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03135223 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.0859     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.8       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 33.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+06     |\n",
      "|    total_cost           | 2.49e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 70631       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 724         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022804288 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020959243 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0267      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.62e+06    |\n",
      "|    total_cost           | 2.88e+05    |\n",
      "|    total_reward         | 6.23e+05    |\n",
      "|    total_reward_pct     | 62.3        |\n",
      "|    total_trades         | 72968       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 759         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027400611 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | -0.00324    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.25        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 7.08        |\n",
      "-----------------------------------------\n",
      "day: 2706, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2071196.27\n",
      "total_reward: 1071196.27\n",
      "total_cost: 289140.51\n",
      "total_trades: 73063\n",
      "Sharpe: 0.455\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.07e+06    |\n",
      "|    total_cost           | 2.89e+05    |\n",
      "|    total_reward         | 1.07e+06    |\n",
      "|    total_reward_pct     | 107         |\n",
      "|    total_trades         | 73063       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 776         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030959846 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.44        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.14e+06    |\n",
      "|    total_cost           | 2.33e+05    |\n",
      "|    total_reward         | 1.14e+06    |\n",
      "|    total_reward_pct     | 114         |\n",
      "|    total_trades         | 68966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 794         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026129926 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0319      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 812        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02875458 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.0659     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.3       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 27.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.61e+06    |\n",
      "|    total_cost           | 2.41e+05    |\n",
      "|    total_reward         | 6.12e+05    |\n",
      "|    total_reward_pct     | 61.2        |\n",
      "|    total_trades         | 69224       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 829         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051326543 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | -0.065      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.79        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.29e+06    |\n",
      "|    total_cost           | 2.58e+05    |\n",
      "|    total_reward         | 1.29e+06    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 69877       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 847         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034943834 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.0146      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.09e+06    |\n",
      "|    total_cost           | 2.71e+05    |\n",
      "|    total_reward         | 1.09e+06    |\n",
      "|    total_reward_pct     | 109         |\n",
      "|    total_trades         | 71170       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 864         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021510111 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0631      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-10-05 to  2021-01-05\n",
      "PPO Sharpe Ratio:  0.22842674345206093\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1134_4\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.67e+06 |\n",
      "|    total_cost       | 1.42e+03 |\n",
      "|    total_reward     | 1.67e+06 |\n",
      "|    total_reward_pct | 167      |\n",
      "|    total_trades     | 37943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total timesteps  | 10828    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 26.1     |\n",
      "|    critic_loss      | 21.9     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8121     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-10-05 to  2021-01-05\n",
      "======Best Model Retraining from:  2010-01-01 to  2021-01-05\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_1134_3\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.63e+06 |\n",
      "|    total_cost       | 1.95e+03 |\n",
      "|    total_reward     | 2.63e+06 |\n",
      "|    total_reward_pct | 263      |\n",
      "|    total_trades     | 43542    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total timesteps  | 11080    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -7.41    |\n",
      "|    critic_loss      | 73.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8310     |\n",
      "----------------------------------\n",
      "======Trading from:  2021-01-05 to  2021-04-07\n",
      "Ensemble Strategy took:  446.87563578685126  minutes\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 PPO_model_kwargs,\n",
    "                                                 DDPG_model_kwargs,\n",
    "                                                 timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "-0qd8acMtj1f",
    "outputId": "34e407ec-0b6e-42fb-e707-0c577a79dc74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.735761</td>\n",
       "      <td>0.59481</td>\n",
       "      <td>0.397033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.107594</td>\n",
       "      <td>0.39815</td>\n",
       "      <td>0.39407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.309295</td>\n",
       "      <td>0.269538</td>\n",
       "      <td>0.165761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.029303</td>\n",
       "      <td>-0.125072</td>\n",
       "      <td>0.046839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.700024</td>\n",
       "      <td>0.664932</td>\n",
       "      <td>0.57463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.071683</td>\n",
       "      <td>-0.137901</td>\n",
       "      <td>-0.044055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.191516</td>\n",
       "      <td>-0.059147</td>\n",
       "      <td>0.036422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.254124</td>\n",
       "      <td>0.386318</td>\n",
       "      <td>0.516751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.299421</td>\n",
       "      <td>-0.259072</td>\n",
       "      <td>-0.151925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>693</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.542263</td>\n",
       "      <td>0.381019</td>\n",
       "      <td>0.461829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>756</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.136088</td>\n",
       "      <td>0.152411</td>\n",
       "      <td>0.122548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>819</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.006453</td>\n",
       "      <td>-0.18197</td>\n",
       "      <td>-0.061043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>882</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.366854</td>\n",
       "      <td>0.43434</td>\n",
       "      <td>0.046679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>945</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.436472</td>\n",
       "      <td>-0.434775</td>\n",
       "      <td>-0.387983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1008</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.167282</td>\n",
       "      <td>-0.198378</td>\n",
       "      <td>-0.255342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1071</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.009162</td>\n",
       "      <td>0.124014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1134</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.105637</td>\n",
       "      <td>0.228427</td>\n",
       "      <td>0.277085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0    126  2016-10-03  2017-01-03        A2C   0.735761    0.59481    0.397033\n",
       "1    189  2017-01-03  2017-04-04        PPO   0.107594    0.39815     0.39407\n",
       "2    252  2017-04-04  2017-07-05        A2C   0.309295   0.269538    0.165761\n",
       "3    315  2017-07-05  2017-10-03       DDPG   0.029303  -0.125072    0.046839\n",
       "4    378  2017-10-03  2018-01-03        A2C   0.700024   0.664932     0.57463\n",
       "5    441  2018-01-03  2018-04-05       DDPG  -0.071683  -0.137901   -0.044055\n",
       "6    504  2018-04-05  2018-07-05       DDPG  -0.191516  -0.059147    0.036422\n",
       "7    567  2018-07-05  2018-10-03       DDPG   0.254124   0.386318    0.516751\n",
       "8    630  2018-10-03  2019-01-04       DDPG  -0.299421  -0.259072   -0.151925\n",
       "9    693  2019-01-04  2019-04-05        A2C   0.542263   0.381019    0.461829\n",
       "10   756  2019-04-05  2019-07-08        PPO   0.136088   0.152411    0.122548\n",
       "11   819  2019-07-08  2019-10-04        A2C  -0.006453   -0.18197   -0.061043\n",
       "12   882  2019-10-04  2020-01-06        PPO   0.366854    0.43434    0.046679\n",
       "13   945  2020-01-06  2020-04-06       DDPG  -0.436472  -0.434775   -0.387983\n",
       "14  1008  2020-04-06  2020-07-07        A2C  -0.167282  -0.198378   -0.255342\n",
       "15  1071  2020-07-07  2020-10-05       DDPG   0.001944   0.009162    0.124014\n",
       "16  1134  2020-10-05  2021-01-05       DDPG   0.105637   0.228427    0.277085"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "X4JKB--8tj1g"
   },
   "outputs": [],
   "source": [
    "unique_trade_date = processed_full[(processed_full.date > val_test_start)&(processed_full.date <= val_test_end)].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "q9mKF7GGtj1g",
    "outputId": "5de4e5e6-d74b-4d12-b786-7e299dabd6a5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  0.638680121204779\n"
     ]
    }
   ],
   "source": [
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "oyosyW7_tj1g",
    "outputId": "29307dfb-1d27-4fb7-dc7a-7a34a4902d59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.999796e+05</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>2017-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.978065e+05</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.932461e+05</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>-0.004570</td>\n",
       "      <td>2017-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.905973e+05</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>-0.002667</td>\n",
       "      <td>2017-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1.509944e+06</td>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>-0.004485</td>\n",
       "      <td>2021-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>1.506310e+06</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>-0.002406</td>\n",
       "      <td>2021-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>1.511841e+06</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>2021-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1.531096e+06</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>0.012736</td>\n",
       "      <td>2021-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1.529126e+06</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>-0.001286</td>\n",
       "      <td>2021-04-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1071 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      account_value        date  daily_return    datadate\n",
       "0      1.000000e+06  2016-01-04           NaN  2017-01-03\n",
       "1      9.999796e+05  2016-01-05     -0.000020  2017-01-04\n",
       "2      9.978065e+05  2016-01-06     -0.002173  2017-01-05\n",
       "3      9.932461e+05  2016-01-07     -0.004570  2017-01-06\n",
       "4      9.905973e+05  2016-01-08     -0.002667  2017-01-09\n",
       "...             ...         ...           ...         ...\n",
       "1066   1.509944e+06  2021-03-30     -0.004485  2021-03-30\n",
       "1067   1.506310e+06  2021-03-31     -0.002406  2021-03-31\n",
       "1068   1.511841e+06  2021-04-01      0.003672  2021-04-01\n",
       "1069   1.531096e+06  2021-04-05      0.012736  2021-04-05\n",
       "1070   1.529126e+06  2021-04-06     -0.001286  2021-04-06\n",
       "\n",
       "[1071 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_account_value.set_index('date').account_value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "1053083a-d74c-48b0-a623-de33282e2fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.105092\n",
      "Cumulative returns     0.529126\n",
      "Annual volatility      0.184847\n",
      "Sharpe ratio           0.638680\n",
      "Calmar ratio           0.434061\n",
      "Stability              0.554263\n",
      "Max drawdown          -0.242113\n",
      "Omega ratio            1.152888\n",
      "Sortino ratio          0.797683\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.039143\n",
      "Daily value at risk   -0.022820\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.999796e+05</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>2017-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.978065e+05</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.932461e+05</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>-0.004570</td>\n",
       "      <td>2017-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.905973e+05</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>-0.002667</td>\n",
       "      <td>2017-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1.509944e+06</td>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>-0.004485</td>\n",
       "      <td>2021-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>1.506310e+06</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>-0.002406</td>\n",
       "      <td>2021-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>1.511841e+06</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>2021-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1.531096e+06</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>0.012736</td>\n",
       "      <td>2021-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1.529126e+06</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>-0.001286</td>\n",
       "      <td>2021-04-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1071 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      account_value        date  daily_return    datadate\n",
       "0      1.000000e+06  2016-01-04           NaN  2017-01-03\n",
       "1      9.999796e+05  2016-01-05     -0.000020  2017-01-04\n",
       "2      9.978065e+05  2016-01-06     -0.002173  2017-01-05\n",
       "3      9.932461e+05  2016-01-07     -0.004570  2017-01-06\n",
       "4      9.905973e+05  2016-01-08     -0.002667  2017-01-09\n",
       "...             ...         ...           ...         ...\n",
       "1066   1.509944e+06  2021-03-30     -0.004485  2021-03-30\n",
       "1067   1.506310e+06  2021-03-31     -0.002406  2021-03-31\n",
       "1068   1.511841e+06  2021-04-01      0.003672  2021-04-01\n",
       "1069   1.531096e+06  2021-04-05      0.012736  2021-04-05\n",
       "1070   1.529126e+06  2021-04-06     -0.001286  2021-04-06\n",
       "\n",
       "[1071 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-04-06'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.loc[len(df_account_value)-1,'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lKRGftSS7pNM",
    "outputId": "4f77cef2-3934-444a-cacc-4ed8f94514ae",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (1322, 8)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: DatetimeIndex(['2019-04-05 00:00:00+00:00', '2019-04-08 00:00:00+00:00',\\n               '2019-04-09 00:00:00+00:00', '2019-04-10 00:00:00+00:00',\\n               '2019-04-11 00:00:00+00:00',\\n               ...\\n               '2020-03-30 00:00:00+00:00', '2020-03-31 00:00:00+00:00',\\n               '2020-04-01 00:00:00+00:00', '2020-04-02 00:00:00+00:00',\\n               '2020-04-03 00:00:00+00:00'],\\n              dtype='datetime64[ns, UTC]', name='date', length=252, freq=None). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a60e87739ae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==============Compare to DJIA===========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m backtest_plot(df_account_value, \n\u001b[0m\u001b[1;32m      4\u001b[0m              \u001b[0mbaseline_ticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'^DJI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0mbaseline_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2016-01-04'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FinRL/FinRL/finrl/trade/backtest.py\u001b[0m in \u001b[0;36mbacktest_plot\u001b[0;34m(account_value, baseline_start, baseline_end, baseline_ticker, value_col_name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mbaseline_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_daily_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_col_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"close\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpyfolio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         pyfolio.create_full_tear_sheet(\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mreturns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pyfolio/tears.py\u001b[0m in \u001b[0;36mcreate_full_tear_sheet\u001b[0;34m(returns, positions, transactions, market_data, benchmark_rets, slippage, live_start_date, sector_mappings, round_trips, estimate_intraday, hide_positions, cone_std, bootstrap, unadjusted_returns, turnover_denom, set_context, factor_returns, factor_loadings, pos_in_dollars, header_rows, factor_partitions)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                      positions, transactions)\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     create_returns_tear_sheet(\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mpositions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pyfolio/plotting.py\u001b[0m in \u001b[0;36mcall_w_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_w_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pyfolio/tears.py\u001b[0m in \u001b[0;36mcreate_returns_tear_sheet\u001b[0;34m(returns, positions, transactions, live_start_date, cone_std, benchmark_rets, bootstrap, turnover_denom, header_rows, return_fig)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbenchmark_rets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_returns_to_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     plotting.show_perf_stats(returns, benchmark_rets,\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pyfolio/utils.py\u001b[0m in \u001b[0;36mclip_returns_to_benchmark\u001b[0;34m(rets, benchmark_rets)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0mclipped_rets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mclipped_rets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;31m# handle the dup indexing case GH#4246\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1055\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_seq_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"display.width\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1322\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                     \u001b[0;34m\"is no longer supported. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: DatetimeIndex(['2019-04-05 00:00:00+00:00', '2019-04-08 00:00:00+00:00',\\n               '2019-04-09 00:00:00+00:00', '2019-04-10 00:00:00+00:00',\\n               '2019-04-11 00:00:00+00:00',\\n               ...\\n               '2020-03-30 00:00:00+00:00', '2020-03-31 00:00:00+00:00',\\n               '2020-04-01 00:00:00+00:00', '2020-04-02 00:00:00+00:00',\\n               '2020-04-03 00:00:00+00:00'],\\n              dtype='datetime64[ns, UTC]', name='date', length=252, freq=None). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
     ]
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlLT9_5WN478"
   },
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YktexHcqh1jc",
    "outputId": "38566531-a3a0-4705-db30-d437e8f8fc73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (1322, 8)\n",
      "Annual return          0.136321\n",
      "Cumulative returns     0.955059\n",
      "Annual volatility      0.198830\n",
      "Sharpe ratio           0.743460\n",
      "Calmar ratio           0.367579\n",
      "Stability              0.823306\n",
      "Max drawdown          -0.370862\n",
      "Omega ratio            1.175499\n",
      "Sortino ratio          1.025462\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.888069\n",
      "Daily value at risk   -0.024464\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "FinRL_ensemble_stock_trading_ICAIF_2020.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
